<?xml version="1.0" ?>
<rss version="2.0">
  <channel>
    <title>Ledge.ai Articles</title>
    <link>https://ledge.ai/</link>
    <description>Latest articles from Ledge.ai</description>
    <lastBuildDate>Thu, 24 Aug 2023 22:50:00 +0000</lastBuildDate>
    <item>
      <title>https://ledge.ai/articles/matsuo_lab_releases_llm_weblab</title>
      <link>https://ledge.ai/articles/matsuo_lab_releases_llm_weblab</link>
      <description/>
      <pubDate>Thu, 17 Aug 2023 01:30:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/gartner-hype-cycle_2023</title>
      <link>https://ledge.ai/articles/gartner-hype-cycle_2023</link>
      <description>米国のワシントン大学、カーネギーメロン大学（CMU）、中国の西安交通大学などの研究者が2023年5月15日に発表した[論文](https:\u002F\u002Faclanthology.org\u002F2023.acl-long.656.pdf){target=“_blank”}によると、対話型AI（チャットボット）「ChatGPT」などが採用する既存の大規模言語モデル（LLM）はそれぞれ異なる政治的なバイアス（偏見）を持っている。\n\nLLMはインターネット上の大量のテキストを学習し、自然な文章を生成する。研究者らは14種類のLLMを対象に政治的にセンシティブな話題を質問し回答の傾向を分析した。\n\n論文では米国OpenAIの開発するChatGPTのLLMと「GPT-4」を区別して扱っているが、いずれも社会面では自由至上主義、経済面では左派の傾向を持つ。一方Metaの開発する「LLaMA」は社会面では権威主義で、経済面では右派の傾向を示した。\n\n訓練データの内容によってLLMの政治的バイアスが変わることも確認した。具体的には左派や右派のニュースメディアやソーシャルメディアのデータを用いてモデルを再訓練することで、該当する政治的傾向が強化できた。ただし「RoBERTa」や「GPT-2」といった世代の古いLLMでの検証であることには注意が必要だ。\n\nLLMの政治的傾向は、ヘイトスピーチ（憎悪表現）や誤情報の検出にも影響を及ぼす。例えば左派寄りのバイアスを持つ学習モデルはLGBTQ+や黒人のような広く知られた少数派集団に対するヘイトスピーチの検出により良い性能を示す一方、右派寄りのバイアスを持つモデルは、男性や白人といった自認を持つ支配的な集団を対象としたヘイトスピーチの検出でより良い性能を示す傾向がある。\n\nこの研究は、今や多くの製品やサービスが採用しているLLMの持つ政治的想定やバイアスを理解することの重要性を示している。\n\n:::box\n[関連記事：ChatGPTの文章を「ファクトチェック」するツール「FacTool」 上海交通大やMetaなど開発](https:\u002F\u002Fledge.ai\u002Farticles\u002Ffactool_llm)\n:::\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Farticles\u002Fchatgpt)\n:::</description>
      <pubDate>Thu, 24 Aug 2023 22:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/llm_political_bias</title>
      <link>https://ledge.ai/articles/llm_political_bias</link>
      <description>:::small\n画像出典：Connected Shoppers Report\n:::\n\n\n世界各国で買い物客の約6人に1人が生成AIの回答を参考にしているとの調査結果を米国Salesforce（セールスフォース）が2023年8月18日に「[Connected Shoppers Report](https:\u002F\u002Fwww.salesforce.com\u002Fnews\u002Fstories\u002Ftrends-in-retail-2023\u002F){target=“_blank”}」第5版の中で明らかにした。この報告書では新型コロナウイルス感染症流行後の小売業界が新しい技術やデータをどのように活用し、顧客満足度を高めるかについての考察を行っている。\n\n生成AIは小売業界の変革を推進している。買い物客の17%の購入の参考として生成型AIを利用しているばかりか、まだ生成AIを積極的に利用していなくても、どんな贈り物をするか考えるのに役立てたり、家電の情報調べに活かしたりすることに関心を持っている。小売業者もマーケティングやカスタマーサービスにもこの技術の活用を検討している。\n\nとはいえ過去20年間に小売業で導入が進んださまざまなデジタル技術を例にとって考えれば、生成AIをめぐる動きは目新しいものという訳ではない。セールスフォースによると、インターネット通販は2021年には買い物全体の59%を占めるまでになり、2023年にはいったん51%に減少したものの、2025年には再び56%に増加するとの予測だ。小売業者はオンラインとオフラインの販路の統合基盤への投資を進めている。\n\nまた2023年時点では実店舗でも買い物客の60%がスマートフォンなどを利用している。インターネットで商品について調べたり（36%）、店内のQRコードを読み取ったり (32％)、さらに読み取った内容をもとに購入手続きを完了する「scan＆go（スキャンアンドゴー）」（18%）を行うためだ。小売業者も客の行動から着想を得て、店員にモバイル機器を装備させていて、2023年時点では推定32%が仕事の一部として使いこなしており、さらに2026年までに41%へ上昇する見込みだ。\n\nこうした既存のデジタル技術に続くように生成AIについても買い物客と店舗の双方に影響が広がったかたちだ。\n\nConnected Shoppers Report第5版の調査は2023年5月18日から6月21日の期間、買い物客2,400人と小売業の意思決定者1,125人に実施した。対象地域はオーストラリア、ベルギー、ブラジル、カナダ、デンマーク、フィンランド、フランス、ドイツ、インド、 日本、ルクセンブルク、オランダ、ニュージーランド、ノルウェー、スペイン、スウェーデン、英国、米国。\n\n:::box\n[関連記事：生成AI「活用方法わからず」営業・サービス担当者での導入率4割未満 – セールスフォース調査](https:\u002F\u002Fledge.ai\u002Farticles\u002Fsalesforce_ai_investigation)\n:::\n:::box\n[関連記事：セールスフォース、エンタープライズ向けAIを利用した製品群「AI Cloud」を発表](https:\u002F\u002Fledge.ai\u002Farticles\u002Fsalesforce_ai_cloud)\n:::\n\n\n</description>
      <pubDate>Thu, 24 Aug 2023 06:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/salesforce_connected_shoppers_report</title>
      <link>https://ledge.ai/articles/salesforce_connected_shoppers_report</link>
      <description>:::small\n画像出典：NVIDIA AI Workbench | Fine Tuning Generative AI\n:::\n\nパソコンやワークステーションから、公開中の事前学習済みモデルを利用して独自の生成AIを作成、試験、実行できるツールキットを米国NVIDIAが2023年8月8日に[発表](https:\u002F\u002Fwww.nvidia.com\u002Fja-jp\u002Fabout-nvidia\u002Fpress-releases\u002F2023\u002Fnvidia-ai-workbench-speeds-adoption-of-custom-generative-ai-for-worlds-enterprises\u002F){target=“_blank”}した。「AI Workbench」の名称で展開する。\n\n @[youtube](https:\u002F\u002Fyoutu.be\u002FntMRzPzSvM4)\n\nNVDIAによると、生成AIを開発する素材となる事前学習済みモデルはすでに何十万種類も利用可能だが、オープンソースのツールを駆使してそれらをカスタマイズするのは困難で時間がかかる場合がある。特に大規模な開発プロジェクトでは、モデルの設計図にあたるソースコードを公開している「GitHub」や「Hugging Face」といったオンラインリポジトリから目的に沿うフレームワーク、ツール、コンテナを探し、適切なスキルセットを採用してユースケースに合わせて組み合わせる必要がある。さらにプロジェクトをある環境から別の環境に移す際には作業を再度やり直さなければならないこともある。\n\nAI Workbenchを導入すれば、数回のクリックで生成AIをカスタマイズして実行可能。モデル、フレームワーク、SDK、ライブラリを統合した開発者ワークスペースにまとめられ、環境の移行も容易としている。\n\nこのツールはDell Technologies、Hewlett Packard Enterprise、HP、Lambda、Lenovo、SupermicroなどのマルチGPU対応デスクトップ ワークステーション、ハイエンドモバイル ワークステーション、仮想ワークステーションで利用できる。OSにWindowsまたはLinux を採用した「NVIDIA RTX」対応のパソコンでも動作する。また拡張の必要が生じた場合にはデータセンターやクラウドサービスも簡単に利用可能という。\n\nなお、NVIDIAはエンタープライズ ソフトウェア プラットフォームの最新版「NVIDIA AI Enterprise 4.0」も併せて発表した。企業が生成AI導入に必要なツールを入手でき、信頼性の高い運用に必要なセキュリティ機能や安定したAPIを利用できるとのこと。\n\n:::box\n[関連記事：エヌビディアとソフトバンク、次世代通信向けAIプラットフォーム構築へ](https:\u002F\u002Fledge.ai\u002Farticles\u002Fnvidia-softbank-ai-platform)\n:::\n:::box\n[関連記事：WPPとNVIDIA、広告制作に生成AI技術を導入](https:\u002F\u002Fledge.ai\u002Farticles\u002Fwpp-nvidia-omniverse)\n:::</description>
      <pubDate>Thu, 24 Aug 2023 05:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/nvidia_ai_workbench</title>
      <link>https://ledge.ai/articles/nvidia_ai_workbench</link>
      <description>デロイト トーマツ グループは2023年8月8日、世界各国のコンタクトセンターを対象に行った調査「2023 グローバルコンタクトセンターサーベイ」を公開した。日本ではすでに約半数が業務のためにAIを導入している一方、成果の面では課題があるとしている。\n\n日本のコンタクトセンターのAI導入率は49％で、海外の44％を上回る水準。2年前の前回調査では日本28％、海外21％であり、いずれも大幅に上昇していることがわかる。\n\nしかしAIの主要用途であるチャットボット・ボイスボットについてみると、十分な効果を発揮できていないという声も、日本のコンタクトセンターの約半数（51％）から挙がっている。\n\n![jp-crm-global-contact-center-survey-2023-japan_page-0010.jpg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fjp_crm_global_contact_center_survey_2023_japan_page_0010_9316c26f67\u002Fjp_crm_global_contact_center_survey_2023_japan_page_0010_9316c26f67.jpg)\n:::small\n画像の出典：2023 グローバルコンタクトセンターサーベイ日本版レポート\n:::\n\nデロイト トーマツ グループは、AIの導入は進めど成果が出ない背景として、解決率やカバー率が比較的高い用件、領域を対象に想定効果の高い順にユースケースを選定できていない点や、投資の膨張、予算超過を防ぐための定量的な重要業績評価指標（KPI）を設定、評価できていない点を挙げる。\n\n対策としてはAI導入に関するユースケース選定やKPI設定のほか、業務改革（BPR）、中核となる社内人材の育成と定着、企業のリーダー自身が社内組織横断での協力を推進する「チェンジマネジメント」などが重要だとも述べている。\n\n調査は2022年11月から2023年2月にかけて実施し、国内41社、海外46社から協力を得た。\n\n:::box\n[関連記事：対話型AI コンタクトセンター市場で着々と成長、Gartner分析](https:\u002F\u002Fledge.ai\u002Farticles\u002Fgartner_conversational_ai_capabilities_will_help)\n:::\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Farticles\u002Fchatgpt)\n:::</description>
      <pubDate>Thu, 24 Aug 2023 02:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/deloitte_global_contact_center_survey2023</title>
      <link>https://ledge.ai/articles/deloitte_global_contact_center_survey2023</link>
      <description>:::small\n画像の出典：Chaincode Labs\n:::\n暗号資産「Bitcoin（ビットコイン）」関連の技術開発を手がける米国Chaincode Labs は2023年8月3日、新たな対話型AI（チャットボット）「[ChatBTC](https:\u002F\u002Fchat.bitcoinsearch.xyz\u002F){target=“_blank”}」をリリースした。技術情報の「高品質な情報源」を使用して、主要なブロックチェーンに関する質問に答えてくれるという。\n\nOpenAIのチャットボット「ChatGPT」などは質問を受けた場合「Hallucination（ハルシネーション、幻覚）」と呼ばれる現象によって、虚偽を織り交ぜて回答してしまうことがある。一方でChaincode Labsによると、ChatBTCはChatGPTと同じように使用でき、なおかつハルシネーションを起こしにくい。\n\n![chtabtc_release.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fchtabtc_release_6932178747\u002Fchtabtc_release_6932178747.png)\n:::small\n出典：[Adam Jonas氏 X（旧Twitter）アカウント](https:\u002F\u002Ftwitter.com\u002Fadamcjonas\u002Fstatus\u002F1687184918030209024){target=“_blank”}より\n:::\n\nChatBTCは、ビットコインの技術やその歴史について学べるよう設計されている。AIの学習には、bitcoin-dev メーリングリスト、Lightning dev メーリングリスト、Bitcoin StackExchange、Bitcoin Optech、BTC Transcripts といった信頼性の高いデータを使用しているという。\n\nChatGPTのような見た目の操作画面を採用しており、質問したい内容を文章による指示「プロンプト」として入力すると対話形式で回答が受け取れる。標準設定では「Holocat（ホロキャット）」という仮想の猫の姿をしたキャラクターが一般的な質問に回答してくれるが、ほかにも3種類のビットコイン専門家のアバター（分身となるキャラクター）を選択でき、それぞれのアバターのもとになっている人物がかつて実際に発信した情報から回答を得られる。\n\n![chatbtc.jpg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fchatbtc_5dcacd9732\u002Fchatbtc_5dcacd9732.jpg)\n\nChatBTCはビットコインによる有料課金方式を採用している。試用として数回の質問ができるが、以降は支払いの要求画面があらわれる。プロンプト1回につき50Satoshi（サトシ、SAT）から、または6時間あたり500サトシといった料金体系だ。\n\nちなみにサトシはビットコインの最小単位で、ビットコインの基礎技術を築いた謎の人物Satoshi Nakamoto（サトシ・ナカモト）氏にちなんだ名称。2023年8月後半時点の相場で日本円に換算すると50サトシは2円未満だ。\n\nなおChatBTCはまだ初期のアルファ版だと Chaincode Labs の特別プロジェクト責任者 Adam Jonas氏はX（旧Twitter）上で断っている。すべての回答が100％正確というわけではなく、あたたかく見守って欲しいとし、フィードバックも求めている。\n\n![chtabtc_mercy.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fchtabtc_mercy_6fa29ba044\u002Fchtabtc_mercy_6fa29ba044.png)\n:::small\n出典：[Adam Jonas氏 X（旧Twitter）アカウント](https:\u002F\u002Ftwitter.com\u002Fadamcjonas\u002Fstatus\u002F1687184925873627136){target=“_blank”}より\n:::\n\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Farticles\u002Fchatgpt)\n:::\n:::box\n[関連記事：LLMの「幻覚」軽減のカギに？OpenAIが「プロセス監視」による新たなアプローチを発表](https:\u002F\u002Fledge.ai\u002Farticles\u002Fopenai_reserch_mathematical_reasoning_process_supervision)\n:::\n:::box\n[関連記事：Open AIアルトマン氏 生体認証によるデジタル通貨「ワールドコイン」本格稼働 虹彩スキャン装置「Orb」に長蛇の列](https:\u002F\u002Fledge.ai\u002Farticles\u002Fworld_coin_project)\n:::</description>
      <pubDate>Wed, 23 Aug 2023 23:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/chaincode_labs_chatbtc</title>
      <link>https://ledge.ai/articles/chaincode_labs_chatbtc</link>
      <description>:::small\n画像の出典：[UK Reserch and Innovation](https:\u002F\u002Fwww.ukri.org\u002Fnews\u002F13-million-for-22-ai-for-health-research-projects\u002F?utm_source=Twitter&amp;utm_medium=social&amp;utm_campaign=Orlo){target=“_blank”}\n:::\n欧州連合（EU）がAIの管理強化を打ち出すなか、英国ではリスクを軽減しながら利益も追求する姿勢を示している。米国、中国に次ぐ世界第3位のAIリーダーを自認する同国は2023年秋に開催を予定する国際会議「AI Safety Summit（AI安全サミット）」でAIのリスク軽減手法開発を主導する一方、AIの医療分野への応用に投資を行うと明らかにした。\n\n英国政府は8月10日、秋のAI安全サミットの準備のための専門家2人を任命したと[発表](https:\u002F\u002Fwww.gov.uk\u002Fgovernment\u002Fnews\u002Fexperts-to-lead-ai-safety-summit-preparations-as-new-funding-announced-to-modernise-healthcare){target=“_blank”}した。\n\n投資会社Entrepreneur Firstの最高経営責任者（CEO）で英国高等研究発明局（ARIA）非常勤代表でもあるMatt Clifford（マット・クリフォード）氏と、オックスフォード大学ブラバトニック公共政策大学院のヘイウッド・フェロー（客員研究員）であり、元英国G7およびG20シェルパ、国家安全保障担当首相副補佐官であるJonathan Black（ジョナサン・ブラック）氏だ。両氏は首相の名代としてAI安全サミットに参加し、AIのリスクを軽減する各国共通の手法開発が進むよう調整する。\n\nまた今回の発表に併せてMichelle Donelan（ミッシェル・ドネラン）技術大臣が最先端のAIで医療を革新するための研究に1,300万ポンド（約24億円）を拠出する方針だと述べた。腫瘍の除去のための半自動外科ロボット基盤から、個人の現在の状態を基に将来の健康問題の可能性を予測する方法まで、さまざまな分野が対象だ。\n\nなお英国政府は、国内のAI産業がすでに経済に37億ポンド（約6800億円）貢献し、5万人の雇用を生み出したとあらためて訴えた。AIのリスクについての国際的な話し合いの場を持つ一方、活用にも前向きな姿勢を強調したかたちだ。\n\n:::box\n[関連記事：イギリス、AIのリスク議論のため初の「AIサミット」を今秋開催予定](https:\u002F\u002Fledge.ai\u002Farticles\u002Fbritish_ai_summit)\n:::\n:::box\n[関連記事：EUのAI規制法案に警告「チャンスを妨げる可能性」大手企業など150社幹部が署名](https:\u002F\u002Fledge.ai\u002Farticles\u002Feuropean_firms_sign_open_letter)\n:::\n:::box\n[関連記事：AIサイバー攻撃 すでに国連PKOを標的に グテーレス事務総長 対策機関の設立求める](https:\u002F\u002Fledge.ai\u002Farticles\u002Fun_calls_for_establishment_of_ai_countermeasure_agency)\n:::</description>
      <pubDate>Wed, 23 Aug 2023 22:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/ai_safety_summit_experts_announced</title>
      <link>https://ledge.ai/articles/ai_safety_summit_experts_announced</link>
      <description>:::small\n画像出典：写真AC\n:::\n\nカナダ[BlackBerry](https:\u002F\u002Fblogs.blackberry.com\u002Fen\u002F2023\u002F08\u002Fwhy-companies-ban-chatgpt-ai){target=“_blank”}が2023年8月8日付で公表した調査によると、世界各国の組織の75%が、職場でのChatGPTやほかの生成AIの使用禁止を現在検討または実施中であることがわかった。\n\nさらに禁止を実施または検討している組織の多数（61%）は、これらの措置を長期的または恒久的に行うことを意図している。\n\n組織がChatGPTを禁止する主な理由として、データのセキュリティとプライバシーへの潜在的なリスクが最も大きく（67%）、次に企業の評判へのリスク（57%）が挙げられる。\n\nまた組織内のどのような地位にある人物が生成AIの使用禁止を推し進めているかを複数回答で訊くと、「最高情報責任者（CIO）／最高技術責任者（CTO）／最高セキュリティ責任者（CSO）／情報技術担当者（IT） 」が72%で最も多く、「最高経営責任者（CEO）」も48%にのぼった。以下「コンプライアンス担当者（Legal Compliance）」 （40%）、「最高財務責任者（CFO）／財務担当者（Finance）」 （36%）、「人事担当者（HR）」 （32%）と続く。\n\nまた全体の80％以上が、安全を確保できていないアプリケーションが自社のIT環境にサイバーセキュリティ上の脅威をもたらすと懸念している。\n\n一方、BlackBerryの調査に回答したIT意思決定者の多くは、生成AIが職場での生産性を向上させる可能性を認識しており、効率の向上（55%）、革新（52%）、創造性の向上（51%）などの利点を予見している。\n\nまたIT意思決定者の80%が、組織が「従業員がビジネス目的で使用するアプリケーション」を制御する権利を持っていると信じている一方で、74%が全面的な禁止は「過度なコントロール」の兆候を意味すると考えていることがわかった。\n\nこの調査は、米国、カナダ、英国、フランス、ドイツ、オランダ、日本、オーストラリアの2,000人のIT意思決定者を対象としたもの。\n\n:::box\n[関連記事：デジタルツインの導入に関する調査が公表　日本は調査対象10カ国の中では導入に遅れ](https:\u002F\u002Fledge.ai\u002Farticles\u002Fdegital_twin_tyosa)\n:::\n:::box\n[関連記事：生成AI「活用方法わからず」営業・サービス担当者での導入率4割未満 – セールスフォース調査](https:\u002F\u002Fledge.ai\u002Farticles\u002Fsalesforce_ai_investigation)\n:::\n\n</description>
      <pubDate>Wed, 23 Aug 2023 15:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/blackberry_reserch_chatgpt</title>
      <link>https://ledge.ai/articles/blackberry_reserch_chatgpt</link>
      <description>:::small\n画像出典：FacTool: Factuality Detection in Generative AI ? A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\n:::\n\n\n中国の上海交通大学やMeta AIなどに所属する研究者らは、AIが生成した文章の事実性を検証するための枠組み「FacTool」を開発し、論文「[FacTool: Factuality Detection in Generative AI ? A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios](https:\u002F\u002Farxiv.org\u002Fabs\u002F2307.13528v2){target=“_blank”}」で2023年7月25日に発表した。対話型AI（チャットボット）「ChatGPT」などの中核となっている大規模言語モデル（LLM）が生成した文章が事実誤認などを犯していないかを確かめられるという。\n\nLLMが生成した文章は人間にとって有用な情報源となる可能性があるが、能力には限界があり、しばしば不正確で、真実から逸脱した返答をする。したがって金融、保健、法律といった分野では用途に制限がかかっている。信頼性と有用性を向上させるには、誤りを体系的に特定することが重要だ。\n\nFacToolは、文章から事実かどうかの検証が必要な「主張（claim）」を抽出する機能、主張をもとに検証のための「質問（query）」を生成する機能、さまざまな外部ツールに質問を送る機能、外部ツールから検証のための「根拠（evidence）」を受け取る機能、そして集まった根拠をもとに実際の検証を行う機能、合わせて5つの部分で構成している。\n\nなお検証のために使うツールはGoogleの通常の検索エンジンをはじめ、学術論文探しに特化した「Google Scholar」や、プログラムを実行する各種のコードインタプリターなどだ。\n\n![スクリーンショット 2023-08-23 092103.jpg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002F2023_08_23_092103_8627a90794\u002F2023_08_23_092103_8627a90794.jpg)\n:::small\n画像出典：FacTool: Factuality Detection in Generative AI ? A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\n:::\n\n研究チームは、複数のLLMに知識ベースの質疑応答、プログラミングコードの生成、数学の問題解決、科学論文のレビュー執筆の4つの作業をさせ、それぞれについてFacToolで検証を行った。結果、ChatGPTが採用する米国OpenAIの最新LLM「GPT-4」がほかのモデルと比較して、事実精度が最も高いことが確認できた。一方で例えばオープンソースのチャットボット「Vicuna-13B（ビクーニャ）」のLLMは、知識ベースの質疑応答で良好な成績を示したものの、コード生成などほかの作業ではのタスク性能が低いことがわかった。\n\n:::box\n[関連記事：AIが書いた文章に「電子透かし」埋め込み 人間の文章と区別 米大学が手法開発](https:\u002F\u002Fledge.ai\u002Farticles\u002Fa_watermark_for_large_language_models)\n:::\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Farticles\u002Fchatgpt)\n:::</description>
      <pubDate>Wed, 23 Aug 2023 07:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/factool_llm</title>
      <link>https://ledge.ai/articles/factool_llm</link>
      <description>:::small\n画像出典：写真AC\n:::\n\n米国のGoogle Researchは、American Airline（アメリカン航空）やビル・ゲイツ氏の気候変動投資ファンドBreakthrough Energyと協力し、AIを活用した飛行機雲予測マップを開発したと2023年8月8に[発表](lhttps:\u002F\u002Fblog.google\u002Ftechnology\u002Fai\u002Fai-airlines-contrails-climate-change\u002F){target=“_blank”}した。このマップの目的は、地球温暖化に影響を与える飛行機雲の発生を回避する飛行経路を、パイロットが選択できるようにすることだ。\n\n2022年の気候変動に関する政府間パネル（[IPCC](https:\u002F\u002Fwww.ipcc.ch\u002Freport\u002Far6\u002Fwg3\u002Fdownloads\u002Freport\u002FIPCC_AR6_WGIII_Chapter10.pdf){target=“_blank”}）の報告によれば、航空機が放出するコントレイル（航跡雲）、つまり飛行機雲は航空による地球温暖化の影響の約35%を占めている。\n\n飛行機雲は航空機が湿気の層を通って飛行する際に生まれ、大気の状態に応じて巻雲として数分から数時間持続する。日中には太陽光を反射して宇宙に戻す一方、夜間には地球の大気が放出する大量の熱を閉じ込めるため、差し引きでは温暖化効果をもたらしている。\n\nこの問題に対応するため、Google Researchは衛星画像、天気、飛行経路のデータを組み合わせ、AIを使用して飛行機雲の予測マップを開発した。その結果、パイロットは飛行機雲を作らない飛行経路を選択できることがわかった。\n\nアメリカン航空のパイロットはBreakthrough Energyのコントレイルモデルと相互参照するGoogle ResearchのAI予測を使用して、6か月間で70回のテスト飛行を実施した。結果、パイロットは飛行機雲を54%減少させることができた。しかし飛行機雲が生まれるのを避けるためのフライトは、2%の追加燃料を消費することも確認した。それでも少数のフライトを調整するだけで、飛行機雲による温暖化の大部分を避けることが可能となる。\n\n今後は飛行機雲の発生回避を自動化するほか、特に影響の大きな飛行機雲を標的に据え、衛星による検証作業を改善する方針。\n\n:::box\n[関連記事：Google DeepMind ロボット動かすAI「RT-2」 ネットの知識活かし臨機応変に動作](https:\u002F\u002Fledge.ai\u002Farticles\u002Fgoogle_deepmind_rt2)\n:::\n:::box\n[関連記事：ファーウェイの気象予報AI「Pnangu-Weather」科学誌Natureに掲載 – 台風の予測速度を1万倍に向上](https:\u002F\u002Fledge.ai\u002Farticles\u002Fpnangu_weather_nature)\n:::\n\n</description>
      <pubDate>Wed, 23 Aug 2023 06:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/google_reserch_american_airlines_breakthrough_energy</title>
      <link>https://ledge.ai/articles/google_reserch_american_airlines_breakthrough_energy</link>
      <description>:::small\n[UnsplashのShayna Douglas](https:\u002F\u002Funsplash.com\u002Fja\u002F%E5%86%99%E7%9C%9F\u002FTQV8qkwuEzA?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText){target=“_blank”}が撮影した写真   \n:::\n米国時間の2023年8月10日、動画アプリケーション「TikTok」を開発する中国ByteDanceの研究者らが、大規模言語モデル（LLM）の整合性と信頼性に関する論文を[発表](https:\u002F\u002Fhuggingface.co\u002Fpapers\u002F2308.05374){target=“_blank”}した。LLMから容易に著作権で保護された書籍の内容を引き出せたことに触れ、さらに波紋を広げるような分析も示している。\n\n論文では著作権問題の代表としてまず、米国OpenAIとMetaのLLMがコメディアンSarah Silverman氏の書籍の内容を流出させたとして訴訟になった件を取り上げている。Silverman氏がLLMに自著の要約を依頼して発覚したもので、実際にLLMの訓練データは書籍の海賊版を含んでいたという。\n\nByteDanceの研究者らはこの問題に関して検証した結果も報告している。 人気作家J. K. Rowling氏のベストセラー『ハリー・ポッターと賢者の石』の冒頭を、文章による指示すなわち「プロンプト」として使用し、続きをOpenAIが開発した世代の古いLLM「GPT-3」に生成させるという試みだ。\n\n![2308.05374_pages-to-jpg-0020.jpg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002F2308_05374_pages_to_jpg_0020_e358560c4f\u002F2308_05374_pages_to_jpg_0020_e358560c4f.jpg)\n:::small\n「ハリー・ポッターと賢者の石」の冒頭箇所をプロンプトが書くと、GPT３がその続きを答える\n:::\n\nもちろんGPT-3の回答した文章は著作権で保護されているものだった。LLMの訓練データがSilverman氏の著書ばかりかRowling氏の長編シリーズを含んでいた可能性をうかがわせる。\n\n問題への対策として、論文では著作権で保護された情報の抽出を目的とした悪意あるプロンプトを検出する方法や、電子透かしなどを活かして学習モデルでの著作権データの使用を追跡する方法を提案。先行例としてOpenAIが導入した次のような仕組みを紹介している。\n\nLLM「GPT」シリーズで構築した対話型AI（チャットボット）として知られる「ChatGPT」は最近、前述のようなプロンプトを使用して著作権で保護された情報を抽出しようとすると回答を中断するようになったという。以前は見られなかった挙動で、開発者が新たな仕組みを導入した結果だろうと、ByteDanceの研究者らは推測し、表向きは肯定的な評価を与えている。\n\nただ論文のこのくだりについては、額面通りに受け取るべきかどうか判断の難しい部分もある。\n\nなるほどChatGPTが導入したとみられる仕組みは、プロンプトが著作権で保護された情報の抽出を目的としたものかどうかを検出し、悪用を阻止するためのものといえなくもない。\n\nしかし別の見方をすれば、プロンプトがChatGPTの回答と著作権で保護された情報の類似性の調査を目的としたものかどうかを検出し、調査を妨害するための仕組み、ともいえるのだ。\n\n米国のBusiness Insiderは8月16日、論文が暗示している内容を大胆に解釈し、「[OpenAIはChatGPTが著作権の保護された書籍で訓練されたことを隠蔽しようとしている](https:\u002F\u002Fwww.businessinsider.com\u002Fopenais-latest-chatgpt-version-hides-training-on-copyrighted-material-2023-8){target=“_blank”}」と報じた。\n\n:::box\n[ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Farticles\u002Fchatgpt)\n:::\n:::box\n[関連記事：Meta・OpenAI・Google AI学習データをめぐり次々と集団訴訟に](https:\u002F\u002Fledge.ai\u002Farticles\u002Fseries_of_class_action_lawsuits_over_training_data)\n:::\n:::box\n[関連記事：開発者向け対話AI「GitHub Copilot Chat」パブリックベータ版登場 文脈読みコーディング課題に回答](https:\u002F\u002Fledge.ai\u002Farticles\u002Fgithub_copilot_chat)\n:::</description>
      <pubDate>Wed, 23 Aug 2023 05:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/openai_concealed_its_use_of_copyrighted_data_for_learning</title>
      <link>https://ledge.ai/articles/openai_concealed_its_use_of_copyrighted_data_for_learning</link>
      <description>画像生成AI「Stable Diffusion」で知られる英国Stability AIの日本法人Stability AI Japanが、画像に何が映っているか、描いてあるかを日本語で教えてくれるAI「[Japanese InstructBLIP Alpha](https:\u002F\u002Fja.stability.ai\u002Fblog\u002Fjapanese-instructblip-alpha)」を2023年8月17日に一般公開した。画像から文章を生成するAIはすでに複数存在するが、これは同社が日本市場を重視する意思表示といえる。\n\nJapanese InstructBLIP Alphaは先日公開した日本語向け指示応答言語モデル「Japanese StableLM Instruct Alpha 7B」を拡張したもの。入力した画像に対して文字で説明を生成するほか、画像について質問すると分析した結果を回答として返す。\n\n![st2.jpeg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fst2_bf996959dd\u002Fst2_bf996959dd.jpeg)\n\n大規模な英語のデータセットで事前学習した画像言語モデル「InstructBLIP」で一部を初期化し、限られた日本語データセットを用いて調整した。日本語での回答に加え、日本特有の建造物、例えば東京スカイツリーや金閣寺を正しく認識できるのが特徴という。\n\n![st3.jpeg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fst3_7822ef8fcb\u002Fst3_7822ef8fcb.jpeg)\n\n用途としては画像による検索エンジン、目の前の情景の説明や質疑応答、目の不自由な人への画像の解説などを見込んでいる。AIプラットフォーム「Hugging Face」で公開しており、推論や追加学習を試せる。なお研究目的での利用に限定している。\n\n米国Metaが7月に公開して話題を呼んだ「CM3leon（カメレオン）」など画像から文章を生成するAIそのものはすでに珍しくない。\n\nしかしStability AI Japanは、同社が発表する最初の画像言語モデルとしての意義を強調する。英語圏と比べ日本語のデータセットは限られ、マルチモーダル（複数のデータ形式）なデータセットはさらに限られるなか、日本向けの生成基盤モデルを構築、公開することで日本のAIコミュニティの活性化に貢献するという。\n\nつまりJapanese InstructBLIP Alphaはそれ自体、日本を重視する姿勢のあらわれ、意思表示といえる。\n\nStability AIに限らず、海外のAI開発者や企業は最近、日本市場に重点を置いている。米国Microsoftは7月、企業や政府などがインターネットを通じてAIを利用できるクラウドサービス「Azure OpenAI」のデータセンターを東日本にも置くと発表した。アジアでは初の試みだ。またGoogleでトップクラスのAI研究者だった2人が8月、東京でスタートアップSakana.aiを立ち上げると明らかにしている。英国The Financial Timesの報道によると優れた技術インフラや、労働者の教育水準、非西洋社会や文化でうまく機能するよう調整されたモデルの訓練データと機構が次世代技術の開発に役立つとの判断だという。\n\n:::box\n[Stable Diffusionとは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Farticles\u002Fstable_diffusion)\n:::\n:::box\n[関連記事：元GoogleのAI研究トップ2人 東京にスタートアップ「Sakana AI」設立 次世代技術に挑む](https:\u002F\u002Fledge.ai\u002Farticles\u002Fsakana_ai_tokyo)\n:::\n:::box\n[関連記事：日本政府 ChatGPT中枢「GPT-4」利用開始へ Microsoftが国内データセンターに移植 安保の課題解消](https:\u002F\u002Fledge.ai\u002Farticles\u002Fnippon_gov_and_gpt_4)\n:::\n:::box\n[関連記事：MetaがStable Diffusionなど打ち負かすAI開発か 「テキストから画像」「画像からテキスト」自在に生成する「カメレオン」](https:\u002F\u002Fledge.ai\u002Farticles\u002Fmeta_ai_cm3leon)\n:::</description>
      <pubDate>Tue, 22 Aug 2023 23:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/japanese_Instructblip_alpha</title>
      <link>https://ledge.ai/articles/japanese_Instructblip_alpha</link>
      <description>:::small\n画像出典：Waymo\n:::\n\n[米国カリフォルニア公共事業委員会（CPUC）](https:\u002F\u002Fwww.cpuc.ca.gov\u002Fnews-and-updates\u002Fall-news\u002Fcpuc-approves-permits-for-cruise-and-waymo-to-charge-fares-for-passenger-service-in-sf-2023){target=“_blank”}は2023年8月10日、CruiseとWaymoの2社に対し、いわゆる「Robotaxi（ロボタクシー）」の追加運営権限を承認した。両社はサンフランシスコ市でドライバーのいない自動運転車両による有償サービスを終日運行可能になった。\n\nWaymoはIT大手Googleの親会社Alphabet、Cruiseは自動車大手General Motors（GM）傘下のロボタクシー企業。今回の承認はCPUCが2020年に採択した決定に基づき、両社の提出したサービスに関する文書を評価し、ライセンス要件、特に乗客の安全対策を満たしているかどうかを確認して与えたもの。\n\nこれまで両社はサンフランシスコやその他の地域で特定の制限のもとでロボタクシーを運営していた。\n\n例えばCruiseは、サンフランシスコの限定エリアで夜10時から翌朝6時までのドライバーなしの有料サービスを手がけるほか、サンフランシスコ全域で終日ドライバー在籍の有料サービスとドライバーなしの無料サービスを提供していた。\n\n一方Waymoは、サンフランシスコ全域でドライバー在籍の有料サービスとドライバーなしの無料サービスを提供。さらにロサンゼルスの一部やマウンテンビュー周辺でドライバーの有無に関係なく無料の乗客サービスを提供していた。\n\n:::box\n[関連記事：東北自動車道に「自動運転用レーン」設置へ 新東名に続き](https:\u002F\u002Fledge.ai\u002Farticles\u002Fautomated_lanes_tohoku_expressway)\n:::\n:::box\n[関連記事：AIで完全無人化する実証実験を開始。自動運転レベル4解禁に向け、遠隔監視の自動化やデジタルツインを活用した運行の最適化に関する検証](https:\u002F\u002Fledge.ai\u002Farticles\u002Fsoftbank-autonomous-car)\n:::\n</description>
      <pubDate>Tue, 22 Aug 2023 22:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/cruise_waymo_robotaxi</title>
      <link>https://ledge.ai/articles/cruise_waymo_robotaxi</link>
      <description>東京大学の松尾研究室は、2023年8月18日に公開した大規模言語モデル（LLM）「Weblab-10B」について「オープンソース」とする説明の文言を[削除](https:\u002F\u002Ftwitter.com\u002FMatsuo_Lab\u002Fstatus\u002F1693828112512086472){target=“_blank”}したと同月22日に発表した。同LLMの商用利用を禁じる規定について、Twitter（X）などでオープンソースの定義から外れるものと指摘があった。\n\n松尾研では、現在オープンソースの定義を主導している米国の団体[Open Source Initiative（OSI）](https:\u002F\u002Fopensource.org\u002F){target=“_blank”}にならい、Weblab-10Bについては商用利用不可のため定義に当てはまらないものとして、発表文の文言を修正した。\n\nなお、今後、商用利用可能なモデルの開発も検討しているとのこと。\n\n:::box\n[東大松尾研 オープンソースの大規模言語モデル「Weblab-10B」公開 100億パラメータ・日英2か国語対応](https:\u002F\u002Fledge.ai\u002Farticles\u002Fmatsuo_lab_releases_llm_weblab)\n:::</description>
      <pubDate>Tue, 22 Aug 2023 07:10:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/matsuo_lab_remove_opensource_statement_from_llm</title>
      <link>https://ledge.ai/articles/matsuo_lab_remove_opensource_statement_from_llm</link>
      <description>:::small\n出典：Amazon.com\n:::\n米国Amazon.comは2023年8月14日、生成AIを活用し、商品ごとに複数のカスタマーレビューをひとつに要約する[新機能を発表](https:\u002F\u002Fwww.aboutamazon.com\u002Fnews\u002Famazon-ai\u002Famazon-improves-customer-reviews-with-generative-ai){target=“_blank”}した。商品詳細ページに短い段落として表示する。複数のレビューにまたがって頻繁（ひんぱん）に言及される商品の特徴や、使った人が感じたことに光をあて、商品が自分に合っているかどうかをひと目で判断できるようにする。\n\nこの機能はまだ米国の一部のモバイルユーザーにのみ利用可能だという。\n\n![amazonhighlight.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Famazonhighlight_d437713f9e\u002Famazonhighlight_d437713f9e.png)\n:::small\n画像の出典：[Amazon.com](https:\u002F\u002Fwww.aboutamazon.com\u002Fnews\u002Famazon-ai\u002Famazon-improves-customer-reviews-with-generative-ai){target=“_blank”}\n:::\n\nAIが生成するレビューの要約の下には、「Performance（性能）」「Ease of use（使いやすさ）」などのボタンも表示する。例えば「使いやすさ」のボタンをタップすると、商品の使いやすさについてコメントしているレビューを読める。\n\n![amazon button.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Famazon_button_dd8c8afad2\u002Famazon_button_dd8c8afad2.png)\n:::small\n画像の出典：[Amazon.com](https:\u002F\u002Fwww.aboutamazon.com\u002Fnews\u002Famazon-ai\u002Famazon-improves-customer-reviews-with-generative-ai){target=“_blank”}\n:::\nAmazon.comは今後数か月かけてこの機能に関するフィードバックを反映したうえで、より多くの商品カテゴリーやカスタマーに拡大する可能性があるとしている。\n\n\n:::box\n[関連記事：AWS 日本企業の生成AI開発支援、総額600万ドル規模のコスト負担へ](https:\u002F\u002Fledge.ai\u002Farticles\u002Faws_llm_proglam)\n:::\n:::box\n[関連記事：Google、生成AIと検索機能を融合させ新しいショッピング体験を提供へ](https:\u002F\u002Fledge.ai\u002Farticles\u002Fgoogle_seg_ai_try_on_shopping)\n:::</description>
      <pubDate>Tue, 22 Aug 2023 06:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/amazon_reviews_with_generative_ai</title>
      <link>https://ledge.ai/articles/amazon_reviews_with_generative_ai</link>
      <description>:::small\n画像出典：写真AC\n:::\n\n情報通信研究機構（NICT）とIT企業9社が、新団体「[安全なデータ連携による最適化AI推進コンソーシアム](https:\u002F\u002Fwww.nict.go.jp\u002Fpress\u002F2023\u002F08\u002F04-1.html){target=“_blank”}」を設立したと2023年7月28日に発表した。プライバシーや機密を守りながら多様なデータを安全に連携してAIを開発する「分散型機械学習」と呼ぶ技術の確立を目指す。\n\n![image1.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage1_ffd9bdbac3\u002Fimage1_ffd9bdbac3.png)\n:::small\n画像出典：情報通信研究機構\n:::\n\nNICTのほかKDDI、KDDI総合研究所、情報通信研究機構、グリーンブルー、日本電気（NEC）、ピコラボ、さくらインターネット、凸版印刷、プラナスソリューションズ、ギリアが参加する。\n\n同団体が重視する分散型機械学習では、ネットワーク上にある大規模な計算資源すなわち「クラウド環境」と、データの入力端末がある「エッジ環境」を分けて考える。\n\nエッジ環境で入力した個人情報や機密情報などのデータは、エッジ環境にあるAIの学習のみに使用する。その後エッジ環境のAIを「連合学習」という仕組みでクラウド環境に集約することで、データは共有せずにより高度なAIを作り出し、成果を再びエッジ環境のAIに反映する。\n\nこの仕組みの実現に向けて取り組む研究開発の対象は大きく「マルチモーダルAI」「エッジAI」「連合学習」の3種類だ。\n\n（1）マルチモーダルAI\n多様なデータを組み合わせて複雑な予測ができる大規模マルチモーダル深層学習モデルの構築技術を開発するほか、実空間から収集したデータの差異を吸収できるロバスト（頑健）なマルチモーダルAI技術を研究する。\n\n（2）エッジAI技術\nマルチモーダル深層学習モデルを対象に、エッジ環境の限られた計算資源でも効率よく学習ができる技術の研究開発を進める。\n\n（3）連合学習技術\nマルチモーダル深層学習モデルを対象に、多数のエッジ環境間におけるデータの偏りを前提とした高精度な連合学習技術を研究開発する。\n \nこれらの成果を活かして、データを安全に連携させる「データ連携AIプラットフォーム」を作り、複数の分野を横断したデータ活用を促進し、社会課題の解決や産業競争力の向上に貢献したいとしている。\n\n:::box\n[GPTがクラウド上からほかのAIを訓練 スマホ・クルマ・工場まで制御する「自律型エッジAIシステム」](https:\u002F\u002Fledge.ai\u002Farticles\u002Fedge_ai_for_connected_intelligence_microsoft)\n:::\n:::box\n[関連記事：KDDI 通信異常をAIで検知 61時間続いた大規模障害の再発防止](https:\u002F\u002Fledge.ai\u002Farticles\u002Fkddi_ai_detects_communication_anomalies)\n:::\n:::box\n[関連記事：KDDI、生成AIを活用したチャットサービスを実業務で利用開始](https:\u002F\u002Fledge.ai\u002Farticles\u002Fkddi-ai-chat)\n:::\n</description>
      <pubDate>Tue, 22 Aug 2023 06:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/nict_consortium</title>
      <link>https://ledge.ai/articles/nict_consortium</link>
      <description>:::small\n画像出典：写真AC\n:::\n\nローマ・カトリック教会のフランシスコ教皇は2023年8月8日、人工知能（AI）による社会への影響が拡大していると指摘し、使用については「人類に奉仕する」方向であるべきだと訴えた。これは2024年の「世界平和の日」のテーマとして「人工知能と平和」が決定された際の[声明](https:\u002F\u002Fpress.vatican.va\u002Fcontent\u002Fsalastampa\u002Fen\u002Fbollettino\u002Fpubblico\u002F2023\u002F08\u002F08\u002F230808c.html){target=“_blank”}で述べられたものだ。\n\n教皇は、AIには「破壊的な可能性と両義的な効果」があるとし、その技術に関する「開かれた対話」を求めている。またAIが「争いや反目」を助長しないよう、責任を持って使われる必要があると述べた。\n\nさらに教育や法の観点から、AIの使用において倫理的な考察が必要であるとの見解を示した。教皇はAIの進歩が「最も弱い立場にある人々」を犠牲にするものであってはならないと強調した。\n\n:::box\n[関連記事：イタリア、ChatGPTの使用禁止措置を解除](https:\u002F\u002Fledge.ai\u002Farticles\u002Fitaly-chatgpt-ban-removed)\n:::\n:::box\n[関連記事：ChatGPTのOpenAI、イタリアのデータ保護機関からのタスク完了は困難か](https:\u002F\u002Fledge.ai\u002Farticles\u002Fopenai_italy_task)\n:::\n</description>
      <pubDate>Tue, 22 Aug 2023 02:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/pope_francis_speach</title>
      <link>https://ledge.ai/articles/pope_francis_speach</link>
      <description>:::small\n[UnsplashのDavid Smooke](https:\u002F\u002Funsplash.com\u002Fja\u002F%E5%86%99%E7%9C%9F\u002FEn_wELYYhD4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText){target=“_blank”}が撮影した写真   \n::: \n米国の主要紙The New York Times（ニューヨークタイムズ、NYT）は2023年8月3日、[利用規約](https:\u002F\u002Fhelp.nytimes.com\u002Fhc\u002Fen-us\u002Farticles\u002F115014893428-Terms-of-Service){target=“_blank”}を更新し、機械学習（ML)やAIの訓練を目的とした同社コンテンツの無断使用を禁止する項目を追加した。文章や写真、イラスト、デザインもちろん音声、動画、メタデータなどの使用を幅広く制限する。\n\n一件を報じた [Adweek](https:\u002F\u002Fwww.adweek.com\u002Fmedia\u002Fthe-new-york-times-updates-terms-of-service-to-prevent-ai-scraping-its-content\u002F){target=“_blank”} は「一般的な利用規約にはデータのスクレイピングに関する制限が含まれているが、AIの訓練への明確な言及は新しい」とする Gunderson Dettmer法律事務所のパートナー弁護士、Katherine Gardner氏のコメントを掲載した。\n\n既存のAIは文章や画像を生成するため主として報道機関の記事や、著作権の保護対象となるアートなどを学習しており、場合によってはそれらをそのままの形で再現してしまうこともあれば、研究者が「幻覚（ハルシネーション）」と呼ぶ現象によって虚偽を織り交ぜた形で伝えることもある。\n\n有料会員のみが内容を閲覧できる「PayWall（ペイウォール）」や定期課金（サブスクリプション）の仕組みで安定した事業を展開しているニュースメディアなどは、AIが学習内容から再現した情報を著作権表示なしで公開すれば収益を損なうことはもちろん、誤情報で報道への信頼を低下させることも懸念していると、Adweekは分析する。\n\nなお、[米国公共ラジオ放送（NPR）](https:\u002F\u002Fwww.npr.org\u002F2023\u002F08\u002F16\u002F1194202562\u002Fnew-york-times-considers-legal-action-against-openai-as-copyright-tensions-swirl){target=“_blank”}が米国時間の2023年8月16日付で報じたところによると、NYTは対話型AI（チャットボット）「ChatGPT」などを開発する米国OpenAIへの訴訟も検討している。OpenAIがAI開発にNYTの記事を利用するにあたって対価を支払うライセンス契約の締結をめぐって数週間にわたる交渉が続いたものの実を結ばず、NYTは法的措置を考慮中とのこと。\n\n:::box\n[関連記事：米大手メディア AI企業提訴の準備か ニューヨークタイムズやニューズコープなど](https:\u002F\u002Fledge.ai\u002Farticles\u002Fsemafor_nyt)\n:::\n:::box\n[関連記事：OpenAIウェブからAI学習データを集める「GPTBot」のブロック方法を公開](https:\u002F\u002Fledge.ai\u002Farticles\u002Fopenai_gptbot_usage)\n:::</description>
      <pubDate>Mon, 21 Aug 2023 23:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/nyt_prohibited_unauthorized_use_of_articles_to_ai_learning</title>
      <link>https://ledge.ai/articles/nyt_prohibited_unauthorized_use_of_articles_to_ai_learning</link>
      <description>:::small\n画像出典：Hugging Face\n:::\n\nアリババクラウドは2023年8月3日、70億パラメーターの大規模言語モデル「通義千問（Tongyi Qianwen）」をもとにした基盤モデル「[Qwen-7B](https:\u002F\u002Fhuggingface.co\u002FQwen\u002FQwen-7B){target=“_blank”}」と対話型AI向けモデル「[Qwen-7B-Chat](https:\u002F\u002Fhuggingface.co\u002FQwen\u002FQwen-7B-Chat){target=“_blank”}」のオープンソースコードを公開した。このコードは、同社が運営する開発者向けのAIモデルコミュニティ「魔搭（ModelScope）」と「Hugging Face」で無償利用可能。商用利用も認められている。「中国IT大手としては初の試み」として話題を呼んでいる。\n\nQwen-7BはWebテキスト、書籍、コードなどを含む2兆2,000億トークンで学習し、一般分野から専門分野までカバーしている。中国語と英語の語彙に基づく他のオープンソースモデルと比較して15万トークンを上回る語彙を使用し、複数の言語にも対応。Qwen-7B-Chatは、Qwen-7Bに基づいた対話型AI向けモデルだ。\n\n\n:::box\n[関連記事：アリババクラウドが大規模言語モデル「通義千問」を発表、GPTに対抗か](https:\u002F\u002Fledge.ai\u002Farticles\u002Falibaba-tongyi-qianwen)\n:::\n:::box\n[関連記事：アリババクラウド主催ブロックチェーンゲームハッカソン「#asobiHack_Tokyo」受賞者が発表](https:\u002F\u002Fledge.ai\u002Farticles\u002Falibaba-asobi-hack-2023-winners)\n:::\n\n\n</description>
      <pubDate>Mon, 21 Aug 2023 22:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/qwen_7b_alibaba_cloud</title>
      <link>https://ledge.ai/articles/qwen_7b_alibaba_cloud</link>
      <description>:::small\n画像出典：Sakana AI\n:::\n\nAIの革新にかかわる論文「Attention Is All You Need」の共著者でGoogleを最後に離れたLlion Jones氏と、Google日本法人のAI研究部門の責任者だったDavid Ha氏が2023年8月17日、東京に新たなスタートアップ「[Sakana AI](https:\u002F\u002Fsakana.ai\u002F){target=“_blank”}」を設立すると[発表](https:\u002F\u002Ftwitter.com\u002Fhardmaru\u002Fstatus\u002F1692170657470263347){target=“_blank”}した。テキストや画像、コードなどの生成AIの開発を予定している。\n\n![スクリーンショット 2023-08-21 091741.jpg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002F2023_08_21_091741_17e472272d\u002F2023_08_21_091741_17e472272d.jpg)\n:::small\n[画像出典:Twitter](https:\u002F\u002Ftwitter.com\u002Fhardmaru\u002Fstatus\u002F1692170657470263347){target=“_blank”}\n:::\n\n[Jones氏](https:\u002F\u002Fledge.ai\u002Farticles\u002Fgoogle_lion_jones_retirement)が共著した論文は大規模言語モデル（LLM）の重要な要素となり、ChatGPTなどのAI製品を支える技術となっている。またHa氏は、Stable Diffusionを生んだ英国Stability AIの元研究責任者。\n\n新会社の「Sakana」という名称は、日本語話者には言うまでもなく、魚を意味する「さかな」から派生したもの。自然からのコンセプト、特に集団知性や進化を基にした研究に触発されているという。\n\n東京を本拠地として選択した理由は、優れた技術インフラや教育を受けた労働力により、AI企業の成長に適した位置にあるからだ。「それに加えて、非西洋社会や文化でうまく機能するように調整されたモデルの訓練データと機構は、次の技術的進歩の触媒となるだろう」と両氏は[The Financial Times](https:\u002F\u002Fwww.ft.com\u002Fcontent\u002F1f0cee71-2a44-4080-8c79-b037243ac6f5){target=“_blank”}に語っている。\n\n:::box\n[関連記事：AI技術の画期「トランスフォーマー」の生みの親 Google退社しスタートアップ設立へ](https:\u002F\u002Fledge.ai\u002Farticles\u002Fgoogle_lion_jones_retirement)\n:::</description>
      <pubDate>Mon, 21 Aug 2023 07:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/sakana_ai_tokyo</title>
      <link>https://ledge.ai/articles/sakana_ai_tokyo</link>
      <description/>
    </item>
    <item>
      <title>https://ledge.ai/articles/ledgeai_expo_2023_summer_review</title>
      <link>https://ledge.ai/articles/ledgeai_expo_2023_summer_review</link>
      <description>AI（人工知能）関連メディア「Ledge.ai」を運営するレッジが2023年7月に開催したオンライン／オフラインハイブリッド型の展示会「Ledge.ai EXPO 2023 summer」。生成AIのビジネス利用で最前線を突き進む[Google Cloud](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)と[日本マイクロソフト](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)のセッションには多くの関心が寄せられた。反響の大きさを踏まえ、今回は内容を動画アーカイブとして期間限定で公開する。自社のAI導入を急ぎたい人も、熟考する人も是非視聴したうえで両社の「本気度」「熱」を測ってほしい。\n\n\n|  　 |  　   |\n| ---- | ---- |\n|  [![google_360px記事画像_2.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fgoogle_360px_2_8dcff3af95\u002Fgoogle_360px_2_8dcff3af95.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)  |  [![ms_360px記事画像_2.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fms_360px_2_821e6088fd\u002Fms_360px_2_821e6088fd.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)   |\n\n今夏のEXPOに登場したGoogle Cloudの下田倫大氏と、日本マイクロソフトの濵田隼斗氏はいずれも企業のAI利用を水先案内するエキスパート。セッションではそれぞれ「ダジャレの面白さを理解するAI」や「野良ChatGPTを止められるサービス」など自社の強みとカルチャーを前面に押し出し、「Vertex AI」や「Azure OpenAI Service」といったサービスの最新情報を紹介している。\n\n## Googleの「ダジャレがわかる」AIの卓越した日本語能力\n[![gcloud2.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fgcloud2_b2f29c09cc\u002Fgcloud2_b2f29c09cc.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)\n:::small\n出典：PaLM 2 Technical Report\n:::\n\nGoogle Cloudは「[Google Cloud の次世代 AI 〜 ジェネレーティブ AI 最新情報](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)」と題してセッションを行った。語り手の下田倫大氏は2023年1月から同社のAI\u002FML事業開発部長を務める。人工知能と機械学習を日本のビジネスシーンに導入するため陣頭指揮をとる立場だ。同氏が打ち出したGoogleのAIの特徴のひとつが「ダジャレの面白さがわかること」だ。\n\n2023年5月に日本語対応した対話型AI（チャットボット）「Bard」の中枢となる大規模言語モデル（LLM）「PaLM 2」は、「おでんの予約は？お電話で！」といったダジャレの意味を質問すると、「oden and odenwa are pronounced the same way（おでんとお電話は同じように発音しますね）」などと英語で詳細に解説してくれる。\n\nダジャレの面白さについてAIから丁寧に教えてもらうのは不思議な体験だが、少なくとも日本語能力の高さははっきり理解できる。PaLM 2はこのほかにも定量的な評価として、外国人の日本語能力を客観的に測定する試験「J.TEST実用日本語検定」で「専門用語を使ったコミュニケーションが可能になるレベルをパスした」（下田氏）という。従来は人間が行ってきた業務の多くをこなすことを期待できそうだ。\n\n:::button\n[特別公開の動画アーカイブはこちら](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)\n:::\n\nこのPaLM 2をはじめとしたGoogleのAIは研究と実験の段階を過ぎ、多くの企業にとって手が届くところへ来た。\n\n例えばGoogle Cloud の機械学習プラットフォーム「Vertex AI」は従来、機械学習エンジニアやデータサイエンティストのためのサービスを数多く展開してきたが、このほど幅広い層が生成AIを使ったアプリケーションを作れるよう2つの新機能「Model Garden」と「Generative AI Studio」を追加した。\n\n[![gloud3.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fgloud3_fbfd8536dd\u002Fgloud3_fbfd8536dd.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)\n:::small\n出典：Google Cloud\n:::\n\nModel GardenではGoogle製のほかオープンソースやサードパーティのモデルが数多く並び、テキスト生成や画像生成など企業が用途に応じて最適なものを選べるようになっている。\n\nGenerative AI Studioはモデルが目的に沿った情報を生成するよう、追加でデータを与えて訓練する「ファインチューニング（微調整）」や、指示の出し方を工夫する「プロンプトエンジニアリング」などの作業を特別な知識なしでGUIから進められる。\n\n:::button\n[特別公開の動画アーカイブはこちら](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)\n:::\n\nこれらの機能を使ってどんなサービス、アプリが実現できるのか。今回のセッションで下村氏は、メルカリと協力して開発したデモを紹介した。\n\nデモではメルカリの商品を「T-shirts with dancing people（踊っている人のTシャツ）」と自然な文章で検索すると、一瞬で該当する柄のTシャツがずらりとあらわれる。次に1語だけ変えて「Cups with dancing people（踊っている人のカップ）」とすると同様に該当する柄のカップがすぐあらわれた。文章に一致する商品をAIが画像データから推測しているため、従来のキーワード検索に比べ高速で融通がきくのが特徴だ。\n\n通販サイトに便利な仕組みだが、社内データの検索などにも応用できる。目的の資料を見つけるための正確なキーワードがわからなくても、AIが推測して一致しそうな候補の一覧を出す。しかも社内データ検索については、開発をマネージドサービスに委ねる「Generative AI App Builder」も利用可能だ。企業は対象のデータをアップロードするだけで面倒な設定なしに一括して検索が可能になる。\n\nこのほかにも、セッションではモデルの訓練に使ったデータが企業の制御の外に出ないようにする「ソロテナント」の仕組みなども説明しており、見どころ、聞きどころは実に多い。Vertex AIを含むGoogle CloudのAIサービスの全体像を把握するには、是非動画アーカイブで全編を視聴されたい。\n\n:::button\n[特別公開の動画アーカイブはこちら](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)\n:::\n\n## MicrosoftのAIは「野良ChatGPTを止める」\n[![ms1.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fms1_865b9f1285\u002Fms1_865b9f1285.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)\n:::small\n出典：AIの革新：マイクロソフトの新時代技術である生成AIと未来へのビジョン\n:::\n\n日本マイクロソフトは「[AIの革新：マイクロソフトの新時代技術である生成AIと未来へのビジョン](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)」と題してセッションを行った。語り手の濵田隼斗氏はGlobal Black Belt Asia Pacific AI\u002FML Specialistという立場で、今回強調したのは「ChatGPT」をはじめ提携先のOpenAIが開発したAIサービスの最新機能を、クラウド基盤「Microsoft Azure」上で各企業の方針に沿ったかたちで安全に利用できる「Azure OpenAI」の取り組みだ。\n\nいわゆる「野良ChatGPT」を止めるのにも役立つという。\n\n:::button\n[特別公開の動画アーカイブはこちら](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)\n:::\n\n野良ChatGPTとは、企業の許可や把握をしていないまま従業員がChatGPTを業務に利用している状態を示す。かつて大手企業などでもクラウド導入が進んでいなかった頃、従業員がファイル共有サービスなどを個人で先んじて使い始めた結果、情報管理に問題が生じた現象「野良クラウド（Rogue Cloud）」になぞらえた言葉として知られる。\n\n野良ChatGPTを引き起こすのも、野良クラウドと同じく新たな技術を仕事に生かしたいという熱意といえる。ChatGPTやその中枢であるLLM「GPT-4」などはプラグインと呼ぶ追加機能と組み合わせて、多様な作業を人間に代わって行えるようになり、生態系（Ecosystem）として大きくなってゆく見込みだ。自然「どんどんGPTを活用していきたい、生成AIを活用していきたいというモチベーションになってくる」と、濵田氏は予測する。\n\n例えば従業員が個人利用しているChatGPTで、セミナー受講者リストと過去の顧客リストを比較して一致する人物を探してほしい、と指示したとする。ChatGPTは要求に応え、業務ははかどるが、濱田氏は「個人情報や社内の機密情報が流出するリスクがある」と指摘する。\n\n:::button\n[特別公開の動画アーカイブはこちら](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)\n:::\n\nすでに海外の幾つかの調査でこうしたリスクが現実のものとして確かめられていることは、Ledge.aiでも既報の通り。\n\n濱田氏は生成AIとの付き合い方として「ルール」「ガバナンス」「マナー」を作る重要性を説く。組織としてAIを利用できる部門、業務を制限し、利用状況はモニタリングすべきだという。AIを使った業務では個人情報、機密、不正な情報を取り扱わないといった規則も必要だ。\n\n[![ms2.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fms2_bb3d2cf2f5\u002Fms2_bb3d2cf2f5.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsof)\n:::small\n出典：AIの革新：マイクロソフトの新時代技術である生成AIと未来へのビジョン\n:::\n\nとはいえただ厳格に縛るだけでは、先ほどのリストの突き合わせなどはAIに任せられなくなる。そこでMicrosoft Azureの環境で動作し、企業の方針に合わせてさまざまな制御が可能なChatGPT、すなわち「Azure OpenAI ChatGPT」の出番になる。流出対策を施すことができ、機密情報や個人情報を含め活用することが可能。通常のAI倫理のフィルタリング、プライバシー、セキュリティニーズのあるサービスなどを利用できる。\n\nこれに加えSLA保証（サービス品質保証）や耐障害性、ロールベースのアクセス制御など、いざ企業としてChatGPTを業務に組み込むとなれば求められる機能も充実している。\n\nさらにAzure OpenAIではChatGPTに限らず、AIが取り扱うデータすべてについて不正使用の監視やコンテンツフィルタリングを行うようになっており、安全を重視した運用に向いている。一方で企業の判断でこうした機能を外すこともできる。つまりMicrosoft Azure上だからこそより厳格にも、より自由にも、企業の方針次第で柔軟に生成AIを業務に生かせる。野良ChatGPTを止める有効な手だてと言えるだろう。\n\nなお、今回のセッションの内容は野良ChatGPT対策に限ったものではなく、OpenAIのAIサービスそのものについての入門者向けの解説から、オフィススイート「Microsoft 365」や開発プラットフォーム「GitHub」などとの統合、いわゆる「Copilot」の取り組みに関する最新動向まで俯瞰できるものとなっている。\n\nAIのビジネス導入の現場を知りつくした担当者が、濃密かつ大量の情報を力のかぎり語るようすは、ぜひ動画アーカイブで確認されたい。\n\n:::button\n[特別公開の動画アーカイブはこちら](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)\n:::\n\n## 日本市場の重要さを感じるビッグテックの「熱」\n今回の各セッションからわかるのは、両社ともすでに業界別に生成AIの具体的な用途を描き出し、使いやすいアプリケーションを細やかに取り揃えるなど、生成AIのビジネス導入に強烈に前のめりになっているということだ。\n\n|  　 |  　   |\n| ---- | ---- |\n|  [![google_360px記事画像_2.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fgoogle_360px_2_8dcff3af95\u002Fgoogle_360px_2_8dcff3af95.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-googlecloud)  |  [![ms_360px記事画像_2.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fms_360px_2_821e6088fd\u002Fms_360px_2_821e6088fd.png)](https:\u002F\u002Fexpo-2023summer-watch.ledge.ai\u002Fwatch_form-microsoft)   |\n\nまた、ダジャレを解するほどの日本語対応の充実や、野良ChatGPTをはじめ国内の生成AI人気故に起きうるリスクへの目配りからは、ビッグテックにとってこの分野における日本市場の重要さがあらためて感じられる。動画アーカイブをじっくり視聴すれば、今後日本向けにどのようなサービスが追加、拡充されてゆくのかのヒントも読み取れそうだ。\n\n:::box\n[特集：ビジネスAI最前線！Ledge.ai EXPOスペシャルレポート](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Fledgeai_expo_2023_summer_review)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/intellilink_data_management</title>
      <link>https://ledge.ai/articles/intellilink_data_management</link>
      <description>※この記事は、NTTデータ先端技術株式会社による[コラム](https:\u002F\u002Fwww.intellilink.co.jp\u002Fcolumn\u002Fdx\u002F2023\u002F050800.aspx)からの転載です。\n\n## はじめに\n近年、デジタルトランスフォーメーション（DX）はさまざまな業界で求められており、各企業はDX化の取り組みを推進しています。その取り組みのなかで、データの利活用は重要な要素として位置づけられています。\n\n人や企業の多くの活動がデジタル化され、取得可能なデータの種類と量も増え、あらゆる業界、あらゆる領域でデータ利活用の試みが行われるなかで、データに基づく意思決定や予測、最適化、データ駆動型の戦略策定と遂行は、企業の競争力強化に不可欠となっています。一方で、ユースケースばかりに目を向けてしまい、データ品質がおざなりになっている場合があります。データはそのものだけでなく、加工・変換をして分析した結果をビジネス上の意思決定に利用したり、AI／機械学習の学習データとして利用したりと二次、三次と加工されて活用されます。元のデータの品質が悪いとそのデータを利用して導出した結果の品質にも悪影響を及ぼすことになり、その結果ビジネスに損失を与えることがあります。\n\nデータ利活用の文脈においてよく使われる表現に、「Garbage in, Garbage out」（ゴミからはゴミしか生まれない）というものがありますが、このような課題を解決するには、単にデータを収集するだけでなく、データ品質の観点で管理を行うことが重要です。本連載では、複数回にわたり、データ品質管理における考え方や全体のプロセス、運用について、具体例を交えて解説します。\n\n## データ品質管理とは\nデータ品質の課題に取り組むには体系的なアプローチが必要です。国際的なデータ専門家で組織されたData Management Association International（DAMA I）のデータマネジメント知識体系ガイド（DMBOK）の中にデータ品質管理について次のような考え方が提唱されています。\n\n\u003E データが様々な目的で利用されていて、データ利用者の要求を満たすことを保証するために、品質管理に関わる技術を適用する活動の計画、実施、管理である\n\nつまり、データ品質とは「データ利用者にとってのデータの品質」のことであり、その「要求」というのはビジネス上の「目的」のことを示します。それに合致するデータこそが、品質の高いデータと定義することができます。\n\n極端な話をすれば、99.9%のレコードが完全であっても、その0.1%だけが、利用者が求めているデータであったならば、そのデータは使い物にならない（品質が低い）データといえます。\n\nデータ活用の目的によって、求められるデータ品質の基準は異なるので、組織内におけるデータ品質の現状の認識、目標となるデータ品質基準を定義したうえで、データ品質を向上させるための計画を策定することが、データ品質管理を実施していくうえでのポイントになります。\n\nまた、データ品質管理は特定の時点だけで行うだけではなく、継続的に改善を図っていくものです。定期的に評価し、データが品質基準を満たし、ビジネス上の目的に沿った形で活用できているかを確認することが重要です。データ品質管理においても、製品の品質管理におけるPDCAサイクルと同様に下図のような管理サイクルを回す必要があります。\n\n![figure0001.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Ffigure0001_1a46242110\u002Ffigure0001_1a46242110.png)\n\n|  Plan（計画） |  データ活用目的の明確化とその目的に合致するデータ品質の基準・評価軸を決定します。データ利用者を交え、ビジネスの要求に沿った評価軸を定め、その評価軸に沿って「データが利用できる状態であること」を判定するための基準（データ品質基準）を策定します。   |\n| ---- | ---- |\n|  Do（実行）  |  定めた評価軸に対して、現状がどのような状態なのか定量的に把握します。この時点で、データ品質の問題に対するプロセス（データクレンジングの方法）なども検討しておきます。   |\n|  Check（評価）  |  データの状態を監視し、データ品質基準を満たしているかどうか評価します。データの品質が許容範囲を下回る場合は、問題に対する対処を検討します。   |\n|  Action（改善）  |  評価結果をもとに、定めたプロセスに沿って問題の対処（データクレンジング）を行い、期待する品質に適合させていきます。また、データの利用目的や外的要因により、データ品質に対する期待が変わる場合は最初のプロセスから繰り返します。   |\n\n## データ品質管理の難しさ\nここまでデータ品質管理の基本的な概念を紹介しましたが、実践していくには次のような課題があります。\n\n:::box\n- データ品質基準の定義\nデータ品質は高ければ良いというわけではありません。製品と同じように、品質を高めれば、それに伴いコストも高くなることに留意が必要です。実行フェーズを確実に遂行できるように、データ品質基準、コストのバランスをとる必要があります。\n\n- データ品質の評価軸の選定\nデータ品質という言葉だけをみると、今DWHに格納してあるデータの完全性、一意性、一貫性といった評価軸に目が向きがちですが、「利用者の活用目的に合致しているか」状況を可視化できる評価軸を定義する必要があります。\n評価軸にはDMBOKで定めるところでは、正確性、完全性、一貫性、整合性、妥当性、適時性、一意性、有効性がありますが、他にも複数種の評価軸が提唱されています。データ活用の目的と照らし合わせた形で、重視すべき評価軸を決める必要があります。\n\n- データソースの多様性\nこれまで企業は、販売データや在庫データなど、自社の業務システムから生成されたデータを主に利用していました。しかしながら、現在収集できるデータは多様化し複雑さを増しています。例えば、Webサイトのアクセスログやモバイルデバイスから取得したデータ、大量のログやセンサーデータ、画像や音声といった非構造データなど、企業にとって、さまざまなデータソースから複雑な構造を持つデータの品質管理は困難な作業となります。\n\n- データを取り巻く人・プロセス・テクノロジー\nデータ品質管理は、IT部門だけで取り組むものではありません。業務部門、経営を含めたメンバーがデータ品質の影響度や重要性を理解することが求められます。また、保有しているデータを維持・運用・活用できるよう、プロセスとテクノロジー（ツール、プラットフォーム）を整備していく必要があります。\n:::\n\nこのような状況のなかで、先に紹介したDMBOKが役に立ちます。DMBOKには、データ品質管理におけるプロセスやアクティビティ、検討が必要な項目など取り組みの基本的な指針が定められており、体系的に整理された方法論を参照しながら遂行していくことができます。\n\nしかしながら、DMBOKはあらゆる業界やシステムに適用できるように抽象化されているため、具体的なアクションやアウトプットのイメージがしづらいところがあります。そこで、次回以降DMBOKをベースに具体例を交えながらデータ品質管理の進め方について解説していきます。\n\n## おわりに\n今回は、データ品質管理の概要とその課題について述べました。次回は、データ品質管理の進め方を具体例も交えて紹介していきます。\n\n:::box\n[特集：データマネジメントの要！データ品質管理のことはじめ NTT先端技術連載 Vol.1～3](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Fintellilink_data_management)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/data-management-1</title>
      <link>https://ledge.ai/articles/data-management-1</link>
      <description>※この記事は、NTTデータ先端技術株式会社による[コラム](https:\u002F\u002Fwww.intellilink.co.jp\u002Fcolumn\u002Fdx\u002F2023\u002F052200.aspx){target=“_blank”}からの転載です。\n\n本コラム「データマネジメントの要！データ品質管理のことはじめ」は、3回に分けてお送りしています。第1回では、「データ品質管理とは」と題し、データ品質管理の基本的な概念と実践する際の課題について述べました。第1回をまだ読んでいない方は、ぜひ以下からご覧ください。\n\n第一回は[こちら](https:\u002F\u002Fledge.ai\u002Fdata-management-1\u002F)\n\n## データ品質管理とは\nデータ品質管理は、データから効果的に価値を引き出したいと考えている企業にとって重要な取り組みとなります。しかしながら、実践する際に以下のような課題があるため、なかなか取り組みが進まない実状があるかと思います。\n\n前回述べた4つの課題を再掲します。\n\n- どのデータを対象にデータ品質管理を実施すれば良いのか分からない\n- データ品質の基準の決め方が分からない\n- データソースの多様化によるデータ品質管理の複雑さ\n- データを取り巻く人・プロセス・テクノロジーの変化への対応\n\n上記の1点目と2点目に関しては、データ品質管理の計画時における進め方やその過程で検討すべき事項などが具体的にイメージできると、取り組みやすくなると考えています。\n\n今回は、データ品質管理を実施するうえでのアクティビティ（活動内容）や進め方について、前回に引き続きDMBOKに沿って解説していきます。\n\n## データ品質管理のアクティビティと作業ステップ\nDMBOK では、データ品質管理の活動として、6つアクティビティを定義してします。それぞれのアクティビティで実施する大まかな活動内容と対応する作業ステップで整理すると、次のようになります。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103233\u002Ffigure00011.png)\n:::small\n図1：データ品質管理のアクティビティと作業ステップ\n:::\n\n### 作業ステップの概要\n**①ビジネスニーズの明確化**\nデータ利活用に対するビジネスニーズを5W1Hの観点でまとめます。対象となるデータセットの選定までは踏み込まず、ビジネス視点で求められるデータ要件とその品質評価指標などの要件を定めます。\n**②データ品質管理対象の選定**\n対象となるデータセットを洗い出し、実データの現状を把握したうえで、データ品質管理対象を絞り込みます。\n**③データ品質基準の策定**\nデータ品質の測定方法やデータ品質の指標に対する閾値を定義します。また、閾値を超えた場合の対応方法もここで検討します。\n**④運用フローの策定**\nデータ品質管理を継続的に運用するためのフローを整理します。データ品質に問題が生じた場合のデータ修正や定期的なレポーティングなど運用フローを策定します。\n\n上記の作業ステップに沿って進めることで、データ品質管理の対象となるデータや項目が明確になり、データ品質の基準に基づく継続的な運用方法を定めることができます。\n\n※本稿ではデータ品質管理を進めるための組織や体制については触れません。ただし、データ品質管理を推進する役割は個別の組織横断チームを想定しています。業務部門やIT部門などその領域の専門家からインプットを得たり、合意形成を図ったりすることが求められるためです。DMBOKにおいても、その役割の必要性を述べており、本稿ではその役割を「データ品質管理チーム」として記載しています。\n\n## データ品質管理の各作業ステップの活動内容\nデータ品質管理の各作業ステップで実施する具体的な活動内容を見ていきます。\nよりイメージをつかみやすいように、ECサイトを運営する架空の企業におけるデータ利活用をモデルケースに用いて解説します。\n\n### ①ビジネスニーズの明確化\nデータ品質管理の最初のステップは、データ品質の向上が、どのようなビジネスニーズによって要求されているかを把握し、分析するところから始まります。\nビジネスニーズを明確化するには、「ビジネス上の目的」、「対象業務」、「データ要求」、「データ品質要件」の4つの観点に対し、5W1Hで整理していきます。\n\nモデルケースを用いて整理してみると次のようになります。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103230\u002Ffigure0002.png)\n:::small\n図2：「ビジネスニーズの明確化」の整理イメージ\n:::\n\n各観点に関して、それぞれ以下の要領で整理します。\n\n- **ビジネス上の目的**\n背景やねらい（Why）、目的（What）をビジネス視点で記載します。目的は可能な限り具体的に記載します。また粒度が粗い場合は、ブレークダウンして記載すると良いでしょう。また、複数の目的が存在する場合はその目的ごとに各観点を整理します。\n\n- **対象業務**\n対象業務（Where）やその業務の実施頻度（When）、関連する部署や担当者（Who）を整理します。\n\n- **データ要求（What）**\nビジネス目的を満たすために必要な情報の要求（What）を洗い出します。この段階で対象のデータセットを決めるのではなく、要求レベルで整理します。\n\n- **データ品質要件**\nデータ要求に対して、どのような品質が求められるか特性も踏まえて重要な評価軸（How）を定義します。なお、DMBOKでは、以下の8つの評価軸を定義しています。\n\n|  評価軸  |  説明  | 例 |\n| ---- | ---- | ---- |\n|  正確性  |  データが「現実」の実体を正しく表している。他の正しい情報と値が一致している。  |  システム上で登録されている顧客の居住地とその顧客の現居住地が一致している。  |\n|  完全性  |  必要なデータが、適切な値で、全て存在している。  |  住所テーブルの郵便番号を入力する項目に全て適切な値が入っている。  |\n|  一貫性  |  あるデータセット内のデータ値が、他のデータセットの値と一致している。  |  単価は複数のシステムで保持している項目だが、必ず1円単位で表されている。  |\n|  整合性  |  外部キーで参照するレコードが実際に存在し、そのエンティティが一意である。  |  受注明細に記載されている品目コードを外部キーとして参照した際、該当するレコードが品目マスタに存在する。  |\n|  妥当性 |  データのパターンが期待を満たすものである。  |  今期の売上額が、前年比での±5%以内に収まっている。  |\n|  適時性  |  情報を必要な時にすぐ利用できる。（利用者が望むタイミングでデータが利用できている）  |  株式市場のレコードは取引されてから5分以内に届いている。  |\n|  一意性  |  エンティティがデータセット内に一つだけ存在する。  |  顧客「A株式会社」は、顧客コード「12345」で表され、重複して登録されていない。  |\n|  有効性  |  データ値が定義された値の範囲と合致している。  |  フィールドX＝値1の場合、フィールドYは値1～値2で入力されている。  |\n\n### ②データ品質管理対象の選定\n「①ビジネスニーズの明確化」で実施した整理結果をもとにデータ品質管理の対象となるデータおよび項目を選定します。ここでは、「データ要件に関連するデータ・項目の洗い出し」と「プロファイリングの実施」、「データ品質管理対象の選定」の流れで進めていきます。\n\n**データ要件に関連するデータ・項目の洗い出し**\nデータ要件に関連するデータ（テーブル）、項目（カラム）を洗い出します。ER図やテーブル定義書などのインプット情報などを活用すると効率よく実施できます。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103228\u002Ffigure0003.png)\n:::small\n図3：データ要件に関連するデータ・項目の洗い出しイメージ\n:::\n\n図3の例では、2つのテーブルから対象項目の洗い出しができていますが、実際はアクセスログや顧客情報に加え、購買実績を集計した結果を格納したテーブルなど正規化された複数のテーブルが関連することが多いでしょう。必要に応じて、業務部門にヒアリングを実施して対象テーブルや項目の見当をつけるなども進めるうえでのポイントとなります。\n\n**プロファイリングの実施**\nデータ要件に関連するデータ、項目の洗い出しが完了したら、次は現状のデータ品質を把握するためにプロファイルを実施します。各項目に対し、データの抽出条件や測定方法を定義し、評価軸（データ品質要件）に沿って、実データの適合の度合いを測定します。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103229\u002Ffigure0004.png)\n:::small\n図4：プロファイル結果のイメージ\n:::\n\nプロファイルの実施方法は、評価軸（データ品質要件）によって異なりますが、例えば以下のような測定を行います。\n\n- NULL数：NULLの件数をカウントする\n- 最大値・最小値：値が許容される範囲に収まっているか確認する\n- 最大長・最小長：特定の桁数要件をもつフィールドの外れ値や異常値を検出する\n- 度数分布：値の妥当性を評価する（トランザクションの国コードの分布など）\n- データ型とフォーマット：フォーマット要件への不適合を検出する（小数点以下の桁数、スペースの混入など）\n\nなお、プロファイリングの実施はツールを利用すると効率よく実施できます。ここでは、弊社が提供するオールインワンデータ分析プラットフォーム「Dataiku」を利用した例を紹介します。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103236\u002Ffigure0005.png)\n:::small\n図5：Dataikuを使ったデータセットへのクエリ\n:::\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103237\u002Ffigure0006.png)\n:::small\n図6：Dataikuを使ったデータプロファイリング\n:::\n\nDataikuのようなデータ視覚化機能や、複数データセットへのクエリが容易に発行できる機能を持つツールの活用は、データ探索やプロファイリングにおいて、特に重要になります。\n\n**データ品質管理対象の選定**\nプロファイル結果と対象項目のビジネス影響を踏まえ、データ品質管理対象にするか否かを判定します。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103235\u002Ffigure0007.png)\n:::small\n図7：データ品質管理対象の選定イメージ\n:::\n\nビジネス影響は、影響範囲の大きさ（部門間にまたがる影響）やそのデータ品質を損なわれることによるリスクの大きさにより度合いを決めます。例えば、モデルケースの場合、顧客に関する情報のビジネス影響を高く設定しています。これは、販促メールの重複送信や誤った情報を配信することにつながるためです。\n\n管理対象の選定では、プロファイル結果とビジネス影響度を総合して要否を判定します。例えば、現状のエラー件数が多くても（データ品質の品質が低くても）、ビジネス影響が低ければ、対象としなくても良いという場合があります。最終的な判断に際しては、ステークホルダーとの協議・合意形成を図ります。\n\n### ③データ品質基準の策定\n「②データ品質管理対象の選定」で選定したデータ品質管理対象の項目に対して、データ品質測定方法やデータ品質の許容閾値、許容閾値を超えた場合の対応などのSLAを定義します。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103231\u002Ffigure0008.png)\n:::small\n図8：データ品質基準の策定イメージ\n:::\n\nデータ品質の測定方法は、実施タイミングや対応組織・担当者および具体的な実施方法まで落とし込みます。また、守るべきデータ品質の水準（図8では適合件数の割合で記載）を閾値として設定します。この閾値はデータ品質の目標値にもなるため、目標を達成するためのコストとのバランスも考慮する必要があります。\n\n### ④運用フローの策定\n「③データ品質基準の策定」まででデータ品質の測定方法および基準を策定できました。最後は、データ品質で問題が発生した場合の対応手順や定期報告などの運用フローを定義します。\n\n![](https:\u002F\u002Fs3-ap-northeast-1.amazonaws.com\u002Fledge-ai-assets\u002Fmedia\u002Fwp-content\u002Fuploads\u002F2023\u002F05\u002F29103227\u002Ffigure0009.png)\n:::small\n図9：運用フローの策定イメージ\n:::\n\nここでのポイントは、問題発生時の対応タイミング（対応期限）や実施方法、定期報告のタイミング（日時）や対応者を可能な限り定義しておくことです。これにより、問題が発生した場合にいつまでに誰が責任をもって対応するのか明確になり、問題が放置されることを防ぐことができます。\n\nまた、定期報告は業務部門などステークホルダーを巻き込んで実施することで成果をアピールすることにもつながり、継続的な取り組みを推進するためのスポンサーを得ることも期待できます。\n\n## おわりに\n今回は、データ品質管理の進め方について解説しました。データ品質管理は、戦略的に実施していく必要があります。ビジネス上の目的に沿った形でデータ品質管理の対象となるデータの選定と基準の策定、誰が・いつ・どのように対応するのかといった運用も検討しておくことが重要です。\n\nここまでで、データ品質管理のPDCAサイクルを回すことができるようになりました。しかしながら、この取り組みを継続的に実施し、定着化させるには運用の効率化が欠かせません。また、冒頭で述べた4つの課題のうち、残す以下の2つについても対応が必要になってくることでしょう。\n\n- データソースの多様化によるデータ品質管理の複雑さ\n- データを取り巻く人・プロセス・テクノロジーの変化への対応\n\nこれらの課題を解消するには、ツールやデータ品質管理を実現できるプラットフォームの助けが必要です。\n\n次回は、上述の「プロファイリングの実施」で紹介したDataikuを使って、データ品質管理を効率的に実施するために整備が必要な仕組みや実践例を紹介します。\n\n※文章中の商品名、会社名、団体名は、各社の商標または登録商標です。\n\n:::box\n[特集：データマネジメントの要！データ品質管理のことはじめ NTT先端技術連載 Vol.1～3](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Fintellilink_data_management)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/data-management-2</title>
      <link>https://ledge.ai/articles/data-management-2</link>
      <description>※この記事は、NTTデータ先端技術株式会社による[コラム](https:\u002F\u002Fwww.intellilink.co.jp\u002Fcolumn\u002Fdx\u002F2023\u002F053100.aspx){target=“_blank”}からの転載です。\n\n## はじめに\n本コラム「データマネジメントの要！データ品質管理のことはじめ」は、3回に分けてお送りしています。第1回では、「データ品質管理とは」と題し、データ品質管理の基本的な概念と実践する際の課題について述べました。第2回では、「データ品質管理の進め方」と題し、DMBOKに沿ってデータ品質管理を進めるにあたっての作業ステップと検討内容などを解説しました。これまでの記事をまだ読んでいない方は、ぜひ以下からご覧ください。\n\n:::box\n[第1回「データ品質管理とは」](https:\u002F\u002Fledge.ai\u002Farticles\u002Fdata-management-1)\n:::\n\n:::box\n[第2回「データ品質管理の進め方」](https:\u002F\u002Fledge.ai\u002Farticles\u002Fdata-management-2)\n:::\n\nこれまでの解説で、データ品質管理のプロセスとフローを定義しました。しかしながら、データ品質管理を継続的な取り組みとして、定着させるには運用の効率化が欠かせません。\n\n今回は、データ品質管理の運用における課題とそれらを解消し、効率よく運用するための仕組みをどのように構築していくのか、解説していきます。\n\n## データ品質管理の効率化が必要になる背景と課題\n[前回](https:\u002F\u002Fledge.ai\u002Farticles\u002Fdata-management-2)策定したデータ品質管理の運用フローが示すとおり、データ品質管理を効果的に行うには、データ品質の評価や監視やデータ品質への問題対処、レポーティングなどのプロセスを継続的に実施していく必要があります。\n\nしかしながら、それらのプロセスは時間と労力（コスト）を要する場合があることや、データ品質管理の対象が増えると、[第1回](https:\u002F\u002Fledge.ai\u002Farticles\u002Fdata-management-1)で述べた次の点についても考慮が必要になるでしょう。\n\n- データソースの多様化によるデータ品質管理の複雑さ\n- データを取り巻く人・プロセス・テクノロジーの変化への対応\n\nでは、具体的にどのような課題が発生するのかを前回策定した運用フローで見ていきます。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage1_0260ebd431\u002Fimage1_0260ebd431.png)\n:::small\n図1. データ品質管理の運用フローと主な課題\n:::\n\n**①\tデータソースの多種多様化によるデータ品質管理の複雑化**\nデータを活用する業務によってデータに求められる品質要件は異なります。その業務で必要とされるデータの種類は、構造化データだけでなく、非構造化データも含まれることがあります。また、格納場所についても、オンプレ・クラウド問わず対象になることも想定され、データソースとルールの対応付けなどの管理が複雑化してしまいます。\n**②\tデータ品質の継続的な監視にかかるコスト**\nデータ品質の監視は継続的に実施する必要があります。監視する対象が増えると都度の品質評価および、データ品質の問題発生時の通知先の管理など運用が煩雑になってしまいます。\n**③\tデータ品質問題発生時の原因特定やデータ修正の作業負荷増大**\nデータ品質の問題に対処する際、問題が発生する度に人手での原因特定およびデータ修正は時間と労力がかかるものです。また、SLAを遵守しながら複数の問題の対処をする場合に作業負荷は増大してしまいます。\n**④\t関係者間のコミュニケーションコスト**\nデータ品質管理は IT部門と業務部門が協調して実施する必要があります。データ品質はビジネス要件によるため、データ品質の状況はデータの利用者に適切に共有することが重要です。そのコミュニケーションコストが増えると取り組みが滞ってしまいます。\n\nこれらの課題を解決し、データ品質管理を効率よく実施していくには、どのような対策が必要になるのでしょうか。\n\n## データ品質管理を効率化するには\nデータ品質管理を効率化するには、その取り組みを支えるテクノロジーを整備することが重要になります。DMBOKにおいても、「IT上の推進要因」として以下の「ツール」と「技法」が述べられています。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage2_d3671d2607\u002Fimage2_d3671d2607.png)\n :::small\n図2. IT上の推進要因となるツールと技法\n:::\n\nツールには、データの理解や品質の問題に対する原因特定および対処を手助けし、データ品質のチェックやモニタリング、それらを管理するものが述べられています。また、技法には、ツールを活用し、データ品質を継続的に改善するための要素が述べられています。\n\nつまり、「ツール」と「技法」を活用することで、データ品質管理を効率よく実施するための”仕組み“を作るものと考えることができます。これを踏まえた解決方法は次の通りです。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage3_991f1f47e5\u002Fimage3_991f1f47e5.png)\n:::small\n図3. データ品質管理課題と解決方法\n:::\n\n![image12.png](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage12_d31ddcb3bc\u002Fimage12_d31ddcb3bc.png)\n\n上述のとおり、様々な（下線部に示す）ツールを組み合わせることで、データ品質管理の仕組みを構築できるように思えます。しかしながら、一連のプロセスを動かすには、異なるツール間を相互に連携することが求められ、高度なITスキルが求められることは想像に難しくありません。従って、システムの開発だけでなく運用においても、専門性を持った多くのITエンジニアを抱える必要があります。自社で人材確保が難しい場合は、運用コストの観点で一考の余地がでてきます。\n\nこれらのすべての課題を解決するには、「オールインワンプラットフォーム」の利用が選択肢の一つとしてあげられます。本稿では、Dataikuというデータ分析プラットフォームで実現する例を紹介します。\n\n## オールインワンプラットフォーム「Dataiku」を使った例\n本稿で紹介する「Dataiku」は、データ接続から、データの準備、機械学習モデルの構築、本番運用まで一つのプラットフォーム上で完結でき、IT部門や業務部門などあらゆる役割のユーザーが共同作業できることが大きな特徴となっています。\n\n品質の高いデータは、「利用者の活用目的に合致しているデータ」のことを指しますが、オールインワンプラットフォームを利用すると、データの利用者からシームレスにデータ品質に関する改善のフィードバックを得られるようになり、効果的な改善サイクルを回すことが可能になります。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage4_f9ff27a4ff\u002Fimage4_f9ff27a4ff.png)\n:::small\n図4. Dataikuを使った場合の全体イメージ\n:::\n\nDataikuを使うと、データ品質管理の仕組みをどのように実現できるのか、次に紹介します。\n**①\tデータ品質チェックルールの一元管理**\nデータ品質チェックルールの一元管理を実現するには、一つのプラットフォームで多種多様なデータへの接続ができることと、接続したデータに対するデータ品質チェックを一元的に実施できることが重要です。Dataikuでは、以下の機能を活用することができます。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage5_7aeeef5b87\u002Fimage5_7aeeef5b87.png)\n:::small\n図5. 多種多様なデータソースに対応したコネクタ\n:::\n\n- データの格納場所や構造化・非構造化データ問わず、様々なデータソースに対応したコネクタを利用しデータへ接続\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage6_f80bf0379e\u002Fimage6_f80bf0379e.png)\n:::small\n図6. メトリクスとチェック\n:::\n\n- 接続したデータセットに対して、欠損値の数や値の範囲などの評価指標（メトリクス）と許容値（チェック）などのデータ品質チェックルールを設定\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage7_60fc99949b\u002Fimage7_60fc99949b.png)\n:::small\n図7. データセットと品質チェックルールの紐づけ\n:::\n\n- データセットに設定した品質チェックルールはデータセットのStatus（データ品質チェックルールやチェック結果）として紐づけて管理\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage8_19d14c3971\u002Fimage8_19d14c3971.png)\n:::small\n 図8. 非構造データのメタデータ抽出とデータセット化\n:::\n\n- 非構造データに対してはPython コードを使いメタデータを抽出し、データセットとして出力。構造化データ同様にデータ品質チェックルールを適用\n\n**②\tデータ品質監視の定型化・自動化**\nデータ品質監視の定型化・自動化を実現するには、品質チェック結果の自動収集と監視を行い、データ品質に問題が発生した場合は、予め設定した通知先へ自動的にアラート通知を行う仕組みの構築が必要です。Dataikuでは、品質の監視と、問題発生時の通知先として様々なチャネルに対応しています。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage9_ad6a8f4c3e\u002Fimage9_ad6a8f4c3e.png)\n:::small\n図9. データ品質の監視・アラート通知\n:::\n\n- 新しいデータの取り込みやデータが更新されたタイミングでメトリクスの算出とチェックルールを実行し、結果を監視\n- データ品質に問題があった場合の通知先とチャネルを設定\n\n**③\t自動・半自動によるデータ修正**\nデータ品質に問題があった場合の対処を定型化できるところは自動的に実施することで効率化できます。Dataikuでは、データプリパレーション機能を使ったパイプラインの構築と自動実行のためのシナリオ機能（トリガー）で実現できます。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage10_a7ea46cff8\u002Fimage10_a7ea46cff8.png)\n:::small \n図10. データクレンジングの自動化\n:::\n\n- データプリパレーション機能を使いデータクレンジングのパイプラインを構築\n- データ品質に問題が発生した場合に自動実行するためのトリガーの設定\n- 人手の判断が必要な場合は、データを確認後、データクレンジングのパイプラインを手動実行\n\n**④\tデータ品質モニタリングダッシュボード**\nデータ品質状況は関係者に常に共有できる状態にしておくことで、コミュニケーションの円滑化にもつながります。Dataikuでは、データの可視化とダッシュボードの構築が容易にできます。\n\n![](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fimage11_abb425128d\u002Fimage11_abb425128d.png)\n:::small\n図11. モニタリングダッシュボード\n:::\n\n- データ品質の評価結果はデータセット化し、可視化\n- モニタリングダッシュボードを構築\n\nこのようにオールインワンプラットフォームを利用すると、データ品質管理に必要なツールをシームレスに活用できるため、データ品質管理の仕組みを容易に構築することができます。また、Dataikuのようなノーコードツールであれば、業務部門のユーザー自ら実装し運用することも可能になるでしょう。実際にDataikuの導入したお客様では、内製開発からオールインワンプラットフォームにシフトしたことで、「乱雑に配備されたツール類による非効率さが解消された」といったことや、「そのデータが何を意味するのか、どこから得たデータなのかをスタッフが理解できデータ品質が向上できた」といった効果を述べられています。データ品質管理を継続的な取り組みとして定着させるには、オールインワンプラットフォームの導入も有効な方法の一つとなります。\n\n## おわりに\n本コラムでは全3回にわたって、データ品質管理の重要性や進め方、効率的に運用するために必要なツールの整備、実践方法について解説してきました。\n\nデータから価値を効果的に引き出すにはデータ品質が重要になります。\n\nデータ品質管理は、データマネジメントにおける土台となる要素の一つで、企業のビジネス目的に沿った形で行われる戦略的な取り組みであり、DXおよびデータ駆動型ビジネスの成否を分けると言っても過言ではありません。\n\nデータ品質は一朝一夕に向上するものではなく、地道な取り組みになります。\n\nデータに求められる品質の要件はビジネス環境と共に変化し、テクノロジーの進化によっても変わってきます。決まった正解があるものではなく、繰り返し実施して改善する、これを業務に組み込んでいくことが重要です。データ品質は、常に業務と利用者のニーズを考えながらアクションを検討し実施することで改善されます。その取り組みは、企業の競争力を高め、目標に向かって前進させることにも役立つものと考えています。\n\nデータ品質管理の進め方やその実践方法について、本コラムが参考になれば幸いです。\n\n:::box\n[特集：データマネジメントの要！データ品質管理のことはじめ NTT先端技術連載 Vol.1～3](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Fintellilink_data_management)\n:::</description>
      <pubDate>Fri, 23 Jun 2023 10:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/data_management_3</title>
      <link>https://ledge.ai/articles/data_management_3</link>
      <description/>
    </item>
    <item>
      <title>https://ledge.ai/articles/alts-cto-series</title>
      <link>https://ledge.ai/articles/alts-cto-series</link>
      <description>:::box\n**ChatGPTを始めとした生成型AIのニュースは現在、飽和していると言えるほどだ。しかし、そもそも生成型AIとは何なのか、口で説明できる人がどれくらいいるだろうか？改めて、生成型AIとは一体何か、どのような仕組みで動いているのかを確認しておくことには、大きな意味があるだろう。そこで今回、NLP若手の会委員長や言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任し、数々の論文で受賞歴を持つ、株式会社オルツの最高技術責任者 西川 仁氏に、全4回の連載で解説してもらった。本稿は1回目。**\n:::\n\n![nishikawa.jpeg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fnishikawa_81d8b94200\u002Fnishikawa_81d8b94200.jpeg)\n\n:::box\n**＜著者プロフィール＞\n株式会社オルツ 最高技術責任者　西川 仁（にしかわ・ひとし）**\n慶應義塾大学大学院政策・メディア研究科修士課程修了。奈良先端科学技術大学院大学博士後期課程修了（優秀奨学生として短期修了）。IE Business School (with Beta Gamma Sigma Honor) 修了。博士（工学）、MBA。日本電信電話株式会社にて自然言語処理の基礎研究から商用開発、実用化まで一貫して従事。東京工業大学情報理工学院にて助教として人工知能の研究開発、教育、コンサルティング等を実施。データコンサルティングベンチャーにて執行役員として新規事業開発、開発組織マネジメント、データ基盤構築、投資家コミュニケーションに従事。その後現職。学会活動においてはNLP若手の会委員長、言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任。言語処理学会最優秀論文賞、言語処理学会年次大会優秀発表賞、情報処理学会特選論文など受賞多数。言語処理学会、人工知能学会会員。情報処理学会シニア会員。 Association for Computational Linguistics 会員。\n:::\n\n## 人間が書くテキストを高度に模倣する生成型AI\nChatGPTの登場以来、テキストや画像を生成するAIへの注目が著しく高まっています。この連載では、これら何らかのテキストや画像といったものを生成するAIを便宜的に生成型AIと呼ぶこととします。この種類のAIは、生成系AI、生成AI、また生成以外の分類などのタスクなどもこなせることから基盤AIとも呼ばれるなど、様々な呼び方がありますが、本連載では生成型AIと呼ぶことにします（英語でのGenerative AIをどのように訳出するかというだけの問題であるため本連載ではその点を特に重視しません）。特にその中でもテキストを生成するものについて、その実態について解説したいと思います。\n\nまず、ChatGPTもこの生成型AIの一種に分類することができます。ChatGPTに触ったことがある方はよくご理解いただけると思いますが、生成型AIは入力に対して流暢なテキストを出力します。この実態としては、生成型AIは人間の知的活動の一部である、文章を書く、やや技術的な言い方をしますと、テキストを生成することができるプログラムである、ということができます。\n\n内部的にどのように動作しているかということについては後述するとしまして、この生成型AIは人間が書くテキストを高度に模倣することができます。例えば、文章の要約を行ったり、何らかの質問に回答したり、メールに返信したり、またテーマに沿って記事を書いたり、記事の骨子を作成するといったことができます。\n\n## 基盤となる「大規模言語モデル」とは？\n基本的な機構としては、ChatGPTに代表される、特にテキストを生成する生成型AIは「大規模言語モデル」と呼ばれるものが基盤となっています。この機構についても後述しますが、インターネット上に存在するテキストや書籍などの大量のテキストから、人間がかく、「もっともらしい」テキストとはどのようなものか、といったことを大規模言語モデルは学習しています。\n\n現時点においては、この大規模言語モデルは、条件反射的な動作をしているに過ぎず、人間から与えられた何らかの指令に対して、もっともらしい回答を内部的に計算し、出力します。ちなみにこの指令を与える際の入力欄をプロンプトといいますが、これは計算機を利用したことがある方には馴染み深いものだと思いますが、本来の動詞としての意味は「〜をすることを促す」というもので、まさに人間が計算機、この場合は大規模言語モデルに対してプロンプトを通じて何らかの出力を促していると言うことができます。\n\nこの大規模言語モデルは、多少の差こそあれ、その構造は大きく変わりません。OpenAIがChatGPTを公開した際にGoogle社が大変な危機感を覚えたという報道がありましたが、そもそもChatGPTに使われている基本的なモジュールはGoogle社を中心にして開発され、2017年に発表されたものです。ChatGPTの後に公開されたGoogle社のBardやmeta社のLLaMAなども、構造としては大きく変わりはありません。\n\n## 大規模なテキストのみを与えるだけでさまざまな作業が可能になった\nChatGPTの印象深い点は、非常に自然な対話、すなわちチャットをその名の通り行うという点にあります。この点についてはまず説明していきたいと思います。そのためには、まず、ChatGPTの基盤となっている過去のGPTについて解説する必要があります。\n\nGPTはトークン(Token)といった単位で言語を処理しています。トークンは概ね単語と対応していますが、人間が扱いやすいように定義した単語（そもそも日本語においては単語という単位に関して議論があります）とは異なり、計算機によって処理しやすい単位となっています。内部的には、GPTは、プロンプト経由で入力されたテキストをトークン単位の列として処理し、トークンの列をテキストとして出力しています。入出力は文ないし文章を構成している単語の列である、と理解していただければわかりやすいのではないかと思います。\n\nGPT-3は概ね3種類の文章から訓練されています。ここでいう訓練という言葉は、GPT-3が自然なテキストを生成するために、人間が書いたテキストから自然なテキストとはどういうものか、すなわち、自然なトークンの列とはどういうものか、と学習する過程であると考えてください。1つめはインターネット上から収集されたテキストで、これには4129億トークンが含まれています。2つめは書籍であり、670億トークンが含まれています。最後に、英語のウィキペディアのテキストであり、30億のトークンが含まれています。これらのテキストは多言語のものであり、またトークンという単位に基づいているため、一概に日本語に換算するのは難しいのですが、合計4829億トークンが含まれ、これを単語数だと便宜的に考えますと、概ね日本語の中編小説の文庫本929万冊からGPT-3は訓練されたということが言えます。\n\nGPT-3が興味深い点は、これはGPT-2の時点から理解されていましたが、一般的なテキストを与えるだけで、例えば翻訳のために対訳文、例えば日本語から英語の翻訳であれば、日本語と英語で意味的に対応している文をそれぞれ与えなくても、翻訳ができる、という点です。これが意味することは、特に特定の作業、例えば翻訳や要約のための訓練データを与えることなく、大規模なテキストのみを与えるだけで、人間が行う様々な作業を計算機が実施できる、という点です。\n\n計算機にテキストを処理させる分野、テキストを生成するAIを研究する分野は自然言語処理と呼ばれます。自然言語処理の世界では、これまで、機械翻訳のためには機械翻訳のためのデータを用意することが重要でしたが、そうではなく、単に多言語の大規模なテキストを与えるだけで自然に翻訳が可能になった、という点が驚くべき点です。\n\n## ChatGPTはGPTを会話用に訓練したもの\nこの観点からChatGPTを見ますと、ChatGPTは、GPT-3という、特定の目的にために作られてはいないものの、様々なテキスト生成に関する作業を行うことのできるプログラムを、より自然なチャットができるように特別に訓練したものである、ということができます。ChatGPTは、GPT-3が出力する様々なテキストに対して、人間がより応答として自然だと考えるテキストに対して高い得点を与えることによって訓練されました。ChatGPTから見ますと、人間によって、自然である、と評価された応答を教えられていますから、この基準に則ってテキストを出力するようになります。\n\nこのように見ますと、GPT-3の時点で既に一定の能力をこの生成型AIは保持していましたが、人間によるフィードバックを得ることによって、人間にとって驚異的であるほどの応答を生成することが可能になった、ということが言えます。したがいまして、ChatGPTの本質は第一に自然なテキストを生成する能力にあります。その能力は言語モデルと呼ばれますが、言語モデルについては次回解説したいと思います。\n\n:::box\n[特集：生成AIを解き明かす。オルツCTO連載 Vol.1～4](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Falts-cto-series)\n:::\n\n:::box\n[関連記事：ChatGPTとは？【2023年5月版】｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Fchatgpt\u002F)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/alts-1</title>
      <link>https://ledge.ai/articles/alts-1</link>
      <description>:::box\n**ChatGPTを始めとした生成型AIのニュースは現在、飽和していると言えるほどだ。しかし、そもそも生成型AIとは何なのか、口で説明できる人がどれくらいいるだろうか？改めて、生成型AIとは一体何か、どのような仕組みで動いているのかを確認しておくことには、大きな意味があるだろう。そこで今回、NLP若手の会委員長や言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任し、数々の論文で受賞歴を持つ、株式会社オルツの最高技術責任者 西川 仁氏に、全4回の連載で解説してもらった。本稿は2回目。**\n:::\n\n![nishikawa.jpeg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fnishikawa_81d8b94200\u002Fnishikawa_81d8b94200.jpeg)\n\n:::box\n**＜著者プロフィール＞\n株式会社オルツ 最高技術責任者　西川 仁（にしかわ・ひとし）**\n慶應義塾大学大学院政策・メディア研究科修士課程修了。奈良先端科学技術大学院大学博士後期課程修了（優秀奨学生として短期修了）。IE Business School (with Beta Gamma Sigma Honor) 修了。博士（工学）、MBA。日本電信電話株式会社にて自然言語処理の基礎研究から商用開発、実用化まで一貫して従事。東京工業大学情報理工学院にて助教として人工知能の研究開発、教育、コンサルティング等を実施。データコンサルティングベンチャーにて執行役員として新規事業開発、開発組織マネジメント、データ基盤構築、投資家コミュニケーションに従事。その後現職。学会活動においてはNLP若手の会委員長、言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任。言語処理学会最優秀論文賞、言語処理学会年次大会優秀発表賞、情報処理学会特選論文など受賞多数。言語処理学会、人工知能学会会員。情報処理学会シニア会員。 Association for Computational Linguistics 会員。\n:::\n\n## そもそも「自然なテキスト」とはどういうことか？\n今回は生成型AI、特にテキストを生成するAIの歴史について解説していきます。そのためにはまず、言語モデルと呼ばれるものについて言及する必要があります。言語モデルとは、端的に言えばより自然なテキストに対して高い確率を与えるアルゴリズムです。まずこのテキストの自然さ、というものについて考えてみましょう。\n\n「今日はまだ私は昼食を……」というテキストがあったときに、次にどのようなテキストが想像されるでしょうか。「……」に入るべきテキストはおそらく「食べていません」となると思います。これは、もし、「私」が既に昼食を取っていたのであれば「まだ」という単語を使うことが不自然であるためで、「今日はまだ私は昼食を食べました」というテキストを日本語母語話者の方であれば奇妙なものであると感じられると思います。この場合であれば、「今日はまだ私は昼食を食べていません」とする方が自然です。\n\nもし仮に手元に大量のテキストがあるとしますと、「まだ」のあとに「いません」といった単語（文法に関する厳密に議論は除外しここでは便宜的にこれらが単語であるとしておきます）が出てきやすいといった傾向を計算機に学習させることは可能そうであり、実際に計算機はそれを学習しています。\n\nより具体的には、「今日はまだ私は昼食を食べていません」というテキストが生起する（やや硬い表現になりますが出現する、発生する、というものとお考えください）確率は「今日はまだ私は昼食を食べました」というテキストが生起する確率より高く評価されます。計算機がより自然なテキストに高い確率を与えることができるのは、大量のテキストから、人間が記述したテキストの傾向を学習し、自然なテキスト、すなわち大量のテキストの中に含まれている文字や単語の使い方の傾向に合致したテキストはどのようなものか、ということを学習できるからです。\n\n## 大規模言語モデルはテキストの自然な「続き」を出力する\nさて、そもそもなぜ言語モデルが必要なのでしょうか。ChatGPTなどは大規模言語モデルと呼ばれますが、上の説明からは、要はとにかく自然なテキストを生成してくれるプログラムである、ということになりますので、その必要性は自明ではあります。ただ、やや歴史的背景を一部説明させていただいた方が、より理解が深まるものかと思います。\n\n身近な例では言語モデルはまず機械翻訳のために必要でした。以下の英語の文を考えてみます。\n\n　**「I could not eat lunch.」**\n\nこの文を、英日辞書などを使い文頭から1単語ずつ訳していきますと、以下のような日本語の文ができあがります。\n\n　**「私　できた　ない　食べる　昼食　。」**\n\n必ずしも意味が通らなくはないですが、明らかに不自然な文です。日本語の活用（「できる」の否定形が「できない」といったものです）は一旦考えずに自然な順序にこれを並べ直しますと以下のようになると思います。\n\n　**「私　昼食　食べる　できた　ない」**\n\nさらに単語の位置や活用を考えて補足しますと以下のようになるかと思います。\n\n　**「私は昼食を食べられなかった。」**\n\nこの場合言語モデルが必要な理由はまさに、「英日辞書の結果として得られた単語列を、自然な順序に単語を並べかえ、加えて単語の位置や活用にそって自然なものにすること」です。まずこのような能力を言語モデルは持っている、と考えてください。\n\n先ほどの例に戻りますと、優秀な言語モデルは「今日はまだ私は昼食を……」の続きとして「食べていません」というテキストを出力することができます。この能力を極端に強化したものがChatGPTに代表される大規模言語モデルです。「今日はまだ私は昼食を……」といった無味乾燥としたテキストではなく（本稿の著者は昼食を取る時間がないときがあり著者にとってこれは由々しき事態ではありますが）、その代わりに「『こんにちは！』と返してください。」と入力しますと、大規模言語モデルは「こんにちは！」と出力してくれます。「『今日は私はまだ私は昼食を食べて』の続きを書いてください。」と入力しますと、概ね、「いません。そのためお腹が空いています」といった出力が返ってきます。\n\nここまでの点を要約しますと、大規模言語モデルは入力されたテキストの自然な「続き」となるテキストを出力している、と理解できます。例えば、「（なんらかの長い文章）上の文章を要約してください。」と入力しますと大規模言語モデルは上記のなんらかの長い文章の要約を出力してくれます。これは大規模言語モデルにとって、入力に対する自然な出力とは、入力された長い文章を要約した結果であるからです。\n\n## 大規模言語モデルを動かすには適切な命令と補足情報が必要\n第1回でご説明したように、この入力はプロンプトと呼ばれます。ChatGPT等をお使いになったことがある方はご理解いただけると思いますが、ChatGPT等はこのプロンプトの内容に非常に敏感です。ここでいう敏感の意味では、プロンプトの内容によって著しく出力が異なる、ということを意味します。\n\n例えば、「何か記事を書いてください。」という入力を与えたとします。この場合、大規模言語モデルはまず、何かを「書かなければならない」ということを理解します（ここでの理解は人間的な意味での理解とは異なることに留意してください）。次に、書かなければならないものは「記事」であることが指定されています。このような場合、大規模言語モデルは何らかの記事らしきものを出力しますが、その記事の内容はナンセンスなものであったり、よくわからないものであったりします。これは、この入力における「記事」がどのようなものであるべきか指定されていないためです。所望の出力を得るためには、例えば、「神奈川県鎌倉市で2019年7月10日に開催された第71回花火大会は大変混雑したものの好評を博したという趣旨の新聞記事を書いてください。」といったような、具体的な指示を与える必要があります。\n\nこの入力を分解しますと、「書いてください」というある種の命令と、命令の内容を補足する何らかの追加情報の2つにわけることができます。これは要約や翻訳を大規模言語モデルに行わせる際も同様であり、「（なんらかの長い文章）上の文章を要約してください」という要約を行わせる場合においては、「要約してください」という命令と、要約の対象となる「（なんらかの長い文章）」という追加情報に分解することができます。翻訳の場合においても、例えば、「以下の文章を日本語から英語に翻訳してください。（日本語の文章）」という形で、「日本語から英語に翻訳してください」という命令と、翻訳の対象となる「（日本語の文章）」に分解することができます。\n\nこのように、大規模言語モデルは適切な命令と、それを補足する追加情報を適切に与えなければ動作しません。大規模言語モデルを擬人化することにはやや危険を伴いますが、どなたかに対して「何かしゃべってください」とお願いしたとしても、多くの方は困惑すると思われます。一方で、「今日のお昼の感想について話してください」ということであれば、一定の感想をお話しいただけるでしょう。\n\n:::box\n[特集：生成AIを解き明かす。オルツCTO連載 Vol.1～4](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Falts-cto-series)\n:::\n\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Fchatgpt\u002F)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/alts-2</title>
      <link>https://ledge.ai/articles/alts-2</link>
      <description>:::box\n**ChatGPTを始めとした生成型AIのニュースは現在、飽和していると言えるほどだ。しかし、そもそも生成型AIとは何なのか、口で説明できる人がどれくらいいるだろうか？改めて、生成型AIとは一体何か、どのような仕組みで動いているのかを確認しておくことには、大きな意味があるだろう。そこで今回、NLP若手の会委員長や言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任し、数々の論文で受賞歴を持つ、株式会社オルツの最高技術責任者 西川 仁氏に、全4回の連載で解説してもらった。本稿は3回目。**\n:::\n\n![nishikawa.jpeg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fnishikawa_81d8b94200\u002Fnishikawa_81d8b94200.jpeg)\n\n:::box\n**＜著者プロフィール＞\n株式会社オルツ 最高技術責任者　西川 仁（にしかわ・ひとし）**\n慶應義塾大学大学院政策・メディア研究科修士課程修了。奈良先端科学技術大学院大学博士後期課程修了（優秀奨学生として短期修了）。IE Business School (with Beta Gamma Sigma Honor) 修了。博士（工学）、MBA。日本電信電話株式会社にて自然言語処理の基礎研究から商用開発、実用化まで一貫して従事。東京工業大学情報理工学院にて助教として人工知能の研究開発、教育、コンサルティング等を実施。データコンサルティングベンチャーにて執行役員として新規事業開発、開発組織マネジメント、データ基盤構築、投資家コミュニケーションに従事。その後現職。学会活動においてはNLP若手の会委員長、言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任。言語処理学会最優秀論文賞、言語処理学会年次大会優秀発表賞、情報処理学会特選論文など受賞多数。言語処理学会、人工知能学会会員。情報処理学会シニア会員。 Association for Computational Linguistics 会員。\n:::\n\n## 生成型AIのユースケース\n今回は、生成型AIをどのように利用できるか、また利用の際の注意点、すなわち課題について述べたいと思います。\n\nこれまで説明してきたように、生成型AIは、テキストを生成するものに関して言えば非常に自然なテキストを入力に対して出力することができます。したがって、分かりやすい面においては以下のようなユースケースが考えられ、既に利用されています。\n\n### 翻訳\nテキストの翻訳。これは既に高い水準の機械翻訳が実現されていますが、生成型AIでも同様に翻訳が可能です。ただ、あくまで大規模言語モデルに関して言えば（これは他の専用の機械翻訳システムでも同様ですが）、インターネット上で広く利用されている言語に関しては高い品質の翻訳が可能ですが、あまり利用されていない言語に関しては、その言語のデータ量が少ないといった点から、出力の品質には注意を要する必要があります。\n\n### 要約\nテキストを短く要約することも可能です。この際には当然、要約の対象となるテキストが入力として必要となり、加えてそれを「要約してください」という指示も必要です。また、どれくらいの長さで要約して欲しいのか、また、集中的に理解したい部分があるのであれば、特にこの点について要約してください、といった指示が有効になるでしょう。\n\n### 記事等の作成\nもっともわかりやすいユースケースがこの記事等の作成になるでしょう。なんらかの主題に関する記事、あるいはレポートを生成させることができます。記事の見出しの案であったり、記事の骨子案であったり、または記事そのものを生成させることも可能です。何らかの主題に関してまとまったレポートを作成させる、といったことも可能です。このユースケースの場合、入力の際に大規模言語モデルに知識を追加することによって、より高品質なレポートを作成することができるでしょう。単に記事を作成させるだけではなくて、記事を書く際のアイデア出しにも、骨子案の作成を通じて利用することができます。\n\n### メールの返信\nメールの返信もわかりやすいユースケースです。ただし、届いた何らかのメールを入力として、このメールに返信してください、という指示だけでは、適切な返信を生成できない場合があるでしょう。これは、メールを返信する方、すなわちこの場合であれば生成型AIを利用する方ということになりますが、この方がどのような返信を望むか、といったことを生成型AIが知っている必要があるためです。例えばオンラインでのミーティングのための日程調整のメールを考えますと、メールを返信する方の都合がよい時間帯というものを生成型AIに与えなければ、適切な返信は期待できません。この点からは、生成型AIを他のシステム、この場合においてはカレンダーと連携して使う必要が当然に生じます。\n\n### 対話\nメールの返信と本質的には変わりません。何らかの問いかけや質問に対して適切な回答を行うことが生成型AIは可能です。ここで注意が必要である点は、ある特定の主題に関する対話を行わせたい場合、その主題に関する知識を入力しておく必要があるという点です。例えば、何らかサービス、例えば保険に関する問い合わせに自動対応する対話システムを想定してみます。この場合は、その保険がどのようなものであるのか、といった知識が当然適切な回答を生成させるためには必要ですし、また、問い合わせをなさった方に関する知識も必要になるでしょう。\n\n### 質問応答\nこれは対話と記事等の作成、要約の組み合わせとみなすことができますが、知りたいことに関してまとまったレポートを作成させることもできます。これは検索と類似していますが、いわゆる検索エンジンにキーワードを入力するのではなく、直接、知りたいことに関して自然言語で尋ね、自然言語で回答を得ることができます。まとまった文章を通じて情報を得ることができるのは大きな利点になるでしょう。\n\n上に述べた例は生成型AIの中でもテキストを生成するものに関するものであり、またごく一部のユースケースに過ぎません。今後、生成型AIが普及するにつれ、さまざまな用途に生成型AIが利用されることに疑いはなく、テキストや画像、音声などを扱う分野において、これまで人間が人手で作成していた様々なものが、機械によって生成されるようになるでしょう。\n\n## 生成型AIを利用する際の注意点とは？\n次に、上のユースケースを踏まえて、生成型AIを利用する際の注意点について述べてみたいと思います。\n\n第一に、上の例で指摘しましたように、適切な出力を得るためには適切な入力を与えなければなりません。第2回で述べましたように、生成型AIは入力に対して非常に敏感であり、わずかな入力の差が大きく出力に影響することがあります。すなわち生成型AIに対して指示を与えるプロンプト、このプロンプトをいかに適切に作成するか、といった点が大きな課題となっており、適切なプロンプトを探索し作成する作業は「プロンプト・エンジニアリング」(Prompt Engineering)と呼ばれています。生成型AIに対して適切な指示を出すことができるか、という点は今後生成型AIを利用するにあたって重要な点になります。\n\n第二に、これは第一の点とも関係しますが、出力に期待される内容に必要となる事前知識を収集し入力する、という点です。当然ですが、出力に含まれて欲しい情報が特に、専門的な内容であったり、インターネットに公開されていない社内の情報であったり、個人の情報であったりする場合、これらを生成型AIに入力しない限りは、適切な出力を期待することはできません。この点はプライヴァシーや、秘匿が必要な情報に関する扱いとも関連し、その扱いは簡単ではありません。\n\n第三に、出力の信頼性という観点です。これは第一の点と第二の点から導き出されるものですが、生成型AIは非常にもっともらしいテキストを生成しますが、それが事実でないことがままあります。この現象はハルシネーション(Hallucination)と呼ばれており、幻覚、まやかし、と直訳することができると思いますが、人間が読んだ限りではとてもそれらしいテキストなのですが、事実と反したことが出力されることがあります。極端な例を考えますと、事実に反するテキストだけで訓練された大規模言語モデルを想定しますと、その大規模言語モデルが出力するテキストは、何らかの追加情報を与えない限りでは、事実に反することだけを出力することになります。果たして実際に適切な応答が生成されているか、という点については特に注意が必要であり、特にレポートや記事などを生成型AIに作成させる場合には、その出力に対して、利用者自身が慎重な吟味を行う必要があるでしょう。\n\n:::box\n[特集：生成AIを解き明かす。オルツCTO連載 Vol.1～4](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Falts-cto-series)\n:::\n\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Fchatgpt\u002F)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/alts-3</title>
      <link>https://ledge.ai/articles/alts-3</link>
      <description>:::box\n**ChatGPTを始めとした生成型AIのニュースは現在、飽和していると言えるほどだ。しかし、そもそも生成型AIとは何なのか、口で説明できる人がどれくらいいるだろうか？改めて、生成型AIとは一体何か、どのような仕組みで動いているのかを確認しておくことには、大きな意味があるだろう。そこで今回、NLP若手の会委員長や言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任し、数々の論文で受賞歴を持つ、株式会社オルツの最高技術責任者 西川 仁氏に、全4回の連載で解説してもらった。本稿は4回目。**\n:::\n\n![nishikawa.jpeg](https:\u002F\u002Fstorage.googleapis.com\u002Fledge-ai-prd-public-bucket\u002Fmedia\u002Fnishikawa_81d8b94200\u002Fnishikawa_81d8b94200.jpeg)\n\n:::box\n**＜著者プロフィール＞\n株式会社オルツ 最高技術責任者　西川 仁（にしかわ・ひとし）**\n慶應義塾大学大学院政策・メディア研究科修士課程修了。奈良先端科学技術大学院大学博士後期課程修了（優秀奨学生として短期修了）。IE Business School (with Beta Gamma Sigma Honor) 修了。博士（工学）、MBA。日本電信電話株式会社にて自然言語処理の基礎研究から商用開発、実用化まで一貫して従事。東京工業大学情報理工学院にて助教として人工知能の研究開発、教育、コンサルティング等を実施。データコンサルティングベンチャーにて執行役員として新規事業開発、開発組織マネジメント、データ基盤構築、投資家コミュニケーションに従事。その後現職。学会活動においてはNLP若手の会委員長、言語処理学会代議員、情報処理学会自然言語処理研究会幹事などを歴任。言語処理学会最優秀論文賞、言語処理学会年次大会優秀発表賞、情報処理学会特選論文など受賞多数。言語処理学会、人工知能学会会員。情報処理学会シニア会員。 Association for Computational Linguistics 会員。\n:::\n\n## 生成型AI利用の流れは止められない\n最後に、生成型AIの今後について考えてみたいと思います。既に生成型AIは技術に敏感な方々が積極的に利用していますし、一般の方々への普及も急速に進んでいます。レポート作成の補助に生成型AIを利用している学生は多数いることでしょう。\n\nまず、この流れを止めることは不可能です。人間は便利なものであればそれを手放すことはありません。著作権や倫理、教育上の問題など、様々な懸念が提示されていますが、いくら利用を禁止したとしても、なんらかの形で利用され続けることでしょう。むしろ、積極的にこの生成型AIを使いこなせるように努力すべきです。今後、生成型AIを使いこなすことができる方々とそうでない方々の間には大きな生産性の差が生じることは間違いありません。言うなれば、生成型AIを味方として利用できるようになること、が非常に重要になります。\n\nまた、職場に生成型AIが導入された方も多いと思います。ここで本来考えるべきことは、そもそも書く必要のある文書を書いているのか、ということです。職場での繁文縟礼のため、無意味な文書が書かれていないでしょうか。誰も読むことのない報告書や日報が大量に蓄積されていませんでしょうか。報告書や日報に対するテキストマイニングは既に一定の歴史を持っていますが、このままでは計算機が書いた文書を計算機が分析するという奇妙な状況が出現します。そもそも本当にその文書作成業務は必要なのでしょうか？\n\n## 自然なテキストを書くAIが誕生した以上、人が書く文書の存在意義を問う必要がある\n非常に自然なテキストを書く能力を計算機が獲得した以上、そもそもテキストである文書の存在意義を問う必要があります。その文書を書く必要性の吟味、文書で伝えるべきである要点、要点を的確に伝えるべき構成、こういった点に利用者はより注意を払い、これらの点に知的活動を集中させるべきでしょう。加えて、何かを評価する際に、レポートといったテキストを通じて評価を行うことが困難になってきています。計算機が出力したテキストや計算機の補助を受けて書かれたテキストは非常に自然なものですから、ある方の人事評価を、レポートを通じて行うことはあまり意味のないことになるかもしれません。\n\n生成型AIは、適切な事前知識さえ与えれば、かなり難しい試験を通過するだけの性能を持っています。何らかの資格試験等において、当該試験に必要な情報を入力し、質問を与えれば、適切な回答を選択する能力を持っています。この点においては、知識量を問うような試験に関しては既に生成型AIは多くの人間より高い性能を持っています。その意味では、雑駁な例えとなりますが、生成型AIは大学に入学することはできるでしょう。おそらく卒業することも可能でしょう。ただし、博士号を取ることができるか、というとまた別問題となってきます。科学の世界において、それが小さいものであっても、ある種の発明を行うことはまだ生成型AIにとって難しい問題です。\n\nこのような発明を行わせるAIも開発が進んでいますが、あくまで特定の領域に特化したプログラムとして開発が進んでいます。すなわち、あくまで人間が設定した問題をより効率的に解く、新しい解法を見つける、といったことは可能となりつつありますが、そもそも人間がそのようなプログラムをそういった問題を解けるように作成しているのであって、計算機自体が自律的に新しいことを発明する、という段階には至っていません。\n\n## 生成型AIを基礎とする、次の何かが生まれる？\n上記のような発明が、人間が何かしら特定の目的のためにプログラムを設計しなくとも、可能になった際に汎用人工知能（この定義については様々な議論があります）と現在呼ばれているものが出現すると考えられますが、その観点から、今のChatGPTやGPT-4が汎用人工知能であるかというと疑わしい、というのが筆者の立場です。ただ、仮に、将来発明が可能な人工知能が開発されたとして、それが自然言語の入力および出力を受け付ける際には、現在の大規模言語モデルの利用されている技術が一つのモジュールとして利用される可能性はあります。一方で、この分野の技術の進歩は著しく、将来についての見通しは不透明です。\n\n今後について考えると、生成型AIの誕生には、大規模な計算資源とテキストデータの存在が不可欠でした。前者の計算資源については、クラウドコンピューティングや分散計算、ストレージの発達があり、さらに考えますと計算能力が安くなった、すなわち性能に比較して半導体の価格が安価になった、という基礎があります。後者については言うまでもなくインターネットの普及があり、大規模なテキストや音声、画像データを安価に収集することが可能となり、ビッグデータを取り扱うことが容易になった、という基礎があります。\n\nこれらの進歩が生成型AIの誕生の基礎になっています。このことから、今度は生成型AIを誕生の基礎とする次の何か、が当然想定されます。それが何か、というと、科学技術の進歩の観点から、現時点では予測は容易ではありません。ただ一つ言えることは、この潮流が止まることは考えづらく、この技術を利用することが今後社会生活を営む上で重要な要素となる、ということでしょう。\n\n:::box\n[特集：生成AIを解き明かす。オルツCTO連載 Vol.1～4](https:\u002F\u002Fledge.ai\u002Fcategories\u002Fcoverstory\u002Falts-cto-series)\n:::\n\n:::box\n[関連記事：ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと](https:\u002F\u002Fledge.ai\u002Fchatgpt\u002F)\n:::</description>
    </item>
    <item>
      <title>https://ledge.ai/articles/alts-4</title>
      <link>https://ledge.ai/articles/alts-4</link>
      <description/>
    </item>
    <item>
      <title>https://ledge.ai/articles/coverstory</title>
      <link>https://ledge.ai/articles/coverstory</link>
      <description/>
    </item>
    <item>
      <title>https://ledge.ai/articles/engineering</title>
      <link>https://ledge.ai/articles/engineering</link>
      <description/>
    </item>
    <item>
      <title>https://ledge.ai/articles/entertainment</title>
      <link>https://ledge.ai/articles/entertainment</link>
      <description/>
      <pubDate>Sun, 20 Aug 2023 06:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/adp_pronpt</title>
      <link>https://ledge.ai/articles/adp_pronpt</link>
      <description/>
      <pubDate>Sun, 20 Aug 2023 08:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/fandao_market_ai_aidol</title>
      <link>https://ledge.ai/articles/fandao_market_ai_aidol</link>
      <description/>
      <pubDate>Sat, 19 Aug 2023 04:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/stack_overflow_ai_wrong_answer</title>
      <link>https://ledge.ai/articles/stack_overflow_ai_wrong_answer</link>
      <description/>
      <pubDate>Sat, 12 Aug 2023 04:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/optical_neural_network</title>
      <link>https://ledge.ai/articles/optical_neural_network</link>
      <description/>
      <pubDate>Sat, 12 Aug 2023 02:00:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/pew_research</title>
      <link>https://ledge.ai/articles/pew_research</link>
      <description/>
      <pubDate>Mon, 14 Aug 2023 22:50:00 +0000</pubDate>
    </item>
    <item>
      <title>https://ledge.ai/articles/automated_lanes_tohoku_expressway</title>
      <link>https://ledge.ai/articles/automated_lanes_tohoku_expressway</link>
      <description/>
    </item>
  </channel>
</rss>
