<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Fri, 02 Aug 2024 08:18:11 +0000</lastBuildDate><item><title>失われた声をAIで取り戻すーー米連邦会議で、闘病中の下院議員がAIを使った「自分の声」で演説</title><link>https://ledge.ai/articles/speech_in_her_own_voice_with_ai-voice</link><description>:::small
画像の出典：{target=“_blank”}
:::

民主党下院議員のジェニファー・ウェクストン氏は2024年7月25日、米連邦議会で、AIを利用して再現された「自分の声」で{target=“_blank”}した。

ウェクストン氏は進行性核上性麻痺（PSP）という神経疾患を患っている。PSPは、脳の特定の領域に影響を与えるまれな神経変性疾患で、運動機能やバランス、眼球運動に関する困難を引き起こす。同氏のケースでは、特に発話機能が深刻に損なわれ、通常の会話や即興の演説が困難になっているという。また、歩行困難や転倒のリスクも高まり、最終的には車椅子が必要となることが多いとのこと。

同氏は11日にX（旧Twitter）で「私の声が再び聞こえるのはAIのおかげ。これが健康やアクセシビリティの課題に直面する人々に力を与え、私たちの能力が私たちを定義しないことを示す助けになることを願っている」と{target=“_blank”}。また、「AIは悪意を持った人々によって誤用されると危険な新しいフロンティアになる可能性があるが、障害を持つアメリカ人にとって新しく、想像もつかないほどの人生を変える機会を提供することもできる」とも述べている。

25日は、毎年7月に祝われる障害者プライド月間を記念するために行われた特別な演説で、ウェクストン議員は自身のキャリアを通じて障害者の権利とアクセシビリティの問題に取り組んできたこと、そしてPSPの診断以来、それがどれほど個人的な戦いとなったかを語った。

「私がこの仕事を愛し続け、できる限り最善を尽くして生きている姿を見たとき、多くの異なる能力を持つアメリカ人が日々示す勇気、レジリエンス、そして精神を理解し、評価してもらいたい。AIの声であっても、障害を持つアメリカ人の声となれることを望んでいる。なぜなら、私たちはその障害だけで見られるべきではないからだ」とウェクストン議員は述べた。

ウェクストン議員を支えるAI音声モデルは、AIスタートアップのElevenLabsが開発したもの。同氏の演説データを基に数日間で作成されたとのこと。この技術は、従来のロボット音声とは異なり、自然で感情豊かな発声を可能にしているという。同氏が初めてこのAI音声を聞いたとき「最も美しい音だった」と涙を流したと語った。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 02 Aug 2024 08:18:11 +0000</pubDate></item><item><title>Canva、生成AIプラットフォーム「Leonardo.AI」を買収：AI技術強化へ向けた戦略的ステップ</title><link>https://ledge.ai/articles/canva_leonardo-ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月30日、オンラインデザインツール企業である豪Canvaは、同国の生成AIプラットフォーム「Leonardo.AI」を買収することを{target=“_blank”}した。買収により、CanvaはAI技術のさらなる強化を図り、視覚的コミュニケーション分野でのリーダーシップを一層確立することを目指している。

Leonardo.AIは2022年にシドニーで設立されたスタートアップ企業で、広告、デザイン、建築、エンターテインメントなどの業界向けに、高度な生成AIモデルを提供している。同社の技術は、プロフェッショナルデザイナーから趣味のクリエイターまで幅広いユーザーに支持されており、わずか18ヶ月で10億以上の画像を生成した実績を持つ。

!
:::small
画像の出典：{target=“_blank”}
:::

Canvaは、Leonardo.AIの技術を自社のAI機能「Magic Studio」に統合するという。統合により、Canvaユーザーはより高度なAIツールを利用できるようになり、創造的なプロジェクトの効率化と質の向上が期待される。また、Leonardo.AIは引き続きスタンドアロンプラットフォームとして運営され、さらに多くのクリエイターに新しい可能性を提供することになる。

今回の買収は、Canvaにとって8番目の企業買収であり、同社のAI技術とクリエイティブツールの充実を進める重要なステップとなる。Canvaの共同創業者兼最高製品責任者であるキャメロン・アダムス氏は、「Leonardo.AIとの協力により、これまでにないレベルのAI技術が実現し、両社のチームが共に強化されることを楽しみにしている」と述べている


:::box

:::
:::box

:::
</description><pubDate>Thu, 01 Aug 2024 03:52:28 +0000</pubDate></item><item><title>NVIDIA「次のAIの波はロボティクス」　新プラットフォームでヒューマノイドロボット開発を加速</title><link>https://ledge.ai/articles/nvidia_accelerates_worldwide_humanoid_robotics_development</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAは現地時間の2024年7月29日、世界のロボットメーカーやAIモデル開発者、ソフトウェア開発者向けに、次世代のヒューマノイドロボティクスの開発、訓練、構築を支援するための新しいサービスやモデル、コンピューティングプラットフォームを{target=“_blank”}した。
## ヒューマノイドロボット開発のための三大コンポーネント
新しいプラットフォームは、次の三つの主要なサービスで構成されている。
### 1. NVIDIA OSMO
NVIDIA OSMOは、クラウドベースのオーケストレーションプラットフォームで、データ生成、モデルのトレーニング、ソフトウェアおよびハードウェアインザループのワークフローを管理する。このプラットフォームは、分散環境でのロボット開発を支援し、開発期間の短縮を図る。
### 2. NVIDIA Infrastructure for Modeling (NIM)
NIMは、AIモデルの開発を支援するマイクロサービス群で、特に生成AIを活用したロボティクスのモデル作成に強みを持つ。このサービスにより、開発者は効率的にAIモデルを訓練し、実際のロボットに適用できるようになる。
### 3. Isaac Sim
Isaac Simは、仮想環境でのシミュレーションツールで、ロボットの動作や学習をシミュレーション内で実施し、効率的な開発を可能にする。このツールは、強化学習や複雑なタスクのシミュレーションに最適化されており、ロボティクス開発を大幅に簡素化する。
## Project GR00T: 汎用AIモデルの発表
同社はまた「Project GR00T」というヒューマノイドロボット向けの汎用AIモデルも発表した。このモデルは、人間の動きを観察し、自然言語を理解する能力を持ち、実世界でのタスクを迅速に学習・適応できるよう設計されている。新しいJetson ThorというSoC（System on Chip）は、このモデルの動作に必要な高性能計算を提供する​という。


同社創業者兼CEOであるジェンセン・フアン氏は、「次のAIの波はロボティクスであり、その中でもヒューマノイドロボットは最もエキサイティングな進展の一つだ」と述べ、NVIDIAのロボティクススタック全体を強化し、世界中の開発者や企業が最適なプラットフォームやAIモデルを利用できるようにしていく方針を示した。

この新プラットフォームには、すでにBoston DynamicsやByteDance Researchを含む複数の大手企業が早期アクセスプログラムに参加している。これにより、これらの企業は最先端の技術を活用して、ロボット開発をさらに推進することができるとのこと。




:::box

:::
:::box

:::
</description><pubDate>Thu, 01 Aug 2024 03:49:26 +0000</pubDate></item><item><title>Perplexity AI、パブリッシャー向け収益分配プログラムを発表</title><link>https://ledge.ai/articles/perplexity_publishers_program</link><description>:::small
画像の出典：{target=“_blank”}
:::

AI検索エンジンを提供するPerplexity AIは2024年7月29日、パブリッシャーとの関係を強化するため、「Perplexity Publishers’ Program」を{target=“_blank”}した。このプログラムは、AIによる検索結果で使用されたコンテンツに対して、広告収入の一部をパブリッシャーに分配することを目的とするものだ。

Perplexity AIは、ユーザーに高品質な回答を提供するために信頼できる情報源に依存しており、これまでにも検索結果に引用を含めることで、コンテンツ作成者に適切な評価を与える努力をしてきた。しかし、ForbesやCondé Nastといった大手メディアから、Perplexityが無断でコンテンツを使用しているとの批判を受け、より透明で公正な収益モデルの導入が求められていた。

同プログラムでは、TIME、Der Spiegel、Fortune、The Texas Tribune、WordPress.comなど、著名なパブリッシャーが初期パートナーとして参加している。これは、Perplexityが検索結果や「関連質問」機能で広告収入を得た場合、その収益が該当コンテンツの提供者と分配される仕組みだ。また、パブリッシャーはPerplexityのAPIに無料でアクセスできるようになり、自社サイトにカスタムAI検索エンジンを導入することも可能となる。

さらに、Perplexityはパートナーに対して、Perplexityの高度な機能を提供する「Enterprise Pro」サービスを1年間無料で提供するとのこと。このサービスには、データプライバシーやセキュリティの強化が含まれており、特に調査やファクトチェックを行う際に役立つとされている。

同社CEOのアラヴィンド・シュリニヴァス氏は、「このプログラムは、すべての関係者のインセンティブを調整し、持続可能な成長を目指して設計された」と述べており、今後もパブリッシャーからのフィードバックを反映して、システムの改善を図るとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jul 2024 12:27:42 +0000</pubDate></item><item><title>未来の職場のニューノーマルを知るＬＩＶＥ配信イベント 【DX &amp; Future Work 2024】9/19-20 開催</title><link>https://ledge.ai/articles/dx-futurework-announce</link><description>国内最大級のAI（人工知能）関連メディア「Ledge.ai」を運営するほか、AIソリューションの企画・開発を行う株式会社レッジは、2024年9月19日(木)〜9月20日(金)にかけて、デジタルトランスフォーメーション（DX）と未来の働き方をテーマにした、LIVE配信イベント『DX &amp; Future Work 2024』を開催します。視聴は無料です。

:::button
{target=“_blank”}
:::

## デジタル変革と未来の働き方
ここ2~3年で見せた生成AIの広がりにより、企業活動において「AI」が必要不可欠であるという声を多く聞くようになりました。しかし、「AI」はあくまで企業のDXを加速させるツールでしかありません。そこで本イベントでは、AIに限らず、リモートワーク、自動化技術、サステナビリティなどを含む幅広いテーマを探究し、企業のDXを促進し生産性向上を実現する "未来の職場のニューノーマル" を模索していきます。

2日間にわたって行われる全18回の講演では、先進企業や有識者からDX/AIの現在地や、未来に向けての考察などが発信される他、LIVE配信イベントならではのリアルタイムでの質疑応答も行われます(*)。
「今後、我々の働き方はどうなっていくのか」「どう会社を変えていくのがよいのか」、ビジネスや働き方の変革につながる情報を得られる絶好の機会です。企業DXを主導される方をはじめ、多くのビジネスパーソンの方におすすめのイベントとなります。ぜひ専用サイトより、ご視聴ください。

:::small
(*)セッションによっては質疑応答がないものもございます。あらかじめ、ご了承下さい。
:::

## 視聴方法
ご視聴には参加登録（無料）が必要です。
登録したメールアドレスにてイベントサイトへログインいただくと、視聴が可能になります。

:::button
{target=“_blank”}
:::

## 登壇者紹介
### 一般社団法人日本デジタルトランスフォーメーション推進協会　代表理事　森戸 裕一氏
!

### 株式会社 博報堂D Yホールディングス　執行役員 CAIO 兼 Human Centered AI Institute代表　森 正弥氏
!

### SF作家　樋口恭介氏
!

※その他の最新の講演・登壇情報はサイトよりご確認ください。


## イベントスポンサー募集中！
現在、開催の趣旨に賛同いただき、本イベントを一緒に盛り上げていただけるスポンサー企業様を募集しております。
スポンサーシップに関する詳細やご興味をお持ちいただいた場合、より詳細のご説明を行わせていただきますので、お気軽にお問合せください。
お問合せは{target=“_blank”}

※スポンサー情報も随時更新中


## イベント概要
名称：DX &amp; Future Work 2024
開催期間：2024年9月19日(木)〜9月20日(金)
開催方式：オンラインLIVE配信
サイト：{target=“_blank”}
参加費用：無料（事前登録制）
主催：株式会社レッジ</description><pubDate>Wed, 31 Jul 2024 01:24:41 +0000</pubDate></item><item><title>OpenAI、新たなアプローチ「Rule-Based Rewards」でAIの安全性向上　RLHFと同等</title><link>https://ledge.ai/articles/openai_improving_model_safety_behavior_with_rbr</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年7月24日、AIモデルの安全性と有効性を高めるための新たなアプローチ「Rule-Based Rewards（RBR）」を{target=“_blank”}した。この手法は、AIの出力を明確なルールに基づいて評価し、人間によるデータ収集を必要とせずに安全に動作させることができるという。

RBRは、固定された言語モデル（グレーダー）を使用して、AIの応答がルールにどれだけ適合しているかをスコアリングする。このスコアをもとにAIの行動を調整し、安全かつ有用な応答を生成するように訓練する。従来の人間のフィードバックに依存する方法に比べて効率的でコスト効果が高く、トレーニングプロセスの迅速化が期待されている。

OpenAIの実験では、RBRを用いたモデルは人間のフィードバックで訓練されたモデル（RLHF）と同等の安全性を示し、安全な要求を誤って拒否する「過剰拒否」の減少も確認された。また、RBRは新しいルールの追加や変更が容易で、モデルの再訓練を必要としない。

!
:::small
画像の出典：{target=“_blank”}
:::
上図は、RBRが従来の報酬モデルとどのように統合されているかを示している。RBRは、個々の行動を評価するための細かいルールセットを使用し、これらの評価を直接強化学習の報酬として組み込むことで、モデルの安全性を高めている。

実験では、RBRを用いたモデルは人間のフィードバックで訓練されたモデルと同等の安全性を示し、安全な要求を誤って拒否する「過剰拒否」の減少も確認されたという。また、RBRは新しいルールの追加や変更が容易で、モデルの再訓練を必要としない。

RBRは明確なルールが存在するタスクには適しているが、エッセイの執筆などの主観的なタスクには適用が難しい場合がある。そのため、人間のフィードバックと組み合わせることで公平性と正確性を確保することが推奨されている。

このアプローチは、モデルの能力や安全ガイドラインの進化に迅速に対応できるため、効果的かつ効率的なトレーニング方法とされているという。
RBRは、GPT-4の開発中に初めて採用され、現在も進化を続けているとのこと。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jul 2024 08:31:06 +0000</pubDate></item><item><title>野村総合研究所、ELYZA、KDDI、法人向け生成AIソリューションで協業</title><link>https://ledge.ai/articles/nri_elyza_kddi_colaboration</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月24日、株式会社野村総合研究所（NRI）、株式会社ELYZA、KDDI株式会社の3社は、法人顧客向けの生成AIソリューションを提供するための協業を{target=“_blank”}した。この協業は、企業の生成AI活用を加速させることを目指している。

## 主要な協業内容
### 協業の目的：
NRI、ELYZA、KDDIの3社は、法人顧客の機密情報や業務特化情報を安全に取り扱える高セキュリティかつ効果的な生成AIソリューションを提供する。この協業により、企業の生成AI活用を促進することを目指している。

### 各社の役割:
- **NRI:**  生成AI活用のコンサルティング、システム開発、関連ソリューションの提供を担当
- **ELYZA:**  国産大規模言語モデル（LLM）の開発と生成AI活用基盤サービスの提供
- **KDDI:**  低遅延・大規模計算基盤、ネットワーク、関連ソリューションの提供
### 提供予定のソリューション:
**国産LLMの開発と提供：** 汎用国産LLM（ELYZA LLM）および業界や個社向けの領域特化型LLMを開発、提供する。
**生成AI関連サービスの提供：** ELYZAの生成AI活用基盤サービス、NRIのAIセキュリティ統制支援サービスやプライベートLLM、KDDIのビジネスプラットフォーム「WAKONX」などを含む関連ソリューションを提供する。

協業により、3社の強みを活かした生成AIソリューションが提供され、特にエンタープライズ領域の顧客に対して、セキュリティレベルの高い生成AIの導入が可能になると期待されている。これにより、企業の生成AI活用が加速し、ビジネスの効率化や新たな価値創造が促進される見込みだという。


:::box

:::

</description><pubDate>Tue, 30 Jul 2024 04:37:31 +0000</pubDate></item><item><title>Salesforce、1兆トークンのマルチモーダルデータセット「MINT-1T」を公開</title><link>https://ledge.ai/articles/salesforce_mint-1t</link><description>:::small
画像の出典：{target=“_blank”}
:::

SalesforceのAI研究部門であるSalesforce AI Researchは2024年7月24日、新たなオープンソースのマルチモーダルデータセット「MINT-1T」を{target=“_blank”}した。このデータセットは、1兆のテキストトークンを含んでおり、AI研究において重要なリソースとなることが期待されているという。
## MINT-1Tの主な特徴
**1. 規模と多様性：** MINT-1Tは、テキストトークンだけでなく3.4億枚の画像も含んでおり、その規模は既存のオープンソースデータセットを大きく上回る。データソースにはHTMLページ、PDF、ArXiv論文が含まれ、科学技術分野の文書も幅広くカバーしているという。

**2. データ品質の確保：** データセットの品質を確保するために、不適切なコンテンツや非英語のテキストを排除するフィルタリングプロセスが採用された。具体的には、Fasttextを用いた言語識別やNSFW検出器を用いた画像コンテンツのフィルタリングが行われた。また、Bloomフィルタを用いた重複除去も実施されているとのこと。

**3. マルチモーダル統合：** MINT-1Tは、テキストと画像が組み合わさった文書を含んでおり、複合的な入力に対応できるAIモデルのトレーニングに適している。このようなデータ構造により、テキストと画像の両方を理解し推論する能力が向上する​という。

**4. オープンソースとしての利用可能性：** MINT-1TはCC-BY-4.0ライセンスの下で自由にアクセスでき、学術研究や商業利用に広く活用できるリソースとなっている。データセットは{target=“_blank”}や{target=“_blank”}で公開されている​。

同データセットの公開は、AI研究の進展に大きく寄与することが期待されている。特に、大規模なマルチモーダルモデルの開発において重要な資源となるという。



:::box

:::
:::box

:::
</description><pubDate>Tue, 30 Jul 2024 04:24:43 +0000</pubDate></item><item><title>産総研とNVIDIA、AIスーパーコンピューター「ABCI 3.0」導入で日本のAI主権を強化　今年中に稼働開始予定</title><link>https://ledge.ai/articles/aist_nvidia_hpe_abci_supercomputer</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

国立研究開発法人産業技術総合研究所（産総研）は、AI用スーパーコンピューター「ABCI（AI Bridging Cloud Infrastructure）」の新バージョン「ABCI 3.0」を導入する。2024年7月11日、産総研は数千基のNVIDIA H200 GPUとNVIDIA Quantum-2 InfiniBandを搭載したHPE Cray XDシステムを導入することで、ABCI 3.0の性能と拡張性を大幅に向上させると{target=“_blank”}発表した。これは、日本のAI研究開発能力を高め、技術的独立性を強化する戦略的施策の一環だという。

ABCI 3.0は、日本における最新の大規模オープンAIコンピューティングインフラとして設計されており、今回のコラボレーションは、産総研、株式会社AIST Solutions、HPEの協力により実現された。このシステムは、柏市の施設に設置され、今年中に稼働予定だという。

!
:::small
画像の出典：{target=“_blank”}
:::

ABCI 3.0の導入により、6エクサフロップスのAI演算性能、410ペタフロップスの倍精度演算性能が実現される。各ノードはQuantum-2 InfiniBandプラットフォームを通じて200GB/sのバイセクション帯域幅で接続されることで、AI集約的なワークロードや膨大なデータセットを効率的かつ高速で処理することが可能となるという。

このプロジェクトは、経済産業省の1,566億円におよぶイニシアティブの一環として実施されるもので、日本の生成AI研究開発を加速し、次世代AIテクノロジー開発のための時間と費用を削減することを目指しているとのこと。

NVIDIAのH200 GPUは、毎秒4.8TB/sの帯域幅を持つ140GBを超えるHBM3eメモリを搭載しており、生成AIとLLMを加速する。H200 GPUのより大きく高速なメモリにより、エネルギー効率が向上し、低コストで科学的コンピューティングが可能となる。

さらに、先進的なNVIDIA Quantum-2 InfiniBandは、ネットワークデバイスがデータを基に演算を行うIn-Network Computingを統合しており、AI集約的なワークロードや膨大なデータセットを処理するために不可欠な、効率的かつ高速で低遅延の通信を実現するという。


:::box

:::
:::box

:::</description><pubDate>Mon, 29 Jul 2024 15:33:12 +0000</pubDate></item><item><title>三菱商事、生成AI活用による経理業務改革を実証</title><link>https://ledge.ai/articles/mitsubishi_pwc_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

PwC税理士法人は2024年7月25日、三菱商事の生成AIを活用した経理業務の効率化を目指す実証実験を支援したことを{target=“_blank”}した。同プロジェクトは2024年4月から5月にかけて行われ、保証債務情報の抽出と支払調書の提出要否判定を中心に検証が行われたという。

## 実証実験の概要
同実証実験では、AI-OCR（光文字認識技術）と生成AIを組み合わせることで、保証債務情報の抽出と支払調書の提出要否判定の精度を検証。保証債務情報の抽出では平均97％の正解率、支払調書の提出要否判定では98％の再現率を達成し、実務への応用が期待される結果となった。

## 実施内容と成果
4月にはPDFデータの前処理、AI-OCRによるテキスト化、生成AIによるデータ抽出、調書提出要否判定までの処理フローを構築。5月には、週単位のスプリント開発で三菱商事担当者のフィードバックを反映し、最先端手法の実装やプロンプト改善などを行い精度向上を図ったという。特に、税法上の定義をプロンプトに反映するだけでなく、具体的な事例や説明を追加することで精度を向上させたとのこと。

また、保証債務の開示基礎資料作成では、必要項目のみを抽出する際にプロンプト改善だけでは精度向上につながらなかったため、「Multi-Agent」と呼ばれる複数のAIが協働する仕組みを実装した。この仕組みにより、異なるAIが連携して作業を分担することで精度を高めたという。

今後PwC税理士法人は、生成AIによる自動処理プロセスの構築や要件定義から開発、検証までをワンストップで支援する。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::</description><pubDate>Mon, 29 Jul 2024 14:40:00 +0000</pubDate></item><item><title>OpenAI、GPT-4o の高度な音声機能「Voice mode」アルファ版を一部提供開始</title><link>https://ledge.ai/articles/gpt-4o_voice_mode_to_come</link><description>:::small
画像の出典：{target=“_blank”}
:::
OpenAIのCEOであるサム・アルトマン氏は7月26日、自身のX（旧Twitter）アカウントを通じて、ChatGPTの「高度な音声機能」のアルファ版提供を翌週に開始すると{target=“_blank”}した。この機能は、AIが人間の声に込められた感情や非言語的な合図を理解し、リアルタイムでより自然な会話を実現する。

!
:::small
画像の出典：{target=“_blank”}
:::
同社が5月に開催した{target=“_blank”}でこの機能をデモンストレーションしており、当初は6月下旬にアルファ版を公開する予定だったが、さらなる改善が必要となったため、公開が1ヵ月延期されていた。

アルトマン氏は、アルファ版がChatGPT Plus契約者の一部に限定して提供されるとし、すべてのChatGPT Plus契約者への展開は2024年秋になる見込みだと述べている。

高度な音声モードは、AIが感情を理解し、会話中に中断されても対応できる機能を持ち、リアルタイムでの翻訳も可能である。この機能により、友人と一緒に新しい言語を学ぶ過程がより効果的になることが期待されている。OpenAIは、ユーザーからのフィードバックを集め、機能の安全性と信頼性を高めることを目指している。

下の動画では、英語を母国語とするクリスティンとスペイン語を母国語とするナチョが登場し、ポルトガル語を使って会話を進める様子が紹介されている。2人は、ChatGPTの高度な音声機能を使い、以下のようなやり取りを行っている。
@

このように、AIがリアルタイムで翻訳し、感情や文脈を理解することで、ユーザー同士がスムーズにコミュニケーションを取ることができる。また、旅行の計画についても会話が進み、「オーストラリアに行きたい」というフレーズの翻訳も自然に行われた。

さらに、OpenAIは新しいビデオおよび画面共有機能の展開も計画しており、具体的なタイムラインについては今後の発表を待つことになる。現在、基本的な音声モードはChatGPTアプリで利用可能で、ヘッドホンアイコンをタップすることで開始できる。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 29 Jul 2024 03:16:16 +0000</pubDate></item><item><title>Adobe　Photoshop と illustratorが、生成AI機能強化によるアップデート</title><link>https://ledge.ai/articles/adobe_photoshop_and_illustrator_update_with_enhanced_gen-ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

Adobeは2024年7月24日、IllustratorとPhotoshopの新バージョンを{target=“_blank”}した。これらのアップデートには、最新の生成AIモデルを採用した複数の新機能が含まれており、クリエイティブな作業を大幅に効率化することが期待されているという。
## Photoshopの新機能
Photoshopでは、最新の生成AIモデル「Firefly Image 3」を活用した「画像を生成」機能を導入。同機能により、ユーザーはテキストから画像の生成が可能になる。また、特定のテイストに沿った画像生成を行うために参照データをアップロードできる「参照画像」機能や、生成した画像のディティールを向上させる「生成塗りつぶしのディテール向上」も搭載されている。

!
:::small
画像の出典：{target=“_blank”}
:::

その他にも、ブラシでなぞるだけで選択範囲を指定できる「選択ブラシツール」や、フィルターのプリセットを使用して画像の外観を数ステップで変更できる「調整プリセット」、不要なオブジェクトを簡単に除去できる「Removeツール」などの新機能が追加されており、これらのツールは画像の選択や合成、フィルターや塗りつぶしの適用を簡単かつ柔軟に行えるようにしているとのこと。

## Illustratorの新機能
新しいバージョンでは、特にベクターデータに特化した最新の「Firefly Vector Model（ベータ版）」を使用した「生成塗りつぶし（シェイプ）」機能が注目される。この機能により、ユーザーはプロンプトを入力するだけでシェイプ内にベクターの図案や柄を追加できる。
!
:::small
画像の出典：{target=“_blank”}
:::

また、プロンプトからベクターパターンを作成する「パターン生成（ベータ版）」や、ユーザーのデザインテイストを参照する「スタイル参照機能」も強化されているという。

さらに、パッケージやアパレル製品の写真から形状を認識し、作成したロゴデータなどを配置・自動変形して印字した状態を確認できる「モックアップ」機能や、正確なサイズをプロットできる「寸法ツール」、静止テキストを編集可能にする「Retype」機能も実装した。

:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jul 2024 08:49:54 +0000</pubDate></item><item><title>「短期開発したAI VTuberに大きな反響」エンジニアから42 Tokyo発の起業家へ　42Tokyo特別インタビュー【第5回】第1期生　福山 裕介さん</title><link>https://ledge.ai/articles/42tokyo-5</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第5回。**
:::

※インタビューは2024年2月22日に行われた。

:::box
!

**42 Tokyo 第1期生**
**福山 裕介**
株式会社ツクルバ、株式会社メルカリでエンジニアインターンを務めた後、スタートアップ企業の技術担当を務め、42 Tokyo卒業後にKinkaku株式会社を設立。
:::

## 再び学びの場へ　42 Tokyoを選んだ理由
福山さんは長い間海外で過ごし、日本に帰国した後は文化の違いに戸惑いながらも、企業のエンジニアとして活躍していた。既にエンジニアとしての経験を積んでいた中、どのようなきっかけで42 Tokyoを知り入学を決意したのか。福山さんは以下のように振り返った。

:::box
**福山さん**
私は幼い頃から15年以上インドやフィリピンなど、海外に住んでいました。海外に住んでいた学生時代は、中学生からPCに触れる環境だったため、PC操作に馴染みはありましたが、プログラミングに関しては全く知りませんでした。

海外の高校卒業時期が5～6月だったため、日本の大学の入学時期まで結構期間が空くんです。その期間に、アメリカの大学へ進学した友人から、「プログラミングで有名な講師のオンライン講座が無料で受けられる」と勧められて始めたのが、プログラミングを知るきっかけでした。

大学入学のタイミングで帰国したのですが、日本の文化や教育に馴染めないと感じ、すぐに休学しました。その後、学んだプログラミングスキルを活かし、株式会社ツクルバやメルカリでエンジニアのインターンを経て、スタートアップの技術担当を務めました。年数でいうと、エンジニアの仕事を5年ほど続けました。
この経験からエンジニアとして知識や経験が身についたのは事実ですが、もう一度しっかり学び直したいという思いがありました。

情報収集する中で、Twitterで42 Tokyo開校の情報を見つけたのが42 Tokyoを知るきっかけでした。新しい教育システムに興味が湧き、実際に入学して自分自身で体感したいと思い、受験を決意しました。
:::

福山さんは勤めていた会社を退社し、第一期生として42 Tokyoに入学した。既にエンジニアとしての経験を積んでいた福山さんは、42 Tokyoに入学する前から起業する目標を持っていたという。42 Tokyoでどのような学生生活を送っていたのか、以下のように語ってくれた。

:::box
**福山さん**
とにかく入学試験の「Piscine(ピシン)」が凄く楽しかったんです。会社に勤めていた頃は、文化の違いに馴染めず本来の実力が発揮できなかった苦い経験がありました。しかし、42 Tokyoは文化の違いも関係なく、皆がプログラミングを学ぶという同じ目標に向かって進んでいくので、萎縮することなく話せました。誰かと無邪気に話したり、意見を言い合いながら自由に学ぶ場というのが新鮮で楽しかったという印象がとても強いです。

日本初の「42」開校なので、一般的には少し様子を見たり、一旦立ち止まって入学を考えますよね。私含めですが、新しいものに飛びついて受かった人は、結構特殊だと思うんです。第一期生は躊躇なく受験した人たちの集まりなので、やはり個性的な人が多く、バックグラウンドや年齢も様々でした。また、良い意味で他人の過去にはあまり興味を示さないので、何をやっていたとか年齢も気にせず、皆対等に接することができました。

「42」は、根本的に目的意識が強い学びたい人しか集まらないので、そういったところが大学とは違うと感じ、皆が学びへの姿勢も熱量もモチベーションも高いので、私の意識も一層高まりました。
:::

「周囲の人たちに刺激を受けながら学生生活を送っていた」と語った福山さんだが、全ての学生が今までの人生を苦難なく過ごしてきたかと言うと、必ずしもそうではないという。

:::box
**福山さん**
過去に学校や仕事を辞めた人、ずっと家で過ごしていた人、周りから過小評価されていた人もいました。しかし、共通して言えるのはコードを書く能力が高く、シンプルに課題解決能力や適応能力、学習速度が速い人が多かったですね。

エンジニアとしてステップアップしたいというのはもちろんですが、私自身も大学生活で躓いた経験があるので、リハビリも兼ねて社会や人と触れ直すきっかけがほしかったんです。共通の話題があることで自然と話せましたし、そういう部分でも42 Tokyoを選んで良かったと思います。
:::

## 42 Tokyoの魅力　実践的な学びの重要性と習得したスキル
!

大学との学び方の違いを体感し、改めて42 Tokyoのカリキュラムの良さを実感したという。モチベーションが下がることなく課題に取り組むことができた理由を、福山さんは以下のように話してくれた。

:::box
**福山さん**
6～7年前は、ソフトウェアエンジニアで情報系出身の人材がかなり少ない時代でした。学べる場といえば、仕事で任されるタスクに関連した内容がほとんどなので、どうしても知識の偏りが生じてしまうんです。

現在は環境が変わっていると思いますが、当時の大学は知識を詰め込む座学が多く、コードを書く物量が全然足りていなかった。そのまま大学に通っていても理論は学べるが、実践的なことはあまり身につかないと思いました。コードを書く機会が少ないと「こうやって書くんだ」だけで終わってしまうので、もったいないですよね。

42 Tokyoは100％プロジェクトベースの実践的カリキュラムなので、コードを書く物量でいうと数十倍はあると思います。例えば、ソフトウェアを制作するという課題があったとして、それを作るために理論を学びにいくので、目的ありきの学び方なんです。

また、現状の知識より少しチャレンジングな課題をあえて渡されるので、独学で勉強していたら学べないようなものが多いんです。簡単すぎない、少し背伸びをした課題を解くために、自身の持っている知識を活用したり、調査したり、時間を使って向き合えば絶対にクリアできるので、達成感や自信に繋がります。モチベーションも上がっていきますし、「勉強すればなんとかなる」というマインドセットが身につきました。次の課題への意欲も湧いてきますし、そこだけは陳腐化せずに自分のスキルとして身につくことを、課題を通して学べたと思います。
:::

## 42 Tokyoでの経験を経て起業の夢を実現
42 Tokyoを卒業した福山さんは、その後、ともに学んだ仲間とハッカソンに参加し、見事優勝した。その成功体験を経て、起業した当時を以下のように福山さんは語ってくれた。

:::box
**福山さん**
42 Tokyoに入る前から起業はひとつの目標でした。
42Tokyoに在籍しながら、大学院で画像生成の研究をしていた友人と、二人で共同創業者として会社を立ち上げました。当時はちょうどChatGPTがリリースされた時期で、「なんか化け物みたいなものが出てきた！」と、とても衝撃を受けました。この言語モデルを使って一番ワクワクするものを作り出したいという思いから「AI VTuber」の開発プロジェクトが始まりました。

その後、短期間で開発したAI VTuberをXに投稿したところ大きな反響があり、「これはいけるかもしれない」と二人で意気込み、さらにこの波に乗るために開発を進めました。

私たちはエンジニアなので絵を描くことができません。そのため、画像生成AIを活用してキャラクターを描いたりコンテンツを制作していたのですが、開発を進める中で、現状の生成AIは絵柄や顔の一貫性がなくなる課題が見えてきました。また、画像を生成するにあたって、テキストで自分の作りたい画像のイメージを伝えることの難しさを知り、それを簡単に解決できるサービスはないか？と考え、その課題に対応するサービスを開発しました。
そのサービスは、ビジュアルベースで作りたい画像のイメージを描いてAIに指示をすると、リアルタイムで画像が生成することができます。基盤モデルはStable Diffusionを使用しており、高速で生成する技術を用いながら独自で改良を重ね、0.1秒という高速生成を実現することができました。
:::

## 今後のビジョンと新たな目標
様々な生成AIに関連するサービスを開発してきた福山さんだが、さらに大きな目標を掲げて今後も開発を続けていくという。今後の具体的な展望も以下のように語ってくれた。


:::box
**福山さん**
私たちは、42 Tokyo卒業後初めて起業した実績があるので、今後は上場も視野に入れて、「コンテンツ周りの生成AIならKinkaku」と言われるくらい、日本を代表するような生成AI企業に成長したいと思っています。

先ほども話したように、画像生成における絵柄の一貫性がない問題も、その部分を解決すれば活用の幅はさらに広がるので、改良してビジネスで役立つものを生み出したいと考えています。最終的には、生成AIをアニメなどのコンテンツ制作の場で使用されるものを開発したいですね。

すべての作業をAIが行えば良いとは考えていません。例えば、漫画制作でストーリーや構成を人間が考えて、キャラクターの名前やセリフをまとめる部分をAIが担っていくというように、基本的に面白いコンテンツを作り出せるのは人間だと思います。そこは今もこれからも変わらないと思います。人とAIが協業する世界に向けて、アニメや漫画業界と基盤モデルの橋渡し役を私たちが担いたいです。
:::

:::box
特集：
:::</description><pubDate>Mon, 22 Jul 2024 01:51:14 +0000</pubDate></item><item><title>東大松尾研究室が監修・開発のLLM講座「大規模言語モデル 2024」の受講生募集を開始</title><link>https://ledge.ai/articles/large-language-model_matsuo_iwasawa_lab</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月9日、松尾・岩澤研究室が主催する講座「大規模言語モデル 2024」の受講生募集を{target=“_blank”}した。

本講座は、データサイエンティスト育成講座やDeep Learning講座を10年以上運営し、多くの人材を育成した実績を持つ東京大学松尾・岩澤研究室の松尾豊氏と岩澤有祐氏が監修・開発しており、生成AIの基盤モデルである大規模言語モデル（LLM）の基礎理論や既に公開されているLLMモデル、APIの活用方法を学び、幅広い知識やスキル習得を目的としている。全12回の講義と受講生同士で競うLLMに関するコンペティション型の最終課題を実施予定だ。

受講料無料の完全オンラインでの実施で、募集締切は2024/7/31(水)10:00までとのこと。
!

:::small
画像の出典：{target=“_blank”}
:::


2023年9～10月に東京大学サマースクールで開催されたLLM講座では、約2,000名の受講者が参加し、最終課題のGPUを使ったコンペディションでは約800名が熱戦を繰り広げたという。講義のスライドが{target=“_blank”}でダウンロード可能だ。


:::box

:::
:::box

:::
:::box
[関連記事：年末年始こそAIのリスキリング　2023-24年のおすすめ無料講座を一挙紹介！ー松尾研LLM講座・Google認定資格プログラム・プロンプトエンジニアリングなど](https://ledge.ai/articles/free_courses_in_winter2023-24
)
:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Jul 2024 06:56:44 +0000</pubDate></item><item><title>コンサルからエンジニアへ　東京・パリで学び、データ分析でグローバルな活躍を目指す　42 Tokyo特別インタビュー【第4回】小林 瑠理さん</title><link>https://ledge.ai/articles/42tokyo-4</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第4回。**
:::

※インタビューは2024年1月30日に行われた。

:::box
!
**42 Paris 在学生**
**小林 瑠理**
新卒で外資系コンサルティング企業に入社し、ビジネスアナリストを経験したのち、転職してIT企業に転身。その会社でエンジニア養成機関「42 Tokyo」を勧められ、2022年4月に入学。仕事と並行しながら基礎カリキュラムを修了し、現在は「42 Paris」に留学中。 現在は勉強と並行して、フリーランスエンジニアとして、アメリカの企業でwebオートメーション支援と日本のベンチャー企業でLLM活用支援をおこなっている。
:::

## 未経験からの挑戦　42 Tokyoで見つけた学びの道

:::box
**小林さん**
大学卒業後は、ITのシステムインテグレーターの会社に入社して、ビジネスコンサルとして仕事をしていましたが、そこでエンジニアリングに興味を持ち、未経験でITエンジニアとして転職しました。しかし、全く教育を受けていない状態で転職したため、自主学習も思うように進まずに悩んでいたんです。そんな中、社内の技術担当の方から「42 Tokyo」を教えていただき、入学試験「Piscine（ピシン）」を受験しようと決意しました。

42 Tokyoを教えてもらうまでは、オンライン講座を受講したり、本を読んだりしていましたが、自分でプログラムを最初から作るのが一番習得への近道だと思っていたので、42 Tokyoでは実践的にプログラムを作り、その過程を学べるのがとても魅力的でした。

一般的な学習方法である教師がいる環境もメリットはあると思うのですが、インターネットで情報が簡単に手に入る今の時代の中で、教師がいることで受け身になってしまう部分もあるように感じていました。42 Tokyoは、教師がいないからこそ主体的に動けるのではないかと思い、興味が湧いてきたんです。

年末の休みと有給休暇を利用してPiscineを受験して無事に合格し、入学しました。
:::

小林さんは、Piscineを受験した時はC言語にも触れたことがなく、ロジックの組み立て方も分からず、なかなか思うように進められずに焦る場面もあったという。周りがどんどん進んでいく中、「なんで自分はできないんだ」と落ち込むことも何度かあったというが、落ち込みながらも合格まで辿り着くことができた。その理由を小林さんは以下のように振り返った。

:::box
**小林さん**
当時は本当に簡単なコードの書き方も全然分からない状態だったので、進みが遅い自分に焦りを感じ、落ち込むことが多かったです。何度か心が折れたこともありました。最後まで乗り切れたのは、相談しあったり、励まし合ったりできる仲間がいたからだと思います。仲間がいなかったら合格まで辿り着けなかったかもしれません。その点でも、仲間の存在はとても大きかったですね。

入学試験を受けている仲間同士で学業以外のこと、人生相談など結構深い話もしていました。年齢層やバックグラウンドが皆様々で、18歳から60代歳まで幅広い年齢層の人が集まっているので、課題の合間に皆でコミュニケーションを取っていましたね。"意欲的に何かを成し遂げたい"と強い意志を持ってチャレンジしている方が多く、良い刺激を受けていました。友達というよりは、ともに試験合格を目指す“仲間”と呼べる存在でした。
明確な目的があって、自分のやりたいことを探求したい野心的な人は42 Tokyoで能力を発揮できると思います。実際に42 Tokyoでは、目的意識が高い人が多く、自分の目的を達成するために課題と向き合う強い意志が大切なので、そういった意志がある人にはピッタリな環境ですし、普通の大学や職場では得られないことが経験できる環境だと思います。
:::

## 42 Tokyoでの実践的な学びの風景　仲間とともに挑む課題と成長
!

:::small
42Tokyoの学習風景
:::

無事に入学試験をクリアして42 Tokyoに入学した小林さんだが、仕事を休職することなく、学業と両立していくことを選んだという。どのように両立していたのか、42 Tokyoでの学習環境を詳しく聞いてみた。

:::box
**小林さん**
課題を進めるにあたって、週に35〜40時間は必要なので、仕事と学業の両立がすごく大変でした。朝早く起きて仕事が始まる前に勉強して、仕事が終わってからも勉強して、土曜日は一日中校舎に行って課題を進める生活を1年半ほど続けていました。当時勤めていた会社は人を大切にする会社で、42 Tokyoに通うことを応援してくれたり、様々な場面で助けていただきました。学業と両立できたのは、会社の皆さんの協力あってのことだと思います。

42 Tokyoの課題をこなす時は、実際にプログラムを書いて仲間同士で教えあったり、時には突っ込まれたりもするんですが、そういった生徒同士で教え合いながら学ぶ学習方法が想像以上に濃い内容でした。課題を提出したあとに3回レビューをするのですが、相手が全くの知識0の人もいれば、すでにかなりの知識を備えた熟練者だったり、色々なレベルの人とランダムでマッチングする形式なので、相手に合わせた説明が求められるんです。

例えば、知識が0の人には基礎から分かりやすく説明して理解してもらう必要がありますし、逆に熟知している人からは、自分の説明に対して鋭い指摘を受けて、少しずつ直していく、ということの繰り返しでした。同じ課題でも、相手によって自分も視点を変えて学習した内容を分かりやすく説明する必要がある。そういったことから、今振り返るとコミュニケーション能力や説明能力も身についたと思います。
:::

課題のレビューは生徒同士で行う。相手によって説明内容や視点を変えることで、改めて課題への理解が深まったという。レビューをし合う中での発見や、印象に残っていることを小林さんは以下のように語った。

:::box
**小林さん**
レビューはポイント制になっていて、自分がレビューをすると1ポイント加算され、そのポイントを使用して課題を提出してレビューを依頼するシステムなので、必ず交互にランダムでマッチングする形式になっています。

最初は知識がない中でレビューをしなければならないので、相手の説明を正しく理解することを心がけていました。自分でも正誤が分からない状態なので、分からないことは理解できるまで教えてもらったり、自分でも調べながらレビューをしていました。一年ほど経ってくると自分の知識も広がっているので、「良いコードだな」と、自分で判断できるようになり、「ここのコードはこうやって書き直すとより見やすいんじゃないか」など、アドバイスができるようになりました。

とにかく実践的に課題に取り組むカリキュラムなので、本を読むよりも自分には合っていると思います。課題の進捗をチームごとに確認できるのですが、課題が進んでいる人を見ると、良い意味で競争心が掻き立てられて、「もっと頑張ろう」と意気込んでいました。
:::

課題をクリアするには、3回レビューを通さなければならないルールがある。1、2回目はクリアできても3回目で返されるとまた1回目から再度レビューになるため、3回目で返されるのが一番キツかったと話す小林さんだが、そのレビューがきっかけで自身の考え方が大きく変わったという。

:::box
**小林さん**
課題の説明をする上で、その結論に至るまでの “過程” の部分にこだわりを持つ人が多かったので、その相手の主張に対して、「私はこういう理由で実装した」と論理的に伝えることが難しく、苦労しました。意見が対立した時に、私は逃げてしまうタイプだったのですが、何故この考えに至ったのかを論理立てて主張することの重要さを学びました。

相手にも意見があって、別に精神的な攻撃をしたいわけではない、建設的な議論がしたいんだと思えるようになったので、メンタルにくることも少なくなりました。自分の意見をしっかり伝えることの大切さに気づけたことが私自身に大きなプラスとなりましたし、社会人としても成長できたと思います。
:::

## 42 Tokyo卒業後の挑戦　42 Paris本校への留学と新たな目標

小林さんは42 Tokyoの基礎カリキュラム（コモンコア）を1年半で修了した後、会社を退社し、42 Paris本校へ留学をした。インタビューの最後に、パリでの生活や42 Paris校の様子、そして今後の展望を語ってくれた。

:::box
**小林さん**
東京で働いていた時は主にアプリ開発をしており、その間に42 Tokyoのコモンコアで基礎であるC言語の勉強を行っていました。コモンコアを修了後は、別の国の42に移籍できるようになるので、データ分析を学ぶためにパリに移籍をしました。もちろん42 Tokyoでもデータ分析は学べますが、もともとグローバルに働いてみたいという思いがあり、パリを選択しました。

パリに来て言語の不安がありましたが、ほぼ全員が英語が流暢に話せるので、今は英語で勉強をしています。仕事と学業の両立をしていた日本での生活と比べると、今は自分の時間も確保できますし、勉強の時間もしっかり取れているので、充実した生活を送っています。データ分析の基礎を楽しみながら学んでいるので、今後はデータ分析に関連する仕事に就きたいと思っていますが、ロケーションを日本にするかヨーロッパにするかはまだ決めていません。
今はパリの生活を存分に楽しみたいと思います。おしゃれな街並みに囲まれて、すぐ近くには美術館があったり、ミーハーなだけかもしれないですが結構楽しんでいます（笑）

42 Parisは、東京校と比べると学校の雰囲気が違います。規模も大きいですし、人数も多いので両隣の人との距離が近くて教室での密集度がかなり高いです。東京校の方が自分の空間が取れてその点は東京校の方が過ごしやすくて好きでした。

42 ParisではRNCPという職能資格を習得できる制度があり、そのためにインターンシップ経験が必要なので、インターンでも様々な経験を積んでより知識を深めていきたいと思います。基本的に勉強が好きなので、身につけた技術を仕事に活かしつつ、新しい技術の勉強はずっと続けて、両輪で生きていく人生にしたいと思っています。
:::

:::box
特集：
:::</description><pubDate>Mon, 08 Jul 2024 07:44:09 +0000</pubDate></item><item><title>【無料LIVEウェビナー】RAGの活用方法や最新AIツールを紹介！生成AIを活用する時に知っておきたい重要トピックを解説</title><link>https://ledge.ai/articles/expo2024-live-webinar</link><description>:::box
Ledge.aiが6月に開催したオンラインイベント「{target=“_blank”}」のうち、終盤に実施したライブ配信による解説ウェビナーには多くの好評をいただいた。この反響を受け、イベントの追加コンテンツとして、7月31日までLIVEウェビナーの追加企画を実施している。また、それに伴って一部コンテンツは延長公開中だ。気になるコンテンツがあれば、是非チェックしていただきたい。
:::

## これからのビジネス環境で必須となる生成AI活用の重要トピックを解説
生成AI技術の企業での業務利用は、いまだ慎重論は一定数見られるものの、徐々にその風潮に変化が見られている。
ICT市場調査コンサルティング企業のMM総研が2024年3月に発表した調査結果によると、2025年度には69％の企業が生成AI技術の本格的な利用を検討すると回答している。

:::box
{target=“_blank”}
:::

今はまだ顕在化していないが、今後生成AI技術を効果的に活用できている企業とそうでない企業との間には、ビジネスでの競争力に大きな差を生み出していくことになるだろう。

今回Ledge.aiでは、先月開催したオンラインイベント「{target=“_blank”}」の追加企画として、昨今の生成AIトレンドの中で、押さえておくべきトピックについて解説するLIVEウェビナーを開催する。

:::button

:::

## 配信ラインナップ紹介
以下がこの先の配信予定だ。一度参加登録することで、すべての配信に視聴参加できるようになるので、合わせてご覧いただきたい。

**「RAGを使った独自データの活用の基本」
配信日時：7/9（火） 15:00-15:30**
大規模言語モデル（LLM）に不足している知識を補い、独自の情報を反映した回答を出力させることができる「RAG（Retrieval-Augmented Generation）」という手法について、その基本的な仕組みや活用方法について解説する。
なぜ独自の情報を参照させる必要があるのか？といった背景知識を押さえた上で、外部から与えた知識の処理プロセスや、精度向上の鍵となる技術要素など、RAG導入の基本となるポイントを押さえる。

**「今話題の生成AIツールを紹介」
配信日時：7/11（木） 15:00-15:30**
ChatGPTやGemini、Claudeといった会話型AIツールだけでなく、昨今生成AI技術を活用した様々なツールが登場している。本配信では、その中でも最近特に注目度の高いツールを2つ紹介する。
一つ目は、誰でも手軽にLLMアプリケーションが構築できるLLMアプリ開発プラットフォーム「Dify.AI」を紹介する。RAGを使ったエージェント形式のチャットボットや、複数のタスクを組み込んだワークフローなどが実際にどれくらい簡単に作れるのかをLIVEでデモ実演する。
２つ目は、テキストや画像から高品質な動画を生成することができるサービスとして話題になっている動画生成AI「Luma Dream Machine​」だ。活用ケースを想定しながら、実際にプロンプトを送り、どのような動画が生成されるのかをデモ実演する。

**「RAGの回答精度を上げるためにすべきこと」
配信日時：7/16（火） 15:00-15:30**
7/9配信のRAG解説に続く発展編として、RAGの性能を向上させるための手法・テクニックを解説する。「質問に関連するドキュメント群を探し出すこと」、「取得したドキュメント群から正しい回答を生成すること」という２つの要素に分解して、RAGの回答精度向上につながる重要なアプローチをいくつかピックアップして紹介する。
RAGに取り組んでみたけどうまくいかない、これから実装を検討する上で躓くポイントが知りたいという方は、是非参考にしていただきたい。

**「優秀なAI部下で管理業務を楽にする！上司が知りたい生成AIの活用術」
配信日時：7/18（木） 15:00-15:30**
2022年のChatGPTの登場から進化が止まらない生成AI。新しいモデルや新機能の発表で、なかなかアップデートが追いつかず、使いこなせていない読者も多いのではないだろうか。本ウェビナーでは、生成AIを優秀な部下として活用し、業務効率を上げるためのテクニックを解説します。ChatGPTなどの会話型AIツールを使ってはみたものの、途中で挫折してしまった方も、このウェビナーを通じて、仕事で使えるテクニックを学び、あなただけの優秀なAI部下を作り、育てていくきっかけとして活用いただきたい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button

:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。


## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
配信形式：zoomウェビナー（LIVE）
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Mon, 08 Jul 2024 10:25:57 +0000</pubDate></item><item><title>松尾研インターンから42へ　基礎カリキュラムを最速で終了した学生がAI開発企業の人事統括になるまで　42Tokyo特別インタビュー【第3回】松本悠秀さん</title><link>https://ledge.ai/articles/42tokyo-3</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第3回。**
:::

※インタビューは2024年4月23日に42Tokyoの校舎にて行われた。

:::box
!
**42 Tokyo卒業生**
**松本悠秀**
東京大学松尾研究室主催のGCIにて優秀賞を受賞し、現在は同講義の教材開発及び講師として関わる。株式会社松尾研究所の複数のプロジェクトにてエンジニア・マネージャーを経験。42 Tokyoのコモンコアを最速で突破。現職ではAIスタートアップにて、プロダクトマネージャー/人事統括を担当している。
:::

## データサイエンスとの出会い　松尾研から42 Tokyoへの挑戦
松本さんは大学4年生で転機を迎えた。それが、データサイエンスとの出会いだったという。普通の大学生からどのようにして「42 Tokyo」への入学を決意したのか、以下のように語ってくれた。

:::box
**松本さん**
僕の経歴は少し特殊で、大学4年生を2度経験しています。入学してから3年間は、サークルへの参加や家庭教師をするなど、普通の大学生活を送っていました。大学4年生に上がったタイミングで経済学部に転学し、教育に携わる仕事に就くために就職活動を進めていました。その後、教育関連企業への内定も決まったのですが、就職活動をしている中でデータサイエンスの重要さを知り、卒業後に良いスタートが切れるように、という思いから松尾研のGCIというデータサイエンスの講義を受講しました。


GCIは、東京大学松尾研究室の研究室が運営するデータサイエンスの講義で、東大以外の人も受講可能です。この講義を受講して、データサイエンスやプログラミングの面白さに気づきました。僕が本格的にプログラミングに触れたのは、この講義がきっかけでした。

この講義が一通り終わったあと、松尾研でのインターンを開始し、GCIの講義開発や講師を務めたり、共同研究において機械学習のエンジニア/プロジェクトマネージャーを経験しました。
:::
松本さんは、希望していた教育関連企業への就職が決まっていたが、子どもと関わりたいという気持ちがある中、自身の強みを活かせるキャリアプランをどのように作っていくか悩んでいたという。

:::box
**松本さん**
松尾研のインターンでは主に機械学習のモデリングを担当していました。その中で、実際に作ったモデルが実社会へ実装されることに興味を持ち、実装にはソフトウェアエンジニアリングが必要だということを知りました。その時、全く関係ない文脈で「教育に興味があるのであれば、42 Tokyoというところに入学してみたらどうか」とお話をいただいたんです。「革新的な教育プログラムらしい」ということを聞き、後から調べたところ、ソフトウェアエンジニアリングを学べることを知りました。まさに求めていたものだと思い、一切の迷いなく入学試験を受けることを決めました。


就職が決まっていた企業での業務は、僕が得意とすることとは少し乖離があったんです。就職について悩んでいたとき、松尾研の方から42 Tokyoの話を聞いて、内定を辞退して学ぶことを選びました。ソフトエンジニアリングの勉強をしたいというのが一番でしたが、独自の教育カリキュラムへの興味もありましたので、とても良いタイミングだったと思います。

試験に合格したあとは、松尾研のインターンをしながら42 Tokyoのコモンコア（基礎カリキュラム）の勉強を始めました。
:::

## 日本最速でコモンコアをクリアした松本さんが語る42Tokyoの学び方
!
通常の授業のように時間が決まっているのではなく、好きな時間に好きなだけ勉強ができるのが「42」の魅力のひとつだ。松本さんは42 Tokyoのコモンコアを開校以来最速でクリアしているが、どのようにして課題を進めていたのだろうか。

松本さんは、42 Tokyoのカリキュラムについて、「今までの学習方式を破壊したような斬新なカリキュラムだった」と語った。
:::box
**松本さん**
コモンコアの修了については急いで終わらせようと思ってやっていたわけではなく、結構黙々と一人で集中して課題に取り組む時間が多かったんです。もちろん周りの人と協力しながら進める場面もありましたが、一人でできるところは黙々と課題を解いていました。


これまで色々な人たちが学問というものを紡いできた歴史がありますよね。今までの一般的な学習方式は、論文や学術本などを発表して、それを授業や研究という形で紡いでいく考えだったのですが、「42」はこれを破壊しているんです。課題を渡されて、自分で考えたり周りに相談しながら答えを導き出して、自分の力で登っていかないといけない。


効率性の観点で考えると、決して効率的とは言えません。しかし、課題をクリアするために自分たちで情報を取得しながら進めなければならないので、「未知のものに対する対応力」という、育成するのが難しい能力を育てる上では、最適な構図だと思います。最初に教科書をもらった方が全部覚えられて学びやすいじゃないですか。
すべての人に刺さる学習方法ではないと思いますが、この方法で学ぶことで得られるものは多いと思います。
:::
松本さんは2度目の大学4年生になることを決意したときから「あと1年しかないのに、この時間を無駄にはできない」と、黙々と課題をこなしていたという。そして、最速でのコモンコアクリアを実現した。自主性を育む環境で、一人で自由に課題を進めることもできる。自分のペースでこなせるところも42Tokyoの魅力なのだ。
:::box
**松本さん**
「42」の学習方法についてですが、例えば、「ウェブページを自分でデザインして作れるようになりたい」という具体的な目標がある場合、42 Tokyoで学ぶことはエンジニアの基礎なので、他のスクールの方がその目的達成のゴール到達は早いかもしれません。
しかし、エンジニアという刻々と変化していく分野において、「基礎・土台となるような力を、時間をかけてでもいいので学びたい」など、幅広く応用の効くところまで学ぶ目的があるのであれば、力を養う学習方法として最も効率的なカリキュラムだと思います。
:::

## 42 Tokyoで得たスキルと知識
!
:::small
42 Tokyoの実際の学習風景
:::
42 Tokyoでの学びを通して、どのようなスキルが身についたのだろうか。特殊カリキュラムをこなす日々の中で身についた知識やスキルについて、松本さんに詳しく聞いた。
:::box
**松本さん**
42 Tokyoでのコモンコアが終了した時点では、正直、自分に身についた知識やスキルについてはあまり実感はなかったんです（笑）目に見えたスキルの習得がゴールになっていないので、実際に課題をこなしているときは「これ、役に立つときが来るのか？」と思っていました。恐らく、僕以外にも同じことを思いながら続けていた人は多いと思います。


しかし、役に立ったと思う日が来たんです。それは、松尾研在籍中、プロジェクトでエンジニアリングをしていた時期があり、定期的に業務の進捗報告をする機会があったんですが、「なぜこのような実装に至ったか」と聞かれたとき、「このような背景があり、こういった意図で実装しています」と、とてもスムーズに説明ができたんです。学生同士でフィードバックしあいながら課題を進める42 Tokyoの学習フローを、ここで活かすことができました。自分が行った作業の内容を、相手がしっかり理解できるように説明しないと課題をクリアできなかったので、そこで“説明力”が身についたのだと思います。


未知の領域に対しての対応力は確実に身につきましたし、自身の技術面の成長も感じました。コモンコアで学んだ内容とは違う技術領域に触れたときに、「これはあの課題で学んだ内容と裏にある理念は共通なのではないか」と気づき、さらに理解が深まった瞬間もありました。

そういった気づきがあるたびに、課題の意味を改めて理解できたと実感しました。
:::
松本さんはさらに、「42 Tokyoの特殊なカリキュラムは、偶発的な学びが起きやすい環境となるよう、意識的に設計されているんだろうと実感した。」と続けた。42 Tokyoを通して身についたスキルの存在に気づくたびに、点と点がつながっていく感覚があったのだという。
## 人事統括担当として描く組織像
42 Tokyoと松尾研の両軸で進んでいった1年間は、どのような将来像を描いて日々を過ごしていたのか。そして、42 Tokyoを卒業した現在は、どのようなビジョンを描いているのか、松本さんは以下のように語った。
:::box
**松本さん**
当時は明確なビジョンを意識していなかったんです。ただ、松尾研も42 Tokyoも同様に、自分の得意分野に気づけたというのは、人生を大きく変えたきっかけでもありますし、人生に与えたインパクトはとても大きいと思います。


42 Tokyoは去年の7月に卒業していて、現在はスタートアップで働いています。所属企業は、オーダーメイドでAIの受託開発を主に行っています。AIを学ぶ環境も展開しており、講義の設計なども行っています。その中で現在は、人事統括及びプロダクトマネージャーとして仕事をしています。人事統括としては、Missionの達成を第一としつつ、メンバーそれぞれの強みを活かしながら、事業を一番成長させられる文化の浸透・採用・アサインを日々模索しています。また、プロダクトマネージャーとしては、プロダクトの設計から、開発や機能検証のマネジメントを行っています。


42 Tokyoに在籍していた当初は明確なビジョンはなかったと話しましたが、現在の僕は、将来的には教育関連に携わることを目標としています。そのためにも、まずは自分の価値を最大限に発揮できる今の会社で、尊敬できる人たちと一緒に会社としての目標を達成していくことが大事だと思っています。
:::
松本さんの所属している企業のビジョンは “テクノロジーですべての「ひと」の力を解き放つ” であり、この「すべて」の部分は、外の人たちだけではなく、会社で働くメンバーも含まれるそうだ。社内外でこのビジョンを達成すべく、現在は業務にあたっているという。

:::box
特集：
:::</description><pubDate>Tue, 02 Jul 2024 02:23:09 +0000</pubDate></item><item><title>日本リスキリングコンソーシアム　最新の生成AI講座「 Google AI Essentials」を先着1万人に無料提供
</title><link>https://ledge.ai/articles/google_ai_essentials</link><description>:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::

2024年6月19日、日本リスキリングコンソーシアムは、 最新の生成AI講座「Google AI Essentials」を新規会員先着10,000人に無料で提供すると{target=“_blank”}した。

本講座は、初心者でも10時間程度でAIの基礎知識と活用方法を習得できる日本語対応のオンライン講座だ。通常8,000円相当の有料講座だが、今回は新規会員の先着10,000人が無料で受講できるという。GoogleのAIエキスパートが講師を務め、受講修了時には認定証が発行される。

### 主な学習内容は以下の通り
- 生成 AI ツールを使って、アイデアやコンテンツを開発し、より多くの情報に基づいた意思決定を行い、日々の作業をスピードアップする
- 明確で具体的なプロンプトを作成し、必要なアウトプットを得る。プロンプトのテクニックを応用して、要約やキャッチフレーズの作成などに役立てる
- AI にありうるバイアスを特定し、その弊害を回避することで、責任を持って AI を使用する
変化する AI の今後の展開の中で常に最新の情報を得るための戦略を立てる

AIに興味はあるが、何から学んだら良いのか迷っている方、日々の業務を効率化したい、AIスキルを習得してキャリアアップを目指す方に推奨の基礎講座で、さらに本講座を受講すると、以下2種の講座も無料で受講が可能だという。

### Google データアナリティクス プロフェッショナル認定証（2022 年提供開始）
データに基づいてビジネス上の意思決定を行うためのデータ収集、変換、整理スキルを学び、データアナリストとして即戦力となるためのスキルを身につけるコース

### Google サイバーセキュリティ プロフェッショナル認定証（2023 年提供開始）
一般的なリスク、脅威、脆弱性を特定する方法やそれらを軽減するテクニックなど、成長著しいサイバーセキュリティ分野で即戦力として活躍するためのスキルを身につけられるコース

!
:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::
学位や事前知識など受講条件はなく、誰でも申込みが可能とのこと。AIの基礎知識を身に着けたい方はぜひお見逃しなく。

:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:41:55 +0000</pubDate></item><item><title>【6/27 15:00開始】 最新モデル「Claude 3.5 Sonnet」の実力に迫るLIVE配信をレッジが開催！GPT-4oやGemini 1.5 Proとの違いなど徹底解説</title><link>https://ledge.ai/articles/expo2024_claude3-5_sonnet_live</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している特設サイト「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 突如発表された最新モデル「Claude 3.5 Sonnet」 その実力を検証するLIVE配信の開催が決定
2024年6月21日にAnthropicが突如として最新AIモデル「Claude 3.5 Sonnet」を発表した。

:::box
{target=“_blank”}
:::

Claude 3.5 Sonnetは、コードの生成やイメージの認識の性能が大幅に向上し、前バージョンの上位モデルであるClaude 3 OpusやGPT-4oなどの競合モデルを上回る性能を持っているという。

現在公開中の「{target=“_blank”}」では、LLM比較というテーマで、GPT-4o（OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった主要LLMの最上位モデルの比較結果のまとめ記事（{target=“_blank”}）を公開している。

今回の発表を受け、EXPO特設サイトでは、上記記事の追加企画として、Anthropicの最新LLM「Claude 3.5 Sonnet」について解説するLIVE配信を行う。

前バージョンのモデルであるClaude 3 Opusとの違いや、GPT-4oやGemini 1.5 Proといった他LLMとの違いを実際のデモを通じて比較しながら、リアルな使用感をお届けする。
主要LLMの最新情報をアップデートしたい読者は、是非視聴してみてほしい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button
{target=“_blank”}
:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。

## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
URL：{target=“_blank”}
配信形式：zoomウェビナー（LIVE）
配信日時：2024年06月27日（木） 15:00〜15:30
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Tue, 25 Jun 2024 13:36:46 +0000</pubDate></item><item><title>NLP（自然言語処理)これまでの80年とこれからの20年（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-msd-short</link><description>
:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

## ChatGPTなどに活用されるNLPの歴史を紐解く
生成AIの台頭により "NLP" が一般的にも広く認知されるようになったが、NLPが80年にわたって発展してきた技術であることはご存じだろうか。実は、NLPの起源を探ると、1940年代の機械翻訳までさかのぼる。

今回は、長年研究されてきた技術であるNLPについて、元女子高生AI「りんな」などで知られるrinna株式会社の元CEOであり、現在はマイクロソフト ディベロップメント株式会社のプリンシパル アプライド サイエンティストであるZhan (Cliff) Chen / 陳 湛 氏にお話を伺った。

:::box
!
**マイクロソフト ディベロップメント株式会社**
**Zhan (Cliff) Chen / 陳 湛 氏**
:::

:::button
{target=“_blank”}
:::

**Cliff 氏**
私は今年の４月にマイクロソフトに入社しましたが、実は入社は２回目です。2015年にマイクロソフトでAIチャットボットのrinnnaを作り、翌年以降もディープラーニングの技術を用いたチャットボットを開発していました。例えば、音声合成、歌、ダンスなど、現在生成AIで話題になっているコンテンツを2017年～2019年ごろに研究していて、2019年にはGPTがチャットボット開発に適していることも発見していました。
そもそもなぜチャットボットなのか？という点ですが、チャットボットは人間の知能に一番近いと考えていたからです。GPTには未来がありそうだと考えていました。2019年11月には、現在「RAG」として認知が広がっている技術も作って、発表も行っていました。

!

2020年にマイクロソフトからrinnaがスピンオフして、rinna株式会社を設立し、そこのCEOに就任しましたが、面白かったのは2021年4月ごろに日本語版のGPT-2のオープンソースで発表したことです。そこからGPTをアップデートし続け、Hugging Faceでオープンソースとしてリリースしていました。
凄く自慢できることがあるのですが、その当時の日本のNLP大会の中で、rinnaのGPT-2の技術を引用した論文が全体の3%から5%程あったことです。その当時はBERTが主流で、GPTはマイナーな技術だったのですが、日本語のGPTの論文の中にrinnaの技術が参照されていたのは印象深かったです。

**箕部（モデレーター）**
RAGの研究に関してもかなり早い段階から行われていたのですね。

**Cliff 氏**
我々もその時、KGC(※)は重要だということをたくさん話していましたが、そもそもGPTがマイナーだったのと、GPTは誤回答をすることから「全然ダメだ」と言われていましたね（笑）

OpenAIのChatGPTが出たことは、アカデミックから見るとそんなに革新的ではないのですが、インダストリーの観点から見ると一般ユーザーのマインドセットが変わった出来事でしたね。

:::box
（※）KGC（Knowledge Graph Construction）：知識グラフの構築のこと。知識グラフとは、知識を抽象化したデータ間の関係性を示すデータベース。知識情報が体系的に整理されることで、検索や情報抽出などのタスクにおいて必要な情報を提供することに役立つ。
:::

**箕部（モデレーター）**
AIを理解するうえで、”これまで” と “これから” を理解していくことが重要だと考えますが、クリフさんは専門だと思いますので、そのあたり詳しくお話を伺えればと思います。

**Cliff 氏**
「今までのNLPの80年」について、つまり、LLM（大規模言語モデル）はどこから来たのか？という話ですが…

※続きは特設サイトよりご覧ください 

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：
開催形式：オンライン（特設サイト）</description><pubDate>Fri, 21 Jun 2024 06:43:48 +0000</pubDate></item><item><title>【主要LLMの最上位モデルを比較】GPT-4o、Gemini Pro1.5、Claude 3 Opus 仕事で使えるLLMはどれか？まとめ記事公開中！</title><link>https://ledge.ai/articles/expo2024-llm-comparison</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

大規模言語モデル（LLM）は、チャットボットや文章生成、翻訳、要約、コード生成などの様々なタスクで活用されている。その一方で多くのLLMが存在しており、どれを選べばよいか頭を悩ませている読者も多いと思われる。

6月10日（月）より公開しているLedge.ai EXPO 2024 Summerでは、GPT-4o（ChatGPT / OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった最新モデルを比較したまとめ記事を公開している。いわゆるLLMのスペック比較ではなく、実際の出力結果を比較し、その使用感や出力の特徴を解説しているので、自社にとって最適なLLMを探す際の参考情報としてご覧いただきたい。

:::button
{target=“_blank”}
:::

## ビジネスシーンでの活用を想定した３つのタスクの実行結果を比較
今回の比較記事の中では、以下３つの主要LLMの最上位モデルを対象として比較を行っている。

- GPT-4o（ChatGPT / OpenAI）
- Gemini 1.5 Pro（Gemini / Google）
- Claude 3 Opus（Claude / Anthropic）

パラメータ数や学習データの範囲といったスペック比較は既に様々なところで行われているため、今回は仕事で実際に使えそうか？という観点で、企画、データ分析、ルーティンワークといった切り口で、LLMのアウトプットの比較を行った。
ビジネスシーンでの活用を想定した３つのタスクとその結果の一部を以下に紹介する。

## 企画：アイデアを創造する能力を比較
記事の中では、各LLMに「新しいテクノロジー製品のアイデアを提案してください。」というプロンプトを送り、それぞれの出力結果を比較している。
LLMは、学習した膨大な過去データから確率的な推論を行い、もっともらしい出力を行うものである。よくも悪くも私たち人間の一般的な価値観に合わせた平均的な回答の生成が得意なLLMが、新しいアイデアの発想において、現在どの程度のアウトプットを出すことができるのかをまとめている。

例えばOpenAIが開発した最新の大規模言語モデルGPT-4oでは、アイデアの中身については、真新しさや面白みには欠けるのは否めないというのが正直な評価であった。しかし出力に関する指示はなくとも、文章の項目構成を整理したアイデアが出力してくれる点には有用性も感じられた。アウトプットをそのまま使うレベルではないものの、着想のきっかけを得るための手段としては十分に使えるものではないだろうか。

!
:::small
GPT-4oが出力した企画案
:::

その他の２つのLLMの実行結果も記事の中で取り上げている。詳細は是非記事をご一読いただきたい。

## データ分析：データを理解し、可視化する能力を比較
２つ目のデータ分析の比較も興味深い示唆が得られる内容になっている。比較の内容としては、ChatGPTで生成したマーケティングデータのサンプルファイルを元に各LLMに分析結果を出力してもらった。上述した企画よりも、LLM毎の違いが見受けられた。

特にGeminiは、出力後もグラフをインタラクティブに操作でき、その場でデータの編集ができる。またGoogleスプレッドシートとの連携もスムーズにできる点などは、Google製品で業務を行っているビジネスマンにとっては、有力な選択肢となりそうだ。

!
:::small
Gemini 1.5 Proでのグラフ編集の動画も公開している
:::

## ルーティンワーク：記事を要約する能力を比較
最後に記事要約の実行結果をまとめている。シンプルなタスクであるがゆえに、LLMが有する言語処理能力がわかりやすく現れる内容といえるだろう。
今回は以下の記事の原稿ファイルを読み込ませ、要約を実行した。

:::box
{target=“_blank”}
:::

要約の内容については、どのLLMも違和感はなく、十数秒ほどで得られるクオリティとしては十分なものだった。しかし要約の仕方にはそれぞれ違いがあり、この部分は個人によって判断が分かれるように思われる。記事内の実行結果をその目で見て判断いただきたい。

!
:::small
Claude 3 Opusが出力した要約結果
:::

今回はプロンプト内で出力の形式などを特段指示していないため、プロンプトの作り込みで変わってくる部分もあるだろう。しかし同一の条件の元で、各LLM毎のアウトプットの違いを把握しておくことは、LLMを選ぶ際の重要な参考情報となりうる。記事をきっかけに是非お手元で試し、実際の使用感を体験いただきたい。
比較記事の全文は以下の特設サイトより閲覧できる。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 20 Jun 2024 06:38:09 +0000</pubDate></item><item><title>AWSが新AI認定試験を発表　2024年8月13日より開始、初の「ベータ試験」での日本語試験も提供</title><link>https://ledge.ai/articles/aws_crtified_ai_practitioner</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年6月14日、Amazon Web Services, Inc.（AWS）は、AI人材育成に関する説明会で、AIスキルを証明できる「AWS Certified AI Practitioner」と「AWS Certified Machine Learning Engineer（MLA）」の2種の新しい認定試験が2024年8月13日から開始することを{target=“_blank”}した。

**「AWS Certified AI Practitioner」**
AI、機械学習（ML）、および生成AIのコンセプトやツールに精通していることを証明する際に役立つ、AIに特化した資格だ。この資格は、AWS認定試験の4つのレベルの中でも基礎的な知識習得を目的とした「Foundational」のカテゴリに位置づけられる。

**「AWS Certified Machine Learning Engineer（MLA）」**
こちらは、AIやMLソリューションの構築、デプロイ、保守に必要なスキルを証明するものであり、モデルパフォーマンスの最適化、計算資源の管理、モデルのバージョンアップ、AIソリューションの保護などをスキル対象とする技術者向けの認定資格だ。AWS認定試験の「ASSOCIATE」のカテゴリに位置づけられる。

新たな2種の認定資格は、2024年8月13日から「ベータ試験」として登録を開始する。通常は英語での実施だが、このベータ試験は同社として初の試みである日本語試験も提供をする予定だという。
</description><pubDate>Thu, 20 Jun 2024 09:19:07 +0000</pubDate></item><item><title>その日から使えるデモも実演！「マルチモーダルAI」の概念を15分で丁寧に解説するウェビナーが公開中</title><link>https://ledge.ai/articles/expo2024-webinar-multimodalai</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 多種多様なデータを扱うことが生成AIをビジネスで活用する際の重要な鍵となる
生成AIは、ビジネスの多岐にわたる分野で急速に活用されている。生成AIは、テキスト、画像、音声、ビデオなどの多種多様なデータを扱う能力により、より高度な意思決定や業務効率化を実現するツールとして注目を集めている。特に、マルチモーダルAIの多様なデータソースを統合して分析・生成する能力は、ビジネスの競争力を高める鍵として注目を集めている。

とはいえマルチモーダルAIという言葉こそよく耳にする機会は増えてきたものの、実はまだその概念について良くわかっていない読者も多いのではないだろうか？

6月10日（月）より開催している「Ledge.ai EXPO 2024 summer」オンライン特設サイトでは、マルチモーダルAIについて15分で基本的な概念を解説するウェビナーを公開している。マルチモーダルAIの概要を短時間で学べるため、興味のある方は是非動画をご覧いただきたい。



:::button
{target=“_blank”}
:::

## マルチモーダルAIとは何か？
マルチモーダルAIとは一言で説明すると、複数種類の情報を組み合わせて高度な判断を行うAIのことである。モーダルとはデータの種類を指し、テキストや画像、音声、映像など様々なデータを扱うことが含まれている。
ビジネスの現場で扱うデータが多様化してきたことで、このマルチモーダルAIが今注目を集めている。

!

私たちがこれまでAIとして扱ってきたいわゆるシングルモーダルAIでは、単一のデータ形式に特化していた。マルチモーダルAIでは、異なるデータ形式間の関連性を学習し、それを基にした高度な予測や判断を行うことが可能になる。これにより単一のデータ形式だけでは得られない複雑な処理結果を引き出すことができる。

!

## 大規模言語モデルとの統合でマルチモーダルAIの能力は飛躍的に向上
大規模言語モデル（Large Language Models, LLM）は、テキストデータの処理に特化したAIモデルであり、膨大なテキストデータから学習することで、高度な言語理解能力を持っている。この言語処理能力が、異なるデータ形式間の関連性の理解においても非常に高い性能を発揮し、主要な大規模言語モデルにも、画像、テキスト、音声などのデータを統合して処理するマルチモーダル機能が強化される動きが加速した。

ウェビナーの中でも国内外の主要な大規模言語モデルを4つほどピックアップしているので、是非チェックしてみてほしい。

!

## マルチモーダルAIでどんなことができるかをデモ実演
ウェビナーの中では、OpenAIの最新モデル「GPT-4o」を使い、ビジネスシーンでの活用を想定したデモを実演している。すぐ試すことができるデモ内容になっているので、是非動画を参考に自身の業務の中でも活用してみてもらいたい。

今回は
- ホワイトボードの会議メモの整理
- 手書きのラフデザインからhtmlのソースコードを生成

の2種類のデモを行った。
ホワイトボードの会議メモを整理するデモについてその一部を簡単に紹介する。

会議でディスカッションした内容をホワイトボードに書き込んで記録することは、ビジネスの現場でよく見られる光景だ。
ホワイトボードの内容を構造化して整理しておきたい場合に、手打ちでテキストメモに書き起こしたりしていないだろうか？
こうした作業は、マルチモーダルAIを活用することで、作業を大幅に効率化できる。

!
!

デモの中では、ホワイトボードを撮影した画像と簡単な指示テキストを与えるだけで、情報が整理されたテキストメモが出力される過程を確認することができる。さらにそのメモからアイデアをブラッシュアップするといった追加指示を与えて、ただの文字起こしに＋αのタスクを実行させるところまで実演しているので、このあたりも注目してみてもらいたい。

ーーー

マルチモーダルAIは、大規模言語モデルと統合し、より自然で人間らしいインタラクションが実現可能になり、さまざまな分野での応用が期待されている。
この機会にぜひ動画をご覧いただき、ビジネスの現場でどのように活用できるかを学び、実際に導入するためのヒントとなれば幸いである。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）

</description><pubDate>Fri, 14 Jun 2024 04:03:02 +0000</pubDate></item><item><title>生成AIの未来を掴むための3つのキーワード（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-keyword-short</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

生成AIの発展は目覚ましいものである。その中で特に「マルチモーダルAI」「AIエージェント」「独自データ活用」の3つは、今期の企業の生成AI活用において、押さえておきたい重要キーワードだ。

「マルチモーダルAI」とは、テキストや画像、音声など複数の情報形式を統合的に理解・生成する技術で、「AIエージェント」とは特定のタスクを自律的に実行するAIプログラムであり、ビジネスプロセスの自動化と効率化を実現できるものである。また、最近の生成AI活用事例で多く耳にするようになった「独自データ活用」は、企業が保有するデータを活用してAIモデルのトレーニングを行う、または、保有データを参照して企業に特化した回答を生成する手法だ。

この3つのキーワードは、生成AIの未来を切り拓くために不可欠な要素であり、企業の競争力を高め、ビジネスの成長を加速させるものである。生成AIの社内活用を推進している、または、今後更なるAI活用を検討するユーザーは必見の内容だ。ぜひ特集サイトから一読いただきたい。

:::button
{target=“_blank”}
:::
## 目次
1. マルチモーダルAI：データの壁を越える技術
2. AIエージェント：企業のパートナーとしての役割
3. 独自データ活用：基盤モデルをベースに競争力強化
4. まとめ

## マルチモーダルAI：データの壁を越える技術
マルチモーダルAIは、テキスト、画像、音声などの複数のデータ形式を同時に解析する技術だ。これにより、単一のデータ形式では得られない洞察を引き出すことができる。例えば、画像とテキストを組み合わせることで、物体認識とその説明を同時に行うことが可能となる。こうした技術は、特に多様なデータを扱う現代のビジネス環境において非常に重要だろう。

技術的な中核には…

※続きは特設サイトよりご覧ください。

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 13 Jun 2024 03:47:03 +0000</pubDate></item><item><title>AWSが、生成AI業務アプリを作成する「AWS App Studio」のプレビューを公開　開発スキルがなくても自然言語で利用できる</title><link>https://ledge.ai/articles/aws_app_studio_public_preview</link><description>:::small
画像の出典：{target=“_blank”}
:::

現地時間の2024年7月10日、米Amazon Web Services（AWS）は、ニューヨークで開催された「AWS Summit New York 2024」で、生成AIでアプリ作成ができる「AWS App Studio」のパブリックプレビューを{target=“_blank”}した。

「AWS App Studio」は、専門的なソフトウェア開発スキルがなくても、自然言語で作成したい業務アプリの説明を行うと、数分で業務アプリを作成することができる。

以下のように、左側に作成したい業務アプリの説明を入力をすると、入力されたプロンプトをもとに、生成AIがアプリのユースケース、操作の流れや主要機能を右側に書き出す。内容に問題がなければ生成を開始すると、わずか数分でアプリを作成することができる。さらに、生成されたアプリは公開前に実際のデータソースを使用して、プレビューで検証することもできるという。

!

:::small
画像の出典：{target=“_blank”}
:::

また、AWS App Studioの利用料金は無料で、開発されたアプリを使用した分だけ支払うシステムとのこと。例えば、企業で今後3ヶ月以内にAWS APP Studioを使用して2つのアプリを作成予定だった場合、2つのアプリを公開後1ヶ月のうちに10日間各アプリを使用した場合は、以下のような料金体系となる。

!

:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::

:::box

:::
</description><pubDate>Tue, 16 Jul 2024 13:58:52 +0000</pubDate></item><item><title>AGI実現への一歩となるコンテスト「ARC Prize 2024」開催中　賞金総額は約1億8000万円！</title><link>https://ledge.ai/articles/arc_prize_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月11日より、Zapier社の共同創設者マイク・クヌープ氏とGoogleの研究者フランソワ・ショレ氏が提案する「ARC」（Abstraction and Reasoning Corpus）を用いたコンテスト「ARC Prize 2024」が{target=“_blank”}されている。

ARCは、AGI（汎用人工知能）に向けた進歩を測定するAIベンチマークであり、人工知能と人間の知能を比較することを目的として作られた。これまでの競争では、人間の平均84％の正解率に対して、AIの最高スコアは34％程度となっている。これらの根本となる知識は、人間が子供の頃から自然と身につけている感覚のため、人間にとっては簡単だがAIには難解なテストだという。

現代のAI研究は大規模言語モデル（LLM）に重点を置いているが、これらのモデルは基本的な新しい発明や単純な問題への適応ができないため、真の知能とは言えない。この問題に対処するため、ARCというベンチマークテストが注目を集めている。

「ARC Prize 2024」は、LLMを超えた新しいアイデアを研究者が探求し、その進歩をオープンソース化することを目的としている。コンテスト提出締切は11月10日で、12月3日に賞の発表を予定しているとのこと。

テスト内容は以下のとおり、カラフルなグリッド図形から規則性を見つけ、右側のテスト用のアウトプットにその規則性に基づいた図形を表現する簡単なテストだ。
!
:::small
画像の出典：{target=“_blank”}
:::

【ARC Prize 2024の概要】
**グランプリ**
・1位：25万ドル（約3,500万円）
・2位：10万ドル（約1,400万円）
・3～5位：5万ドル（約700万円）
・追加グランプリ：50万ドル（約8,081万円）
※人間の正解率が平均84％のため、85％以上の精度スコアを達成した上位5チームに追加のグランプリ50万ドルを分配。
**2024進歩賞**
・1位: 2.5万ドル（約404万円）
・位: 1万ドル（約161万円）
・3〜5位: 各5,000ドル（約80万円）
※2024年の競争期間中に最高スコアを記録した上位5チームに授与
**論文賞**
・優勝: 4.5万ドル（約727万円）
・次点: 5,000ドル（約80万円）
※ARC-AGIでの性能を実現する方法についての理解を最も進展させた論文に授与
**参加条件**
・提出物のコードと手法はパブリックドメインのオープンソースライセンスの下で公開する必要がある
・第三者のコードや手法もオープンソースライセンスの下で利用可能でなければならない

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Jul 2024 07:18:15 +0000</pubDate></item><item><title>OpenAI が開発者向けQ&amp;AコミュニティサイトStack Overflowと新たなAPIパートナーシップを発表</title><link>https://ledge.ai/articles/openai_stackoverflow_api_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、OpenAIとStack Overflowは、開発者向けに最適化された技術情報とAI開発ツールを提供する新しいAPIパートナーシップを{target=“_blank”}した。

このパートナーシップにより、OpenAIのユーザーや顧客は、Stack Overflowが提供する正確で検証済みのデータを基に迅速な問題解決を図り、重要なタスクに集中できるよう支援されるという。

この協業の一環として、OpenAIはStack Overflowの「OverflowAPI」を利用し、ユーザーにStack Overflowの検証済み技術知識を直接提供する。これにより、ChatGPTはStack Overflowの豊富な技術データベースと連携し、利用者に対してより精度の高い支援を提供できるようになる。また、Stack Overflowは、OpenAIのAIモデルを利用して「OverflowAI」の開発を行い、内部テストから得た洞察を活かしてAIモデルの性能向上を図る。

このパートナーシップは、技術者が直面する課題への対応速度を向上させ、開発者コミュニティ全体の生産性とエンゲージメントの向上を目指している。両社は、開発者が必要とする情報や解決策を、より迅速かつ正確に提供できる環境を整備することで、技術開発の新たなスタンダードを築くことを目指している。

Stack Overflowは2月29日にGoogle Cloudとの協業を発表しており、「Gemini for Google Cloud」との統合を進めている。この連携ではGoogle Cloudのプラットフォーム上でStack Overflowの情報を活用し、開発者が容易に重要なナレッジベース情報やコーディング支援を利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 12:52:43 +0000</pubDate></item><item><title>AWSが「Amazon Q」の一般提供を開始　企業内データを活用したAIアプリケーション開発の加速を目指す</title><link>https://ledge.ai/articles/amazon_aws_q</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）は2024年4月30日、生成AIアシスタント「Amazon Q」の一般提供を開始したと{target=“_blank”}した。

このサービスは、開発者が自社のデータを活用してAIアプリケーションを構築できるよう支援することを目的としており、特にソフトウェア開発の加速と企業データの活用が可能になるという。

Amazon Qは、コード生成、テスト、デバッグ、計画立案、推論機能を備え、開発者はコードの自動変換やアップグレード（Javaバージョンアップグレードなど）、新しいコードの実装が可能となる。この生成AIアシスタントは、エンタープライズデータリポジトリへの接続もサポートしており、企業のポリシー、製品情報、業績、コードベース、人材に関する質問への回答や、データの論理的な要約、トレンド解析、データ関連の対話が行えるとのこと。

また、社内データから生成AIアプリの構築を可能にする新機能「Amazon Q Apps」も同時に発表された。従業員は自然言語でアプリについて記述するだけで、必要とされる業務を遂行するアプリを生成できるという。この機能により、日常業務の簡素化と自動化が促進される。

さらに、Amazon Qは40以上の一般的なビジネスツールと簡単に接続でき、企業は自社のデータを効率的に集約し、アクセスできるようになる。この広範なデータ統合能力により、企業はよりデータ駆動型で効率的な運営が可能になる​とのことだ。


:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 11:42:47 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>AIモデルの「モデル崩壊」に対する脆弱性が判明　他のAIモデルが生成したデータを学習することのリスク</title><link>https://ledge.ai/articles/ai_models_collapse_when_trained_on_recursively_generated_data</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月25日、オックスフォード大学のイリア・シュマイロフ氏率いる研究チームが、AIモデルが「モデル崩壊」と呼ばれる現象に対して根本的に脆弱であることを示す論文を学術誌『Nature』に{target=“_blank”}した。

この現象は、他のAIモデルによって生成されたデータを学習することで発生し、AIモデルが時間とともに基礎となるデータ分布を忘れてしまうという退化プロセスを指すという。

論文では、モデル崩壊の現象を視覚的に示すために、言語モデルを用いて実験を行った。下図は、モデルの世代が進むにつれてデータの品質がどのように劣化するかを示している。

図a：モデル崩壊のフィードバックメカニズムの高レベルの説明。初期データは人間によってキュレーションされたものであり、時間とともにモデル生成データがデータセットに加わる。
!
:::small
画像の出典：{target=“_blank”}
:::


図b, c：異なる世代のモデルが生成するデータの複雑度（perplexity）のヒストグラム。初期モデルが生成したデータは高品質だが、世代が進むにつれてデータの品質が低下し、エラーが蓄積される

!
!


:::small
画像の出典：{target=“_blank”}
:::

研究によると、「モデル崩壊」を防ぐためには、人間が生成したデータに依存することが重要だという。AI生成データと人間生成データを区別し、適切にフィルタリングする必要がある。例えば、AI生成データにウォーターマークを付ける方法が提案されているが、これには大規模な調整と協力が必要とされる。さらに、元のデータ分布にアクセスし続けることが不可欠であると強調した。

この研究は、将来的なAIモデルの開発において、人間の監視とデータの管理の重要性を示しているという。AIの生成するデータの品質と信頼性を確保するため、AIモデルのトレーニングデータの出所を明確にし、人間の生成するデータを活用することが不可欠だと述べられている。


:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jul 2024 08:46:28 +0000</pubDate></item><item><title>ディープフェイク画像の新たな見抜き方「眼の中の星を観て検出」ー英国王立天文学会で発表される</title><link>https://ledge.ai/articles/want_spot_deepfake_look_stars_their_eyes</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月14〜19日にイギリスで開催された{target=“_blank”}で、イングランド・ハル大学の研究チームは、銀河の測定に使用される天文学的手法を応用して、ディープフェイクを見分ける新たな技術を{target=“_blank”}した。この手法は、人間の目の反射に基づいて画像の真偽を判断するものだという。

同大学の大学院生アデジュモケ・オウォラビが中心となった研究チームは、ディープフェイク画像の目の反射に不一致が見られることに着目した。通常、現実の人間の目では左右の目の反射が一致するが、AI生成画像ではこの反射が物理的に一致しないことが多いという。

研究チームは、天文学で使用される手法を応用して反射を定量化し、左右の眼球の反射の一致性をチェックした。まず、光の分布を測定し、眼球の反射の形態学的特徴を分析するためにCAS（集中度、非対称性、平滑性）指標を使用したが、これは偽の目の予測には成功しなかった。一方、Gini係数を用いることで、反射の不一致を検出することができたという。Gini係数は、銀河の画像の光がピクセル間でどのように分布しているかを測定するためのものであり、この手法が眼球の反射の分析に有効であることが示された。

下の画像は、それぞれの目に一貫性のない反射を示すディープフェイクの目を並べたもの


!
:::small
画像の出典：{target=“_blank”}
:::

こちらは、両目にほぼ一貫した反射を示す本物の目を写したもの

!
:::small
画像の出典：{target=“_blank”}
:::


この新しい方法により、ディープフェイクの検出精度が向上することが期待されるが、万能な解決策ではないと研究者たちは強調している。ハル大学のケビン・ピンブルト教授は、「この方法はすべての偽画像を検出できるわけではなく、誤検出や見逃しが存在する。しかし、ディープフェイクとの戦いにおいて重要な基盤を提供する」と述べた。



:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jul 2024 08:39:52 +0000</pubDate></item><item><title>Stability AI、新たなマルチアングル映像生成モデル「Stable Video 4D」を発表</title><link>https://ledge.ai/articles/stability_ai_svd-4d</link><description>:::small
画像の出典：{target=“_blank”}
:::

Stability AIは2024年7月24日、1本の動画から8つの異なるアングルやビューの動画を生成するAIモデル「Stable Video 4D」を{target=“_blank”}した。このモデルは、ユーザーが動画をアップロードするだけで、複数の視点からの映像を簡単に生成できるという。

Stable Video 4Dは、Stability AI初のVideo to Video生成モデルで、Stable Video DiffusionとStable Video 3Dを基に開発されたという。ユーザーは希望する3Dカメラの視点を指定することで、入力動画に映るオブジェクトの新規ビュー動画（4D画像マトリックス）を生成し、8つの異なるアングルの動画を出力できる。

@

このモデルは、5フレームの動画を約40秒で生成し、全体の4D最適化には約20～25分かかるという。

Stability AIは、この技術がゲーム開発、動画編集、VRコンテンツ生成などの分野で大きな応用可能性を持つと説明している。複数の視点からオブジェクトを視覚化する能力により、製品のリアリティと没入感を高めることができると期待されているとのこと。

Stable Video 4Dのトレーニングデータセットには、Open Data Commons Attribution Licenseが配布するObjaverseが利用されたという。

現在、Stable Video 4Dは研究段階にあり、{target=“_blank”}で利用可能とのこと。Stability AIのチームは、合成データセットに加えて、実世界のビデオにも対応できるようモデルを最適化している。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jul 2024 08:55:27 +0000</pubDate></item><item><title>枯渇するAIトレーニングデータ：データ収集の新たな課題とその影響　MIT主導の調査団体が発表</title><link>https://ledge.ai/articles/dpi_consent_in_crisis_paper</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

AIモデルのトレーニングに必要となる大量のテキスト、画像、動画データは、主にインターネットから収集されるが、近年、多くのWebサイトがロボット排除プロトコル（robots.txt）を使用して自動収集をブロックしている。また、利用規約を変更してデータの使用を制限するサイトも増えているという。

2024年7月19日の{target=“_blank”}の記事によると、AI企業が使用可能なデータの総量は1年で約5％減少し、高品質なデータは約25％が利用できなくなっているという。これらの制約は、特にニュースサイトやソーシャルメディアプラットフォームからのデータ収集において顕著であるとのこと。

MIT主導のData Provenance Initiative（DPI）によるこの調査は、問題の深刻さを浮き彫りにしている。DPIは、AIトレーニング用データセット「C4」「RefinedWeb」「Dolma」に含まれる1万4,000件のWebドメインを分析し、クローリングで得られるデータとその使用に関する同意状況の変化を追跡した。その結果、これらのデータセットにおけるトークンの約45％が、利用規約の変更により使用制限がかけられていることが判明したという。

DPIは、MITメディアラボのプロジェクトとして開始され、AIトレーニングデータセットのライセンスおよび帰属に関する大規模な監査を行う団体だ。法律および機械学習の専門家が協力し、データセットの出所や使用に関する透明性を向上させることを目的としているという。
## データ制限の現状とその傾向
調査によると、2023年から2024年の間にC4データセットの5％以上、最も重要なソースの28％以上がrobots.txtによって制限されている。また、利用規約による制限は全体の45％に及ぶ。

下図は、2016年から2024年までの期間における、主要なWebドメインにおけるrobots.txtと利用規約の制限の変化を示している。この図は、AI組織のクローラーに対する制限の増加を視覚的に示すもので、特に2023年以降、AIクローラーに対するrobots.txtの制限が急増していることが明らかにされている。

!
:::small
画像の出典：{target=“_blank”}
:::

## 主要なデータ制限の例
- **RedditとStackOverflow：**  各サイトは、AI企業に対してデータアクセスを有料化している
- **The New York Times：** NYTは、OpenAIやMicrosoftを著作権侵害で訴えており、これらの企業がニュース記事を許可なく使用してAIモデルをトレーニングしたことが原因と考えている

高品質なデータの減少は、AIモデルの性能低下や、公開データセットに依存する小規模なAI開発者に対して影響を及ぼすという。

OpenAIは、クローリングによるデータ収集が{target=“_blank”}しているが、出版社やコンテンツ提供者向けにオプトアウト機能を提供するなど、倫理的なデータ利用を推進している。同社は、クローリングによるデータ収集が法的に認められている地域であっても、コンテンツ提供者の意向を尊重する姿勢を示しているという。

DPIは、Web上のデータ収集に関する同意の取り扱いが不十分で、多くのサイトがAI開発に対してデータ利用を制限していると指摘。この傾向は、今後も続くと予測され、AI技術の発展において重大な影響を及ぼす可能性があると述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Jul 2024 22:32:48 +0000</pubDate></item><item><title>AIエージェントに「心の理論」を実装すると、他のエージェントの状態を推測して行動するーースタンフォード大学の研究</title><link>https://ledge.ai/articles/hypothetical_minds</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

スタンフォード大学の研究チームは2024年7月9日、認知科学に基づく設計で、他のエージェントの状態を推測して行動するエージェント「Hypothetical Minds」の成果を{target=“_blank”}した。このモデルは、競争、協力、混合動機のマルチエージェント環境で他のエージェントの戦略や目標を推測し、適応的な行動を取ることができるという。

Hypothetical Mindsは、LLMを中核に据えた認知的なアーキテクチャを特徴とし、認識、記憶、階層的な計画のためのモジュールを統合している。特に、心の理論モジュール（ToMモジュール）を搭載しており、他のエージェントの戦略や目標に関する仮説を自然言語で生成、評価、改良する機能を持つという。

このToMモジュールは他のエージェントの行動を観察し、仮説を生成してからその仮説を評価、改良する一連のステップを経る。このプロセスにより、Hypothetical Mindsは他のエージェントの行動を効果的に推測し、適応的な戦略を実行することが可能となる。

下図は、Hypothetical Mindsがどのようにして他のエージェントの行動を予測し、仮説を評価・改良するかを示している。エージェントは観察データをもとに、他のエージェントの戦略に関する仮説を生成し、それを繰り返し評価することで、より正確な仮説に近づいていく。

!
:::small
画像の出典：{target=“_blank”}
:::


## 実験結果と評価
研究チームは、マルチエージェント環境「Melting Pot」ベンチマークにおいて、Hypothetical Mindsの性能を評価した。このベンチマークには、競争的、協力的、および混合動機のドメインが含まれており、30の異なる評価シナリオが存在する。

**競争環境（Running With Scissors）：** ゼロサムゲーム環境で、エージェントは他のプレイヤーの動きを予測し、対抗する戦略を選択する。Hypothetical Mindsは、固定的な戦略を採用するシナリオでも、適応的な戦略を用いるシナリオでも、常に高い報酬を得ることができた。

**協力環境（Collaborative Cooking Asymmetric）：** 非対称のキッチンでトマトスープを効率的に調理するために、エージェントが協力する。このシナリオでは、Hypothetical Mindsはパートナーのスキルや役割に適応し、高い協力成果を上げた。

**混合動機環境（Prisoner’s Dilemma）：** エージェントは協力または裏切りの選択を行うが、長期的な利益を最大化するためには協力が必要である。Hypothetical Mindsは、動的なパートナーとの相互作用で最も高いスコアを達成した。


Hypothetical Mindsは、LLMを活用して他のエージェントの意図を推測し、適応的に行動するエージェントとして、競争的、協力的、および混合動機のマルチエージェント環境で高い性能を発揮した。特に、心の理論モジュールの導入により、他のエージェントの戦略を効果的に推測し、それに基づいて行動を選択する能力が向上したことが確認されたという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 04:11:05 +0000</pubDate></item><item><title>ディズニーの研究チームが二足歩行ロボット『BD_X』を発表ーー「強化学習」で表現力豊かな動きを実現</title><link>https://ledge.ai/articles/disney_research_bdx</link><description>:::small
画像の出典：{target=“_blank”}
:::

ディズニーリサーチとウォルト・ディズニー・イマジニアリングの研究チームは2024年7月15日、エンターテインメント分野向けに特化した新しい二足歩行ロボット「BD_X」の設計と制御技術を{target=“_blank”}した。このロボットは、観客に対する魅力的なパフォーマンスを実現するために、芸術的な動きと動的な安定性を両立しているという。

@

このロボットは、ディズニーキャラクターのような表現力豊かな動きを実現することを目的としている。ロボットが芸術的な動きをしながらも、バランスを保って安定して動くことができるように設計されている。

「BD_X」は、両足に5つの関節、首と頭に4つの関節を持つ。このため、複雑で多彩な動きを可能にしている。さらに、強化学習によりロボットが芸術的な動きを学習し、実行するという。

下図は、キャラクターデザインと制御の全体的な流れを示している。アニメーションとロボットの設計が互いに影響し合いながら進められ、最終的にはリアルタイムでの操作が可能になる。

!
:::small
画像の出典：{target=“_blank”}
:::

強化学習とは、ロボットが試行錯誤を通じて最適な動きを学ぶ方法である。この技術を使って、ロボットはさまざまな動きや歩行を習得する。ディズニーの研究チームは、ロボットが立ったり歩いたり、特定の動作を繰り返したりするための複数の動きを学習させた。

実際の運用では、リモコンを使ってロボットを操作する。操縦者は、直感的な操作でロボットにさまざまな動きをさせることができる。この技術は、エンターテインメントだけでなく、教育や医療、サービス業などのさまざまな分野での応用が期待できるとのこと。

下図は、操縦者がロボットを操作し、人間と対話する様子を示している。上部の画像では、ロボットが紙巻きを見つけて、それをベンチの下に蹴り飛ばすシーンを演じている。下部の画像では、ロボットが人間に近づき、頭をなでられる様子を示している。このようにして、ロボットはさまざまな感情表現やインタラクションを実現する。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 04:07:03 +0000</pubDate></item><item><title>Microsoftがスプレッドシートなどの表計算ソフトを理解できる大規模言語モデル「SpreadsheetLLM」を発表　複雑なスプレッドシートの処理を削減</title><link>https://ledge.ai/articles/spreadsheet_llm_microsoft</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月12日、Microsoftの研究チームは、大規模言語モデルを活用してスプレッドシートの処理を効率的に行う技術「SpreadsheetLLM」を{target=“_blank”}した。

スプレッドシートは、ビジネスで広く使用されるデータ管理ツールだ。しかし、その複雑なレイアウトや多様なフォーマットで大量のデータを効率的に処理することは従来の手法では困難だったという。この課題改善のために、スプレッドシートの理解および、効率的に処理することを目的として「SpreadsheetLLM」が開発された。

SpreadsheetLLMの中心となるのは、「SheetCompressor」という手法で、表計算シート内で重要な構造を特定し、その情報を保持しながらデータ量を大幅に削減する。SheetCompressorは、表計算データを平均して25倍に圧縮することに成功しており、LLMが一度に処理できるデータ量が増加する。これにより、複雑な表計算ファイルの分析が可能となり、データ処理にかかる計算コストも96％削減されたという。

実験結果において、SpreadsheetLLMは表計算検索タスクで従来のモデルを12.3％上回る性能を達成したと発表している。
!

:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Jul 2024 14:44:17 +0000</pubDate></item><item><title>OpenAI　開発コードは「Q*」から「Strawberry」に。推論能力を向上し、数学などの高正答率を目指す新たなAI技術の開発が進んでいる</title><link>https://ledge.ai/articles/openai_strawberry</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月12日、ChatGPTを開発したOpenAIが「Strawberry」というコードネームの新しいAI技術に取り組んでいることが、内部文書と関係者の証言により明らかになった。{target=“_blank”}によれば、プロジェクトはMicrosoftが支援するOpenAIがAIモデルの推論能力を向上させるために進めているという。

OpenAIの内部文書によると、Strawberryは単に質問に答えるだけでなく、インターネットを自律的かつ信頼性を持ってナビゲートし、「深い研究」を行う能力を持つことを目指している。推論能力の向上により、AIモデルが複雑なタスクを計画し実行する能力を持つことが期待されているとのこと。

Strawberryプロジェクトは以前「Q*」として知られており、すでに社内で画期的なものと見なされていた。内部文書には、Strawberryモデルが複雑な科学や数学の質問に答えるデモを行うことができ、90%以上の正答率を記録していると記されている。

OpenAIは、この技術を使用してAIモデルの推論能力を大幅に向上させると期待を寄せており、特に、自動化された深い研究やソフトウェア・機械学習エンジニアの業務を行う能力を持たせることが目標だという。これにより、AIモデルが自主的にウェブを閲覧し、研究を行うための「CUA」（コンピュータ利用エージェント）を使用することが可能になる。

AIの推論能力が向上すれば、科学的発見の促進や新しいソフトウェアアプリケーションの計画・構築が可能となり、人間または超人間レベルの知能を実現する鍵となる。OpenAIのCEOであるサム・アルトマン氏も、AIにおける最も重要な進歩は推論能力の向上であると述べているという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 07:34:17 +0000</pubDate></item><item><title>Google DeepMind　Gemini1.5を使ってオフィス道順案内などのタスクを自然言語で実行させる</title><link>https://ledge.ai/articles/google_deepmind_mobility_vla</link><description>
:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年7月10日、同社のAIモデル「Gemini 1.5」の最大100万トークンという長大なコンテキストウィンドウを活用することで、オフィス内でのタスクを自然言語で解決させたと{target=“_blank”}した。この様子をデモ動画に納め、AIがオフィス内での道案内やタスク実行を行う様子を紹介している。例えば、「どこで絵を描けるか教えて」といった指示に対して、AIがユーザーをホワイトボードに案内する様子が示された。

!
:::small
画像の出典：{target=“_blank”}
:::

Gemini 1.5の特徴に「Mixture-of-Experts（MoE）」アーキテクチャが挙げられる。この技術により、AIモデルは入力に応じて関連する部分のみを活性化することができ、効率的に動作する。これにより、長文のQAや長時間の動画の理解など、従来のモデルでは困難だったタスクも高い精度で実行できるという。

Mobility VLAと呼ばれるナビゲーションポリシーは、長大なコンテキストウィンドウを持つ視覚と言語を組み合わせたAI（VLM）と、地図のような役割を果たすトポロジーグラフを使って、ロボットがどこに行くべきかを決定する仕組みを組み合わせている。このAIは、デモンストレーションツアービデオとユーザーからの指示をもとに、最適なルートを導き出す。

下図は、Mobility VLAのアーキテクチャを示している。デモンストレーションツアービデオとマルチモーダルユーザー指示を使用して、目標フレームを特定し、オフラインで構築されたトポロジーグラフを使用してロボットのアクションを生成する仕組みが描かれている。

!
:::small
画像の出典：{target=“_blank”}
:::

論文では、AIが自然言語での指示に基づいて、オフィス内の特定の場所にユーザーを案内する様子が紹介された。例えば「これを戻すべき場所は？」といった質問や、「スマートフォンを充電する場所は？」という指示に対して、AIが正確に応答することが示された。

研究チームは、Gemini 1.5が現実世界の大規模な環境での複雑な推論やマルチモーダルなユーザー指示において、最大90％の成功率を達成したと発表している。このモデルは、データセンターからモバイルデバイスまで幅広いプラットフォームで効率的に動作し、今後のAIの可能性に期待すると述べた。



:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Jul 2024 05:32:50 +0000</pubDate></item><item><title>スマホ上でも高速動作可能　NICTが21言語対応のニューラル音声合成技術を開発</title><link>https://ledge.ai/articles/nict_mobile_presen_tra</link><description>:::small
画像の出典：{target=“_blank”}
:::

国立研究開発法人情報通信研究機構（NICT）は2024年6月25日、ユニバーサルコミュニケーション研究所において、21言語に対応した高品質なニューラル音声合成技術開発に成功したことを{target=“_blank”}した。

この技術により、CPUコア一つで1秒の音声をわずか0.1秒で高速合成することが可能となり、従来モデルの約8倍の速さを実現した。また、ネットワークに接続されていないミドルレンジスマートフォン上でも、テキスト入力からわずか0.5秒で音声を生成できるという。

@


この新技術は、NICTが運用するスマートフォン用多言語音声翻訳アプリ「{target=“_blank”}」のサーバに搭載され、既に一般公開されている。今後は、商用ライセンスを通じて多言語音声翻訳やカーナビなど、様々な音声アプリケーションへの導入が期待される。

## 開発の背景
NICTのユニバーサルコミュニケーション研究所では、言語の壁を超えた音声コミュニケーションを実現するため、多言語音声翻訳技術の研究開発を{target=“_blank”}。特にテキスト音声合成技術は、音声認識や機械翻訳と同様に、多言語音声翻訳の実現に不可欠な技術である。従来の音声合成技術では、ネットワークに接続されていないスマートフォン上での合成が困難だったが、今回の開発によりその課題が解決されたとのこと。

## 技術の詳細
この技術は、入力テキストを中間特徴量へ変換する「音響モデル」と、中間特徴量を音声波形へ変換する「波形生成モデル」から成り立っている。「音響モデル」には、高速・高性能なConvNeXt型エンコーダとデコーダが使用されており、従来のTransformer型モデルに比べて3倍の高速化を実現。また、「波形生成モデル」には改良型のMS-FC-HiFi-GANが導入され、合成速度を4倍に引き上げているという。


!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::

</description><pubDate>Mon, 15 Jul 2024 14:08:36 +0000</pubDate></item><item><title>10億のペルソナで合成データを生成、LLM開発に新たな可能性</title><link>https://ledge.ai/articles/tencent_ai_lab_persona_hub</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

中国Tencentの研究チームは2024年6月28日、新しいペルソナ駆動型データ合成手法を{target=“_blank”}した。論文「Scaling Synthetic Data Creation with 1,000,000,000 Personas」では、10億の多様なペルソナを活用し、大規模な合成データを生成する「Persona Hub」の構築とその応用について詳述されている。
## Persona Hubの概要
「Persona Hub」は、ウェブデータから自動的に収集された10億の多様なペルソナで構成されている。これにより、LLMは多くの視点や知識を反映したデータを生成できる。このペルソナは、MinHash法と埋め込みベースの手法を用いて重複を排除し、多様性を維持しているという。


!
:::small
画像の出典：{target=“_blank”}
:::

## ペルソナ駆動型データ合成手法
この手法は、データ合成プロンプトにペルソナを統合することで、LLMにそのペルソナの視点を持たせ、データを生成するもので、以下３つのプロンプト方法が提案されている：

- **ゼロショットプロンプト:**  既存の例を使用せず、LLMの創造性を活かす
- **フューショットプロンプト:** いくつかのデモを提供して要件を満たすデータを合成する
- **ペルソナ強化フューショットプロンプト:** デモごとに対応するペルソナを派生させ、データ合成能力を向上させる
## 実験結果と応用
ペルソナ駆動型手法の有効性は、数学や論理的思考の問題作成、ユーザーインストラクションプロンプト、知識豊富なテキスト、ゲームのNPC（ノンプレイヤーキャラクター）、ツールや関数の開発といった多様なシナリオで実証された。具体的には、数学の問題生成では、ペルソナを追加することで、そのペルソナに関連するコンテキストで問題が作成されることが確認されたという。また、プロフェッショナルなペルソナを用いることで、より深い理解を必要とする高度な問題も生成可能とのこと。

このペルソナ駆動型データ合成手法は、LLMの多様な視点と知識を活用し、スケーラブルかつ多様な合成データを生成する手法であると研究者は述べる。これにより、LLMのトレーニングやテストに必要なデータの作成が大幅に効率化され、研究や開発において大きな影響を与えることが期待されるという。


:::box

:::
:::box

:::

</description><pubDate>Sun, 14 Jul 2024 13:14:09 +0000</pubDate></item><item><title>LLMはRAGと事前知識をどう使い分けるのか　マサチューセッツ大とMicrosoftの研究グループが発表</title><link>https://ledge.ai/articles/from_rags_to_rich_parameters</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年6月18日、大規模言語モデル（LLM）の推論能力向上を目指す研究が{target=“_blank”}された。研究者らは「検索拡張生成（RAG）」を活用した新たな手法により、LLMがどのように内部知識と外部情報を使い分けているかを詳細に分析した。
## RAGの役割とメリット
RAG（Retrieval-Augmented Generation）とは、LLMがユーザーの質問に対してより適切な回答を生成するための手法である。この手法は、外部のデータソースから関連情報を検索し、その情報をモデルの入力に追加することで、モデルの性能を向上させる。特に、訓練データが古くなった場合や、最新の情報を含んでいない場合に有効となる。

## 研究の手法と結果
研究者らは、LLMが事実に基づく質問に答える際に、内部知識（パラメトリック情報）とRAGによって取得された外部情報のどちらに依存するかを調査した。主な手法は以下の通りである。

**1. 因果追跡（Causal Tracing）：** モデルの特定の隠れ層が事実の予測にどのように寄与しているかを調査。これにより、どの層が内部知識に基づく推論を行っているかが特定された。
**2. パラメータ編集：** モデルのパラメータを直接編集し、知識を更新する手法を使用。この手法により、モデルの内部知識がどのように変化するかが観察された。
**3. RAGによる外部情報の利用：** RAGが提供する外部情報がどの程度モデルの回答に影響を与えるかを評価。外部情報が追加された際のモデルの回答と、内部知識のみに基づいた回答を比較した。

研究の結果、LLMは内部知識が豊富な場合にはそれに依存し、事前知識が不完全または古い場合にはRAGから得た外部情報をより活用することが明らかになった。具体的な質問に対しては、RAGが提供する最新情報がモデルの回答を大きく改善することも確認された。

また、RAGによって取得された外部情報を利用することで、モデルのハルシネーション生成頻度が減少することが示されたという。これにより、より正確で信頼性の高い回答が得られることが実証されたとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Jul 2024 07:00:05 +0000</pubDate></item><item><title>IPA「情報セキュリティ白書2024」を発行　アンケート回答でPDF版は無料配布 </title><link>https://ledge.ai/articles/ipa_wp-security_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

独立行政法人情報処理推進機構（IPA）は2024年7月30日、「情報セキュリティ白書2024」を{target=“_blank”}した。同白書は、国内外における情報セキュリティの最新動向やインシデント事例を詳述し、情報セキュリティの全体像を把握するための貴重な資料だという。

PDF版はアンケートに回答することで無料でダウンロード可能だ。印刷書籍は2,200円で、Amazonおよび全国官報販売共同組合が取り扱っているとのこと。IPAは2008年から毎年この白書を発行しており、情報セキュリティ分野の包括的な情報提供を行っているという。

白書では、2023年度の情報セキュリティ状況として、国家支援が疑われる攻撃者グループによるゼロデイ脆弱性を悪用した攻撃や、ファイル転送ソフトウェアを狙ったゼロデイ攻撃による情報漏えいとランサムウェア被害が報告された。また、名古屋港のコンテナターミナルがランサムウェア攻撃により停止するなど、日本国内でも深刻なサイバー攻撃が続いているという。

さらに、政府機関のサイバーセキュリティ対策基準の全面改訂や、福島第一原発処理水放出に関連する偽情報の拡散といったトピックも取り上げられており、現代のサイバー空間における多様な脅威に対する警鐘が鳴らされている。

「情報セキュリティ白書2024」は、情報セキュリティ分野の現状分析と将来展望を包括的にまとめており、その網羅性と参照性の高さが特徴となる。IPAによれば、同白書はセキュリティ対策を検討する企業や組織にとって、全体像を把握するための重要なリソースとなっているという。 

:::box

:::
:::box

:::
</description><pubDate>Thu, 01 Aug 2024 08:04:37 +0000</pubDate></item><item><title>複数のドローンを同時に無力化する高出力マイクロ波システム　日米共同研究で実用化へ</title><link>https://ledge.ai/articles/japan-us_joint_research_neutralizes_multiple_drones_simultaneously</link><description>:::small
画像の出典：{target=“_blank”}
:::


防衛省と米国防省は2024年7月16日、「高出力マイクロ波システムに係る日米共同研究」に関する事業取決めに署名を行ったと{target=“_blank”}した。

この共同研究は、将来の「ゲーム・チェンジャー」とされる高出力マイクロ波システム（HPM）の実用化に向け、日米で共同研究を実施するものだという。

HPMシステムは、無人航空機（UAV）などの脅威に対処するための技術で、強力な電波を照射して電子機器の誤作動や破壊を引き起こす。この技術は、複数のドローンを同時に無力化する能力を持ち、ドローン対策として注目されている。

今回の共同研究では、以下の具体的な内容が含まれている：

**米国内試験場での日米共同試験：** 防衛省の次世代装備研究所と米国防省の海軍研究局が主体となり、米国内の試験場で屋外試験を実施する。この試験により得られたデータを日米間で共有し、HPMの実用化に向けた課題を明らかにする

**高出力マイクロ波の効果評価：** 日米双方のHPMシステムを用いて、電子機器への高出力マイクロ波の効果を評価する。これにより、実用化に向けた教訓事項を得て改善点を明確にする

この共同研究は、防衛装備の技術と能力を向上させるための戦略的パートナーシップに基づいて行われる。HPMシステムは、現在の防衛技術の中でも特に注目される分野であり、日米両国の協力により、その実用化が期待されるという。

:::box

:::
:::box

:::
</description><pubDate>Mon, 29 Jul 2024 03:30:24 +0000</pubDate></item><item><title>DNPが、メタバースを活用した自治体サービス「メタバース役所」の提供を開始</title><link>https://ledge.ai/articles/dnp_metaverse_government_office</link><description>:::small
画像の出典：{target=“_blank”}
:::

大日本印刷株式会社（DNP）は2024年7月24日、インターネット上の仮想空間「メタバース」を活用した自治体サービス「メタバース役所」を提供開始すると{target=“_blank”}した。
## 「メタバース役所」の概要と共同利用モデルの特徴
メタバース役所は、複数の自治体が共同で運用し、サービス利用料を抑える共同利用モデルを採用している。

国内の各地域では、少子高齢化や大都市圏への人口集中による労働力不足が深刻な問題となっている。このような背景から、DNPは2021年より「XRコミュニケーション®」事業を展開し、自治体のデジタル化と地域活性化を支援しており、2024年2月に三重県桑名市との共同で行った実証実験で、電子申請手続きや市民相談、交流の場を提供するなどの経験を重ねて今回のサービス提供に至ったという。

複数の自治体が「メタバース役所」を共有することで、子育てや介護、不登校といった課題に対して連携して取り組み、住民サービスの質を向上させることができ、さらに、緊急時には複数の自治体が互いに支援し合う強固なBCP（事業継続計画）を構築できる。物理的な役所機能が滞った際にも連携先の「メタバース役所」で対応が可能になるそうだ。

DNPは、2028年度に10億円の売上を目指し、「メタバース役所」の運用と関連サービスの提供を継続的に強化していく方針。利用者のニーズに対応しながら、自治体のDX推進を一層支援していき、「メタバース役所」を通じて、誰一人取り残されない、人に優しいデジタル化を実現し、住民の生活の質向上に貢献していくとしている。

:::box

:::

:::box

:::

:::box

:::

:::box

:::
</description><pubDate>Sat, 27 Jul 2024 07:36:41 +0000</pubDate></item><item><title>米の映画俳優組合（SAG-AFTRA）、ストライキ開始を表明　ゲーム業界のAI利用問題で対立</title><link>https://ledge.ai/articles/sag-aftra_strike</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月25日、全米の俳優ら16万人が加入する映画俳優組合（SAG-AFTRA）は、ゲーム部門で働く全ての組合員がストライキを開始することを{target=“_blank”}した。
このストライキは、ゲーム業界における俳優の同意なしにAIを利用する問題に対する抗議として行われる。

SAG-AFTRAは、2022年10月からTake 2 Productions、Electronic Arts、Activision Blizzard、Warner Bros. Gamesなどの大手ゲームスタジオと交渉を続けてきた。この交渉の目的は、AIを用いて俳優の声や容姿を再現する際の事前同意や、AIが俳優を模倣する場合の適切な報酬の支払いがなされていないことにあった。しかし、約18ヶ月にわたる交渉の結果、ゲームスタジオとの交渉は決裂。これにより、SAG-AFTRAは組織のインタラクティブ・メディア契約に基づき、ゲーム部門で働く組合員によるストライキを承認した。

ゲームスタジオには、SAG-AFTRAと契約した俳優を声優、モーションキャプチャーのパフォーマンス、ゲーム内に登場させるなどの条件で採用する場合、SAG-AFTRAが提示する「Tiered-Budget Independent Interactive Media Agreement」および「Interim Interactive Media Agreement」に署名する必要がある。これらの契約には「組合員のための適切なAI保護」が含まれており、2500人以上のナレーションパフォーマー、モーションキャプチャーパフォーマー、スタントマン、スタントコーディネーター、歌手、ダンサー、人形遣い、バックグラウンドパフォーマーが対象となっている。

インタラクティブ・メディア契約交渉委員会のサラ・エルマレ委員長は、「彼らが私たち組合員全員に最適な条件を提示する準備ができた場合、再度交渉を開始する予定です」と述べ、また、SAG-AFTRAの最高契約責任者であるレイ・ロドリゲス氏は「ストライキは最後の手段です。私たちは責任を持ってできる限りの時間を使い交渉に臨んできました。しかし、交渉が成立する可能性が失われてしまったため、ストライキを実行します」と述べている。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 27 Jul 2024 07:29:23 +0000</pubDate></item><item><title>つくば市　NECとLLMおよび画像分析技術を活用した防災実証実験を実施</title><link>https://ledge.ai/articles/nec_tsukuba_supercity</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::


NECは2024年7月12日、茨城県つくば市において、大規模言語モデル（LLM）と画像分析技術を活用し、災害に強いまちづくりを目指す実証実験を行うと{target=“_blank”}した。この実証実験は、2024年11月から2025年1月まで行われ、住民が投稿した画像から街の状況をリアルタイムに可視化し、災害時の迅速な状況把握と対応を支援することを目的とする。

!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みは、2024年度の内閣府「先端的サービスの開発・構築及び規制・制度改革に関する調査事業（スーパーシティ・デジタル田園健康特区対象）」に採択されたことを受けて行われる。つくば市は2022年にスーパーシティに指定されて以降、「つくばスーパーサイエンスシティ構想」を掲げており、NECはその一環として本実証実験を実施するとのこと。

## 実証実験の概要
つくば市内の一部エリアで行われるこの実験は、住民が投稿した画像を収集し、LLMと画像分析によりダッシュボード上に可視化する。つくば市公式アプリ「つくスマ」を通じて、違法駐車や混雑する場所などの平時の状況を可視化し、災害時にはこれらのデータを活用して迅速な初動対応を可能にするという。

また実験では、災害時に投稿される画像に含まれる個人情報の取り扱いについても検証を行う。防災分野におけるデータ活用の可能性を広げ、より安全で安心な防災・減災対策の実現を目指すとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

NECは、この実証実験を通じて得られた結果をもとに、データ連携基盤の活用によるさらなるサービスの高度化を検討する予定だ。また、将来的にはデジタルツインの実装も視野に入れており、取得した情報を基に平時・災害時を通じた多様なサービスの開発を進めていく計画だという。



:::box

:::
:::box

:::

</description><pubDate>Wed, 24 Jul 2024 03:54:20 +0000</pubDate></item><item><title>AWS、政府のAI支援プロジェクト「GENIAC」における計算リソース提供者に選定</title><link>https://ledge.ai/articles/aws_selected_as_geniac_computational_resource_provider</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）2024年7月19日、経済産業省とNEDOが推進する国産生成AI開発力強化プロジェクト「GENIAC」（Generative AI Accelerator Challenge）において、同社が計算リソース提供者として選定されたと{target=“_blank”}した。このプロジェクトは、生成AI基盤モデルの開発を通じて日本国内の技術力を底上げし、企業のイノベーションを促進することを目的としている。
## プロジェクト概要
2024年2月に{target=“_blank”}したGENIACは、国内の生成AI開発力を強化することを目指している。このプロジェクトは、生成AIの基盤モデル開発に必要な高性能な計算資源を提供するだけでなく、開発者同士の連携や国際的な発信活動を支援することで、広範な技術革新を促進する。

## 助成内容
GENIACでは、スタートアップ企業や中小企業、学術機関に対して計算リソース利用料の2/3を助成し、その他の企業や団体には1/2を助成する。総助成額は最大245億円に達する予定。

プロジェクトでは、計算リソースの確保方法として二つの選択肢が設けられている：
1. 提案者が計算リソース提供事業者と個別に調整し、直接確保する方法
2. 経済産業省が計算リソース提供事業者から一括で確保し、提案者に提供する方法

AWSは後者の一括確保方法における計算リソース提供事業者として選定された。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 03:50:50 +0000</pubDate></item><item><title>内閣府　AI戦略会議で「AI制度研究会」のメンバーを発表、座長には東大松尾教授　AIに関する法規制のあり方を議論</title><link>https://ledge.ai/articles/cabinet_office_announces_members_of_ai_system_study_group</link><description>:::small
画像の出典：{target=“_blank”}
:::

内閣府は2024年7月19日、AIに関する法規制のあり方を議論するための「AI制度研究会」のメンバーを{target=“_blank”}した。研究会の目的は、AI技術の進展とそれに伴う社会的影響を考慮し、適切な法規制の枠組みを検討することである。

研究会の座長は、東京大学大学院の松尾豊教授が務める。その他のメンバーには以下の専門家が選ばれた（敬称略）

- 江間有沙（東京大学国際高等研究所東京カレッジ准教授）
- 岡田淳 （森・濱田松本法律事務所弁護士）
- 川原圭博 （東京大学大学院工学系研究科教授）
- 北野宏明 （株式会社ソニーリサーチ代表取締役プレジデント）
- 佐渡島庸平 （株式会社コルク代表取締役社長）
- 田中邦裕 （さくらインターネット株式会社代表取締役社長）
- 山口真一 （国際大学グローバル・コミュニケーション・センター准教授）

この発表は、同日に持ち回りで開催された第10回AI戦略会議において行われ、「AI制度研究会」の設置案が原案の通り決定された。同研究会は、AI技術の健全な発展とその利活用を促進するための法的課題や倫理的問題について、多角的な議論を進めることを目指すという。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 07:53:28 +0000</pubDate></item><item><title>気候変動による猛暑とAIで世界の電力需要急増、17年ぶりの増加率に　IEA報告</title><link>https://ledge.ai/articles/iea_reports_global_electricity_demand_to_surge_with_extreme_heat_and_aiiea_reports_global_electricity_demand_to_surge_with_extreme_heat_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

国際エネルギー機関（IEA）は2024年7月17日、2024年と2025年の電力需要は過去17年で最高の増加率を示す見込みだと最新のレポートを{target=“_blank”}した。特に気候変動による気温上昇、AI技術の普及が主な要因となっており、太陽光発電がその増加の半分を賄うとされている。
## AIとデータセンターの影響
AIの普及に伴いデータセンターの電力需要が急増しており、より信頼性の高いデータと精度の高い評価が求められている。IEAは、エネルギー部門とデジタル化の関係を研究する最前線に立っており、新たなイニシアティブ「エネルギーのためのAIとAIのためのエネルギー」を開始した。この一環として、IEAは政府、産業界、研究者、民間専門家と協議を行う予定である。2024年12月5日にパリで開催される「エネルギーとAIに関する国際会議」が重要なマイルストーンとなるとのこと。
## 需要の急増と再生可能エネルギーの拡大
IEAの「電力半期更新」報告によると、2024年の世界の電力需要は約4％増加し、これは2007年以来の最高年次成長率となる（金融危機やCOVID-19パンデミック後の特異な反発を除く）。この強い増加は2025年にも続き、同様に約4％の増加が見込まれている。

再生可能エネルギーの電力供給も急速に拡大し、2023年の30％から2025年には35％に増加すると予測される。2025年には、再生可能エネルギーによる発電量が石炭を上回る見通しで、特に太陽光発電が2024年と2025年の電力需要増加の約半分を賄う見込みである。太陽光と風力を合わせると、需要増加の約3/4を占めるとされる。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 07:48:24 +0000</pubDate></item><item><title>これは読むべき！経産省発表の音楽産業のビジネスモデルに関するレポートが興味深い　生成AIによる楽曲制作が業界に与える影響についての分析にも注目</title><link>https://ledge.ai/articles/meti_musicindustry_2024report</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月17日、経済産業省は「音楽産業の新たな時代に即したビジネスモデルの在り方に関する報告書」を{target=“_blank”}した。この報告書は、ストリーミング時代を迎えて大きく変化する音楽産業について、定量的な分析や新たなトレンドの可視化を目的とし、各種調査の結果を基に作成されたものだ。

SNSでは、「これは読むべき！」「経産省の本気を見た」などの高評価を得ており、評判となっている。また、音楽業界のみならず、他の業界にも応用可能なビジネスモデルの洞察を提供しているとの声も高い。
## SNSとストリーミングの影響
報告書では、SNSとストリーミングの普及が音楽の消費行動に与える影響を強調している。YOASOBIの「アイドル」やHoneyWorksの「可愛くてごめん」など、SNSでのバズが音楽ヒットに繋がっている具体例が挙げられている。ユーザー生成コンテンツ（UGC）の増加が他のアーティストやインフルエンサーによる発信につながり、さらなる人気を博していることが示されている。

下図：YOASOBIの「アイドル」に関連する公式動画とユーザー生成動画の視聴回数を示したもの。UGCが公式コンテンツ以上に多くの視聴を集めていることを示しており、SNSや動画プラットフォームでのバズの重要性を示唆している。

!
:::small
画像の出典：{target=“_blank”}
:::
## ボカロPとデジタルマーケティング
ボーカロイドを活用した音楽制作の普及により、SNSや動画配信プラットフォームを駆使するボカロP出身のアーティストがデジタルマーケティングに秀で、海外でも人気を得ているという。代表例としてYOASOBIや米津玄師氏が挙げられ、デジタル時代の新たな音楽ビジネスモデルが形成されている。

!
:::small
画像の出典：{target=“_blank”}
:::
## ヒットの事例にみられる要因
報告書では、SNSバズやバイラルによる成功法則の多様性を説明し、ヒット曲が生まれる要因には、特に二次創作の促進がバズの機会を創出することを強調している。

!
:::small
画像の出典：{target=“_blank”}
:::

その他にも、報告書では、生成AIによる楽曲制作が音楽業界に与える影響についての分析や、諸外国において日本の音楽がどのように受容されているかについても触れている。

この報告書の洞察は音楽業界に限らず、他の業界にも応用可能な示唆を含んでいる。デジタルマーケティングの重要性やUGCの効果的な活用、グローバル市場への展開戦略など、多くのビジネスに共通する課題と解決策が示されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Jul 2024 11:35:56 +0000</pubDate></item><item><title>ベネッセコーポレーションが、小学生と保護者による「生成AIの利用に関する調査」の結果を発表　前年より肯定的な意見が増加</title><link>https://ledge.ai/articles/benesse_survey_on_the_use_of_AI</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月17日、ベネッセコーポレーションは、小学生とその保護者を対象にしたChatGPTなどの生成AIの利用に関する調査の結果を{target=“_blank”}した。

## 保護者の認知度と利用に関する意向
調査によると、保護者の53％が生成AIを「知っている」と回答した。「知っている」と回答した保護者のうち66％が「子どもに使ってほしい」と肯定的な意見を示した。「積極的に使ってほしい」と答えた保護者は14％、「少し使ってみてほしい」と答えた保護者は52％で、{target=“_blank”}に比べて肯定的な回答が10ポイント増加したという。

!

:::small
画像の出典：{target=“_blank”}
:::
肯定的な理由としては、「新しい技術の活用力を養う良い機会になりそうだから」（35％）、「子どもが新しい興味に出会えそうだから」（22％）、「自分で考える力が伸びそうだから」（13％）が挙げられた。一方で、否定的な回答をした保護者の理由としては、「自分で考えなくなりそうだから」（48％）、「自分で書いて表現することをしなくなりそうだから」（23％）、「情報の正誤の判断がつかなくなりそうだから」（12％）が主な理由として挙げられた。
## 子どもの認知度と利用状況
子どもに生成AIを知っているか調査をしたところ、「知っている」と答えた子どもは20％、「聞いたことはあるがどんなものか分からない」と答えた子どもは28％、「知らない」と答えた子どもは52％で、前年調査に比べ「知らない」と答えた割合は9ポイント低下していた。

生成AIを知っている子どもの利用状況については、「よく使っている」子どもは16％、「時々使っている」子どもは28％、「試しに使ってみたことがある」子どもは26％、「全く使ったことがない」子どもは29％であった。
!

:::small
画像の出典：{target=“_blank”}
:::


**調査概要**
2024年6月24日から26日にかけてインターネットを通じて行われ、小学3年生から6年生の児童とその保護者1032組を対象にアンケート調査を実施。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Jul 2024 14:36:03 +0000</pubDate></item><item><title>一般にはほぼ無名のAIエンジニア安野たかひろ氏が、急激に支持者を集め都知事選で15万票を獲得するまでを振り返る　最新小説も発売！</title><link>https://ledge.ai/articles/takahiroanno_reflections_on_the_campaign</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月7日に行われた東京都知事選において、政治の世界ではほぼ無名の状態から15万4638票を都民から集め、結果5位に食い込んだというAIエンジニアの安野たかひろ氏が、自身のnoteで都知事選を振り返る記事を{target=“_blank”}した。

「なぜ無名のエンジニアは都知事選で15万票獲得できたのか」と題されたその記事では、「テクノロジーで誰も取り残さない東京を作る」と掲げた自身の選挙活動が、どのように認知を得て得票につながったのかを分析し、その影響について語った。

## AIと双方向コミュニケーション
!
:::small
画像の出典：{target=“_blank”}
:::

安野氏の選挙活動は、従来の政治キャンペーンとは一線を画していた。選挙活動の核となったのは、「ブロードリスニング」と称される、双方向のコミュニケーション手法であった。有権者の意見を直接聴き、それを政策に反映させることで、多くの支持を得た。AI技術を活用した意見収集ツールや、政策のアップデートを行うプラットフォームを駆使して、リアルタイムで有権者との対話を続けた。

安野氏は、選挙活動の過程で、1000万回以上SNSで拡散された{target=“_blank”}を基に、具体的な政策を提示し、有権者からのフィードバックを取り入れ続けた。このプロセスで、6月20日に公開した96ページのマニフェストを何度もアップデートし、最終的に232件の課題提起と104件の変更提案が反映されたという。

また、選挙活動には、AIを活用した「AIあんの」が大きな役割を果たした。YouTubeや電話を通じて、8600回以上の質問に回答し、有権者とのコミュニケーションを拡張することで、支持を広げた。また、街頭演説やメタバースでの活動も行い、直接的な対話の機会を増やした。

@


選挙結果としては5位に終わったが、無名のエンジニアが15万票以上を獲得したことは過去の都知事選の中でも異例であり、特に30代の候補者としては記録的な数値だという。

今後も政治活動に関与する意向を示しており、今回の選挙で得た知見やツールをオープンソースとして公開する予定であると述べた。同氏は、テクノロジーを活用した分断のない政治の実現を目指し、引き続き取り組んでいくとの意向を示している。


2024年7月4日、Ledge編集部でのインタビュー
@


なお、作家としても活動する安野氏のデビュー2作目となる長編小説「松岡まどか、起業します──AIスタートアップ戦記」が7月18日、早川書房より発売された。AIと働き方をめぐる令和の ”お仕事小説” とのことで、ハヤカワ・SFコンテスト優秀賞を受賞した1作目「サーキット・スイッチャー」とはまた違った世界が描かれているようだ。

!
:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 06:22:18 +0000</pubDate></item><item><title>総務省　2024年版「情報通信白書」より、生成AI利活用の現状と潜在的な可能性が明らかに</title><link>https://ledge.ai/articles/mic_2024_white_paper_on_Information_and_communications</link><description>:::small
画像の出典：{target=“_blank”}
:::

総務省は2024年版「情報通信白書」にて、日本国内外における生成AIの利用状況に関する詳細な調査結果を{target=“_blank”}した。この調査により、日本における生成AIの利用率は他国と比較して著しく低いことが明らかになったが、潜在的なニーズの存在も示された。

## 日本の生成AI利用率の低さ
調査によると、日本における生成AIの個人利用率は9.1%と低水準であり、米国（46.3%）、中国（56.3%）、ドイツ（34.6%）、英国（39.8%）と比較して大きく劣っている。利用しない理由としては「使い方がわからない」「自分の生活には必要ない」という回答が多く、セキュリティや情報漏洩に対する懸念は比較的少なかったとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

## 企業における生成AIの利用状況
企業向けの調査でも、日本企業の生成AI利用率は低いことが判明した。生成AIを「積極的に活用する方針を定めている」企業の割合は15.7%であり、米国（46.32%）、中国（71.2%）、ドイツ（30.1%）と比較して低い。特に、メールや議事録、資料作成などの補助業務での生成AIの使用率は、日本では46.8%にとどまり、他国の90%程度に比べて低水準である。

!

!


:::small
画像の出典：{target=“_blank”}
:::

## 潜在的な利用意向の存在
一方で、生成AIの利用意向については、「ぜひ利用してみたい」「条件によっては利用を検討する」と回答した割合は6～7割程度あり、潜在的なニーズがあることがうかがえた。生成AIの具体的な利用場面としては、コンテンツの要約・翻訳、画像や動画の生成、旅行の計画やイベントの企画などが挙げられている。

!

:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 01:43:51 +0000</pubDate></item><item><title>パリ五輪2024、カナダ女子サッカー代表がドローンによるスパイ行為で波紋</title><link>https://ledge.ai/articles/coc-statement_on_canada_soccer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月27日、パリ五輪2024の開幕が華々しく行われたが、その陰でカナダ女子サッカー代表チームが{target=“_blank”}に見舞われた。カナダ代表は、ニュージーランド女子サッカーチームの練習をドローンでスパイしていたことが発覚し、監督とスタッフが追放される事態となった。

7月22日、ニュージーランド代表が練習をしているときにドローンが飛行していることに気づき、国際オリンピック委員会（IOC）のインテグリティ部門に通報。その結果カナダ代表チームの非公認の分析官であるジョセフ・ロンバルディ氏がドローンを操作していたことが判明し、フランス当局に逮捕され、執行猶予付きの判決を受け入れたという。

カナダのサッカーチームの監督であるビバリー・プリーストマン氏は、責任を取る形でパリ五輪から追放され、自ら初戦の指揮を辞退したという。カナダオリンピック委員会（COC）はニュージーランドのサッカー協会およびオリンピック委員会に謝罪を表明し、「フェアプレーを重視し、このような行為にショックを受け失望している」との声明を{target=“_blank”}した。

また、カナダのアシスタントコーチ、ジャスミン・マンダー氏もチームから外されることとなった。NZOCは、事件に対して深い失望を{target=“_blank”}し、選手とチームの支援に努めるとしている。

:::box

:::
:::box

:::</description><pubDate>Tue, 30 Jul 2024 03:37:57 +0000</pubDate></item><item><title>Sakana AIが新たな浮世絵生成モデルを開発　日本の伝統美をAIで再現</title><link>https://ledge.ai/articles/sakana_ai_evo-ukiyoe_evo-nishikie</link><description>:::small
画像の出典：{target=“_blank”}
:::

Sakana AIが2024年7月21日、浮世絵風画像生成モデル「Evo-Ukiyoe」と、浮世絵をカラー化できるモデル「Evo-Nishikie」を{target=“_blank”}した。これらのモデルは、同社が2024年4月に発表した、画像生成モデル{target=“_blank”}を基盤として開発された。
## Evo-Ukiyoe-浮世絵風画像生成モデル-

!

:::small
画像の出典：{target=“_blank”}
:::

Evo-Ukiyoeは、日本語のプロンプトから浮世絵風の画像を生成するモデルだ。風景や着物姿の人など、浮世絵によく取り上げられる題材について、高品質な画像を生成することができる。このモデルは、立命館大学アート・リサーチセンター（ARC）所蔵の24,038枚の浮世絵デジタル画像を学習データセットとして利用し、浮世絵の特徴を詳細に学習している。

桜や富士山、着物を着た人物など、Evo-Ukiyoeが認識しやすいプロンプトを入力することにより、浮世絵に近い画像を生成することができる。しかし、利用する上で「人物」の画像を生成する際の課題も挙がっているそうだ。「男性」と入力しても、女性の着物や髪型を生成してしまうことがあるため、この場合は男女を明確にする必要がある。プロンプトに「男性」、ネガティブプロンプトに「女性」と加えることで、よりイメージに近い画像を生成できるとのこと。
## Evo-Nishikie-浮世絵カラー化モデル-
!

:::small
画像の出典：{target=“_blank”}
:::

一方でEvo-Nishikieは、墨一色で摺られた浮世絵を、多色摺の浮世絵風にカラー化するモデルだ。江戸時代の本の挿絵をカラー化して、現代の絵本のように楽しむことができる。

これらのモデルは、本物の浮世絵と生成した浮世絵を比較することで、浮世絵の特徴を学ぶ材料となり、歴史や文化を学ぶための新たなコンテンツ作成のツールとしても利用できる。浮世絵や日本文化に興味を持つきっかけになることを期待しているそうだ。

Sakana AIは、公式サイトでEvo-UkiyoeとEvo-Nishikieのデモを公開している。ただし、各モデルは研究開発目的で商用利用などは想定しない。「本モデルの使用に伴うリスクを十分に理解し、自己の判断で使用する必要がある」とのこと。

:::box

:::

:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 09:04:15 +0000</pubDate></item><item><title>ディズニー内部Slackデータ1.1TiB流出「生成AIからアーティストの権利を擁護するハッカー集団」Nullbulgeの攻撃</title><link>https://ledge.ai/articles/disney_slack_leak</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月、ハッカー集団「Nullbulge」がウォルト・ディズニー・カンパニーの内部Slackチャンネルから約1.1テビバイト（TiB）のデータを流出させたと{target=“_blank”}した。

!
:::small
画像の出典：{target=“_blank”}
:::

上記のメッセージは、ハッカー集団Nullbulgeがディズニーの内部Slackデータを流出させ、その中には未公開のプロジェクト、ログイン情報、内部APIのリンクなどが含まれていることを伝えるもの。また、内部協力者が途中で撤退したことについて言及し、将来の警告として個人情報を公開するとしている。

Nullbulgeは、約10,000のSlackチャンネルから収集したメッセージやファイル、未公開プロジェクトの詳細、ログイン情報、内部APIやウェブページのリンクなどを含む1.1TiBのデータを公開したと主張している。このデータは、ハッキングフォーラムやソーシャルメディアで広く共有されているという。

同集団は、ディズニーがアーティストとの契約を不適切に扱い、AI技術の導入に対するアプローチが問題であり、さらに消費者を無視していると主張し、このハッキングを行った理由を説明している。特に、ディズニーが「スター・ウォーズ」や「エイリアン」シリーズの作者に対するロイヤリティの支払いを停止したことが批判の中心となっている。

現在、ディズニーはこの事態を調査中であり、公式なコメントはまだ出されていない。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 08:59:41 +0000</pubDate></item><item><title>安達寛高（乙一）ら原作・監督　全編生成AI制作の映画「generAIdoscope：ジェネレイドスコープ」2024年公開予定</title><link>https://ledge.ai/articles/the_film_generaidoscope_produced_entirely_with_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

映画や映像の企画・立案などを行うリアルコーヒーエンタテインメントは2024年7月10日、同社による企画で全編生成AIで制作されるオムニバス形式の映画「generAIdoscope：ジェネレイドスコープ」の製作を{target=“_blank”}した。2024年内の劇場公開を予定しているとのこと。


!
:::small
画像の出典：{target=“_blank”}
:::

「generAIdoscope：ジェネレイドスコープ」は、その全編が生成AIによって制作されるという点が最大の特徴だ。映像、音声、音楽すべてがAI技術を駆使して生成されることで、従来の映画制作とは一線を画す新しい試みとなっているという。映画の原作・監督には、各ジャンルで活躍する映像作家が名を連ねている。安達寛高（乙一）、曽根剛、山口ヒロキの3人がそれぞれ独自の物語を手がける。

### 安達寛高（乙一）氏「モンキーズ・オデッセイ」
大航海時代を舞台に、船乗りが猿たちの住む無人島に漂着する物語「モンキーズ・オデッセイ」を描く。

### 曽根剛氏「AZUSA」
空想癖のある風変わりな女の子が夢を叶えるために二つの世界を行き来する「AZUSA」。この作品では、ファンタジーとリアリティの融合が見どころとなる。

### 山口ヒロキ氏「グランマレビト」
遠い未来の世界を舞台に、元魔術師の老婆が架空の国家を旅する「グランマレビト」を監督。壮大な未来世界のビジョンと共に、人間ドラマが展開される。


@


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 10:07:20 +0000</pubDate></item><item><title>優勝はモロッコのAI美女　世界初のAIビューティーコンテスト「Miss AI 2024」の受賞者発表</title><link>https://ledge.ai/articles/fanvue_miss_ai_winners</link><description>
:::small
画像の出典：参加者たちのインスタグラムより
:::

World AI Creator Awards（WAICA：世界AIクリエーター賞）が2024年7月、「Miss AI 2024」の受賞者を{target=“_blank”}した。このコンテストは、AIによって生成されたモデルが参加する世界初のビューティーコンテストとして、Fanvueとの共同開催で実現したという。

## 受賞者一覧
### 第1位：Kenza Layli（ケンザ・ライリ）氏　モロッコ出身
!
:::small
画像：{target=“_blank”}
:::

1位の栄冠に輝いたモロッコ出身のケンザ・ライリ氏は5,000ドルの賞金に加え、3,000ドル相当のAIメンターシッププログラム、および5,000ドル以上のPR支援を受ける。同氏は、モロッコの文化に根ざした魅力的なコンテンツで19万人以上のフォロワーを獲得し、審査員たちから高い評価を受けたとのこと。

### 第2位：Lalina（ラリーナ）氏　フランス出身

!
:::small
画像：{target=“_blank”}
:::

2位のラリーナ氏には2,000ドル相当のプロモーションパッケージと2,500ドル以上のPR支援が提供された。フランスからの参加で、特に技術力とプロモーション力が評価された。同氏の作品は、その精巧なデザインと高い技術力で注目を集めた。 

### 第3位：Olivia C（オリビア・C）氏　ポルトガル出身
!
:::small
画像：{target=“_blank”}
:::

3位のオリビア・C氏には、2,000ドル相当のプロモーションパッケージとコンサルティングコールを受け取った。ユニークなアプローチと創造性が高く評価された。同氏の作品は、多くのファンから支持を受け、コンテストでも高い評価を得たという。

## コンテストの概要
「Miss AI」は、AIによって生成されたモデルが美しさ、技術力、そしてソーシャルメディアでの影響力を競う新しい形式のビューティーコンテストだ。参加者は、見た目の美しさやポーズ、そしてAIツールを使用した技術力に加え、ソーシャルメディアでのフォロワー数やエンゲージメント率なども評価対象となる。

今回のコンテストには、トルコ、バングラデシュ、ブラジルなど世界中から多くのAIモデルが参加した。参加者たちはそれぞれ独自のAIモデルを作成し、その創造性と技術力を{target=“_blank”}した。


:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 09:45:31 +0000</pubDate></item><item><title>生成される画像の価値とは何なのか？　ライゾマティクスが「AIと生成芸術」がテーマの個展を開催中</title><link>https://ledge.ai/articles/rhizomatiks_beyond_perception</link><description>:::small
画像の出典：{target=“_blank”}
:::

クリエーター集団のライゾマティクスが、AI技術を活用した新しいアートの形を提案している。KOTARO NUKAGA（天王洲）の拡張移転に伴い、2024年6月29日から9月28日までの3ヶ月間にわたり、「AIと生成芸術」をテーマに個展「Rhizomatiks Beyond Perception」を{target=“_blank”}する。

展覧会では、ライゾマティクスが独自に作成した画像のみを学習したAIモデルを新たに開発し、その成果を展示する。現代において誰もがAIを使って画像を生成できる中、ライゾマティクスは「生成される画像の価値とは何なのか？」という問いを観客に投げかける。

展示作品の一環として、初めて販売されるのは “AIモデルデータ” である。購入者はこのAIモデルを使って入力を変えることにより、無限に画像を生成する体験が可能となる。このAIモデルデータは、ライゾマティクス自身の作品108本の映像を静止画に変換した約17万枚の画像を学習データとして使用し、既存の基盤モデルを一切使用せずにゼロから開発されたものだという。

### 展覧会概要
**会期:** 2024年6月29日（土） – 9月28日（土）
**開廊時間:** 11:00 – 18:00（火曜日から土曜日、日月祝休廊）
**会場:** KOTARO NUKAGA（天王洲）
**住所:** 東京都品川区東品川1-32-8 TERRADA Art Complex II 1F
**アクセス:** 東京臨海高速鉄道りんかい線「天王洲アイル駅」から徒歩約8分、東京モノレール羽田空港線「天王洲アイル駅」から徒歩約10分、京急本線「新馬場駅」から徒歩約8分



:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Jul 2024 07:35:19 +0000</pubDate></item><item><title>ハリウッド撮影クルー、AI使用も雇用維持で合意</title><link>https://ledge.ai/articles/hollywood_iatse_amptp_agreement</link><description>:::small
画像の出典：{target=“_blank”}
:::
全米のエンターテインメント産業の撮影現場で働く労働者の組合「IATSE」と主要スタジオを代表する「AMPTP」は2024年6月27日、AIの使用を認めながらも雇用を維持することで合意に達したと{target=“_blank”}した。
この合意は、「ハリウッド基本合意」と「ビデオテープ合意」の枠組みで成立し、IATSEの約50,000人のメンバーに影響を与えるものだという。
## 合意の詳細
今回の合意には、AIの使用に関する新たな保護措置が含まれている。具体的には、AIが労働者の職を奪うことがないようにするための条項が盛り込まれ、労働者がAIプロンプトを提供する場合でも、それが雇用喪失につながらないようにする対策が取られている​。また、賃金の引き上げも合意され、契約期間中3年間で7%、4%、3.5%のスケール賃金率の引き上げを予定しているとのこと。

## 交渉の背景
IATSEは衣装デザイナーやヘアスタイリスト、照明技術者、カメラオペレーターなど、多岐にわたる職種の労働者を代表している。今回の合意は、生成AIの台頭により雇用の危機感が高まる中で、労働条件の是正を求め{target=“_blank”}したものだ。特にコロナ禍のパンデミック以降、ハリウッドの労働者たちは自身の権利と雇用条件についてより積極的に声を上げている。

この合意はまだIATSEのメンバーによる批准が必要だが、正式に承認されれば、ハリウッドの労働環境におけるAIの影響を適切に管理しながら、労働者の権利と雇用を保護する新たな枠組みが確立されることになる見通し。また、同様の合意が他の労働組合との間でも期待されており、エンターテインメント産業全体での労働環境の改善が見込まれているという。

全米の映画俳優組合（SAG-AFTRA）によるストもAMPTPとの暫定合意に達し、2023年11月に終結している。


:::box

:::
:::box

:::

</description><pubDate>Fri, 05 Jul 2024 07:31:03 +0000</pubDate></item><item><title>大阪・関西万博に実物大ガンダム登場へ　バンダイナムコHDが展示計画を発表
</title><link>https://ledge.ai/articles/bandainamco_gundam</link><description>:::small
画像の出典：{target=“_blank”}
:::

バンダイナムコホールディングスは2024年6月26日、2025年に開催される大阪・関西万博で「機動戦士ガンダム」の実物大模型を展示すると{target=“_blank”}した。このガンダム像は、かつて横浜で展示されていた動く実物大ガンダムの部材を再利用しており、関西での展示は初めてとのこと。

展示されるガンダム像は高さ約17メートルで、片膝を立て片腕を上げたポーズを取っている。2020年から2024年3月末まで横浜市の「GUNDAM FACTORY YOKOHAMA」で展示されていた動く実物大ガンダム像の装甲部分を、頭部から足までほぼ再活用しているが、今回の展示では動くことはないという。

このガンダム像は、大阪・関西万博のパビリオン「GUNDAM NEXT FUTURE PAVILION」の近くに展示される予定。パビリオン自体は内装を除き2024年7月の完成を予定しているという。

@

バンダイナムコホールディングスでガンダムシリーズの知的財産戦略を担当する榊原博社長は、「ファンの方と一緒につながりたい」と述べ、ファン参加型の企画を計画していると明らかにした。2024年は「ガンダム」のテレビアニメ放映45周年にあたり、全国で関連イベントが開催される予定だ。SNS上でファンからのメッセージを募集し、その一部はパビリオン内で投影される。


:::box

:::
:::box

:::
</description><pubDate>Mon, 01 Jul 2024 13:23:40 +0000</pubDate></item><item><title>Mantraが7.8億円調達を実施　画像認識とLLM（大規模言語モデル）を併用したマンガ特化の翻訳ツール開発　</title><link>https://ledge.ai/articles/mantra_engine_ai_manga</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月26日、マンガAI翻訳技術の開発を行うMantra株式会社は、集英社、小学館、KADOKAWA、スクウェア・エニックス・ホールディングスなどから、総額7億8000万円の資金調達を行ったことを{target=“_blank”}した。

Mantraが開発した「Mantra Engine」は、AIを活用したマンガ/縦スクロールコミックの翻訳を効率化するクラウドツールだ。画像認識とLLM（大規模言語モデル）を併用し、キャラクターやストーリーを考慮しながら、ブラウザ上で翻訳に関わるすべての作業を完結させる。現在は、国内外の出版社や翻訳会社、配信事業者を中心に利用されており、集英社の人気マンガ『ONE PIECE』『SPY×FAMILY』のベトナム語版などの制作にも用いられている。

今回の資金を活用し、向こう5年を目処に「エンドユーザーが楽しんで読める」を目指し、マンガAI翻訳の精度向上に取り組むと同時に、小説やゲーム、動画への翻訳技術転用を本格化させる研究開発も進めていくという。

Mantraの代表取締役である石渡 祥之佑氏は、「エンタメから言語の壁をなくしたい」という明確な目的意識を創業前から持っており、昨今の急速に進むLLMや画像生成AIの進化を見て、「言語の壁がなくなる未来が少しずつ現実のものとして想像できるようになった」と述べている。

:::box

:::

:::box

:::

:::box

:::

</description><pubDate>Sun, 30 Jun 2024 21:14:19 +0000</pubDate></item><item><title>KRAFTON JAPAN　GPT-4o搭載の推理アドベンチャーゲーム『Uncover the Smoking Gun』を正式リリース</title><link>https://ledge.ai/articles/uncover_the_smoking_gun</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月25日、KRAFTON JAPAN株式会社は、AI技術を搭載した推理アドベンチャーゲーム『Uncover the Smoking Gun』をリリースしたと{target=“_blank”}した。

『Uncover the Smoking Gun』は、KRAFTON JAPAN傘下のクリエイティブスタジオ「ReLU Games」が制作した、ロボットと人間が共存する近未来を舞台にした没入型推理アドベンチャーゲームだ。プレイヤーがAI専門の探偵となり、事件の手がかりを追いながら、容疑者であるロボットに対してチャットで尋問していく。

OpenAIがリリースした「GPT-4o」を搭載しており、容疑者のロボットは単純に質問に回答するだけではなく、プレイヤーの性格に合わせた口調で、まるで実際に人とチャットで会話しているような感覚で楽しめるという。ロボットの曖昧な証言を見極め、真実にたどり着くために鋭い質問を投げかけながら、事件解決を目指す没入型の推理ゲーム。

『Uncover the Smoking Gun』は、現在Steamでダウンロード可能。日本語、韓国語、英語、中国語など全8言語に対応しており、詳細はSteamページおよびReLU Games公式サイトで確認できる。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:57:02 +0000</pubDate></item><item><title>Google DeepMindが動画に合うBGMや効果音を生成するAI「Video to Audio」を発表</title><link>https://ledge.ai/articles/google_deepmind_v2a</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年6月17日、新たな技術「Vide to Audio（V2A）」を{target=“_blank”}した。Generative Mediaチームの発表したこの技術は、動画の映像情報とテキストのプロンプトを用いて、映像にぴったりと合ったサウンドトラックを生成する能力を持つ。

現在、映像生成モデルは急速に進化しているが、多くの現行システムは無音の出力しか生成できない。V2Aは、この課題を解決し、生成された映像にリアルな音響を付与するための重要なステップとなる。

V2Aは、映像ピクセルと自然言語テキストプロンプトを組み合わせて、画面上のアクションに対してリッチな音響効果を生成する。例えば、ドラマチックなスコア、リアリスティックな音響効果、またはビデオのキャラクターやトーンに合ったダイアログを生成することが可能だ。

{target=“_blank”}（音声プロンプト： 映画、スリラー、ホラー映画、音楽、緊張感、雰囲気、コンクリートの上の足音）

!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}（音声プロンプト: 月に向かって吠えるオオカミ)

!
:::small
画像の出典：{target=“_blank”}
:::

## V2Aの技術的詳細
V2Aシステムは、ビデオ入力を圧縮された表現にエンコードし、拡散モデルがランダムなノイズから音声を逐次的に洗練させる。このプロセスは視覚的入力と自然言語プロンプトによってガイドされ、プロンプトに密接に一致する現実的な音声を生成する。最終的に音声出力がデコードされ、音声波形に変換され、ビデオデータと組み合わせられる。

また、高品質な音声を生成するために、詳細な音の説明や音声トランスクリプトを含むAI生成のアノテーションを追加情報としてトレーニングプロセスに加えた。これにより、特定の音声イベントを様々な視覚シーンと関連付けることが可能となり、アノテーションやトランスクリプトで提供された情報に基づいて音声を生成できるという。

!
:::small
画像の出典：{target=“_blank”}
:::


## 創造的なコントロールと今後の展望
V2Aは、任意のビデオ入力に対して無限のサウンドトラックを生成する能力を持つ。ユーザーは「ポジティブプロンプト」を定義して望ましい音にガイドするか、「ネガティブプロンプト」を使用して望ましくない音を排除することができる。この柔軟性により、V2Aの音声出力を迅速に実験し、最適なマッチを選択することが可能だという。


以下は、同じ動画に対して複数のサウンドを生成した例
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）
{target=“_blank”}(音声プロンプト: 優美なチェロの雰囲気）
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）

!
:::small
画像の出典：{target=“_blank”}
:::


Google DeepMindは、責任あるAI技術の開発を重視し、クリエイティブコミュニティからの多様な視点や洞察を収集し、研究と開発に反映させているとのこと。また、AI生成コンテンツに透かしを入れるためのSynthIDツールキットも導入し、この技術の誤用を防ぐための対策を講じている。V2A技術は公開前に厳格な安全評価とテストを経る予定だという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 28 Jun 2024 12:32:10 +0000</pubDate></item><item><title>AI音楽生成サービスSunoとUdioを著作権侵害で提訴　ユニバーサル、ソニー、ワーナー含む大手音楽企業</title><link>https://ledge.ai/articles/suno_and_udio_sued_for_copyright_infringement</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

米国の主要レコード会社であるユニバーサルミュージック（UMG）、ソニー、ワーナーを含む複数の企業が、AI音楽生成サービス「Suno」と「Udio」に対し、著作権侵害を理由に{target=“_blank”}。

RIAA（アメリカレコード協会）が2024年6月24日、ニューヨーク南部地区連邦地方裁判所およびマサチューセッツ地区連邦地方裁判所にそれぞれ提出した訴状によると、SunoとUdioは、著作権で保護されたサウンドレコーディングを無断でコピーし、自社のAIモデルのトレーニングに利用したという。その生成物が市場に流通しているとされ、複数のジャンルや時代のアーティストの録音が侵害対象となっているとのこと。

訴訟では、以下の3点を求めている。
- サービスが原告の著作権を侵害したことの宣言
- 将来的な著作権侵害を防ぐための差し止め命令
- 既存の侵害に対する損害賠償

## 訴訟の概要
この訴訟は、AI技術が進化し音楽制作の分野においても大きな影響を及ぼしている中、著作権の保護がいかに重要かを問うものである。原告側は、AIサービスが著作権で保護された楽曲を無断で使用し、生成された音楽ファイルが元の作品と酷似していると主張している （下図参照：訴状より）

!
:::small
画像は訴状より：Udioの生成した曲（上）が、マライアキャリー氏の楽曲（下）に酷似している例。譜面の赤い音符が一致している
:::

RIAAの最高法務責任者であるケン・ドロショウ氏も、「これらのケースは、大規模な著作権侵害に関する単純な事例です。SunoとUdioは、自社のサービスを合法かつ健全な基盤に乗せる代わりに、侵害の全貌を隠そうとしています。この訴訟は、AIシステムの責任ある開発を促進し、SunoとUdioの侵害行為を終わらせるために必要なものです」とコメントしている。

これに対しUdioは6月26日、X（旧Twitter）に{target=“_blank”}し、AI技術の使用に著作権で保護された作品を再現する意図はないと主張した。また、著作権侵害を防ぐためのフィルターを実装していると述べている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 26 Jun 2024 04:14:21 +0000</pubDate></item></channel></rss>