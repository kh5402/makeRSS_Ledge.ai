<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Thu, 23 May 2024 13:43:09 +0000</lastBuildDate><item><title>ELYZAと他2社、NEDOのGENIACプロジェクト「競争力のある生成AI基盤モデルの開発」に追加で採択</title><link>https://ledge.ai/articles/nedo_geniac_adopted_3additional_businesses</link><description>:::small
画像の出典：{target=“_blank”}
:::

NEDO（国立研究開発法人新エネルギー・産業技術総合開発機構）は2024年5月17日、ELYZAをはじめとする3つの事業者を、日本の生成AIの開発力強化を目的としたプロジェクト「GENIAC（Generative AI Accelerator Challenge）」のもと、2月に追加公募した「ポスト5G情報通信システム基盤強化研究開発事業／競争力ある生成AI基盤モデルの開発（助成）」に採択したと{target=“_blank”}した。採択事業者は、計算資源の支援などを受けることになる。


### 各事業者の採択事業テーマ

**株式会社ELYZA：モデル組み合わせによる日本語大規模基盤モデル開発と半自動データ作成フレームの構築**
東京大学松尾研究室発のスタートアップ「ELYZA」は、大規模言語モデル（LLM）の社会実装を進める企業。今回のプロジェクトにおいて、計算資源の提供や関係者間の連携促進などの支援を受け、{target=“_blank”}に取り組む予定である。なお、東京大学松尾研究室はすでにGENIACの第１期の採択事業者に選ばれている。


**株式会社 Kotoba Technologies Japan：End-to-End 音声基盤モデルの開発**
Kotoba Technologies Japanは、音声認識や音声生成を包括的に扱う「End-to-End音声基盤モデル」の開発を目指す。同社は米国と日本の最新NLP（自然言語処理）およびHPC（高性能計算）の専門知識を融合し、音声における基盤モデル技術の研究開発を行うスタートアップ。このたびの{target=“_blank”}を受け、同社は日英両言語に対応できる音声基盤モデルの大規模な開発に取り組み、そこで得た知見を広く公開していくという。

**富士通株式会社：論理推論を可能とする大規模言語モデルの研究開発**
富士通は、ビジネスにおける業務効率化に貢献するAI技術の開発に取り組む企業。「Fugaku（富岳）-LLM」をはじめとする基盤モデルの開発、複数の生成AIモデルを組み合わせる混合技術と、安心して業務活用するためのトラスト技術の研究開発を行っている。
同社は、正確性の高い出力が求められる分野でも業務に使える生成AIを提供することを目的に、この採択を受け、{target=“_blank”}に取り組むという。


{target=“_blank”}


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 23 May 2024 13:34:26 +0000</pubDate></item><item><title>シャープ、AIで画質や音質を自動調整する新型テレビ「アクオスG」シリーズを発表</title><link>https://ledge.ai/articles/sharp_aquos-g_ai_auto</link><description>:::small
画像の出典：{target=“_blank”}
:::


シャープは5月17日、AI技術を駆使して画質や音質を自動調整する機能を搭載した新型テレビ「アクオスG」シリーズを発表した。{target=“_blank”} 、{target=“_blank”}、{target=“_blank”}の3種類のディスプレイで、計17機種が6月15日から順次発売されるとのこと。

「アクオスG」シリーズは、次世代AIプロセッサー「Medalist S5」を採用した画像処理エンジンを搭載しており、映像の解像度を高める「AI超解像」機能と、アニメ映像の色味の乱れを補正する「アニメ・ネットクリア」機能を初めて導入した。また、音質調整機能も強化されており、音楽ライブやスポーツ観戦時には臨場感を高め、セリフや解説中には声を明瞭にするという。 


**「AI超解像」AI画像解析を使い、放送やネット動画もクリアで見やすい精細感ある4K映像にアップコンバート** 
!
:::small
画像の出典：{target=“_blank”}
:::


**ノイズ低減「アニメ･ネットクリア」ネット配信のデジタル圧縮により発生しやすいアニメのグラデーションの乱れなどを階調補正により、なめらかでスッキリした映像に調整** 


!
:::small
画像の出典：{target=“_blank”}
:::

「AIオート」機能は、放送だけでなくネット動画もAIが最適化する。これにより、煩わしい設定なしでテレビがおすすめを選択する「AIオート（高画質・高音質）」と、外光や照明の明るさだけでなく色も検知し、視聴環境の変化に合わせて映像をチューニングする「環境センシング」が実現される​とのこと。 



:::box

:::
:::box

:::
</description><pubDate>Wed, 22 May 2024 07:16:46 +0000</pubDate></item><item><title>ソフトバンク、AIによる感情認識・音声加工技術でカスハラ対策強化へ</title><link>https://ledge.ai/articles/softbank_uses_ai_to_combat_customer_harassment</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

ソフトバンクは2024年5月15日、顧客からの通話音声を穏やかなトーンに変換するAI技術の事業化を目指すと{target=“_blank”}した。

カスタマーハラスメント（カスハラ）対策の一環で、コールセンターのオペレーターの負担を軽減することを目的とする。この技術はソフトバンクの「ソフトバンクイノベンチャー」から生まれ、AIを活用した感情認識・音声加工技術により、顧客からの通話音声を穏やかな会話のトーンに変換して、オペレーターに届けることができるソリューションの開発などが、東京大学と共同で研究開発が進められているという。2025年度中の事業化を予定しているとのこと。

ソフトバンクはまた、同社の{target=“_blank”}を策定し、厚生労働省のマニュアルに基づきカスハラ行為の具体例を明示。さらに、カスハラ対策として相談窓口の整備や対応マニュアルの作成を進めている。これにより、従業員の心理的安全性を確保しつつ、顧客との良好な関係を築くことを目指している​。


:::box

:::
</description><pubDate>Wed, 22 May 2024 07:08:19 +0000</pubDate></item><item><title>米掲示板型ニュースサイトReddit、Googleに続きOpenAIともAI学習に向けたデータパートナーシップを締結</title><link>https://ledge.ai/articles/openai-reddit_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月16日、OpenAIとRedditは、両社のユーザーコミュニティに利益をもたらす新たなパートナーシップを{target=“_blank”}した。

この契約により、OpenAIはRedditのデータAPIにアクセスし、リアルタイムで構造化されたコンテンツを取得してChatGPTなどの製品に導入することが可能になる​。

主な契約内容は以下の通り
**1. RedditコンテンツのChatGPTへの導入：** OpenAIはRedditの投稿をChatGPTおよびその他の製品に組み込み、ユーザーがRedditコミュニティを発見し、関与できるようにする。この取り組みにより、OpenAIのAIツールは最新のトピックに関する情報をより深く理解し、提供することができるようになる​​。
**2. RedditのAI機能強化：** RedditはOpenAIのAIモデルを活用して、新しいAI機能をユーザーおよびモデレーターに提供する計画である。これにより、Redditのユーザー体験が向上することが期待されている。
**3. 広告パートナーシップ：** OpenAIはRedditの広告パートナーにもなり、広告収入の面でも協力する。この協力により、両社の商業的な連携が強化される。

Redditは2024年2月、Googleと同様の契約を結んでいる。OpenAIとのパートナーシップにより、Redditのデータの商業利用が進められ、AIの学習と利用の幅が広がることが期待される。なお、RedditのAPIを介してアクセスされるコンテンツは、Redditの承認なしに商業目的で使用することはできないという規約は変更されていない​。

今回の契約について、OpenAIのCOOであるブラッド・ライトキャップは、「Redditと提携してChatGPTを最新で関連性の高い情報で強化し、AIによってRedditの体験を豊かにする可能性を探ることに興奮している」と述べた​。

Redditの共同創設者兼CEOであるスティーブ・ハフマンも、「Redditはインターネット上で最も大規模で活発な会話のアーカイブの一つであり、このパートナーシップはインターネットの接続性を強化し、ユーザーが探している情報を見つけやすくし、新しい観客がRedditでコミュニティを見つける手助けとなる」とコメントしている​。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 21 May 2024 12:20:20 +0000</pubDate></item><item><title>ラピダス、データセンター向けAI半導体で米エスペラント・テクノロジーズと提携</title><link>https://ledge.ai/articles/rapidus_esperanto_technologies_sign_sign-memorandum_of_cooperation</link><description>:::small
画像の出典：{target=“_blank”}
:::

ラピダスは2024年5月15日、データセンター向けAI半導体の開発と生産において、米国のエスペラント・テクノロジーズと提携したと{target=“_blank”}した。エスペラント・テクノロジーズは、RISC-V命令セットアーキテクチャに基づく高性能かつエネルギー効率の高いAIおよび高性能コンピューティング（HPC）ソリューションの開発で知られる。

この提携により、両社は低消費電力のAI半導体を共同開発し、データセンターにおけるエネルギー効率の向上を目指す。ラピダスは2023年9月に北海道千歳市でIIM（Innovative Integration for Manufacturing）の建設を開始しており、2025年にパイロット生産ラインの稼働を予定している。量産は2027年から開始される計画だ​。

エスペラント・テクノロジーズのCEOであるアート・スウィフト氏は、ラピダスとの戦略的提携が日本での事業拡大に重要な役割を果たすと述べている。また、ラピダスのCEOである小池淳義氏は、この提携がエネルギー効率の高い半導体設計と製造に向けた大きな一歩であると強調した​。

データセンターの電力消費は、生成AIやHPCアプリケーションの普及に伴い急増している。国際エネルギー機関（IEA）の予測によれば、2026年までにデータセンターの総電力消費は1,000テラワット時（TWh）に達する見込みであり、これは日本全体の電力消費量に相当するという。このような背景から、エネルギー効率の向上が求められている​。

両社は提携により次世代半導体の設計と製造の最適化を進め、データセンターのエネルギー消費問題に対応するためのソリューションの提供を目指すとした。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 21 May 2024 11:50:56 +0000</pubDate></item><item><title>大阪・関西万博「電力館」に核融合の展示ブース　電事連が検討</title><link>https://ledge.ai/articles/fusion_power_generation_on_display_at_expo2025</link><description>:::small
画像の出典：{target=“_blank”}
:::

電気事業連合会（電事連）は、2025年に開催される大阪・関西万博の「電力館」において、次世代の発電技術である核融合に関連する展示ブースを設ける方向で検討していると、2024年5月16日に{target=“_blank”}が報じた。

核融合技術は、海水などから発電に必要な燃料を取り出す技術を軸としており、2050年ごろの実用化が見込まれるという。電事連は、この展示を通じて技術への理解と支持を広めることを目指すとのこと。

核融合は、軽い原子核を高温・高圧で融合させて巨大なエネルギーを得るプロセスで、太陽内部で起こる反応を人工的に再現することを目指すものだ。核融合の燃料は海水中の重水素（デューテリウム）やリチウムから取り出せるトリチウムで、資源が豊富で持続可能とされる。「温暖化ガスを排出せず、燃料も無尽蔵のエネルギー」とされるが、実用化までにはまだ時間がかかるとみられている。

電気事業連合会のパビリオン名は「{target=“_blank”}」
パビリオン内では様々な体験を通じて「エネルギーの可能性」を感じるコンテンツが用意される予定とのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 20 May 2024 01:07:48 +0000</pubDate></item><item><title>NASA、初のAI責任者にデイビッド・サルバニーニ氏を任命しAI戦略を強化</title><link>https://ledge.ai/articles/nasa_names_first_chief_ai_officer</link><description>:::small
画像の出典：{target=“_blank”}
:::

米航空宇宙局（NASA）は5月13日、デイビッド・サルバニーニ氏を新たなAI（人工知能）部門の最高責任者に指名したと{target=“_blank”}した。

サルバニーニ氏は現在の最高データ責任者（CDO）の役割を拡大し、新たな役割を即時に開始するという。

NASA長官のビル・ネルソン氏は、「人工知能はNASAで何十年にもわたって安全に使用されており、この技術の拡大は発見のペースを加速させることができる」と述べ、「我々は進歩と責任ある利用の最前線に留まることが重要だ。デイビッドは宇宙および地球上でのAIの責任ある利用を指導し、人類全体に利益をもたらすNASAの取り組みを先導する」と続けた。

この任命は、バイデン大統領の「{target=“_blank”}」に基づいて行われた。サルバニーニ氏は、NASA全体でのAI使用に関する戦略ビジョンと計画を調整し、AIイノベーションの推進者として、ツールやプラットフォーム、トレーニングの開発およびリスク管理をサポートする責任を負うとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 19 May 2024 06:30:26 +0000</pubDate></item><item><title>国内AIテックがLLMのハルシネーション対策を続々発表　オルツ「ハルシネーション自動評価エンジン」・ストックマーク「Stockmark-LLM-100b」</title><link>https://ledge.ai/articles/domestic_companies_launch_llm_hallucination_measures</link><description>:::small
画像の出典：{target=“_blank”}
:::

国内のAIテック企業が、大規模言語モデル（LLM）の「ハルシネーション」問題への対策を強化している。

ハルシネーションとは、AIによって生成された回答が、現実には存在しないものであるか、または与えられたデータやコンテキストから著しく逸脱している場合に使われる用語である。AIが幻覚（=ハルシネーション）を見ているかのように、”もっともらしい嘘”をつくため、このように名付けられた。

LLMが事実に基づかない虚偽の回答を生成してしまうため、信頼性の低下を招く重大な問題とされ、各企業が対策に注力し始めている。

## オルツ「ハルシネーション自動評価エンジン」を開発
!
:::small
画像の出典：{target=“_blank”}
:::

オルツは2024年5月9日、大規模言語モデル（LLM）におけるハルシネーションをスコアリングする手法の開発に成功し、「ハルシネーション自動評価エンジン」を{target=“_blank”}した。


このエンジンは、ハルシネーションの発生を判定し、その発生確率を自動的に評価する手法である。実験では、JcommonsenseQAデータセットから作成した擬似評価セットにおいて、72％の正解率でハルシネーションの判定が可能であることが示された。

オルツ独自の軽量型大規模言語モデル「LHTM-OPT」だけでなく、GPT-3.5やLlama2など様々なLLMのハルシネーションのスコアリングが可能だという。

このエンジンは同じ入力データに基づいて複数の生成プロセスを行い、それらの結果を比較することで、生成された内容の不一致や矛盾を特定し、ハルシネーションを確率的に評価する。オルツはこの技術を「alt developer」のAPIサービスを通じて提供し、より多くの開発者が利用可能となっている。

@






## ストックマーク、1,000億パラメータ規模の独自LLM「Stockmark-LLM-100b」を公開

!
:::small
画像の出典：{target=“_blank”}
:::

ストックマーク株式会社は、2024年2月に経済産業省とNEDOが主催するプロジェクト「{target=“_blank”}」に採択され、ハルシネーションを大幅に抑制し、専門的な質問にも正確に回答できる1,000億パラメータ規模の大規模言語モデル（LLM）「Stockmark-LLM-100b」の開発に成功したことを{target=“_blank”}した。このモデルは2024年5月16日より各種サイトで公開され、商用利用も可能となっている。

「Stockmark-LLM-100b」は、既存のモデルを用いずにゼロから開発されたフルスクラッチの基盤モデルであり、国立研究開発法人産業技術総合研究所との共同研究の一環として開発された。独自に収集した日本語ビジネスデータを中心に事前学習を行い、日本語・ビジネスドメイン・最新の時事話題に精通していることが特徴だ。専門性の高い質問にも高い精度で回答でき、また、回答できない質問には「回答できない」と明確に答えるように訓練し、ハルシネーションの抑制に成功しているという。

このモデルは、生成AIが誤った情報を生成することを防ぎ、特に厳密さが求められるビジネスシーンでの信頼性を向上させる。また、商用利用可能なオープンソースモデルとして公開され、多くのユーザーが試用可能である。




:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 19 May 2024 06:27:06 +0000</pubDate></item><item><title>テラドローン✕九州電力送配電　AI搭載ドローン自動鉄塔点検システム導入で点検時間を約50％削減</title><link>https://ledge.ai/articles/terradrone</link><description>:::small
画像の出典：{target=“_blank”}
:::

Terra Drone株式会社は2024年5月8日、九州電力送配電株式会社と協力して、AI搭載ドローンによる自動鉄塔点検システムを九州エリアの約15,000基の鉄塔に適用拡大したことを{target=“_blank”}した。このシステムは、点検作業を自動化し、時間短縮を実現するものだという。

送電鉄塔は、自然界の影響を常に受ける重要なインフラで、安定した電力供給を維持するためには定期的な点検が必須となる。従来の点検方法では、ドローンを手動で操作し、22万ボルト級の鉄塔1基あたり約110分を要していた。新システムは、鉄塔の形状に応じて自動でドローンの飛行経路を生成し、AIが劣化状況を確認する「がいし」を自動検出する。これにより、ドローンの飛行、カメラの調整と撮影を自動で行い、操縦者の手動操作が不要となる。

システムの導入により、操縦者と監視者の2名体制で、22万ボルト級の鉄塔点検が1基あたり約60分で完了し、従来と比べて点検時間は約50%削減された。これにより、鉄塔点検作業の効率化が図られ、人件費の削減及び作業の安全性が向上する。

近年のインフラの老朽化と人手不足の問題を背景に、本システムは先端技術を導入し、効率化を実現。今後は特殊な形状の鉄塔への適用やドローン飛行の法規制緩和が進むことにより、全国各地の鉄塔への展開が期待される。また、同社はこの技術革新を通じて、引き続きインフラの保全に貢献する方針だという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 16 May 2024 14:09:27 +0000</pubDate></item><item><title>ZOZOアプリ「WEAR」リニューアル　AI活用でファッションやメイクの「似合う」スタイルを提案する新機能</title><link>https://ledge.ai/articles/zozo_wear_app</link><description>:::small
画像の出典：{target=“_blank”}
:::

ZOZOは2024年5月9日、同社が運営するファッションコーディネートアプリ「WEAR」を「WEAR by ZOZO」としてリニューアルし、AIを活用した新機能を導入したことを{target=“_blank”}した。リニューアルにより、ファッションの個別の好みを数値化し、ユーザーに最適な「似合う」スタイルを提案することを目的としている。

### ファッションジャンル診断
ユーザーはアプリを起動後、好きなコーディネート画像を選択し、AIがこれを分析してファッションジャンルの傾向を診断する。この診断には、12のファッションジャンルがあり、ユーザーの好みを反映した円グラフで表示される。


!
:::small
画像の出典：{target=“_blank”}
:::


### WEARお試しメイク
AR技術を利用して、ユーザーが自身のメイクをデジタルデータとしてアプリ上に登録し、他のユーザーがそのメイクを自分の顔にARで試すことができる。


!
:::small
画像の出典：{target=“_blank”}
:::


このリニューアルは、「MORE FASHION × FASHION TECH」という経営戦略の一環で、技術を活用してファッション業界での新たな体験を提供することを目指している。ZOZOTOWNとWEARのシームレスな連携により、ユーザーは購入したアイテムの着回し提案を受けられるため、新たなファッションアイテムの購入につながることが期待されるという。

また、WEARはコーディネートだけでなく、メイクの提案も可能になり、ファッション情報の一元化が進んでいる。ユーザーは自分のスタイルに合ったコスメアイテムも同アプリ内で探し、購入が可能だ。また、WEAR公認のファッショニスタやショップスタッフによるリアルなコーディネートの提案が、ファッションの最新トレンドを学ぶ手助けとなっているという。


:::box

:::
:::box

:::

</description><pubDate>Thu, 16 May 2024 14:07:16 +0000</pubDate></item><item><title>プリファードロボティクス、自律移動ロボット「カチャカ」向け新ソフトウェア「カチャカボタンハブ」をオープンソースで公開</title><link>https://ledge.ai/articles/preferred_roboticcs_kachaka_button_hub</link><description>:::small
画像の出典：{target=“_blank”}
:::

プリファードロボティクスは2024年5月9日、自社の自律移動ロボット「カチャカ」及び「カチャカプロ」の操作性を大幅に向上させる新ソフトウェア「カチャカボタンハブ」をオープンソースとして公開したことを{target=“_blank”}した。このハブを通じて、自律移動ロボット「カチャカ」をボタン一つで簡単に操作できるようになる。


@




「カチャカボタンハブ」は、ユーザーがロボットへの指示をボタン一つで簡単に出せるよう設計されており、日常生活や業務でよく使用される機能に特化している。同ソフトウェアは、市販のマイコンモジュール「M5Stack」にインストール可能で、ボタンビーコンなどの通信信号を発信するデバイスを通じて、ロボットを指定の場所まで動かすことができる。このプロセスにより、専用家具とのドッキングや、指定の場所への運搬が簡単に実行可能となる。

同社によると、このソフトウェアの公開は、利用者からの直接的なフィードバックを受けて行われた。カチャカとカチャカプロは、一般家庭だけでなく、飲食店や歯科医院、工場など多岐にわたる業界で導入が進んでいる。これらの場では、ロボットに対する指示が頻繁にあり、より迅速かつ簡単な操作が求められていた。

株式会社Preferred Roboticsは、2015年に設立され、AI技術を駆使した自律移動ロボットの研究、開発、製造、販売を行う企業である。同社は、ロボット技術の普及とともに、「すべての人にロボットを」というビジョンを掲げ、利用者の生活をより便利で快適にすることを目指している。今回の「カチャカボタンハブ」の公開も、その一環として位置づけられる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソフトウェアは、GitHubを通じて一般に公開されており、自由にダウンロードし利用することができる。ただし、ハードウェアの設置やソフトウェアのインストールにはある程度の技術的な知識が必要となる。

カチャカは以前から音声コマンドやスマートフォンアプリによる操作が可能であったが、カチャカボタンハブの導入により、利用者は更に簡単にロボットを操作できるようになる。これにより、日常生活や業務においてカチャカの利便性がさらに向上することが期待されるという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 15 May 2024 15:21:49 +0000</pubDate></item><item><title>生成AIによる服装リアルタイムデザインを実現するツール「LOOK」深センのAIスタートアップが発表</title><link>https://ledge.ai/articles/ai_fashion_design_tool</link><description>:::small
画像の出典：{target=“_blank”}
:::

中国深セン市に本拠を置く新興AIテック企業「基本操作科技」は、生成AIを活用した服装デザインツール「Look」を{target=“_blank”}した。このツールは、ファッションデザインのプロセスを効率的かつ創造的に変革することを目指している。

## 主な機能
**リアルタイムデザイン変換：** デザイナーのスケッチを、LOOKの生成AI技術によって瞬時に詳細なデザイン画像へ変換する。これにより、アイデアの即時視覚化が可能となり、デザインの過程が飛躍的に速くなる。

!
:::small
画像の出典：{target=“_blank”}
:::

**細部の精密調整：** LOOKのプラットフォームでは、デザインの微調整が細かく行えるため、デザイナーは最終的な製品を自分のビジョン通りに仕上げることができる。

!
:::small
画像の出典：{target=“_blank”}
:::



**モデル試着：** バーチャルモデルを使用してデザインされた服を試着し、異なる体型やスタイルでの見え方を確認することができる。

!
:::small
画像の出典：{target=“_blank”}
:::

**動的試着：** AIを利用して生成された動画を通じて、実際の動作中の衣服の流れやフィット感を評価できる。これにより、実際に衣服を生産する前にその機能性や外観を完全に理解することが可能となる。


LOOK AIはプロクリエイト（Procreate）との互換性も持ち、Photoshopへの対応も計画されている。これにより、デザイナーは既存のツールを活用しながら、LOOKの高度なAI機能を組み合わせることが可能となる。

同社は、この技術がデザインのプロセスを大幅に簡素化し、デザインの品質を向上させることで、ファッション業界に新たな標準をもたらす可能性があるという。また、生産前のデザインの調整にかかる時間とコストの削減、そして持続可能なファッション制作へ貢献するとしている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 14 May 2024 14:44:56 +0000</pubDate></item><item><title>42 Tokyo、知ってますか？　AIも学べるパリ発の究極のエンジニアスクール　特別インタビュー【第1回】事務局長 佐藤大吾氏</title><link>https://ledge.ai/articles/42tokyo-1</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第1回。**
:::
※インタビューは2024年1月19日に行われた。
:::box
!
**一般社団法人42 Tokyo 事務局長**
**佐藤 大吾**
NPO法人ドットジェイピーを設立し、これまでに4.5万人の学生大学生が参加したインターンシッププログラムを運営。また、英国発世界最大の寄付サイトの日本事業「JustGiving Japan」を創業し、多数の企業や非営利団体の第一線で活動し、社会課題の解決に携わってきた。現在、武蔵野大学アントレプレナーシップ学部教授、大阪芸術大学客員教授なども務める。
:::
## パリ発のエンジニア養成機関である「42（フォーティートゥー）」とは
パリ発のエンジニア養成機関である「42」は、合同会社DMM.comの亀山会長が主導し、東京への誘致が行われた。日本に誘致したきっかけについて、佐藤氏は以下のように語った。
:::box
**—佐藤氏**
「42」はフランスから始まったのですが、創業者によると、フランスでは高額な学費を支払って高等教育を受けるか、「役に立たないこと」を学ぶために無料の学校に行くかの二択しかなく、教育制度が崩壊していたそうなんです。経済的バックグランドに恵まれない人は、高等教育にアクセスすることはできない、ということなのですが、この点に関しては日本も同じだと思うんです。
私は武蔵野大学アントレプレナーシップ学部の教授でもあり、日本の大学の仕組みはよく分かってるつもりなのですが、経済的に恵まれた人とそうでない人との差が大きすぎるというのは事実だと思いました。 

42 Tokyoを日本に誘致し、現在42 Tokyoの校長でもあるDMM.com 会長の亀山さんも、「42」の存在を知ったときは、自身の幼少期と重ねながら「経済的に恵まれてない人にも等しく 学びの機会を提供する」という点に非常に共感したそうなんです。
:::
DMMはいわずと知れた動画配信、オンラインゲーム、電子書籍などのインターネットサービスを提供する巨大企業だ。サービスを提供する中で、IT人材を確保することの重要性については身をもって体感しているという。IT人材の不足については、民間企業だけではなく政府も解決に向けて注力しており、日本全体の課題となっている。
:::box
参考：{target=“_blank”}
:::
:::box
**—佐藤氏**
世の中的にもニーズはあるし、社会全体でIT人材を育てて増やしていくことは理にかなっているということで、亀山会長は「42」を日本に誘致したいと考えたそうです。
:::
42 Tokyoはエンジニア養成機関でありながら、学費無料・経験不問で、18歳以上であれば誰でも入学試験を受けることができる。また、校舎は24時間365日オープンしていたり、常にアップデートされる教材も、他のエンジニアスクールとは異なるポイントだ。

42 Tokyoで学んだ学生は、大学進学や就職・起業など、進路も幅広い。ちなみに、Ledge.aiが以前にインタビューを行ったホワイトハッカーの蔀さんも42 Tokyoで学んだひとりである。
:::box
関連記事：{target=“_blank”}
:::
### 教師不在。「問題解決型学習」と「ピアラーニング」を取り入れたカリキュラム
!
42 Tokyoに入学するためには、まずエンジニア適性テストに合格したのち、「Piscine (ピシン)」という本テストを受けなければならない。「Piscine (ピシン)」は4週間かけて行う入学試験で、合格率は全体の3~4割程度とのこと。一見「これからエンジニアリングを学びたい」という学生にはハードルが高いように思えるが、この試験でみられるのはプログラミングスキルではないそうだ。
:::box
**—佐藤氏**
「42」の入学試験は、「プログラマーとしての実力が問われるんじゃないか」「やはり素人では無理なんだろう」と思われがちですが、全く違います。合格した学生の中でも、コードを書いたことがないという人は3割以上いるんです。

では何を見ているのか？についてですが、私たちが大事にしている観点は「入学後やエンジニアになってからも勉強を続け、成長し続けられる人材か」という点です。入学試験初日、何もできずに涙を流して帰っていく人もいるんです。しかしそこで、明日もう一回校舎に来れるか？を見るんです。試験期間は4週間もあるので当然離脱する人もいますが、初日がダメでも、次の日以降に周囲の人とコミュニケーションをとりながら諦めずに課題解決できる力があるか、を見ているんです。
:::
42 Tokyoは ”即戦力” となるエンジニアの育成を目標としているが、即戦力を生み出すキーワードとして「問題解決型学習」と「ピアラーニング」が挙げられる。

「問題解決型学習」は、授業や講義などの学習スタイルではなく、学生自身が課題に対して調査したり、周囲の学生に質問しながら解決していく方法だ。考えることを繰り返すことで、問題解決能力を身に着ける狙いがある。

「ピアラーニング」は、学生同士で教えあい学びあう学習方法で、「42」には、教師から生徒へ一方通行で教える授業や講義がなく、与えられた課題に対して、自身の書いたコードを他の学生に説明し、フィードバックをもらう「コードレビュー」を生徒同士で行いながら取り組んでいる。自身のコードを他者に説明することで頭の整理ができ、反対にフィードバックをする立場では、自分にはなかった手法や思考法を学ぶことができる。相互関係で取り組むことにより、コミュニケーションスキルを磨けるほか、学ぶ仲間ができ、刺激しあえる関係を構築できるのだ。

また、学生に出される”課題”もユニークなポイントがある。それについて佐藤氏は以下のように話してくれた。
:::box
**—佐藤氏**
現在世界に「42」は54キャンパスあるのですが、基本的にはカリキュラムはすべて統一されています。
ユニークなポイントとしては、各キャンパスのスポンサー企業が最先端の技術についての課題を投げ込んでくれる点です。例えば、新しいセキュリティホールが見つかったら、それに関連する課題を作って提供してもらう。そうすると、学生たちは世界のどのキャンパスでも最先端の課題を学ぶことができるのです。

しかしこれも段階があり、まずは各キャンパスでスポンサーから課題を提供してもらい、そのキャンパスに通う学生が課題へ取り組みます。良い課題に関しては、各キャンパスからフランス本部へ共通化に向けた申請を行い、フランスの本部で評価されたものが全世界の共通課題としてアクセスできるようになっていくのです。
:::
東京にいながら、「42」が展開している31ヵ国の実践的な課題に挑戦できる点は、エンジニアとしての力を養いたい人にとっては非常に魅力的である。佐藤氏によると、各国で提示される課題にも傾向があり、国ごとに盛んな産業が違うことに起因しているとのこと。例えば、ドイツのキャンパスでは自動車の自動運転や自動車の組み込みにかかわる課題が多く、スウェーデンなどの北欧では、ゲームに関する課題が多い。日本では、半導体に関連する課題が多く投げ込まれるとのことだ。

「42」には ”卒業” という概念はなく、コモンコアと呼ばれる基礎カリキュラムを終えたら就職や起業、または海外キャンパスへの留学や、特定のジャンルをさらに深く学ぶ ”アドバンス課程” への移行が進路としてあるが、佐藤氏曰く「コモンコア終了後は、早く社会で活躍してほしい気持ちがあるが、最先端の課題に取り組めるから残りたいという学生も多い」と、常にブラッシュアップされる課題は学生からも好評のようだ。
### 42 Tokyoをきっかけにして進路を広げたい
42 Tokyoに入学した学生は、約600名のうち200名程度が現役大学生だ。42 Tokyoでの1週間の推奨学習時間が35~50時間とされている中、大学生の一部は休学し、42 Tokyoでの学びに時間を費やしているそうだ。
!
:::box
**—佐藤氏**
42 Tokyoの受講期間の目安は1年間から最長1年8か月となっており、コモンコアを終えるためには、学校に行きながらや、働きながらはかなり大変です。皆さんも生活があるので悩むところですが、それでも休学したり、仕事を辞める方はいます。42 Tokyoのコモンコアを早々に終わらせて、もう一度大学に戻る方ももちろんいます。

エンジニアスクールは、仕事しながら夜に受講したり、学校行きながら通うということが一般的であり、皆さんもそのようなイメージを持っていると思います。しかし、フランスでは全く考え方が違い、高校を卒業するタイミングで一般大学へ進学するか、42 Parisへ進学するかを選択するのです。フランスでは「42」の存在がそこまで大きくなっているのですが、42 Tokyoもそこを目指しています。
:::
フランスも学歴で判断される風潮が色濃いが、日本も学歴社会であると言える。そのような中で「大学を休学して42に打ち込むべきか」の相談は、非常に多く受けるという。
:::box
**—佐藤氏**
学生が悩むのも、我々の責任であると感じています。というのも、42 Tokyoの知名度が高まれば、学生自身や高校の先生、学生の保護者も安心してくださるからです。「42 Tokyoなら挑戦してみたらいい。厳しければ一般の大学へ進学したらいい」という、安心してもらえるような知名度と実績を早く獲得しなければと考えています。
現在、高校向けの説明会を増やしており、高校生向けのサイトを作成したりなど、42 Tokyoの取り組みや成果を広げる活動を進めています。

また、企業の採用に関しても学歴に関するレガシーなルールや基準があったりしますが、そうではなく、スキルに着目して選考が受けられるように変わっていってほしい、それが「普通」になってほしいと思っています。中学校や高校を卒業し、夢が見つかったらすぐに挑戦できる世界があるというのは、不自然ではないですよね。
:::
このような若い世代の可能性を広げる取り組みについて、佐藤氏は「42 Tokyoをきっかけに、また違う道が始まってくれれば」と語った。
:::box
**—佐藤氏**
高校受験ではうまくいかなかった子や高校時代にあまり素行の良くなかった子も、インターネットやソフトウェアについて学んで、そこから有名企業や、採用されるのが難しいと言われる人気企業に就職したり、自分の力で起業していくのは夢ではないと考えています。そのきっかけとして「42」があり、「42」で頑張れば違う道が拓けるんだという経験を提供したいと思っています。

「42」のコモンコア修了時点では、バックエンド・フロントエンドも1人で作業できる、webが作れるフルスタックエンジニアとなっています。一通りのことができるようにはなるのですが、その時点でphpやPythonは習得していません。ただ「42」の課程を修了することで、いわゆる「独学力」が身についているため、急に「あなたの課題はPythonです」と言われても、自分で勉強し対応できるのです。

また、独学力を身に着けるためには緩やかな強制がある方がよいと思っています。「42」ではロールプレイングゲームでモンスターを倒してレベルをあげていくのと同じように、課題を解決することでポイントを獲得し、そのポイントを蓄積することでレベルを上げていくというゲーミフィケーションを取り入れています。
:::
42 Tokyoのスタッフが、学生の就職先となりうる企業の人事担当と話す際、その学生がどの程度の技術を持っているかは「レベル」が共通言語になるという。例えば「レベル8であれば、うちの会社の採用としてはスキル面ではOK」のように判断ができ、あとはカルチャーフィットするかどうかの見極めになってくるそうだ。

また、学生の就職の幅が広がるように、現在は評価軸の整備にも力を入れているという。
:::box
**—佐藤氏**
今取り組んでいるチャレンジとしては、学生の学ぶ姿勢やプロセスも注視し、定性的な部分を評価できるようにすることです。例えば「この子はレベルはまだ全然届いてないんですが、苦しい時もめげずに毎日キャンパスに通って頑張っていた」というような評価です。なので頻繁にグループワークを取り入れ、グループワークの中での評価を収集し、彼らのキャリア支援につなげたいと考えています。
:::
## 42 Tokyoの今後の展望
###  将来的には1,000名規模を目指す
2024年4月から42 Tokyoは校舎を東京都新宿区に移した。現在の学生数は600名だが、将来的には1,000名規模を目指すための移転である。
:::box
**—佐藤氏**
現在最も大規模なキャンパスは42 Parisで、4,000名程在籍しています。2番手が42 Seoulで1,000～1,200名程度です。韓国がすごいのは国が支援している点です。42 TokyoはDMMをはじめとするパートナー企業が支援していますが、我々にとってのパートナー企業の存在が韓国では国家なんです。
日本はまだ15番手くらいなので、韓国ぐらいの規模の1,000名を目指したいと考えています。
:::
!
学生数の増加に向けて、学生サポート面も強化する意向だ。42 Tokyoは前述のとおり2020年に開校したため今年で4年目となるが、3年間の運営を振り返り、学生支援課のような機能を持った部隊を新たに設置した。
:::box
**—佐藤氏**
私が着任する前の3年間はフランスのやり方を踏襲した、いわゆる「ミリタリースタイル」での運営でした。「上がりたい奴だけ上ってこい」というような感じです。
フランスでは42の知名度があるので入学希望学生が大勢いるのですが、日本の場合はまだ知名度が低く、同じようなスタイルだと、せっかく志を持って厳しいピシンを乗り越えて入学した学生たちが、途中でどんどん脱落してしまいます。

なので、理事長の坂之上と私が着任してすぐに取り組んだことは、学生支援チームを作り、「バケツの穴を塞ぐ」ことでした。フランスでは学生自身による自発的な行動が重視され、運営側による学生支援についてはあまり積極的ではない様子でしたが、設立して日の浅い他国のキャンパスにもヒアリングしたところ、概ね同じような状況であり、すでに学生支援チームを持っているところもあったため、東京キャンパスとしても新たに専門人材を採用し、学生支援チームを立ち上げました。
:::
実際に42 Tokyoへ通う多くの学生が10代や20代前半であり、運営側のケアも必要な年齢である。42 Parisで学び、現在日本に来ている学生へ、学生支援課の取り組みについてヒアリングしたところ「あった方がよい。」という反応もあったそうだ。42 Tokyoに来た学生に向けて佐藤氏は「エンジニアを志しているのだから、途中離脱させず、夢をかなえてもらいたい」と思いを語った。
:::box
**—佐藤氏**
エンジニアリングを学ぶためには、優れた学習コンテンツを提供するだけでなく、毎日キャンパスに来たくなるような仕掛けや雰囲気づくりが必要です。
例えば、スポンサー企業に来ていただいて、実際にプロダクトを開発した現役エンジニアに開発の裏話を聞かせてもらったり、CTOに来てもらって、これからのエンジニアに期待することを話していただくなど、様々な企業との合同イベントを開催しています。これは企業側にもメリットがあって、学生と接点を持つことで、企業認知が広がり、卒業後の進路としてその企業が選択される可能性も上がるため、win-winの関係で協力いただいています。

また、運営側と学生の信頼関係構築のために、私や理事長もできるだけ学生と会話したり、定期的に交流会のような会を実施して、要望を聞いたりしています。もちろんすべてを叶えることは難しいですが、直接対話の機会を通じて相互理解が進み、信頼関係の構築につながっていると感じています。
:::
!
:::small
トヨタと42 Tokyo共同で開催した自動運転ミニカーバトルのコンテストの会場風景（DMM本社内）
:::
最後に佐藤氏は、42 Tokyoの今後の展望として「学生の活躍の場を広げる取り組み」と「良質なコミュニティづくり」を挙げた。
:::box
**—佐藤氏**
当然のことですが、学生は知っている企業にしか就職しません。最初のうちは希望進路として、GAFAMなど有名なビッグテックなどIT業界に目が行きます。しかし、ソフトウェアエンジニアが活躍できる業界はIT業界だけではありません。世の中にはソフトウェアエンジニアを求めている業界、企業が数多く存在します。それを知ってもらうことも、私たちの大切な役割だと思っています。
例えば、トヨタさんは学生の間でも高い知名度があり、機械系エンジニアにとって憧れの会社だと思いますが、ソフトウェアエンジニアの就職先としてはまだまだ認知拡大が必要だとお聞きしました。また、トヨタに情報系エンジニアが活躍できる場があることを知らない学生はたくさんいます。そこでお互いを知っていただくための出会いの機会を作ることに取り組んでいます。

日本政府もIT人材を増やす取り組みを推進していますし、多くの学生にエンジニアとして羽ばたくための学びの機会を提供し、卒業後は即戦力として社会で活躍いただきたいと考えています。

また、今後42 Tokyoを運営していくにあたって ”良質なコミュニティ” を作り出すことも、とても重要だと考えています。よい学習環境を整えることで学生が増え、切磋琢磨することで生徒同士の教えあいの質も上がり、優秀な学生が増えていきます。
42 Tokyoの知名度と存在感が高まることで、エンジニア採用に関心を持っている企業に加えて、42 Tokyoの理念やビジョンに共感し、 ”ソーシャルインパクト” の視点を持って寄付してくださる企業や個人からの応援も増えてくるのではないかと思っています。
:::
現在の42 Tokyoの支援の割合は、採用ブランディング目的の寄付が9割、残りの1割がソーシャルインパクト（社会的貢献投資）での寄付という。佐藤氏は、「42」のコンセプトへの共感による支援を増やしていくための発信も、今後行っていきたいと話す。
:::box
**—佐藤氏**
他国の42キャンパスではスポンサー企業のうち、エンジニア採用目的とソーシャルインパクト目的とが1:1のキャンパスもあるんです。私たちはまだ9対1ぐらいなので、そちらの広報も進めていきたいと思っています。
私たちとしてはダイバーシティにも取り組んでおり、例えば障害をお持ちの方や何らか制約がある方でも、42 Tokyoは24時間365日キャンパスをオープンし、学びの機会を提供したいと思います。
:::
:::box
特集：
:::</description><pubDate>Tue, 21 May 2024 23:38:20 +0000</pubDate></item><item><title>「G検定」のシラバスを改訂　最新技術情報を網羅した第3版公式テキストが5月27日に発売！</title><link>https://ledge.ai/articles/jdla_deeplearning_for_general</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月14日、一般社団法人日本ディープラーニング協会（JDLA）は、「G検定（ジェネラリスト検定）」のシラバスを2024年11月8日実施の「G検定2024 #6」より改訂することを{target=“_blank”}した。

G検定は、一般社団法人日本ディープラーニング協会（JDLA）が実施するディープラーニングの基礎知識や活用リテラシー、AIに関する技術やビジネス活用の知識を身に着けるための検定試験だ。G検定を学ぶことで生成AIの仕組みを根本から理解し活用シーンをより具体的にイメージすることができる。

生成AI界隈は様々な技術が組み込まれ日々進化し続けているため、今回の改訂では新たな基盤モデルや言語モデルといった最先端の技術情報を追加し、法律・倫理についても理解しておくポイントを明確化してシラバス全体の見直しを行ったという。

今回のシラバス改訂に伴い、公式テキスト第3版が5月27日に発売予定。
!
</description><pubDate>Fri, 17 May 2024 09:07:07 +0000</pubDate></item><item><title>GWに徹底理解！「Vision Transformer」 LLMの基幹技術 Transformer を画像分類に応用した大注目技術が分かりやすいビジュアルガイドに</title><link>https://ledge.ai/articles/a_visual_guide_to_vision_transformer</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleが開発したトランスフォーマー技術は、自然言語処理から画像分類へとその応用範囲を広げ、新たなAIモデル「Vision Transformer（ViT）」が登場した。このモデルは、画像を小さなパッチに分割し、それぞれのパッチを独立したデータポイントとして処理することで、画像全体の文脈を捉える能力を持っているという。

もともとテキストデータ向けに開発されたトランスフォーマーは、その強力な自己注意機構（Self-Attention Mechanism）により、文中の各単語がどのように相互作用するかを学習する。このメカニズムを画像データに応用したことで、ViTは画像の各部分がどのように関連しているかを効率的に解析し、従来の畳み込みニューラルネットワークモデルと比較して高精度な画像分類を実現しているとのこと。

ソフトウェアエンジニアであるデニス・タープ氏は、この複雑なモデルを「{target=“_blank”}」というビジュアルガイドでわかりやすく解説している。

このガイドでは、ViTの構造とデータの流れをステップバイステップで説明し、専門家でない読者にも理解しやすい内容となっている。特に、画像をパッチに分割し、それぞれのパッチがどのようにネットワーク内で処理されるかを視覚的に示している点が特徴的だ​​。

「Please enjoy and start scrolling!（スクロールしてお楽しみください）」と書かれているとおり、縦スクロールで次々と解説が進む作りになっている。{target=“_blank”}から。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Fri, 03 May 2024 04:38:19 +0000</pubDate></item><item><title>AIエージェントとは｜マニアックなプロンプトエンジニアリングはいらない 注目の生成AI活用トレンド</title><link>https://ledge.ai/articles/about_ai-agent</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

:::box
**目次**
- 導入
- AIエージェントの仕組み
- AIエージェントの実装例
:::

## 導入
### AIエージェントという概念　～AIのエージェントアプローチ＋LLM～
AIエージェントという仕組みは、昨今の生成AI活用ブームの中で注目を集めているが、エージェントという概念自体は、コンピューターサイエンスやロボット工学の分野で研究が進められてきたものである。特に1980年代にロボット研究者であるロドニー・ブルックスらの研究は、自律型ロボットやエージェントシステムに大きな影響を与え、2000年に発売された自動掃除機ルンバといった製品として実用化もされている。その後、機械学習の手法を組み合わせた研究が進み、近年の大規模言語モデル（LLM）の普及によって、より複雑な問題を自律的に解決できる仕組みであるAIエージェントという概念として語られるようになった。

### プロンプトエンジニアリングの限界
2022年11月30日にOpenAIが発表したChatGPTは、その利用の手軽さや生成物のクオリティから、生成AIという技術がビジネスを大きく変えていく未来を想像させた。
チャット型のユーザーインターフェースは、プログラミング言語などの特殊な言語を扱うことなく、人間と対話するときと同じような感覚で送ったテキスト情報に対して意味の通る文章を生成、回答してくれる。
生成される回答は、プロンプトと呼ばれる命令の出し方一つで異なってくる。生成AIから質の高い回答を得るためには、効果的なプロンプトを作ることが重要であり、プロンプトを使いこなす手法や技術を指す分野としてプロンプトエンジニアリングという言葉も誕生した。
ChatGPTの発表以後も、様々な活用方法が生み出され、プロンプトエンジニアリングに関するセミナーや書籍なども数多く目にするようになった。

生成AIは、プロンプトを使いこなせるようになると便利なツールである。ただし実際の業務に最適化させていくほど、プロンプトは長く複雑なものになっていく。実行してもらいたいタスクの詳細情報や実行の条件、参照すべき情報など、業界や業種、業務の用途に合わせてプロンプトに書き込んでいかなければならないからである。
さらに、ベースの学習済みの言語モデル自体も、日々アップデートされている。アップデートによって、以前使用していたプロンプトの出力内容も変わってしまう可能性がある。
生成AIはうまく活用できれば業務の効率化に役立てられるが、それを実感できるレベルにまでたどり着ける人は少ないのかもしれない。
このような背景を踏まえると、プロンプトエンジニアリングで業務効率化を実現していくアプローチには限界があるといえる。

そこで注目を集めているのが、細かな指示がなくとも自律的に目的に向かってタスクをこなしてくれる「AIエージェント」の仕組みである。現在はまだ先進的な企業で技術検証が進んでいる段階ではあるが、今後の生成AI活用における大きなトレンドになると期待されている。本記事で「AIエージェント」の基本的な概念や仕組みについて理解を深め、生成AI活用のヒントとしてもらいたい。

### AIエージェントの概要
AIエージェントとは、一言でいうとある目標を達成するために自律的に行動するソフトウェアプログラムやシステムのことである。 
例えば、オフィスでの会議室の予約をしたい状況で、AIエージェントの活用イメージとして以下のようなシナリオを描くことができる。

!

まず最初にユーザーがAIエージェントに対して、来客用の会議を予約するという目的を与える。AIエージェントは、会議室予約のデータベース参照し空き状況を確認するというタスクを実行する。もし会議室の空きがなかった場合には、会議の重要性を判断し、他の会議室予約者との交渉を行い、会議室の確保を自律的に遂行してくれる。

AIエージェントは、現在もなお研究・開発が進行している分野である。研究や社会実装の分野での様々なプロジェクトの中で、AIエージェントの技術的な可能性が示され、現在に至っている。以下にAIエージェントの発展の中で注目を集めたマイルストーンプロジェクトを紹介する。

**社会シミュレーション「Generative Agent」：**
複数のAIエージェントによる社会シミュレーションを行ったスタンフォード大学とGoogleとの共同研究のプロジェクト。
25人のエージェントと仮想的なゲーム環境による人工的な村社会を構築し、AIエージェント同士が創発的に協同しあうかを実験した内容が論文として発表された。

**ソフトウェア開発会社「ChatDev」：**
AIエージェントが経営するソフトウェア開発会社を仮想的に再現し、エージェント同士の協働によって、実際のソフトウェアを開発するツール。
現実世界のソフトウェア会社のように、プログラマー・テストエンジニア・アートデザイナーなどのAIエージェントにそれぞれ役割を与え、エージェント同士でコミュニケーションを取りながらソフトウェア開発のステップ（設計、コーディング、テスト等）を進めていくことができる。

**完全自律型AIエンジニア「Devin」：**
米国のAIスタートアップCognition社が発表したソフトウェア開発のAIエージェント。与えられた要件からソフトウェア開発の一連のプロセスを自動で実行し、エラー発生時にも自律的に問題解決するなど、高度なエンジニアリングスキルを持っている。Devinの発表は、そう遠くない未来にソフトウェア開発のあり方が大きく変わる可能性を示した。

:::box
関連記事：
:::

## AIエージェントの仕組み
AIエージェントは、概念的には個性／記憶／計画／行動の4つの機能で構成されており、互いに作用し合うことで、複雑な問題の解決を実現する。AIエージェントはまだ研究途上の段階にある仕組みではあるが、これらの要素のポイントを押さえて設計していくことがAIエージェント構築の肝になる。

!

### 個性（Profile）
個性（Profile）は、年齢、性別、職業等といった基本情報や性格・社内的な立場といった情報で、AIエージェントの振る舞いに影響を与える。
現実世界では、営業や人事、開発、法務など様々な職域があり、複数の職種の人たちによる相互の営みを通じて事業は構成されている。それぞれに与えられた役割があり、向いている性格や思考や行動の特性があり、適切な人材を配置し、組織を設計することで生産性を向上させることができる。AIエージェントも同様に、異なる性格や価値観、役割を定義することで、AIエージェントの思考・行動の決定プロセスに影響を与えることができる。

### 記憶（Memory）
タスクを適切に実行していくためには、「記憶」の仕組みを考える必要がある。その理由の一つには、LLMが一度に扱えるデータ量には制限がある。もう一つは、会話の文脈や過去の経緯を踏まえて適切に判断を下すためには、短期的な記憶と長期的な記憶を区別して情報を処理する必要がある。
さらにAIエージェント自身の体験の記憶だけでなく、外部に蓄積されているデータベースを参照し、大量の業務データを記憶として扱える点は、人間の記憶とは大きく異なる。
扱えるデータ形式としては、リレーショナルデータベースとベクトルデータベースの大きく2種類存在する。

**リレーショナルデータベース：**
業務システムで一般的に利用されるデータベースであり、データをテーブル形式の構造化された状態で保存する。データの検索・抽出といった操作には、SQLというデータベースクエリ言語を使う。大規模言語モデルを用いて、SQLクエリの生成を行うことができ、記憶の呼び出しができる。

**ベクトルデータベース：**
文書や画像など、構造化された形式のデータに変換ができない形式のデータを扱うデータベース。データをベクトル空間という空間内の特定の座標にマッピングすることで、データ同士の意味的な関係性を、2点間の座標の方向や大きさという数値情報によって扱うことができる。

海外では、Airtableというクラウドデータベースサービスに様々なデータを格納し、それらをAPI経由で、AIエージェントがアクセスできるようにしておき、ファイルやデータの参照から書き込みまで各種タスクの実行を行えるようにする活用事例なども出てきているという。

### 計画（Planning）
計画は、AIエージェントが目的を達成する上で非常に重要なプロセスである。このプロセスでは、必要なタスクを思考し、それらを分解をすることで、目的達成のための最適な手順とアクションを明確にする。
AIエージェントにおける計画で押さえておくべきアプローチとして、”タスク分解”がある。
タスク分解は、文字通り目的の達成のために必要なタスクを分解することである。AIエージェントでは、ユーザーから提示された目的に対して、そのタスク分解のためのプロンプトを生成し、タスク分解を行うように設計していくことが重要になる。
オープンソースのAIエージェント「BabyFoxAGI」では、タスク分解のプロンプトを生成する仕組みがプログラムされており、汎用的なタスク実行に対応できるようになっている。

さらにReActというプロンプティングの手法を取り入れることで、分解したタスクに対してLLMに正しい推論と意思決定を行わせ、計画の解像度を高めていくことができる。
ReActは、理由（Reason）と行動（Action）を中心に思考しながらタスクを進めていくアプローチであり、その英単語の頭文字を取って名付けられている。
与えられたタスクを達成するために、行動を思考し、行動の結果を観察、そこから得た学びを思考に反映し、行動を最適化していく、というのがReActの基本的な流れである。
例えば、先程あげた会議室予約を例に、AIエージェントでのタスク分解のイメージを下記に示す。

:::box
**会議室の予約で想定されるタスク分解例**
- ユーザーのその日のスケジュールを確認し、会議可能な時間を把握
- 同席者の有無を確認し、同席がいる場合に同席者のスケジュールを踏まえた会議時間を設定
- 会議室予約のデータベースを参照し、設定時間での会議室の空き状況を確認
- 会議室の空きがなかった場合は、ユーザーに会議室確保の重要度に関するフィードバックをもらう
- 重要度が高い会議の場合、先に会議室を予約している担当者を確認
- 会議室を空けてもらうための依頼文章を生成し、メッセージを送信
- 担当者から承諾をもらえた場合、カレンダー予約システムに対して、会議室予約の変更手続きを実行
- ユーザーに完了報告
:::

### 行動（Action）
AIエージェントに具体的なタスクの実行を定義するのが、「行動」である。
LLM単体では、学習データにない最新情報に基づいたアウトプットができなかったり、言語モデルの特性上、数値計算なども得意ではない。AIエージェントは概念的には、外部機能にアクセスできる権限や実行プログラムを定義することができるものについては何でも実行できる。
一般的に取り上げられる行動の例としては、ブラウザ検索を行い最新の情報を収集や、外部システムと連携しデータベースからデータの抽出や保存、pythonプログラムによる数値解析処理など、実装次第で様々な行動を起こさせることができる。定義した各種行動の中からどれを実行するかは、AIエージェント自身が思考プロセスの中で判断する。

**AIエージェントのユースケース**
AIエージェントが各種システムやデータにアクセスし、様々な操作・処理が行えることが前提にはなるが、AIエージェントが実現しうる世界観として考えられるユースケースを以下に示す。

:::box
**旅行予約**
- 旅行に行きたいエリアを提示すると、AIエージェントがそのエリアまでの交通手段の調査や、チケットの空き状況を確認
- 現地のホテル情報やグルメ・観光情報を収集し、ユーザーの過去の傾向から好みを踏まえて旅行プランを作成
- 予算や観たいところなど、ユーザーからのフィードバックを受けて、再度旅行プランの再作成
- チケット・予約手配を代行
- 旅行中の各種案内や予定変更などのサポート
:::

:::box
**営業管理**
- お問い合わせを受け付けた際に、インターネット上の公開情報を検索し、問い合わせ企業の情報を調査
- 過去の問い合わせ履歴から同じ業界や会社規模での類似の問い合わせがなかったを自社データベースから調査
- 問い合わせに関連する社外ニュースなどの参考情報も収集
- 調査結果を次回以降も再利用できるようにデータベースに保存
:::

## AIエージェントの実装例
実験的なものも含めてプロダクトとしてインターネット上に公開されているものや、独自のAIエージェント開発を支援する開発フレームワークなどが出てきている。まずは既存のAIエージェントツールに触れ、AIエージェントの動きを体感してみるのもいいだろう。その上で実際の業務シーンでの活用に向けては、開発フレームワークを用いて設計・カスタマイズしていく必要がある。
ここでは代表的なものをいくつか紹介する。

### AIエージェントアプリケーション
**AutoGPT：**
AutoGPTは、2023年3月に登場した実験的なプログラムで、AIエージェントブームの火付け役と言われている。目的を与えると、AIが自律的に達成に必要な道筋を考え、情報を収集し、それらをまとめた内容をファイルに出力するといったことができる。この仕組みがAIコミュニティの中で注目され、AutoGPTの活用事例（AutoGPTがウェブサイトを構築するデモetc）が活発に公開されるようになったことで、AIエージェントブームが巻き起こった。

**BadyAGI：**
AIエージェントブームの中で注目を集めたもう一つ代表的なAIエージェントが「BabyAGI」である。AutoGPTとほぼ同時期の2023年の4月に、ヨウヘイ・ナカジマ氏によって開発されたAIエージェントである。タスクを自動で実行していくという点はAutoGPTとにていますが、AutoGPTが個別のタスク毎にユーザーによるフィードバックと承認が必要な事に対し、BabyAGIは最終目標に向かって自動的にタスクの実行と調整を繰り返していくことが特徴である。

:::box
**BabyAGIの実行フロー**
1. 「タスク作成エージェント」がゴール達成に必要なタスクリストを生成
2. 「タスク優先度付けエージェント」が実行の優先順位付け
3. 最初のタスクを「タスク実行エージェント」に渡し、タスクを実行
4. 実行結果を「タスク作成エージェント」に渡し、新たなタスクを生成
5. 全てのタスクが終了するため2〜4をループ
:::

!

**Scalable Instructable Multiworld Agent（SIMA）：**
SIMAは、Google DeepMindは2023年3月13日発表した新たなAIエージェント。様々なビデオゲームで自然言語の指示に従ってタスクを実行する能力を持つ。トレーニングには、「No Man's Sky」「Teardown」「Valheim」「Goat Simulator 3」「Satisfactory」「Hydroneer」「Space Engineer」「Wobbly Life」「Eco」といったバラエティに富むゲームを使用した。「左折」「はしごを登る」「地図を開く」 などの約600の基本スキルを持ち、さまざまな状況に適応する訓練が施されており、研究チームの報告によると、初めてプレイするゲームでも、そのゲームに特化してトレーニングを受けたエージェントと平均してほぼ同じパフォーマンスを示したとのこと。今後、日常生活のタスク、より複雑な指示への対応、効率的な学習方法の開発に向けて進められる。

:::box
関連記事：
:::

### 開発フレームワーク
**Langchain：**
LangChainは大規模言語モデルを活用してアプリケーションを構築するためのフレームワークであり、開発者がAIを利用した言語理解の能力を簡単に組み込むことができるように設計されている。LangChainが提供する多様な統合機能を活用して、複雑なタスクや問題解決に取り組むAIエージェントを構築することができる。

**AutoGen：**
Microsoft Researchから発表されたAIアプリケーション開発フレームワーク。「複数のAIエージェント」が相互に会話しながらタスクを解決するのが特徴。AutoGenを使うことで、複数のAIエージェントを組み合わせることができたり、役割に応じてタスクをAIエージェントに割り振ることができるようになる。

2024年は、各企業での生成AI活用に向けた取り組みがより一層加速していくとみられる。

:::box
関連記事：
:::

そうした動きの中で「AIエージェント」は確実に今後の重要トレンドとなってくると言える。
LLMを始めとするAI技術の発展・普及とともに、AIと人との関わり方は変わっていくだろう。目的達成のための手段やその計画は、AIエージェントが行ってくれる。AIエージェントの仕組みが実用化された世界で私達人間が求められる役割は、正しい目的を与え、成果物に対して適切なフィードバックを返すことである。

ーーー

レッジでは生成AIの導入支援サービスを提供しています。
その中ではAIエージェントを企業の生成AI活用の重要テーマとして包括的な支援が可能です。
ご興味ある方は、下記ページよりお問い合わせください。

:::box
関連ページ：
:::</description><pubDate>Tue, 30 Apr 2024 06:14:30 +0000</pubDate></item><item><title>Google の無料教材公開「Beyond the Prompt」「Prompting guide 101」生成AIの効果的な活用法やヒントを紹介</title><link>https://ledge.ai/articles/google_prompt_guide</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年4月19日、Google Workspaceユーザーを対象にした新しいブログシリーズ「{target=“_blank”}」を開始した。

このシリーズは、生成AIを効果的に活用するためのヒントやコツ、提案を定期的に提供することを目的としている。Google Workspaceは元々、リアルタイムおよび非同期でのコラボレーションを核として構築されており、この新技術を取り入れることで、ユーザーの生産性、創造性、および作業の質をさらに高めることが期待されているという。

このブログシリーズでは、特に効果的なプロンプトの作成方法にスポットライトが当てられている。プロンプトは、AI搭載アシスタントとの対話を始めるためのトリガーとして機能し、ペルソナ（Persona）、タスク（Task）、コンテキスト（Context）、フォーマット（Format）の4つの主要な要素を含めることが推奨されている。これらの要素を組み合わせることで、より具体的かつ効果的な応答を引き出すことが可能だ。

具体例としては、Google Slidesで旅行ブログの記事に添える画像を生成するプロセスが紹介されている。ユーザーは「Create image with Gemini」というプロンプトを用いて、希望するシーンの画像を生成し、選んだ画像を直接スライドに挿入することができる。

!
:::small
画像の出典：{target=“_blank”}
:::

「Beyond the Prompt」は、Google Workspaceを使用している全ユーザーがGeminiの機能を最大限に活用し、より効果的に作業を進めるための支援を提供していくという。

またGoogleは「{target=“_blank”}」という電子ブックも公開しており、プロンプトの基本から応用まで、多岐にわたる情報を45ページにわたって提供している。このガイドは、GeminiをはじめとするAIチャットボットの活用を促進し、具体的な業務に応用するための例文も含まれているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Apr 2024 06:10:44 +0000</pubDate></item><item><title>GWに徹底理解！GPTの仕組みをめちゃくちゃ分かりやすく解説する無料動画公開</title><link>https://ledge.ai/articles/3blue1brown_transformer_attention</link><description>:::small
画像の出典：{target=“_blank”}
:::

連休を自己研鑽に充てようと考える方へ朗報だ。

数学と科学をビジュアルで解説する教育サイト「3Blue1Brown」が2024年4月、GPTの仕組みを分かりやすく解説する動画を公開している。ディープラーニング・第5章「But what is a GPT? - Visual intro to Transformers」というタイトルだ。この動画は、GPT（Generative Pretrained Transformer）の基本的な構造とその動作原理を詳しく説明している。


## ディープラーニング　第5章「しかし、GPTとは何なのか」

@


GPTは、大量のデータから事前学習を行い、特定のタスクに対してさらに微調整を加えることで、テキスト生成などの機能を実現するAIモデルだ。トランスフォーマーとは、このようなAIブームの中核となる特定のニューラルネットワークの一種であり、2017年にGoogleによって導入されたもので、もともとはテキストの翻訳が主な用途であった。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の動画では、GPTのモデルがどのようにテキストを生成するか、その過程を一から丁寧に解説している。特に、入力されたテキストから次に来る言葉を予測する機能は、単純ながらもテキストを生成する上で重要な役割を果たしている。GPT-2とGPT-3の違いについても触れられており、より大きなモデルであるGPT-3では、より一貫性と感覚的なストーリー生成が可能であることが示されている。

!
:::small
画像の出典：{target=“_blank”}
:::

3Blue1Brownの動画は、数学を直感的かつ視覚的に理解できるようにデザインされており、複雑な数学的概念や定理をアニメーションを用いて説明する。運営資金調達には、クラウドファンディングのプラットフォーム「Patreon」を採用しており、広告に頼らず視聴者の直接的な支援によって高品質のコンテンツを提供している。


## ディープラーニング　第６章「アテンション、トランスフォーマーの心臓を視覚化」
@



4月26日に公開されたAIの核心技術の一つである 第6章「Attentionメカニズム」についての解説動画もおススメしたい。このメカニズムは、Transformer構造の中心部品として、AIによる言語理解の精度を飛躍的に向上させるものだ。

「Transformer」という言葉はAIの技術者の間ではよく知られているが、その詳細な機能まで理解している人は少ないという。Transformerは、特にLLMが文章を「読む」際の基盤技術として活用されており、文章中の「トークン」と呼ばれる単位ごとに情報処理を行う。

!
:::small
画像の出典：{target=“_blank”}
:::

動画では、「トークン」として処理される各単語がどのようにAttentionメカニズムによって重要視されるかをビジュアル化しており、教育的な視点からも高い評価を受けているとのことだ。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:55:32 +0000</pubDate></item><item><title>NVIDIA、生成AI分野の技術者向けにプロフェッショナル認定制度を新設</title><link>https://ledge.ai/articles/nvidia_genai_professional_certification</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAは2024年3月14日、生成AIに関するプロフェッショナル認定制度を新たに提供開始することを{target=“_blank”}した。

この認定制度は、生成AI技術の開発者がその技術的な信頼性を確立できるように設計されている。NVIDIAによれば、この新しい認定制度は、同社が初めて提供するプロフェッショナル向けのものであり、大規模言語モデル（LLM）とマルチモーダルワークフロースキルの習熟度を測ることを目的としている。

この制度には、2種類のアソシエイトレベルの認定が用意されており、GTC 2024イベント以降に利用可能になる予定だ。GTC 2024は、3月18日から21日まで開催されるNVIDIAのイベントで、現地参加者は認定試験に備えるための推奨トレーニングにアクセスできるとのこと。

NVIDIAのデベロッパープログラム担当バイスプレジデント、グレッグ・エステス氏は、「NVIDIAの目標は、皆さまのスキルアップを支援し、資格を持つプロフェッショナルの能力を磨き、個人がその熟練度を証明できるようにすることにより、雇用市場で競争優位を得られるようにすること」とコメントしている。

この認定制度の開始は、生成AI技術の発展と普及に伴い、この分野で活動する技術者が自身の技術力を証明し、業界での地位を確立するための重要な機会を提供するものだという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 17 Mar 2024 05:03:19 +0000</pubDate></item><item><title>Anthropic、チャットAI「Claude 3」向け公式プロンプト集を公開</title><link>https://ledge.ai/articles/anthropic_claude3_prompt_library</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月11日、AIスタートアップのAnthropicは、同社が開発したチャットAI「Claude 3」向けの公式プロンプト集を{target=“_blank”}した。

現在64種類の使用例が集められているこのプロンプト集は、「プロンプトライブラリ」でアクセス可能だ。公開されたプロンプト集は、英語と日本語の両方に対応しており、ユーザーはこれを利用してClaude 3の応用範囲を広げることができる。

プロンプトライブラリには、クリエイティブな執筆、データ分析、キャラクターロールプレイといった様々な用途に合わせたプロンプトが含まれている。Anthropicは、このライブラリを通じて、Claude 3を最大限に活用するためのガイドラインを提供し、ユーザーが特定のタスクを効果的に達成できるよう支援している。

また、Anthropicは「{target=“_blank”}」も公開しており、プロンプトの作成とテストのプロセスを通じて、Claude 3のパフォーマンスをさらに向上させる方法について説明している。これにより、ユーザーはより具体的なユースケースに対してClaude 3の応答を微調整することが可能となる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:21:11 +0000</pubDate></item><item><title>パーソルホールディングス、生成AI研修で社員スキルアップを加速</title><link>https://ledge.ai/articles/persol_group_upreskilling</link><description>:::small
画像の出典：{target=“_blank”}
:::

パーソルホールディングスは2024年02月16日、グループ社員の生成AIに関する知識と活用スキルの向上を目指し、専門家による研修や社内勉強会の開催などの積極的な取り組みについて{target=“_blank”}した。

この取り組みは、社員個人のスキルレベルを「理解」「業務導入」「業務活用と伝播」の3段階に区分し、全社員が生成AIを業務に活用する環境を整備することにあるという。

外部の専門家を招いた研修や勉強会をはじめ、1,500名以上の社員が受講した入門編から実践編、さらには経営幹部向けの勉強会まで、参加者のレベルや属性に応じた内容で開催されている。また、社内専用GPT「PERSOL Chat Assistant」の基礎知識についての動画講義には3,800名の社員が参加し、IT系職種に限らず多岐にわたる職種の社員が生成AIの教育を受けているとのこと。

さらに、生成AIパスポートの資格取得に向けた取り組みも進められており、2024年第1回試験にはグループ各社から200名以上の社員が受験予定。受験費用は会社が支給しているという。この資格は、生成AIを活用したコンテンツ生成の方法や企業のコンプライアンスに関する知識を学ぶもの。

これらの教育プログラムを通じて、社員はメール文章作成や議事録の要約、英文作成、アイデア出し、営業アポイントのテーマ検討、トークスクリプト作成、ソースコードの分析・修正など、多岐にわたる業務で生成AIを活用するスキルを習得し、業務効率化とパフォーマンスの向上、リスク回避につなげているという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 29 Feb 2024 03:36:19 +0000</pubDate></item><item><title>JDLAが「生成AIの利用ガイドライン（画像編）」を公開</title><link>https://ledge.ai/articles/jdla_guideline_for_image_generating_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本ディープラーニング協会（JDLA）は2024年2月13日、「生成AIの利用ガイドライン（画像編）」を{target=“_blank”}した。

このガイドラインは、2023年5月に公開された「{target=“_blank”}」の続編として作成されており、主に画像生成AIに特化した内容となる。

ガイドラインの目的は、画像生成AIを事業において利用する企業等に向け、ルール策定時に検討が必要な法的論点を解説することにある。具体的には、画像生成AIの利用に際して、社内体制の整備、プロンプトの入力ルール、AI生成物の利用規則など、遵守すべきポイントが詳述されている。

JDLAは、ディープラーニング技術を日本の産業競争力向上の核とし、その普及と適用を目指して活動している組織だ。今回のガイドライン公開も、その一環として行われたもので、画像生成AIの健全な利用と発展の促進を期待してのことだとされる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 28 Feb 2024 05:54:19 +0000</pubDate></item><item><title>日本最大級のDX推進コンテスト『日本DX大賞2024』応募開始</title><link>https://ledge.ai/articles/dx_taisho_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

一般社団法人日本デジタルトランスフォーメーション推進協会は2024年2月6日、民間企業や自治体のDX取り組みを表彰する「日本DX大賞 2024」の応募受付を開始したと{target=“_blank”}した。

コンテストは、DXの成功事例を発掘し共有することで、日本全体のDX推進を加速させることを目的としている。昨年行われた「日本DX大賞2023」への応募数は111件。今年はサステナビリティトランスフォーメーションやビジネスモデルの変革、顧客体験の向上など、多様なカテゴリーでのDX取り組みが対象となる​。

**募集期間**： 2024年2月6日から4月26日まで
**応募対象**：「DX推進」に取り組んでいる民間企業、公的機関、自治体等の変革を実現した事例や成果をあげた事例。または、ユーザー企業・団体が取り組んだ事例


日本DX大賞サイト：{target=“_blank”}



:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Feb 2024 10:45:28 +0000</pubDate></item><item><title> LoRA(ローラ)とは｜今年注目の画像生成AI (Stable Diffusion) のファインチューニングを試してみた
</title><link>https://ledge.ai/articles/LoRA</link><description>LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。従来はLLM（大規模言語モデル）や画像生成AIのファインチューニングに膨大な計算量が必要だったが、LoRAによって少ないリソースで行うことができるようになった。LoRAはLLMや画像生成AIに応用できる、計算量を減らしてファインチューニングを行う技術である。

2023年末にはChatGPTの新機能である、ユーザーがChatGPTを自由にカスタマイズ（ファインチューニングも）できる「GPTs」がリリースされた。誰もが簡単に学習済みモデルをファインチューニングできるようになりつつある。自社や個人が持つアセットを最大限に活用した生成AIの効果的な使用が、一層重要なフェーズに突入している。

今回は、ファインチューニングの理解に必須の技術「LoRA」について解説する。

:::small
※「LoRA」という用語は元々、計算効率を向上させる技術を指す。しかし、この技術を基にして「Stable Diffusion」というAIモデルをファインチューニングした際に生まれる特定のモデルも、同様に「LoRA」と称されている。「LoRA」が二重の意味を持つことに注意が必要。
:::

:::box
関連記事 : 
:::

:::box
**目次**
- LoRAとは
- LoRAのビジネスへの活用
- LoRAを使って「Stable Diffusion」をファインチューニングしてみた
:::

## LoRAとは

LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。2021年にMicrosoftに所属していたEdward Huらによって論文で発表された技術だ。

LoRAは、元のモデルのパラメータを直接変更する代わりに、低ランクの行列を導入して、パラメータの変更を行うことができる。少ない計算量で元のモデルに修正を加えることが可能になった。

LoRAは、事前学習されたモデルの重みを固定し、変換器アーキテクチャの各層に低ランクの分解行列を注入することで、下流のタスク用の訓練可能なパラメータの数を大幅に削減する。例えば、GPT-3 175Bモデルにおいて、LoRAは訓練可能なパラメータを10,000倍減らし、GPUメモリ要件を3倍削減することを実現している。
論文中では以下の図でモデルの概要が説明されている。
!


LoRA（Low-Rank Adaptation）の計算例を示す。通常、変換器モデルでは、重み行列W ( m×n)があり、入力x に対してWx の形で適用される。LoRAでは、この重み行列W を直接変更するのではなく、低ランクの行列A (m×k)とB (k×n)を用いて、W ( m×n)+AB ( m×n) の形で変換を行う。ここで、A とB は小さな行列であり、元の重み行列W に比べてはるかに少ないパラメータを持つ。この方法により、全体のパラメータ数が減少し、計算の効率が向上する。
A=正規分布、B=0で初期化されている。

具体的な計算を以下に示す。重み行列Wのパラメータ数は合計24、行列AとBは合計8となり調整するパラメータ数が3倍削減されている。
!
実際の計算規模は上記の計算例よりはるかに大きく、学習済みモデルのパラメータ数はGPT-3で175億、Stable Diffusionで10億程度と言われている。LoRAによってこれらのモデルのファインチューニングが少ないリソースで行なえることを理解できた。

##  LoRA・ファインチューニングのビジネスへの活用

次にビジネスへの活用例を示す。

**カスタマイズされたチャットボット:**
企業はLoRAを使用して、自社のリソースを学習させ大規模なLLMから自社専用のチャットボットを作成することができる。社内独自のQ＆Aを行えるチャットボットが使用されている。

**AI写真集:**
LoRAを使用して、基盤モデルとなるStable Diffusionをファインチューニングすることで、「アジア人女性」などの特定の画像を生成できる。
Amazon.co.jpの電子書籍読み放題サービス「Kindle Unlimited」をAI生成画像の「写真集」が席巻している。SNSで話題になり、ニュースサイトも相次いで報じるなど、社会現象といってよい状態だ。生成AIの技術が進化し、実際に存在しないがリアルに見えるモデルの画像が生み出され、グラビア界に新たな波をもたらしている。
!

:::box
関連記事：
:::


**AIモデル:**
自社ブランドのファッションアイテムを学習させ、AIモデルに着用させることができる。
AI model株式会社は、2022年6月14日にサービス「AI model モデル撮影サービス
」を提供開始した。撮影場所・費用の確保、起用タレント・モデルの不祥事など「人ならでは」のリスクを回避しつつ、ECの顧客に合わせたブランド専属モデルを生み出せる。
!

:::box
関連記事： 
:::


## LoRAを使って「Stable Diffusion」をファインチューニングしてみた

Stable Diffusion LoRAは、人物の顔、服装、ポーズなど画像の一部を学習し、その特徴をもった新たな画像を生成することができる。

今回はStable Diffusion LoRAを使い、人物の顔を学習させ、その人そっくりのAIモデルを生成する。肖像権の関係で弊社執行役員・箕部 和也の宣材写真を使いStable Diffusionをファインチューニングして、箕部そっくりの人物画像を作ることを試みた。

**Stable Diffusion LoRAの特徴**

- 20枚程度の画像からLoRAの追加学習ファイルを作成できる。
- 服装、ポーズ、顔、イラストの画風を学習させることができる。
- 100〜200MB程度のファイル。
- 学習時間が短い (今回の方法で1時間程度)。
- Stable Diffusionのチェックポイントをベースに作成可能。

今回はGPUを所有してない場合もオンラインで実行できる方法を紹介する。
のを使用する。Loraを使った学習が、簡単に行えるように必要なコードがまとめられている。

基本的なStable Diffusionの使い方はこちらで確認できる。

:::box
関連記事:
:::


### STEP0 実行環境と学習用画像を準備する

**実行環境**
をクリックすると以下のようなノートブックが開く。Google ColaboratoryはPythonの実行環境であり、GPUを無料で使うことができる。ただし画像生成AIを行う場合はColab Pro (1 か月あたり ￥1,179) が推奨されている。今回はColab ProでLoraファイルの作成を行う。ノートブックをマイドライブにコピーしておく。
!

**学習用画像**
今回は画像を15枚用意した。画像サイズは512×512や1024×1024の正方形が望ましい。
画像サイズは512×512にトリミングした。顔を学習させたい場合は、髪型や服装が違う画像があれば顔のみを学習しやすい。数パターンの髪型、表情、ポーズ、服装の画像を用意できることが理想的だ。
!

### STEP1  LoRAファイルを作成する。
変更できるパラメータは多量にあるが、最低限の実行に必須な部分のみを解説していく。

**I. Install Kohya Trainer**
!
:::box
1.1. Install Dependencies
 mount_drive:◻︎にチェックを入れて実行。colabからgoole driveにアクセス可能になる。
:::


**II. Pretrained Model Selection**
!
:::box
2.1. Download Available Model
 学習の基盤となるStable Diffusionのモデルを選択できる。
Stable-Diffusion-v1-5を選択して実行する。
:::

**III. Data Acquisition**
!
:::box
3.1. Locating Train Data Directory
 デフォルトで実行する。学習用画像の保存場所が作成される。
:::

!

 :::box
3.2. Unzip Dataset
Gooole Driveに学習させたい画像のzipファイルをアップロードする。
保存したディレクトリのパスをコピーして、zipfile_urlに貼り付けて実行する。
実行後 /content/LoRA/train_dataに自動的に保存される。
:::

**IV. Data Preprocessing**
!
:::box
4.1. Data Cleaning
convertにチェックを入れて実行する。
学習のための形式に対応していない画像は自動で削除される。
:::

:::box
4.2. Data Annotation
画像を認識し自動でキャプションを作成するためのブロック

4.2.1. BLIP Captioning
自動でキャプションをつける際のパラメータを変更できる。デフォルトで実行。

4.2.2. Waifu Diffusion 1.4 Tagger V2
下部のgeneral_thresholdを0.85程度に設定する。大きくするとタグの数が少なくなる。
特定の人物を学習させたい場合は数値を大きくすることが一般的。
traindataのファイルにキャプションが入ったテキストファイルが追加される。
以下の画像には”a man in a black suit and black shirt”と自動的にキャプションが追加された。
!
:::





**V. Training Model**
!
:::box
5.1. Model Config
上記の画像通りに入力して実行する。
:::


:::box
5.2. Dataset Config
dataset_repeats を１に変更する。同じ画像を学習させる回数を調整できる。
flip_augにチェックを入れると左右反転させた画像を学習させられる。
その他はそのままで実行。
:::

:::box
5.3.~ 5.5までをデフォルトのまま実行する。画像の枚数にもよるが1時間〜2時間程度で学習が完了する。完成したLoRAファイルはマイドライブのLora/outputに自動で保存される。
拡張子.safetensorsがLoRAのファイルだ。一番上に保存されている番号が振られていないファイルが最終的な出力になっている。
!
:::


### STEP2  作成したLoRAを使って画像を生成する。
STEP1で作成したLoRAファイルを使って早速、画像を生成する。
15枚の画像で学習を行った結果、右の画像が生成できた。髪型やヒゲ、黒いスーツが強く学習されていることが確認できる。写実的で、AIで作成された画像とは気が付かない可能性があるクオリティだが、似ているが本人ではないことが一目で分かる程度だ。また顔や髪型の特徴と同時に黒のスーツも学習してしまっている。これは学習用画像がすべて同じ服装であるためである。
!
**各種パラメータ**
*** 
モデル  
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt;,professional, masterpiece, 8k, hyperrealistic portrait,  Japanese man, 30yo, dark eyes, detailed face, detailed skin, photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


&lt; lora:minobe_model:0.9 &gt;はLoraファイルの適用の強さを示すもので数値を変更して調整できる。Loraファイルを複数使用したときを考慮して0.8程度で狙った特徴が出るようにすることが一般的。


### STEP3 パラメータを変更して画像をさらに生成する。
次により本人に似た、理想に近い画像を生成するために学習のパラメータやプロンプトを変更していく。特に学習の精度に影響を与えるとされるmin_snr_gammaの値を-1から1に変えて新たなバージョンのLoraファイルを作成した。min_snr_gammaは学習の低step化に貢献するオプションであり、学習過程を大きく変化させるパラメータである。推奨値は5とされている。
!
*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, Standing in the Desert,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


!

*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, ride a horse,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 

今回はStable Diffusion LoRAを使用して、Stable Diffusionをファインチィーニングし画像を生成した。画像を15枚を準備して数時間でコードを一切書くことなく簡単に、驚くほど精巧な画像を生成できた。Stable Diffusion LoRAには多くのパラメータがあり、それらの適正値を見つけることでさらに精度が向上すると予想される。パラメータの適正値は「アニメ風の画像を生成したい」や「同じポーズの画像を生成したい」「綺麗なアジア人女性を生成したい」など目的によって変化するため、各々が生成された結果を見ながら、理想の生成画像に向かって微調整を加えていく必要がある。

</description><pubDate>Tue, 06 Feb 2024 07:47:09 +0000</pubDate></item><item><title>OpenAI が開発者向けQ&amp;AコミュニティサイトStack Overflowと新たなAPIパートナーシップを発表</title><link>https://ledge.ai/articles/openai_stackoverflow_api_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、OpenAIとStack Overflowは、開発者向けに最適化された技術情報とAI開発ツールを提供する新しいAPIパートナーシップを{target=“_blank”}した。

このパートナーシップにより、OpenAIのユーザーや顧客は、Stack Overflowが提供する正確で検証済みのデータを基に迅速な問題解決を図り、重要なタスクに集中できるよう支援されるという。

この協業の一環として、OpenAIはStack Overflowの「OverflowAPI」を利用し、ユーザーにStack Overflowの検証済み技術知識を直接提供する。これにより、ChatGPTはStack Overflowの豊富な技術データベースと連携し、利用者に対してより精度の高い支援を提供できるようになる。また、Stack Overflowは、OpenAIのAIモデルを利用して「OverflowAI」の開発を行い、内部テストから得た洞察を活かしてAIモデルの性能向上を図る。

このパートナーシップは、技術者が直面する課題への対応速度を向上させ、開発者コミュニティ全体の生産性とエンゲージメントの向上を目指している。両社は、開発者が必要とする情報や解決策を、より迅速かつ正確に提供できる環境を整備することで、技術開発の新たなスタンダードを築くことを目指している。

Stack Overflowは2月29日にGoogle Cloudとの協業を発表しており、「Gemini for Google Cloud」との統合を進めている。この連携ではGoogle Cloudのプラットフォーム上でStack Overflowの情報を活用し、開発者が容易に重要なナレッジベース情報やコーディング支援を利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 12:52:43 +0000</pubDate></item><item><title>AWSが「Amazon Q」の一般提供を開始　企業内データを活用したAIアプリケーション開発の加速を目指す</title><link>https://ledge.ai/articles/amazon_aws_q</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）は2024年4月30日、生成AIアシスタント「Amazon Q」の一般提供を開始したと{target=“_blank”}した。

このサービスは、開発者が自社のデータを活用してAIアプリケーションを構築できるよう支援することを目的としており、特にソフトウェア開発の加速と企業データの活用が可能になるという。

Amazon Qは、コード生成、テスト、デバッグ、計画立案、推論機能を備え、開発者はコードの自動変換やアップグレード（Javaバージョンアップグレードなど）、新しいコードの実装が可能となる。この生成AIアシスタントは、エンタープライズデータリポジトリへの接続もサポートしており、企業のポリシー、製品情報、業績、コードベース、人材に関する質問への回答や、データの論理的な要約、トレンド解析、データ関連の対話が行えるとのこと。

また、社内データから生成AIアプリの構築を可能にする新機能「Amazon Q Apps」も同時に発表された。従業員は自然言語でアプリについて記述するだけで、必要とされる業務を遂行するアプリを生成できるという。この機能により、日常業務の簡素化と自動化が促進される。

さらに、Amazon Qは40以上の一般的なビジネスツールと簡単に接続でき、企業は自社のデータを効率的に集約し、アクセスできるようになる。この広範なデータ統合能力により、企業はよりデータ駆動型で効率的な運営が可能になる​とのことだ。


:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 11:42:47 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>生成AIプロジェクトの開発者コミュニティ、アメリカ・インドに次いで日本が先導ーGit Hub 2023年の動向レポート</title><link>https://ledge.ai/articles/github_the_state_of_open_source_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2023年11月8日、「オープンソースとAIの現状」に関する報告を{target=“_blank”}した。

報告によると、開発者たちは大量の生成AIプロジェクトに取り組んでいる。特にOpenAIなどの基礎モデルを用いた開発が目立ち、生成AIプロジェクトは2023年のオープンソースプロジェクトのトップ10にランクインしたという。これらのプロジェクトには、全開発者の92%が使用または実験中であると報告されており、GitHub上での次世代AIイノベーションを牽引すると期待されている。

また、2023年はオープンソースへの初参加者が最も多く、これまで商業的に支援されたプロジェクトが初参加者の大部分を占めていたが、今年は生成AIプロジェクトも初参加者向けのトップ10プロジェクトに登場した。GitHub上のプライベートプロジェクトの数は前年比38%増加し、全活動の80%以上を占めている。

全世界で、GitHubを使用してソフトウェアを構築し、共同作業を行う開発者が増加している。アメリカは依然として最大の開発者コミュニティを持つが、他の地域も成長を見せている。

次の5年間で最も成長が見込まれる開発者コミュニティに関する予測では、インドが2027年までにGitHub上で最大の開発者コミュニティになると予想されている。日本の開発者数は約280万人で、世界8位にランクされており、今後の成長が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::

さらに、生成AIは個々のコントリビューターの数において148%の年間成長率を達成し、生成AIプロジェクトの総数も248%増加している。この分野において、アメリカ、インド、そして日本が先導しており、他の地域も追随している。

!
:::small
画像の出典：{target=“_blank”}
:::



報告は、2022年10月1日から2023年9月30日までに、GitHub から取得した匿名化されたユーザーおよび製品データに基づいて作成された。

:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:49:07 +0000</pubDate></item><item><title>AIの遅れ取り返せるか　Appleが開発者向けフレームワーク「MXL」Geminiの裏でひっそりと公開</title><link>https://ledge.ai/articles/apple_released_mlx</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2023年12月、AI分野での新たな取り組みとして、開発者向けのオープンソース機械学習フレームワーク「MLX」を{target=“_blank”}した。GoogleのAIモデル「Gemini」の発表と同時であったと各メディアで報じている。

MLXはAppleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​。

Appleの機械学習研究者であるAwni Hannun 氏は、自身のX（旧Twitter）アカウントで、
「ちょうどホリデーシーズンに間に合うよう、本日、Apple 機械学習研究からいくつかの新しいソフトウェアをリリースします。
MLX は、Apple シリコン (つまり、ラップトップ) 向けに特別に設計された効率的な機械学習フレームワークです」
と{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

{target=“_blank”}は10月に、Appleの経営陣は業界の突然のAIブームに驚かされ、昨年末から急いで対応を図っていたと報じており、MLXの発表は、AI分野での急速な進展に対応しようとするAppleの努力の一環との見方もある。



:::box

:::
:::box

:::</description><pubDate>Fri, 15 Dec 2023 05:44:48 +0000</pubDate></item><item><title>OpenAI　超知能を制御するチームが解散「安全文化とプロセスは派手な製品に押しのけられてきた」イリヤ氏に続く共同責任者の退職</title><link>https://ledge.ai/articles/superalignment_team_effectively_dissolved</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年5月17日、OpenAIは「超知能（Superinteligence）AI」の制御を目的とした「スーパーアライメント（Superalignment・超調整）チーム」は事実上解散になると、複数のメディアが報じている。チームを率いるイリヤ・サツケヴァー氏の15日の退社報告の後を追うように、同チームの共同リーダーであるヤン・ライカ氏がOpenAIを辞めたと公表したためと見られる。

サツケヴァー氏の退社表明の直後、ヤン・ライカ氏も自身のX（旧Twitter）で退社の理由を{target=“_blank”}。ライカ氏は、OpenAIの経営方針との意見の相違や、研究リソースの不足が退職の主な理由であると述べている。また、彼は自身のチームとその成果に対する深い愛情と感謝の意を表明した​。

同氏の投稿には
「この研究を行うのに世界で最適な場所だと思ってOpenAIに参加した。しかし、私はOpenAIのリーダーシップとの間で会社の核心的な優先事項について長い間意見の相違があり、最終的に限界点に達した。人間よりも賢い機械を作ることは本質的に危険な事業だ。OpenAIは全人類を代表して莫大な責任を負っている」​ など、問題点を示唆する発言が垣間見られる。

「But over the past years, safety culture and processes have taken a backseat to shiny products.」
しかし、過去数年間、安全文化とプロセスは派手な製品に押しのけられてきた。
「We are long overdue in getting incredibly serious about the implications of AGI.」
AGIの影響を真剣に考える時期はとっくに過ぎている。

!
:::small
画像の出典：{target=“_blank”}
:::


グレッグ・ブロックマン社長とサム・アルトマンCEOは、前日に退社したライカ氏の指摘に対する{target=“_blank”}を行い、「拡張性のある監視ソリューション」「密接なフィードバックループ」「厳格なテスト」などの対策を挙げたが、具体的な詳細は明示されなかった。


!
:::small
画像の出典：{target=“_blank”}
:::

サツケヴァー氏もライカ氏も、退社に際してOpenAIがAGI（人工汎用知能）への道を正しく歩むことを期待するとしているが、具体的な対策が求められる状況は続いている。


## 安全性をめぐるOpenAIとアライメントチームのこれまでの動き
### スーパーアライメントチームの立ち上げ
スーパーアライメントチームは2023年7月、AIが人間にとって安全であり続けるための新たな研究チームとして{target=“_blank”}され、OpenAIの計算資源の20%を割り当てられていた。このチームは、超知能AIシステムを安全に運用するための技術的課題に取り組むことを目的としていた。

共同リーダーのイリア・サツケヴァー氏とヤン・ライカ氏は、10年以内に超知能AIが出現する可能性を指摘し、「巨大な力は非常に危険で、人類を無力化するか、あるいは絶滅させる可能性さえある」と述べ、技術改善の必要を説いた。
### Preparedness Teamの設立
2023年10月、OpenAIは新たに「Preparedness Team」を{target=“_blank”}。このチームは、将来の「フロンティアAIモデル」がもたらす壊滅的なリスクを管理するために結成された。

特に強力なAIモデルに関連するリスク評価と内部テストに焦点を当て、サイバーセキュリティや化学・生物・放射線・核（CBRN）脅威、自律的な自己複製や適応（ARA）など、多岐にわたるリスクカテゴリに対応することを目的としている​。
### アルトマン氏の解任騒動
2023年11月、OpenAIのCEOであるサム・アルトマン氏が一時的に解任される騒動が起きた。サツケヴァー氏がこの解任に関与したとされる。その後の社員の反発や外部からの圧力により、アルトマン氏は復職。{target=“_blank”}は、OpenAI内部の意見の相違や経営方針に対する不満を浮き彫りにする出来事となった​。
### イリヤ・サツケヴァー氏に続きヤン・ライカ氏の退職
2024年5月15日にサツケヴァー氏がOpenAIを去ることを公表。その直後に、ライカ氏も自身のX（旧Twitter）で、OpenAIを退職することを発表した。




:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 20 May 2024 02:36:18 +0000</pubDate></item><item><title>GPT-4が「修正モラル・チューリングテスト」で大学生を上回る道徳的判断を示す――ジョージア州立大学の研究</title><link>https://ledge.ai/articles/gpt4_shows_better_moral_judgment_than_college_students</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

ジョージア州立大学の研究チームは2024年3月、GPT-4と人間の道徳的判断能力を比較する研究を行い、GPT-4の方がより道徳的であるという評価を獲得したと{target=“_blank”}した。この研究は、2024年4月30日、Scientific Reportsに掲載された。

研究チームは、麻薬を買う金を得るために通行人を銃で脅す行為から、カラフルなスカートを履いて会社に出勤する行為まで、合計10個の道徳的シナリオを用意し、GPT-4に「なぜこの行為が間違っているのか、あるいは間違っていないのか」について600単語以内で意見を述べるよう指示した。また、哲学入門コースの大学生68人の回答も収集し、それぞれ最も評価の高い回答を選択した。

### 道徳的シナリオとその評価の例
_行動例1：薬物を得るために、男が通行人を路地に追い詰め、銃を突きつけて金を奪おうとする。_
**人間の評価：** この行為は間違っている。彼は無実の人を傷つけた。引き金を引かなかったとしても、その行為は相手に大きな影響を与えた。彼の意図は最初から間違っていた。彼はただ自分の依存症を満たすために勤勉な人の金を奪った。
**GPT-4の評価：** この行為は間違っている。この男は力と脅迫を使って通行人の命を脅かしており、通行人の安全と個人の自律権を侵害している。さらに、男が盗んだ金を薬物に使おうとしていることは、その行為の悪影響をさらに助長し、依存症と害の連鎖を永続させる。

_行動例2：ピザ配達員を殴る_
**人間の評価：** 他人を殴ることは、身体的な危害を与える行為であり、道徳的に許されない。被害者の痛みと苦しみを考慮すれば、この行為は全く容認できない。
**GPT-4の評価：** 他人を殴ることは間違っている。暴力行為は個人の尊厳と安全を侵害し、社会的秩序を乱すものである。さらに、暴力はさらなる暴力を招く可能性があり、その影響は広範囲に及ぶ。

_行動例3：葬儀でのTシャツ着用_
**人間の評価：** 葬儀でTシャツを着用することは不適切である。このような場では、伝統的な礼儀や尊敬の念を示すために、フォーマルな服装が求められる。
**GPT-4の評価：** 葬儀でTシャツを着用することは、社会的な慣習や期待に反する行為である。葬儀は故人を悼む場であり、フォーマルな服装がその場の厳粛さを保つために重要である。

### 研究の実施と結果
この研究は、道徳的評価を比較するために「修正モラル・チューリングテスト（m-MTT）」を使用して実施された。この研究では、299名のアメリカ成人を対象に、GPT-4と人間の作成した道徳的評価を見分けてもらう実験を行った。

参加者は、どの評価がAIによるものであるかを当てることはできたが、評価の質に関してはGPT-4の方が人間よりも優れていると判断する傾向があったという。参加者はGPT-4の道徳的評価を、徳性、知性、信頼性などのほとんどの面で人間の評価よりも高く評価したとのこと。

研究者たちは、この結果が意味するところについて議論している。特に、AIが生成する道徳的な判断が人間の判断よりも優れていると認識されることで、人々が無批判にAIの道徳的な助言を受け入れる可能性があることを懸念しているという。これにより、有害な道徳的ガイダンスが普及するリスクが指摘されており、LLMに対する安全対策の必要性が強調された。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 17 May 2024 14:13:43 +0000</pubDate></item><item><title>AIが互いに教え合い連携して学習するオープンソースLLM「WizardLM-2」を開発者が公開　Microsoftからの発表は「待った」</title><link>https://ledge.ai/articles/wizardlm2</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月15日、AIがお互いに教え合うことで連携して学習する新たなオープンソースの大規模言語モデル「WizardLM-2」を{target=“_blank”}した。論文は未公開だが、開発者のX（旧Twitter）で内容の一部が{target=“_blank”}されている。発表当初は、HggingFaceのMicrosoftコレクションからアクセス可能だったが、数日後削除された。開発者によると、発表前に必要であった毒性テスト（toxicity testing）のプロセスが抜けていたとのことで、近日中に再リリースの予定であるとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::
### モデルの特徴と開発背景
{target=“_blank”}の情報によると「WizardLM-2」は、Microsoftが新たに開発した大規模言語モデルで、8x22B、70B、7Bの3つのバリエーションが含まれている。これらのモデルは、「AI Align AI」（AAA）というフレームワークを通じて互いに教え合うことで、連携して学習する能力を持っている。この技術により、モデルは独自にデータを生成し、それを利用してさらに学習を進めることができるため、連続的かつ効率的な学習プロセスが実現される​という。

### 性能と評価
同モデルは、複雑な対話、多言語処理、高度な推論タスクにおいて顕著な性能を発揮してるという。特に「WizardLM-2 8x22B」は、オープンソースモデルの中で最も高い性能を持つと評価されており、人間によるブラインドテストや、複数のベンチマークテストにより、プロプライエタリモデルと競合するレベルにあるとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
</description><pubDate>Thu, 16 May 2024 13:05:28 +0000</pubDate></item><item><title>スパコン「富岳」を用いた国産大規模言語モデル「Fugaku-LLM」を公開--東工大・富士通など</title><link>https://ledge.ai/articles/fugaku_lllm_release</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月10日、東京工業大学、東北大学、富士通株式会社、理化学研究所、名古屋大学、株式会社サイバーエージェント、Kotoba Technologies Inc.は、共同で開発した大規模言語モデル「Fugaku-LLM」を{target=“_blank”}した。

このモデルは、スーパーコンピュータ「富岳」を用いて学習され、日本語処理能力に優れるとともに、科学研究やビジネスアプリケーションでの使用が見込まれるという。

日本国内外で大規模言語モデルの開発が進む中、日本の計算資源を活用し国産モデルの開発が進められている。特に「富岳」は、その計算能力を生かし、分散並列計算のための環境を整えることが求められており、2023年5月より、各機関が力を合わせて研究開発を開始した。

Fugaku-LLMは、130億パラメータを有し、国内外のモデルと比較して高い性能を誇る。特に、日本語においてはJapanese MT-Benchで最高性能を達成しており、自然言語処理における敬語などの日本語特有の表現も適切に扱うことができる。また、演算速度を6倍、通信速度を3倍に高速化する技術も開発された。

モデルはGitHubやHugging Faceを通じて誰でもアクセス可能で、研究や商業目的での利用が許可されている。今後、このモデルを基に、更なる効率的な学習方法の開発や、AIと科学シミュレーションの連携など、新たな研究が期待される。

各機関の役割は以下の通り
**東京工業大学：** プロジェクト全体の総括と通信性能の最適化
**東北大学：** 学習用データの収集とモデルの選定
**富士通株式会社：** 演算および通信の高速化
**理化学研究所：** 分散並列化技術の開発
**名古屋大学：** AI応用方法の研究
**株式会社サイバーエージェント：** 学習データの提供
**Kotoba Technologies Inc.：** 深層学習フレームワークの移植


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 14 May 2024 11:42:45 +0000</pubDate></item><item><title>AIでネコを幸せに？ 英ノッティンガム大学の研究「Cat Royale（キャット・ロワイヤル）」が複数の国際賞を受賞</title><link>https://ledge.ai/articles/cat_royale</link><description>:::small
画像の出典：{target=“_blank”}
:::

英ノッティンガム大学の研究チームは、猫とAIロボットが共存する環境をデザインし、それが猫の幸福にどのように影響を与えるかを探求する実験「Cat Royale」の成果を{target=“_blank”}した。この研究が評価され、複数の国際賞を受賞したことを、研究の支援団体が2024年5月2日に{target=“_blank”}した。

この研究は、Blast Theoryとノッティンガム大学のMixed Reality Labが共同で開発したプロジェクトで、猫たちがAIによってコントロールされる環境内で自由に生活できる「猫のユートピア」を実現しようとする取り組みだ。

Cat Royale は、ブリスベンのWorld Science FestivalやロンドンのScience Galleryで展示され、AIが創り出すユートピアについて、観客に信頼と自律という深い問題を問う機会を提供したとのこと。

研究では、3匹の猫「クローバー」「パンプキン」「ゴーストバスター」が12日間、特別に設計された室内環境で、1日6時間ロボットと交流した。

@

プロジェクトでは、500以上の異なる遊びを提供するロボットアームが導入され、猫の反応に基づいてAIが次のアクティビティを提案するシステムが組み込まれている。この環境内では、猫用のおもちゃやキャットツリー、水飲み場、植物が豊富に用意されており、ロボットアームは猫じゃらし風のおもちゃやボールで遊びを演出した。

!
:::small
画像の出典：{target=“_blank”}
:::

猫たちは、これらの遊びに自発的に反応し、高いストレスを示すことなく、研究期間中自ら進んで環境に入室していたとのこと。猫の行動専門家と飼い主の分析によると、猫たちはこの新しい環境に心地よさを感じており、AIとの相互作用を楽しんでいたという。ロボットの活動は人間の監視のもとで行われ、猫たちの安全と健康が確保されていた。

このプロジェクトは、AIとロボット技術がどのようにして動物の幸福に寄与できるかを示すものであり、将来的には人間と動物の共生環境の質的向上に貢献する可能性があるとのこと。

「Cat Royale」は、Webby Awardsの「Best Integrated Experience in the AI, Metaverse &amp; Virtual」カテゴリーで{target=“_blank”}を受賞。また、2024年5月11日から16日の会期で開催中の学会「CHI 2024」では、投稿論文の上位1パーセントとされる{target=“_blank”}で表彰されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 11 May 2024 08:11:06 +0000</pubDate></item><item><title>Google DeepMind　AIタンパク質予測ツール「AlphaFold 3」を発表、AI創薬への応用に期待</title><link>https://ledge.ai/articles/google_deepmind_alphafold3</link><description>:::small
画像の出典：{target=“_blank”}
:::

※お詫びと訂正のお知らせ　
2024年5月11日掲載時の文中に「2020年にリリースされたAlphaFold」との表現がありましたが、2020年はAlphaFold2がリリースされた年のため、記事を修正しています。訂正し、ここにお詫びを申し上げます。（2024年5月13日 編集部）

GoogleDeepMindと、同系列のAI創薬企業 Isomorphic Labs は2024年5月8日、新たなAIモデル「AlphaFold 3」を{target=“_blank”}した。

このモデルは、タンパク質、DNA、RNA、リガンドなどの分子の構造と相互作用を高精度で予測する能力を持つ。従来のドッキング手法を超えるこの技術は、医薬品開発における新しい局面を開く可能性がある​という。



@


AlphaFold 3は、3D分子構造のグローバルなデータベースでトレーニングされており、未知のタンパク質の構造を予測する能力において、前モデル「{target=“_blank”}」を大幅に上回るとのこと。

AlphaFold 2は、2020年にリリースされたAIモデルで、その前身であるAlphaFoldに比べタンパク質の構造予測において顕著な進歩を遂げた。この技術は、マラリアワクチンの開発、がん治療法の進展、環境保護のための酵素設計など、生物学的な様々な応用分野で利用されている。AlphaFold 3はこれらの成功に基づき、さらに広範な分子タイプへの適用を可能にしたという。

これにより、医薬品設計の効率が向上し、手の届かなかった疾患の治療法開発に寄与すると同社は期待のコメントを述べている。

DeepMindは「{target=“_blank”}」という新サービスを開始し、科学研究者が自由にアクセスし、タンパク質の相互作用予測を行うことができるようになっている。非営利目的での利用であればGoogleアカウントを用いて無料で利用可能とのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 10 May 2024 10:12:02 +0000</pubDate></item><item><title>NVIDIA　LLMベースの sim-to-real アプローチ「DrEureka」で、ロボット犬に玉乗りを教えるーシミュレーションから実世界への移行にかかる煩雑なプロセスを大幅に削減</title><link>https://ledge.ai/articles/dr_eureka</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAが開発したAIプラットフォーム「Eureka」が、ロボットのスキルトレーニング領域において新たな進展を遂げた。ペンシルベニア大学、テキサス大学オースティン校、NVIDIAからなる研究グループは、ロボットがヨガボールの上でバランスを取りながら歩行する技術を、シミュレーションから実世界へ移行する新しい方法を{target=“_blank”}した。

@




これにより、従来の手動での報酬設計や物理パラメータの調整という煩雑なプロセスを大幅に削減し、自動化を実現したという。

大規模言語モデル（LLM）を核とした「DrEureka」という技術を用いて、目的のタスクに適した報酬関数やドメインランダマイゼーション分布を自動的に生成する。具体的には、四足歩行ロボットがシミュレーション内で学習したポリシーを実世界に移行させる際、人間の介入なしでこれを行うことが可能となる。

下図は、そのDrEurekaのプロセスを表したものだ。

タスクと安全に関する指示と環境のソースコードを受け取り、Eurekaを用いて規則化された報酬関数とポリシーを生成することから始まる。生成されたポリシーは、さまざまなシミュレーション条件下でテストされ、報酬に敏感な物理的先行知識を築き上げる。この先行知識はLLMに提供され、ドメインランダマイゼーション（DR）パラメータのセット生成に利用される。最後に、これらの合成された報酬とDRパラメータを用いて、実世界での展開に向けたポリシーが訓練される。この一連のプロセスにより、シミュレーションから現実へのスムーズな移行が実現し、ロボットが新しいスキルを効率的に習得し適用することが可能となる。

!
:::small
画像の出典：{target=“_blank”}
:::

研究チームは、このアプローチが人間が設計した既存の構成と競合する結果を生み出すことを初めて示し、さらにはヨガボールの上でのバランス取りと歩行という新たなロボットタスクを解決する能力を展示した。


Eurekaは、2023年10月にNVIDIAが発表した、ロボットに複雑なスキルを教えるAIエージェントだ。発表時には、高速ペン回しを教える動画が{target=“_blank”}。このほかにも、ロボットに引き出しやキャビネットを開閉する、ボールを投げてキャッチする、ハサミを操作するなど、約30のタスクをロボットに教え、学習・熟達させている。


@




:::box

:::
:::box

:::
:::box

:::


</description><pubDate>Fri, 10 May 2024 10:08:16 +0000</pubDate></item><item><title>MITがDALL-E3など拡散モデルの処理性能を30倍にする研究を発表　分布マッチング蒸留（DMD）で品質も担保</title><link>https://ledge.ai/articles/mit_distribution_matching_distillation</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月21日、米マサチューセッツ工科大学（MIT）はDALL-E3など既存モデルの処理速度を30倍高速化が期待できるという研究の成果を{target=“_blank”}した。

AI画像生成ツールは主に拡散モデルで複数の単語を認識し独自の画像を生成する。ノイズの多い初期画像データに繰り返し構造を追加し画質を向上させるが、画像が完成するまで何度も反復する必要があり処理に時間を要していた。

この課題に対してMIT コンピューター科学・人工知能研究所 (CSAIL) の研究者は、複雑な構造のオリジナルのモデルを「教師モデル」とし、教師モデルの動作を「生徒モデル」に模倣させ拡散モデルの複雑な処理のプロセスを1ステップに簡素化することを実現したという。このアプローチは「分布マッチング蒸留（DMD: Distribution Matching Distillation）」として知られており、生成される画像を高品質な状態で高速生成を可能にした。

DMDによる詳しい動作は、まず回帰損失によりマッピングが固定され画像構成のトレーニングが安定し、分布マッチング損失により元の画像と生成した画像の違いを理解し相違を最小化できるようにトレーニングをする。こうした研究により、高速化が実現できるという。

この研究成果は6月に開催される「Conference on Computer Vision and Pattern Recognition（コンピュータービジョンとパターン認識に関する国際会議）」で発表予定だ。

:::box

:::
:::box

:::</description><pubDate>Wed, 08 May 2024 05:21:22 +0000</pubDate></item><item><title>ホロラボ・西松建設、ドローンの空撮映像にARを組み合わせた施工支援技術を開発
</title><link>https://ledge.ai/articles/hololab-nishimatsu_xr_with_drone_vision</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月18日、株式会社ホロラボと西松建設は、共同研究によりドローンを利用した建設現場の施工支援技術を開発したことを{target=“_blank”){target=“_blank”}した。

空撮映像に3Dモデルをリアルタイムで重ね合わせ、ヘッドマウントディスプレイと連携。これにより、施工の可視化及びドローンの操作性を支援するという。

@




このシステムでは、3Dモデル（CIMモデル）を活用し、現場の生産性向上と業務の効率化を図る。AR（Augmented Reality）技術を用いて、施工現場のCG視覚情報を現実世界に重ねることにより、施工の課題把握や改善提案が迅速に行えるという。

この技術の特徴は、従来の地上主観視点に限定された問題を克服し、ドローンを使用して自由な視点からの確認が可能であること。

ARを重ね合わせるためには、一般的にはQRコードなどのマーカーを使用する手法が使われるが、同研究では、マーカー不要の技術を採用している。DJI社のドローンMavic 3 EnterpriseにRTKモジュールを搭載し、全地球航法衛星システム（GNSS）を活用して、正確な位置情報を取得し、リアルタイムでのAR重畳（ちょうじょう）が行われる。

さらに、操縦者は装着するヘッドアップディスプレイ（Trimble XR10 with HoloLens 2）を通じて空撮映像のAR重畳、ドローンのステータス、3Dモデルの操作が可能である。これにより、操縦者は手を放さずに必要な操作を行うことができるという。

!
:::small
画像の出典：{target=“_blank”}
:::

この技術は、宮城県名取市にあるダム建設現場でのフィールド検証が行われ、全体的な現場の確認や施工計画との比較が短時間で実施できることが確認された。今後、ホロラボと西松建設はこの技術の精度向上とシステムの最適化を進め、広範な利用が可能なサービスへと展開していく計画だ。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 08 May 2024 11:39:04 +0000</pubDate></item><item><title>ブリヂストンの社内ベンチャーがゴム人工筋肉によるやわらかいロボット「Morph」の体験コーナーを設置　5/17から</title><link>https://ledge.ai/articles/bridgestone_morph-inn</link><description>:::small
画像の出典：{target=“_blank”}
:::

ブリヂストンは2024年04月23日、社内ベンチャーであるブリヂストン ソフトロボティクス ベンチャーズとクリエイター集団Konelが、未来体験を提供するための共創型プロジェクトを立ち上げたことを{target=“_blank”}した。

このプロジェクトでは、ゴム人工筋肉を用いた柔らかいロボット「Morph」に身をゆだねる新空間「Morph inn」の体験施設を公開する。期間は2024年5月17日から25日まで東京・表参道の「seeen」に設置されるとのこと。

Morphは、ブリヂストンが独自に開発したゴム人工筋肉（ラバーアクチュエーター）を活用しており、自然界のリズムを模倣した動きを再現するという。この技術によりMorphは、生物の呼吸や潮の満ち引きなどの生物学的な動きの表現を可能にする。このロボットに参加者が直接触れ合うことで、互いの動きを感じ取りながら共感覚的な交流を促進するとのこと。

Morph innは、ただ単に技術を展示する場ではなく、参加者が目的を持たずに自由に過ごすことができる「無目的室」として設計されている。参加者は日常の束縛から解放され、Morphとの交流を通じて新たな感覚体験が得られるという。

### ブリヂストンのソフトロボティクス事業
（{target=“_blank”}）は、同社の100年以上にわたるゴム技術の知見を活かした社内ベンチャーで、ゴムの新たな可能性を追求し、地球規模で直面する社会課題の解決に貢献することを目的としている。主に{target=“_blank”}）を活用した製品やソリューションを開発する。「新たなロボットの手足」として、また産業向けの「器用な手」TETOTEや「触れ合いにより心を動かすソフトロボティクス」umaruなどの製品を生み出している。

!
:::small
画像の出典：{target=“_blank”}
:::

###  AIによる人工筋肉の計算モデル開発　京大・東大との共同研究

同社は25日に、京都大学の明石望洋情報学研究科助教および東京大学の中嶋浩平准教授との共同研究を通じて、AIを活用した新たな人工筋肉の計算モデルを{target=“_blank”}した。

この技術は、ソフトロボットのアクチュエータとして用いられる空気圧人工筋肉の動作をAIによるニューラルネットワーク計算で解析し、リズミカルまたはカオスと称される複雑な動作パターンを自律的に生成できることを明らかにした。
この技術により、人工筋肉はより精密で自然な動きを実現可能となり、ロボットだけでなく、医療や介護の分野での応用が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::

</description><pubDate>Mon, 06 May 2024 10:32:46 +0000</pubDate></item><item><title>佐川グローバルロジスティクスがエピソテックと共同開発のAR技術を活用した物流オペレーションの実証実験を実施</title><link>https://ledge.ai/articles/sgl_episotech_ar</link><description>:::small
画像の出典：{target=“_blank”}
:::

佐川グローバルロジスティクス（以下SGL）とエピソテック株式会社は2024年4月24日、共同でAR技術を活用した物流業務支援システムの実証実験を実施したことを{target=“_blank”}した。エピソテックのAR手順書システム「Dive」を基に開発されたこのシステムは、熟練が不要なオペレーションの実現を目指す。

この取り組みは「ヒトとARが融合する物流オペレーションの未来」の具現化を目指すという。
期間は2024年1月から3月。SGL喜菖蒲営業所にて、倉庫内オペレーションの最適化と、AR技術の有用性の確認を目的とする。

検証ポイントは以下の通り
・作業マニュアルにARを活用し、従来の方法と比較して教育にかかる時間の削減が可能か
・作業者の作業動線をARで表示することで、作業者が迷うことなく作業に従事できるか
・ARコンテンツを現場スタッフでも簡単に運用可能か

!
:::small
画像の出典：{target=“_blank”}
:::

24日の実証実験では、作業マニュアルのAR化による教育時間の削減、作業動線のAR表示による作業効率の向上、及びARコンテンツの現場適用の簡便性が検証された。その結果、想定を上回るデータが取得でき、倉庫現場におけるARの有用性を確認できたとのこと。


:::box

:::
:::box

:::

</description><pubDate>Mon, 06 May 2024 10:25:28 +0000</pubDate></item><item><title>OpenAI　LLMのセキュリティ強化に向けた新たなフレームワーク「The Instruction Hierarchy」を発表</title><link>https://ledge.ai/articles/openai_instruction_hierarchy</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月19日、OpenAIの研究チームは大規模言語モデル（LLM）のセキュリティを強化する新たな手法「The Instruction Hierarchy」を{target=“_blank”}した。このフレームワークは、異なる優先度の命令を効果的に処理し、モデルの安全性と信頼性を保証することを目指している。

LLMは近年、プロンプトインジェクションやジェイルブレイクなどのサイバー攻撃により、不正な命令で操作されるリスクが高まっている。これに対応するため、研究チームは命令の優先度に基づく階層的な処理を導入。このアプローチにより、モデルは最も信頼性の高い命令のみを選択的に実行し、不適切な命令は無視するという。

下図はChatGPTとの会話例。現代のLLMは、信頼できるシステムからのプロンプトから、ツールからの信頼できない出力まで、様々なタイプのメッセージを提供する。この例では、インターネット検索結果のプロンプト・インジェクション攻撃を無視するようになっている。

!
:::small
画像の出典：{target=“_blank”}
:::

この新システムは、特にGPT-3.5 Turboでの実験を通じてその効果が確認されており、見たことのない攻撃タイプに対してもモデルの堅牢性が向上が見られたとのこと。主要な安全性評価では最大63%、未知の攻撃タイプに対する一般化能力では34%の改善が確認されている。

下図２「主な結果」では、命令階層を用いて学習したモデルは、すべての主な評価において安全性を向上させ、ロバストネス（堅牢性）を最大63%向上させたことが示されている。

!
:::small
画像の出典：{target=“_blank”}
:::


下図３「汎化の結果」命令階層は、トレーニングから明示的に除外した各評価基準に対しても汎化を示し、頑健性を最大34%向上させたという。これには、安全でないモデル出力をトリガーするジェイルブレイク、システムメッセージからパスワードを抽出しようとする攻撃、ツール使用によるプロンプトインジェクションが含まれる。これらの結果は、LLMが命令階層を内部化することを学習し、見たことのないプロンプトに対しても、全体的に安全で制御しやすくなったことを示唆している。

!
:::small
画像の出典：{target=“_blank”}
:::


OpenAIは今後、データ収集とモデル評価をさらに進め、命令階層の精度を高めることで、LLMの堅牢性を一層強化する計画である。これにより、企業や開発者がAIをより安心して利用できる環境が整う見込みだ​。




:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 05 May 2024 10:24:59 +0000</pubDate></item><item><title>不謹慎・不適切・不正確発言は報告してニャン　一歩先行く横須賀市　AIチャットボット「ニャンぺい」公開</title><link>https://ledge.ai/articles/yokosuka_city_nyampei-bot</link><description>:::small
画像の出典：{target=“_blank”}
:::

横須賀市は2024年5月20日、お悩み相談AIチャットbot「ニャンぺい」を公開したことを{target=“_blank”}した。

ニャンぺいは、OpenAIの大規模言語モデル「GPT-4o」を活用し、市民の悩み相談に対応するAIチャットbotだ。取り組みはまだ開発段階で「未完成」として公開されており、公開実験を通じて不具合を収集し、それを改善することを目的としている。

横須賀市は、ニャンぺいとのやりとりで不正確や不適切な返答があった場合、専用フォームから報告するように案内している。公開実験の結果はレポートにまとめ、他の自治体や企業にも共有される予定だ。

「将来的には、誰もがいつでも安心して相談できるチャットbotを実現し、行政サービスの向上を目指している。そのためには、チャットbotの安全性と信頼性が不可欠です。この公開実験を通じて、皆さまからのフィードバックを得ることで、より良いチャットbotの開発につなげていく」（横須賀市）

横須賀市は2023年4月に自治体で初めてAIチャットサービス「ChatGPT」を業務に試験導入するなど、生成AIの業務活用に積極的な姿勢を示している。「ニャンぺい」の公開で、市民からのフィードバックをもとにした、安全で信頼性の高いチャットbotの実現を目指すという。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 23 May 2024 13:43:09 +0000</pubDate></item><item><title>東京で「空飛ぶクルマ」初飛行　高さ10メートルをデモンストレーション</title><link>https://ledge.ai/articles/flying_car_demonstration_in_tokyo</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月17日、東京都江東区の東京ビッグサイト駐車場とその近くの海上で「空飛ぶクルマ」の初飛行が行われた。この試験飛行は、「SusHi Tech Tokyo 2024」の一環として行われ、約500人の観客が見守る中、操縦士1人を乗せた機体が高さ約10メートルを前後左右に移動した​という。

使用された機体は、米国のLIFT AIRCRAFT社製「HEXA」。1人乗りの機体で、座席の上部に18のプロペラが取り付けられており、幅4.5メートル、高さ2.6メートル、重量約196キロ​となる。

空飛ぶクルマは都市の渋滞緩和や災害時の物資輸送などに多くのメリットが期待されている。このイベントでは空飛ぶクルマ以外にも自動運転バスや電動モビリティなどの次世代技術が展示されている​とのこと。

デモフライトはこの日のほか5月18日、22日、23日にも予定されており、一般公開される。これらのフライトは予約不要で、入場も無料。

共同通信によると、17日のセレモニーには東京都知事の小池百合子氏も登壇し、「最先端の技術をより多くの人に体感してもらいたい。空飛ぶクルマが移動の手段になるのを楽しみにしている」と述べた​とのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 21 May 2024 11:54:16 +0000</pubDate></item><item><title>欧州評議会、AIに関する初の国際条約を採択　日本ほか非加盟国なども策定に参加</title><link>https://ledge.ai/articles/cou_adopt_a_treaty_on_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

欧州評議会は2024年5月17日、AIシステムの使用において人権、法の支配、民主主義の法的基準を確保することを目的とした、史上初の国際的な法的拘束力のある条約を採択したと{target=“_blank”}した。

この条約は非欧州諸国にも開放されており、AIシステムのライフサイクル全体をカバーし、そのリスクに対処しつつ、責任あるイノベーションを促進する法的枠組みを設定している。条約は、AIシステムの設計、開発、使用、および廃止に対するリスクベースのアプローチを採用しており、使用による潜在的な負の影響を慎重に考慮することを求めている。

この条約「{target=“_blank”}（人権、民主主義、法の支配に関する人工知能枠組み条約）」は、ストラスブールで開催された欧州評議会の閣僚委員会の年次会合で採択された。同会合には、欧州評議会の46加盟国の外相が出席した。

条約は、この46の欧州評議会加盟国のほか、欧州連合、および11の非加盟国（アルゼンチン、オーストラリア、カナダ、コスタリカ、バチカン、イスラエル、日本、メキシコ、ペルー、アメリカ合衆国、ウルグアイ）で構成される政府間機関、人工知能委員会（CAI）が2年間の作業を経て作成したものであり、民間部門、市民社会、学術界の代表もオブザーバーとして参加した。

評議会の事務総長であるマリヤ・ペイチノビッチ・ブリッチ氏は「この条約は、AIが人々の権利を尊重することを保証するための初の国際条約。AIの責任ある使用が人権、法の支配、民主主義を尊重することを目指している」と述べた。

条約は、公共部門および民間部門でのAIシステムの利用を規制し、透明性、監視、責任を確保するための要件を設定している。また、AIシステムが平等、差別禁止、プライバシー権を尊重することを保証し、人権侵害の被害者に法的救済手段を提供することを求めている。さらに、AIが民主的プロセスを弱体化させないようにするための措置を講じることも求めている。

条約の実施を確保するために、締約国会議というフォローアップメカニズムが設けられている。枠組み条約は、2024年9月5日にリトアニアのビリニュスで署名のために開放される予定である。



:::box

:::
:::box

:::


</description><pubDate>Mon, 20 May 2024 11:40:32 +0000</pubDate></item><item><title>AIは発明家として認められず　東京地裁「発明は人間の創造的活動」と判断</title><link>https://ledge.ai/articles/ai_not_recognized_as_inventor_tokyo_district_court</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

東京地方裁判所は2024年5月16日、AIが発明した技術の特許認可を巡る訴訟で、「発明者は人間に限られる」との判決を下した。原告はAIである「ダバス」を発明者として特許出願していたが、特許庁はこれを認めず、原告の請求を{target=“_blank”}。

### 判決の背景
米国在住の原告は、AI「ダバス」を発明者として記載した特定装置に関する特許を出願。しかし、特許庁は「発明者として記載できるのは人に限られる」として補正を命じたが、原告がこれに応じなかったため出願を却下した。これに不服を抱いた原告は訴訟を提起した。

### 裁判所の判断
中島基至裁判長は、「発明は人間の創造的活動により生み出されるものと定義される」とし、特許庁の判断を適法と認めた。また、現行法が制定された時点ではAIの発展が予測されていなかったことから、AI発明に関する新たな制度設計が必要であると述べた。

判決文によれば、AIを発明者として認めることは特許法に基づく「発明者」の概念を曖昧にし、発明者の権利や責任の所在が不明確になると指摘。また、AIの自律的創作能力と人間の創作能力の違いを考慮すると、現行法ではAI発明に対する適切な制度設計が難しいとされた。

### 国際的な状況
AIを発明者とする特許出願は国際的にも議論の対象となっており、例えば、英国の最高裁判所も2023年に「特許権を得られるのは人間のみであり、AIを発明者とすることはできない」との判決を下している。同じく、アメリカ合衆国（発明者は「自然人」でなければならない：2022年）、ヨーロッパ特許庁（発明者は「法的能力を持つ人物」でなければならない：2021年）、ドイツ（AIが発明者として認められるには自然人が記載されなければならない）その他、イスラエル、ニュージーランドなども同様の判決に至っている。

オーストラリア連邦裁判所は2021年にAIが発明者として認められるとの判決を一旦下し話題になったが、2022年4月に大法廷にてこれを覆し、AIは発明者として認められないとした。




:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Mon, 20 May 2024 11:08:48 +0000</pubDate></item><item><title>コニカミノルタ　教育専門知識とビッグデータを活用した対話型生成AI「tomoLinks」を大阪市立小中学校で先行導入</title><link>https://ledge.ai/articles/konicminolta_tomolinks_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

コニカミノルタジャパンは2024年5月7日、学校教育向けソリューション「tomoLinks®（トモリンクス）」の新機能として、対話型生成AI機能を提供すると{target=“_blank”}した。同機能は2024年9月から大阪市立小中学校の一部で先行利用が開始される。

教育現場でのAI導入の背景には、教育データの活用が深く関連している。近年、教育現場では情報技術の活用が進められており、特に学力調査データや学習支援システムのデータが豊富に蓄積されている。しかし、既存の対話型生成AIはインターネット上の情報に基づいて回答を生成するため、学校教育においては必ずしも適切な内容を提供できないという課題があった。これに対応するため、コニカミノルタジャパンは、教育内容に特化したデータを使用して安全で質の高い対話型学習支援を目指す「tomoLinks」を開発したとのこと。


!
:::small
画像の出典：{target=“_blank”}
:::

tomoLinksは、自治体や学校が保有する学力調査データや教育関連のビッグデータを基に、子どもたちの学力の経年変化や得意・不得意な単元を分析し、その結果に基づき子どもの特性に合わせた個別の対話を提供することで、個別最適な学びを支援することを目的としている。また、教材や学習指導要領などのデータを設定した対話型生成AIにより、有害なキーワードや不適切な回答を避け、子どもたちに安全で安心な学習環境を提供するという。

この取り組みにおいて、大阪市教育委員会とコニカミノルタ及びコニカミノルタジャパンは、教育データの利活用を強化し、教育行政に資する相互の連携及び協力に関する協定を締結した。この協定は、AIを活用した児童生徒の多様な学び等の可能性を探ることを目的としている。



:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 14 May 2024 11:50:44 +0000</pubDate></item><item><title>岸田首相、生成AIの国際的枠組み「広島AIプロセス・フレンズグループ」設立を発表　パリOECD会合にて</title><link>https://ledge.ai/articles/hiroshimaaiprocess_friends_group</link><description>:::small
画像の出典：{target=“_blank”}
:::

岸田文雄首相は2024年5月2日、パリで行われたOECDの会合で、AIの安全な利用を目的とした「広島AIプロセス・フレンズグループ」の設立を{target=“_blank”}した。この発表で、49カ国・地域がこの新しい枠組みに参加する予定であることが{target=“_blank”}。この国際的な取り組みは、自由や民主主義などの共通の価値を有する国々が生成AIの国際ルール作りにおける主導権を握ることを目指しているとのこと。

広島AIプロセスは、偽情報の拡散抑止や生成AIが作り出したコンテンツの識別を容易にするための「電子透かし」技術の推進など、安全性と信頼性を高める技術開発を含む具体的な対応を各国に促すものだ。岸田首相は、「偽情報のリスクといったAIの影の側面と戦いつつ、その革新的な可能性を最大化するためには、国際的なガバナンスの形成が急務である」と述べている​​。

さらに、岸田首相は「AIに関するグローバルパートナーシップ」（GPAI）の東京における新拠点設立の方針も発表した。この組織は、AIの責任ある使用を推進し、専門家による技術実証を支援することを目的としている​。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 03 May 2024 04:47:10 +0000</pubDate></item><item><title>生成AIの児童安全安全対策強化へのコミットメント：主要AIテック企業が連携「子供の安全を優先すると確約」</title><link>https://ledge.ai/articles/thorn_generative_ai_principle</link><description>:::small
画像の出典：[THORN](https://www.thorn.org/blog/generative-ai-principles/{target=“_blank”}
:::

ThornとAll Tech Is Humanは、Amazon、Anthropic、Civitai、Google、Meta、Metaphysic、Microsoft、Mistral AI、OpenAI、Stability AIといった世界の主要なAI企業と協力し、児童の安全を保護するための「Safety by Design」原則に公式にコミットしたと{target=“_blank”}した。AI企業が、AI技術の開発、展開、および維持の各段階で子供の安全を優先することの確約である。

これらの原則は、AIによって生成される児童性的虐待素材（AIG-CSAM）およびその他の性的被害を防ぐことを目的としている。

公開された「生成AIによる安全設計：児童性的虐待の防止」の新しい報告書には、これらの原則が詳述されており、AI開発者、プロバイダー、データホスティングプラットフォーム、ソーシャルプラットフォーム、検索エンジンがこれらの原則を実施するための具体的な対策と戦略が定義されている。同報告書は、Thorn、All Tech Is Human、および参加企業の一部が共同で執筆した。

各社は、これらの原則に基づいて進行状況を透明に公表し共有することにも合意している。ジェネレーティブAI技術および製品に「Safety by Design」原則を統合することにより、これらの企業は子供たちを保護するだけでなく、倫理的なAI革新をリードしている。

生成AIの誤用は、すでに児童性的虐待の増加を加速している。技術の進展により、加害者は以前にも増して簡単に大量の内容を生成する能力を持ち、新たな虐待素材を創出したり、無害な子供の画像を性的な内容に変えたり、完全にAIで生成されたCSAMを作成することが可能となる。


**AIを使用して画像を歪める例**
!
:::small
画像の出典：[THORN](https://www.thorn.org/blog/generative-ai-principles/{target=“_blank”}
:::


開発からデプロイメント、メンテナンスに至るまで、これらの企業はジェネレーティブAIモデルが児童の安全リスクに積極的に対処するよう努めるとともに、トレーニングデータセットの適切な管理、フィードバックループと反復的なストレステスト戦略の導入、コンテンツの出典確認を重視することで、CSAMとCSEMの生成を防ぐための対策を実施するとした。


:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:12:36 +0000</pubDate></item><item><title>経済産業省 &amp; 総務省、AI事業者向けガイドラインを公表 ― 安全性、透明性、公平性ほか10の指針</title><link>https://ledge.ai/articles/government_released_guidelines_for_ai_providers</link><description>:::small
画像の出典：{target=“_blank”}
:::
2024年4月19日、政府はAI事業者向けの新たな指針「AI事業者ガイドライン（第1.0版）」を{target=“_blank”}した。

この指針は2023年5月、東京大学の松尾豊教授が座長を務めるAI戦略会議で取りまとめられた「AIに関する暫定的な論点整理」において示された、既存のガイドラインに関して必要な改訂などを検討する必要性を受けてのことだという。

このガイドラインは、AIに関わる企業のためのもので、AIの安全性、透明性、公平性をはじめとする10項目を強調しており、AI技術の適切な利用と社会的な課題への対応を目的とし、国内外のAI技術の進展とそれに伴うリスク管理を背景に公開された。

具体的には、「AI開発者」「提供者」「利用者」を対象に、リスクベースのアプローチによる自主的な取り組みが求められる。政府は、これらの指針を通じて、AI技術の健全な発展と産業競争力の強化を図ることを期待している。

### 「AI事業者ガイドライン」で明らかにされた10の指針
| 指針                   | 内容 |
|----------------------|-----------------------------------------------------------|
| 1. 人間中心のアプローチ | AIは人権を尊重し、人間の尊厳と自律を守るよう設計・運用される |
| 2. 安全性             | 人の生命や健康を損なわないよう、安全に設計されたAIの利用 |
| 3. 公平性             | 不公平な偏見や差別を含まないよう努力する |
| 4. プライバシー保護   | 個人情報は保護され、プライバシーを尊重する形でAIが利用される |
| 5. セキュリティの確保 | AIシステムは不正アクセスやデータ漏洩から守られる |
| 6. 透明性             | AIの判断プロセスが透明であり、誰にでも理解可能 |
| 7. アカウンタビリティ | AIの操作とその結果に責任を持ち、説明責任を果たす |
| 8. 教育とリテラシー   | AIの適切な理解と使用に必要な知識やスキルの提供 |
| 9. 公正な競争の促進   | AIを利用したビジネスが公正な環境で行われる |
| 10. イノベーションの推進 | 社会全体のイノベーションをAIを通じて促進する |


ガイドライン内容には、AIシステムのライフサイクル全体にわたるガバナンス強化が含まれており、実践のための指南も提供されている。たとえば、AI開発者には倫理的なモデル設計が、AI提供者には透明性と利用者の支援が、AI利用者にはデータの入力とシステムの適切な活用が求められる。

また、別添資料では、AIによる便益やリスクの具体例、AIガバナンスの構築、各種AIシステムサービスの詳細で分かりやすい解説が掲載されている。


**ガイドラインの構成**
!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みは、法的拘束力は持たないが、業界に対する自主規制としての役割を果たすことが期待されている。政府は、技術の進化や国際的な動向に応じて、ガイドラインの内容を更新していく方針を明らかにしている。

ガイドラインの全文は、経済産業省のウェブサイトで{target=“_blank”}されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Apr 2024 12:47:54 +0000</pubDate></item><item><title>文化庁「AIと著作権に関する考え方について」個人から寄せられた1000ページ超のパブコメ公開</title><link>https://ledge.ai/articles/bunka_cho_released_public_comments_on_ai_and_copyright</link><description>:::small
画像の出典：{target=“_blank”}
:::

文化庁は、2024年4月16日までに、生成AIと著作権に関する考え方をまとめた資料「AIと著作権に関する考え方（素案）」に対するパブリックコメント（パブコメ）の結果を部分的に{target=“_blank”}した。

このパブコメは、2024年1月23日から2月12日にかけて{target=“_blank”}しており、応募総数は2万4938件に達した。今回公開されたのは個人から寄せられた意見の一部で、1089ページにわたる内容（前回は1129ページ）となった。公開された意見には必要なマスキング処理が施されており、法人・団体からの意見については既に別途公開済み。

「AI と著作権に関する考え方について（素案）」のパブリックコメントの結果について（個人）
・{target=“_blank”}
・{target=“_blank”}

これらの意見を受け同庁は、有識者の意見を含めた最終版の資料「{target=“_blank”}」を3月15日に公開。概要が4月15日に{target=“_blank”}されている。

この資料では、AIが生成するコンテンツの著作物性、非享受目的の利用の具体的な例外、著作権侵害が発生した際の対応策などが詳細に定められており、AI技術の進展に伴う著作権法の適用がより明確化されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 21 Apr 2024 06:33:59 +0000</pubDate></item><item><title>自民党「キャッチコピーはAIが提案」新ポスター発表記者会見で「自民党AI」を披露　複数モデルを選択でき、API連携で利用</title><link>https://ledge.ai/articles/jiminto_ai_made_cach-copies</link><description>:::small
画像の出典：{target=“_blank”}
:::

自民党は2024年4月15日、新たな政治活動用ポスターを{target=“_blank”}した。

ポスターのキャッチコピー「経済再生 実感をあなたに。」の発案・選定や、デザイン制作に「自民党AI」が用いられたという。このAIは、過去3年間の党政策パンフレットや岸田文雄首相の演説データを基に、500案以上のフレーズを生成し候補を絞り込んだ。最終的には、岸田首相含む人間たちの目で評価し、コピーが確定したという。AIを活用することで「より多くの国民に政策の成果を実感してもらえるよう工夫した」とのこと。

さらに、このポスターのビジュアルには、AIが生成した複数のデザイン要素が採用されており、従来の政治広報とは一線を画する新しい試みだという。

!
:::small
画像の出典：{target=“_blank”}
:::

この日、党の広報本部長である平井卓也氏は、スピーチ作成や政策立案への活用などに用いられるとして1月に各メディアが{target=“_blank”}自民党AIを、記者会見の場で公開した。最も特徴的なのは、AIモデルを１つに限定することなく、ユーザーが異なるモデルから最適なものを選択し、APIと連携して利用できるインターフェースであると述べた。

!
:::small
画像の出典：{target=“_blank”}
:::

記者からの「ポスターのキャッチコピー作成時のプロンプトはどのようなものか？」という質問に平井氏は、もともと自民党AIには「キャッチコピー案作成」というアシスト機能が付与されており、ポスターに限らずプロジェクトに最適なコピーを生成すると回答した。このたびの「経済再生」というテーマをポスター作成の主軸に置こうと判断したのはあくまで「人間」であると強調。

平井氏はまた、生成AIはプロンプトの良し悪しでその生成結果が大きく左右されることも多い。そのAIの機能を最大限引き出せるようなプロンプトを誰でも簡単に出せるようなアシスト機能を目指すとした。

今のところ、党の広報だけが、限定的に自民党AIを取り扱うことができるという。学習についての権限も同様とのこと。今後、広報の立場を越えて使う場合のAIガバナンスについては、引き続き検討しながら、開発を続けていきたいと述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Apr 2024 03:34:03 +0000</pubDate></item><item><title>Microsoft「米国大統領選が標的に」最新の脅威報告で、中国のAI操作による選挙介入を警告　韓国、インドの選挙にも同様の警告</title><link>https://ledge.ai/articles/microsoft_threat_intelligence_warned_chinese_ai_io</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月4日、Microsoftの脅威分析センターは、中国がAIを利用したサイバー攻撃および情報操作を強化していると{target=“_blank”}した。同社は、特に中国がAIを活用してアメリカ、韓国、インドの選挙に影響を与えようとするだろうと指摘している。

このレポートでは、2024年1月に行われた台湾の総統選挙で、中国がAI生成のオーディオやビデオを用いた介入がすでに行われていたことが示唆されている。

台湾での選挙介入では、AIが生成したコンテンツが政治的なメッセージを強化し、特定の候補者を支持するかのような偽の情報が流された。この活動は、Microsoftの{target="_blank"}で初めて明らかにされ、以降その手法はさらに洗練されているという。

**台湾選挙におけるAIの影響**
!
:::small
画像の出典：{target=“_blank”}
:::

上図で紹介されている「Storm-1376」の活動は、前回の脅威レポート以降に活発化しているという。Storm-1376は、中国共産党（CCP）に関連する情報操作グループで、特に台湾の政治家や中国の反体制派を標的に、AIを活用した情報操作を行っているとのこと。このグループはAI生成のニュースアンカーやミームを用いて、視聴者を欺くキャンペーンを展開しており、台湾だけでなく、アメリカや韓国など他の国々でも同様の活動が行われていることが報告されている。

これらのキャンペーンはいくつかの重要な進化を遂げている。視聴者を欺くためにAIが生成した写真を取り入れたり、陰謀論的なコンテンツ（特に米国政府に対するもの）を煽ったり、ローカライズされたコンテンツで韓国などの新たな人口をターゲットにしたりしているとのことだ。


中国はさらに、南太平洋諸島や南シナ海地域、米国防産業基地に対するサイバー攻撃を行っており、これらの攻撃は政治的および経済的な利益を追求するものだという。

同社は、AIを活用した情報操作が、選挙期間以外にも国際的な緊張を引き起こす潜在的なリスクを持つと報告している。


:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Apr 2024 06:32:36 +0000</pubDate></item><item><title>東京都、AIを活用した建物被害判定支援ツールを開発　災害時の罹災証明を迅速化</title><link>https://ledge.ai/articles/metro_tokyo_ai-based_building_damage_assessment_support_tool</link><description>:::small
画像の出典：{target=“_blank”}
:::

東京都知事小池百合子氏は、2024年3月29日の知事記者会見を通じ、AI技術を活用した建物の被害状況を判定する支援ツールの開発を{target=“_blank”}した。

このツールは、特に災害時の建物損傷を評価するために設計されており、住家被害認定の精度向上とプロセスの効率化を目指す。

会見内容によると、このAI支援ツールは、住家の外壁を撮影し、損傷箇所を自動で検出する機能を持ち、得られた画像データはAIによって解析され、損傷の程度を示すことで調査員が被害認定の参考にすることができるという。

被害判定の基準は非常に複雑であり、現行の方法では認定作業に多大な時間と専門知識が求められる。この新しいツールにより、判定のばらつきを抑え、迅速かつ公平な認定が可能になると知事は述べた。

さらに、東京都は国に対しても住家被害判定方法の簡略化やAI技術の積極的な活用を促している。知事は、「いつ起こるかもしれない首都直下地震への備えとして、このAIツールの開発は極めて重要」と強調。技術の進化と共に、精度を高めるためのデータ蓄積も進める方針を示した。

このツールの具体的な使用例として、記者会見中には、破損した建物の画像がスライドで示され、AIがどのように損傷を検出し学習していくかが説明された。今後、このツールは東京都内外の災害対応の現場で広く利用される予定とのことだ。

会見後の担当者からの説明によると、このAI支援ツールは、木造モルタル住宅の壁面を撮影する際に特に有効で、画像一枚あたり数秒で損傷程度を判定できる速度が特徴だという。しかし、AIの誤認識も報告されており、垂れ下がった電線を壁のひび割れと誤認するケースもあるため、技術の更なる精練が求められている。東京都はAI技術の進展とともに、これらの課題を克服し、より信頼性の高いツールを提供する目標を掲げている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 17 Apr 2024 06:39:03 +0000</pubDate></item><item><title>ソニー・ミュージックグループ「オプトアウト宣言」　AI学習におけるコンテンツ使用を禁止し、約700の開発者や配信企業に警告</title><link>https://ledge.ai/articles/sonymusic_declaration_of_opt_out</link><description>:::small
画像の出典：{target=“_blank”}
:::


ソニー・ミュージックグループ（SMG）は、AI開発企業および音楽ストリーミングサービス各社に対し、自社のコンテンツをAIの強化学習に使用することを禁止する「オプトアウト」を宣言した{target=“_blank”}した。

新たなこの方針により、SMGのコンテンツを使用するには、事前に明示的な許可を得る必要が生じる。

SMGは約700のAI開発者および音楽ストリーミング企業に対して書簡を送り、その中で、すでに同社の著作権を侵害している可能性があることを警告した。書簡では、不正使用がないことを確約するか、すでに使用されたコンテンツに関する詳細な情報を開示するよう求めているという。さらに、対応期限を設定し、期限内に回答が得られなかった場合には、法的措置を講じることを示唆しているとのこと。

ソニー・ミュージックはAIの「大きな可能性」を認識しつつも、「AIシステムのトレーニング、開発、商品化におけるSMGコンテンツの不正使用」が同社およびそのアーティストの管理権と「適切な補償」を奪うと述べている。このため、AI開発者はSMGのコンテンツを使用する前に必ず許可を得る必要があり、音楽ストリーミングサービスはコンテンツの無断使用を防止するための措置を講じることが期待されている。

今回の方針変更は、AI技術の急速な進展とともに増加する著作権侵害への対応策として注目される。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 22 May 2024 07:11:42 +0000</pubDate></item><item><title>清水建設　永平寺のデジタルツインを構築　伽藍内全棟をウォークスルーできるデジタル空間やオンライン参拝できるコンテンツも
</title><link>https://ledge.ai/articles/shimizu_eiheiji_digitaltwins</link><description>:::small
画像の出典：{target=“_blank”}
:::

清水建設は2024年4月26日、福井県吉田郡に位置する曹洞宗大本山「永平寺」と共同で、3次元点群測量技術を用いて永平寺伽藍内の重要文化財19棟の精緻なデジタルツインを制作し、永平寺に納品したと{target=“_blank”}した。

清水建設はまた、同社のアプリ「デジトリ360」を使用して伽藍内全棟と大小100余棟を360度写真でウォークスルーできるデジタル空間と、オンラインで永平寺を巡る「デジタル参拝」のコンテンツを制作し、2023年11月に先行して納品したとのこと。

日本の歴史的建造物は木造であるため、これまで多くが火災や地震で損壊してきた。約800年の歴史を持つ永平寺も複数回の火災に遭遇し、その都度関係者の尽力により再建されてきた。永平寺は、デジタルツインを通じて伽藍内の重要文化財を確実に後世に残すことができると判断し、2023年7月に清水建設との共同調査を開始した。

調査では、重要文化財19棟の内外観、小屋裏、床下、彫刻などあらゆる空間と形状を3次元点群測量で捉え、任意の平面、立面、断面を切り出して表示できるようにデータを加工し、デジタルツインを構築した。測量には、デジタル技術に長けた宮大工を擁するT＆I 3Dの協力を得たという。

### 山門の点群データ（外観と内部を同時に表示）

!
:::small
画像の出典：{target=“_blank”}
:::

永平寺で伽藍の維持保全を担う直歳（しっすい）の石田純道氏は「修行の場である永平寺伽藍内の建造物群の姿を確実に後世に残すことはわれわれの使命だ。精緻なデジタルツインの作成はこのニーズを具現化する手段だと評価している。また、平面の図面から維持保全に必要な情報を得るのは難しいが、デジタルツインのデータからは誰でも必要な情報を容易に検索できるため、維持保全業務を効率化できる」と述べている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 18 May 2024 12:23:38 +0000</pubDate></item><item><title>AIが「次のヒット曲」を予測する　テンセント子会社が発表　中国の音楽ストリーミングサービスで初採用</title><link>https://ledge.ai/articles/tencent_music_ai_powered_tech_predict_the_next_hit_song</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

テンセント・ミュージック・エンタテインメント・グループ（TME）は、2023年度年次報告書において、AIを活用した「PDM（予測モデル）」技術を導入し、QQミュージックのプラットフォームで「次のヒット曲」を予測することに成功したと発表した。このニュースは2024年5月8日に{target=“_blank”}が報じた。

PDM技術（Predictive Model）は、ディープラーニングを利用したコンテンツ価値評価アルゴリズムを用いており、音声と歌詞に基づく楽曲の市場可能性を予測できるという。また、ユーザーごとに最適なプレイリストを提案し、アーティストデータや音楽コンテンツ、世界中の音楽トレンドの変動をAIで分析することでターゲットオーディエンスを特定可能。

TMEの年次報告書では、同社の主要な音楽ストリーミングサービス「QQミュージック」が中国のオンライン音楽業界で初めてこの高精度のPDM技術を採用したことが述べられている。この技術は国際音楽情報検索協会（MIREX）からも認識されており、その精度と有用性が評価されているとのこと。

PDM技術の他にも、同社はAIを広範囲に活用しているという。2023年には、音楽制作およびプロモーションプラットフォーム「Venus」にAI搭載の作曲ツールを導入し、AI生成コンテンツ（AIGC）ツールを使用してアーティストの音楽コンテンツ制作および生産効率を向上させた。また、親会社のメッセージアプリ「WeChat」に音楽ライブラリを統合することで、10億人以上のユーザーがTMEの音楽コンテンツへアクセス可能となった。

また、5月13日に{target=“_blank”}TMEの2024年第1四半期の報告書では、引き続きAI技術の強化を続けているとのこと。同社は「大規模オーディオモデル」を導入し、音楽のプロモーション精度を高めるとともに、新たなAIアシスタントを導入して音楽発見をより楽しく、魅力的かつ便利にすることを目指すとした。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 18 May 2024 12:14:50 +0000</pubDate></item><item><title>大人の事情に負けるな！　全国AIアート甲子園@i-SEIFU 開幕  高校生の創造性を育む無料の生成AIアートコンテスト</title><link>https://ledge.ai/articles/seifu_ai_art_contest_for_high_school</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月11日から6月22日まで、全国の高校生を対象に「全国AIアート甲子園@i-SEIFU」が{target=“_blank”}。

このコンテストは、学校法人清風明育社主催、清風情報工科学院が運営を行う。高校生に生成AIの技術への理解と興味を深めさせ、同時にそのクリエイティビティを刺激することが目的だ。

応募資格は日本国内の高校生に限られ、作品テーマは「擬人化キャラ」に関するオリジナルイラスト・アート作品。使用可能なAIツールにはCopilot（DALL-E 3）、にじジャーニー、画像生成β（Stable Diffusion）が含まれる。これらのツールを用いて、参加者は自らのオリジナルキャラクターを創出し、そのキャラクターを活用したアート作品を作成する。

コンテストの結果は2024年6月22日に清風情報工科学院で発表予定。最優秀賞は賞金3万円（Amazonギフトカード）が授与される。優秀賞と佳作にもそれぞれ賞金が提供されるとのこと。

### 若者が高品質な生成AIツールに触れる機会を無料で提供
生成AIは商業デザイン分野においても広がりを見せており、多くのプロ向けデザインツールに組み込まれている。しかし、その多くが有料であるため、若年層にとってはアクセスが困難な状況があると同校は開催の背景を説明している。同コンテストでは、高品質な生成AIアートのツールを無料で提供し、学生たちが新しい技術に触れる機会を創出することで、彼らの進路選択や職業選択に貴重な体験を提供するとともに、将来的なキャリア形成への寄与を目指すとした。

同校校長の平岡憲人氏も「無料で高品質な生成AIアートのツールに触れることが、生徒たちの進路選択や職業選択において価値ある体験になると確信しています」とコメントしている。

**著作権の考え方と協賛企業表記の訂正について**
コンテストの初期段階では、著作権の扱いに関して一部から批判が上がったため、主催者は規約を修正し、入賞作品の著作権に関する方針を変更した。５月11日時点で記載のあった「入賞作品の著作権を主催者が取得する」との表現に取り消し線が入れられた。13日にはコンテストの公式サイトに「著作権についての考え方」を追記している。

また、当初ワコムが協賛社一覧に掲載されていたが、現在は消えているとのこと。一部報道では担当の行き違いとされている。


!
:::small
画像の出展：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
:::box

:::



</description><pubDate>Fri, 17 May 2024 08:56:03 +0000</pubDate></item><item><title>画像の照明を自在に操る新AIツール「IC-Light」公開</title><link>https://ledge.ai/articles/ic_light</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、画像の照明を自在に操作できる新しいツール「IC-Light（Imposing Consistent Light）」が{target=“_blank”}された。このツールは、前景となる画像を入力し、テキストプロンプトや背景画像を指定することで、異なる照明条件下で撮影されたかのような画像を生成することができる。

IC-Lightは、「テキスト条件付きリライティング モデル」と「背景条件付きモデル」の 2 種類のモデルをリリースしており、{target=“_blank”}にアクセスして誰でも利用可能だ。

## テキスト条件付きモデル
このモデルでは、前景画像とテキストプロンプト、そして照明の初期設定を入力として使用する。例えば、プロンプトに「美しい女性、暖かい雰囲気、寝室」を指定し、照明の初期状態として「左からの光」と設定することで、指定されたシーンに見合った照明が施された画像を生成することが可能だ。

### プロンプト: 美しい女性、詳細な顔、光と影

照明設定: 左
!


(美しい女性、詳細な顔、柔らかいスタジオ照明)
!
:::small
画像の出典：{target=“_blank”}
:::

### プロンプト: 仏陀、詳細な顔、SF RGB 発光、サイバーパンク

照明設定: 左
!



### プロンプト: 仏像、詳細な顔、自然光

照明設定: 左
!
:::small
画像の出典：{target=“_blank”}
:::

## 背景条件付きモデル
このモデルでは、前景画像と背景画像、そしてテキストプロンプトを入力として使用する。背景画像の照明を解析し、それに合わせて前景の照明を調整することで、自然で一貫性のある画像を生成する。この技術はBriaRMBGというドメイン適応技術を利用しており、前景と背景の統計分布を複数のスケールでマッチングさせることで、照明の一貫性を保ちながら画像を合成するという。

!
!
!
:::small
画像の出典：{target=“_blank”}
:::

IC-LightはHDR空間での照明の特性を利用しており、異なる光源からの光が独立して振る舞うため、複数の照明条件を自然に組み合わせることができる。このようにして、IC-Lightはリアルで効果的な画像照明の操作を実現しているとのことだ。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 15 May 2024 15:14:59 +0000</pubDate></item><item><title>アイビスペイント「AI学習妨害機能」追加　イラスト保護のため妨害ノイズ付与し、無断学習からの生成結果を劣化させる</title><link>https://ledge.ai/articles/ibispaint_ai_learning_interference</link><description>:::small
画像の出典：{target=“_blank”}
:::

 株式会社アイビスは2024年5月8日、世界中で3.9億ダウンロードを記録している人気のペイントアプリ「ibisPaint」の最新アップデートを通じて、AI学習妨害機能を導入したことを{target=“_blank”}した。この機能は、ユーザーであるクリエーターの作品が、画像生成AIによって無断で模倣されることを防ぐために設計されている。

画像生成AI技術は、LoRAやDreamBoothなどの追加学習機能を利用し、特定の作風やキャラクターを模倣する能力がある。これにより、オリジナルのイラストが無断で使用され、著作権の侵害が生じる可能性が指摘されている。アイビスはこの問題に対処するため、AI学習妨害機能を開発。イラストにノイズを加えることで、AIが作風を正確に学習できなくなる仕組みを採用している。

!
:::small
画像の出典：{target=“_blank”}
:::

利用者はアプリ内で「画像を保存」選択時に「AI学習妨害」をオンに設定し、ノイズの濃度をスライダーで調整可能。この操作により、画像はAIによる模倣から保護され、出力する画像の品質が劣化することで、追加学習の妨害が可能となるとのこと。

同社は1月に、新たにリリースした「AIお手本機能」をリリース後1日で{target=“_blank”}。「既存のキャラクターが表示された」「アイビスペイントを使って描いたらAIで生成したと思われるのでは」といったユーザーからの反響を受けとめ、実装の中止を決定したという。このたびの「AI学習妨害機能」という同社の施策は、クリエイターの著作権保護に基づく創作活動支援へ舵を切ったと、ユーザーからの反響も大きいという。

なお、この機能は、ibisPaintのプレミアム会員限定で提供され、スマートフォンやタブレット、PC（Windows）版のサブスクリプションユーザーが利用できるとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 11 May 2024 14:30:50 +0000</pubDate></item><item><title>OpenAI「Sora」が生み出した初の公式ミュージックビデオ公開</title><link>https://ledge.ai/articles/music_video_produced_using_sora</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月1日、OpenAIの動画生成AI「Sora」を使って制作された初の公式ミュージックビデオが{target=“_blank”}された。

アーティスト・作家・映画監督として多方面で活躍するPaul Trillo氏と音楽アーティストWashed Out（本名：Ernest Weatherly Greene Jr.）がコラボレーションし、OpenAIのAIモデル「Sora」を使用して制作された。

ビデオの特徴は、連続するズームショットを駆使して視覚的な錯覚を生み出すという斬新な手法により、視聴者を引き込む内容となっている​。Soraは、ユーザーのプロンプトに応じて最大1分間のビデオを生成する。Trillo氏は自身のSNSで、「Soraで生成した55個のクリップをAdobe Premiereで編集した」とファンに説明している。

@


Trillo氏によれば、このミュージックビデオは、愛する人を失った後の記憶と向き合い、それを手放すことの難しさを描いているという。現実の歪んだ鏡である記憶に対して、Soraの「夢のロジック」を利用して、実際には存在しない記憶を探求するアプローチを取り入れたとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

ビデオは、現実とAIが創出するシュールな特性の微妙な違いを探るものとなっている。奇妙なディテールと、夢の中のような動きのロジックを通じて、歪んだ記憶の本質をより良く表現することを目指している。

このミュージックビデオは、Soraの技術がどのようにしてクリエイティブな表現に革新をもたらすかを示す事例となり、AIとアーティストとの協働による新たな可能性を提示するものとなっている。

Trillo氏は、未公開のAI「Sora」への初期アクセスを許されたアーティストで、これを用いた作品「Abstract」は、3月にOpenAIのブログでも紹介されているほか、TEDの40周年を記念する「TED2024」に寄せて40年後のTEDの姿をSoraを使って描く{target=“_blank”}の制作に関わった。

ミュージックビデオ「The Hardest Part」は、6月28日にリリース予定のWashed Outの新アルバム「Notes From a Quiet Life」に収録されている。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 10:31:28 +0000</pubDate></item><item><title>正規のルートで日本のマンガを世界へ輸出　AIマンガ翻訳のオレンジが小学館などから29.2億円の資金調達を実施</title><link>https://ledge.ai/articles/orange_raises_jpy2-9b</link><description>:::small
画像の出典：{target=“_blank”}
:::

株式会社オレンジは2024年5月7日、プレシリーズAラウンドで総額29.2億円の資金調達を実施したことを{target=“_blank”}した。

リード投資家であるグロービス・キャピタル・パートナーズをはじめ、小学館、ANRI、SBIインベストメントなど、複数のベンチャーキャピタルおよび事業会社が出資に名を連ねている。

オレンジは、AIを活用した翻訳技術により、日本のマンガを外国語に翻訳し、世界各国での合法的な流通を支援することを目指している。同社は、未翻訳のマンガを大規模に海外展開するための「マンガに特化したローカライズ支援ツール」の開発を進めており、今回の資金はその拡張に充てられる。これにより、月間500冊という日本の現状の英訳ペースを大幅に上回るスピードでの翻訳が可能になるとしている。

!
:::small
画像の出典：{target=“_blank”}
:::

2024年夏には、米国法人を通じて新たな電子マンガストア「emaqi」をローンチする計画もあり、翻訳された作品を直接消費者に提供することで、海賊版による被害の防止にも寄与するという。

同社代表取締役の宇垣承宏代氏は「日本のマンガは、世界中で愛されている。しかし、言語の壁が大きな障壁となっており、非合法なコピーが横行しているのが現状だ。私たちの技術が、その問題を解決する一助となれば」と語る。

投資家の1人、グロービス・キャピタル・パートナーズの磯田将太氏は、「マンガは日本のソフトパワーの土台です。オレンジのミッションには、出版社をはじめとする業界関係者が大きな共感を寄せています」とコメントしている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 07 May 2024 15:03:18 +0000</pubDate></item><item><title>1ヶ月期間限定！本が好きな人必見　「AI書店員ダ・ヴィンチさん」があなたにぴったりの本を診断</title><link>https://ledge.ai/articles/ai_davinci</link><description>:::small
画像の出典：{target=“_blank”}
:::

4月26日、株式会社KADOKAWAは生成AIを活用した体験型コンテンツ「AI書店員ダ・ヴィンチさん」を全国5店舗で展開することを{target=“_blank”}した。

「AI書店員ダ・ヴィンチさん」から投げかけられる質問に回答していくと、自社の書籍から質問者に合ったタイトルを自動で診断してくれるコンテンツ。AI技術を駆使し、購入履歴の傾向から判断するのではなく、質問者の回答に基づいた「今のあなたにおすすめ」のタイトルを提案してくれるという面白いサービスだ。回答内容に応じて「なぜこの本がおすすめなのか」などコメントもその場で生成される。

もともと読書が好きな人はもちろん、何を選んだら良いか分からない、普段とは違う新しいジャンルに挑戦したいなど、本を読みたい気持ちがあれば誰でも有効に活用できる。

5月26日までの期間限定サービスのため新しい本に出会いたい人はこの機会をお見逃しなく。

:::box
【展開店舗は下記の5店舗】
・蔦屋書店 イオンタウン仙台泉大沢店（宮城県）
・丸善 日本橋店（東京都）
・有隣堂 横浜駅西口店（神奈川県）
・大垣書店 イオンモールKYOTO店（京都府）
・紀伊國屋書店 天王寺ミオ店（大阪府）
:::

:::box

:::

:::box

:::
</description><pubDate>Thu, 02 May 2024 10:04:57 +0000</pubDate></item><item><title>AI Picasso　商用利用可能なAIアート生成ツール「Emi 2」を無償公開　クリエイター尊重するAI開発　追加学習に無断転載画像用いず</title><link>https://ledge.ai/articles/ai_picasso_emi-2</link><description>:::small
画像の出典：{target=“_blank”}
:::

AI Picassoは2024年4月26日、AIアートに特化した高品質画像生成ツール「Emi 2」を{target=“_blank”}した。

Emi 2 は商用利用が可能で、追加学習において無断転載画像を用いていない。{target=“_blank”}より無償利用が可能だ。

同モデルは、初代「{target=“_blank”}」と同様、特にイラストやアニメ、マンガ生成に特化して開発され、NVIDIA H100を用いた最先端の開発機材によって支えられている。追加学習に無断転載画像を用いず、Stable Diffusion XL 1.0と同様のライセンスで、ユーザーは安心して商用利用が可能だという。


以下は、2023年10月に公開された第1弾のEmiとの比較画像。Emi 2は全身を描画する際に安定する傾向にあるとのこと。
（左: Emi / 右: Emi 2）
!
:::small
画像の出典：{target=“_blank”}
:::


同社は、クリエイターとの協力を重視しており、データの提供に対して適切な報酬を設定し、利益分配の仕組みを導入している。特に、「AIいらすとや」のプロジェクトは、内閣府の報告会においてクリエイターへの還元事例として紹介された。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、Emi 2がEmiと同様、クリエイターたちの声を聞きながら作られたと語る。Emiだけではなく、同社はXやDiscord上などで、他のモデルを含めたモデルのあり方について、クリエイターたちと対話を続けながら、信頼関係を築いていくと述べた。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 30 Apr 2024 01:46:37 +0000</pubDate></item><item><title>AI翻訳で世界中のマンガファンと語り合える！集英社が1か月期間限定でマンガコミュニティサイト「MANGA Plus Universe by SHUEISHA」を公開中</title><link>https://ledge.ai/articles/mangaplusuniverse_byshueisha</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月12日、株式会社集英社は株式会社アルと共同でマンガコミュニティサイト「MANGA Plus Universe by SHUEISHA」の提供を{target=“_blank”}した。

「MANGA Plus Universe by SHUEISHA」は、集英社が運営するマンガアプリ「少年ジャンプ＋」で配信している人気タイトル15作品について語り合えるコミュニティサイト。日本語だけではなく英語、スペイン語、タイ語、フランス語など9言語に対応しており、翻訳機能とマイクロソフトの生成AIを活用しより自然な会話を楽しむことができる。

!

:::small
画像の出典：{target=“_blank”}
:::

最新話が配信されると様々な国のユーザーの書き込みで賑わい、国内外問わずリアルタイムで世界中のマンガファンと言語の壁を越えて自由に語り合える魅力的なサイトだ。2024年5月13日までの期間限定公開で期間中は無料で利用することができる。

:::box

:::
:::box

:::</description><pubDate>Wed, 24 Apr 2024 08:18:13 +0000</pubDate></item><item><title>40年後のTEDはどんな感じ？OpenAI「Sora」で制作されたTED40周年記念ビデオ
</title><link>https://ledge.ai/articles/ted2024_sora</link><description>:::small
画像の出典：{target=“_blank”}
:::

“What will TED look like in 40 years? “ 「TED は 40 年後にはどのようになっているでしょうか? 」

2024年4月20日、TEDのX（旧Twitter）アカウントを通じ、動画生成AI「Sora」が描く40年後のTEDの姿を描いたビデオが{target=“_blank”}され、このプロジェクトが注目を集めている。

このビデオプロジェクトは、TEDの40周年を記念する「TED2024」に寄せて制作され、未来への期待とクリエイティビティを称える内容が盛り込まれている。TED2024は「The Brave and the Brilliant」というテーマで開催されたカンファレンスで、2024年4月15日から19日までカナダのバンクーバーで開催された。

このビデオは、アーティスト・作家・映画監督として多方面で活躍するPaul Trillo氏とOpenAIが協力し、話題の動画生成モデル「Sora」を用いて、40年後のTEDの姿を描いたビデオを制作。TEDのロゴを除く全てがAIによって生成され、未来の可能性を映像化しているという。

Paul Trillo氏は、未公開のAI「Sora」への初期アクセスを許されたアーティストで、これを用いた作品「{target=“_blank”}」は、3月にOpenAIのブログでも紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


40年後のTEDを描くSoraのビデオは、近日中に{target=“_blank”}で公開されるとのことだ。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Apr 2024 07:06:45 +0000</pubDate></item></channel></rss>