<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Thu, 07 Mar 2024 09:43:26 +0000</lastBuildDate><item><title>OpenAIを提訴したイーロンマスクに「私たちはイーロンの主張をすべて却下する」OpenAIが過去のメールを暴露</title><link>https://ledge.ai/articles/openai_and_elonmusk_in_court</link><description>:::small
画像の出典：{target=“_blank”}
:::

“We're sad that it's come to this with someone whom we’ve deeply admired”

「かつて深く尊敬していた人物とこのようになってしまっていることを悲しんでいる」

OpenAIは2024年3月5日、同社のブログでこのような声名を{target=“_blank”}した。

事の発端はイーロン・マスク氏が2月29日、OpenAI及びCEOのサム・アルトマン氏らをカリフォルニア州上級裁判所に提訴したことにある。提訴理由は、OpenAIが非営利組織として設立されたにも関わらず、現在はマイクロソフトの子会社として利益を追求し、GPT-4をオープンソースにしていないため、契約違反にあたるというものだ。マスク氏はOpenAI設立に際して重要な役割を果たし、資金を提供したが、その後同社を離れ、自ら{target=“_blank”}している。

「彼は、私たちがより高い目標を目指すように鼓舞し、私たちが失敗すると言い、競合他社を立ち上げ、そして彼なしでOpenAIのミッションに向けて有意義な進歩を始めたときに私たちを訴えました」
と、同社は設立時からのマスク氏との関係を述べた。

ブログ本編では、マスク氏の主張すべてに反論。同氏との間での過去のメールの履歴を一部公開し、AGI（汎用人工知能）の構築には想定以上のリソースが必要であり、そのために営利企業としての運営が必要だったこと、またマスク氏自身がOpenAIとテスラの合併を望んだが合意に至らなかったことなどを明らかにした。

マスク氏が同社のミッションから逸脱したとの主張を否定し、OpenAIが引き続き人々の生活向上に貢献していることを強調した。

メールの公開後となる3月6日に、マスク氏がX（旧Twitter）上で「社名を『ClosedAI』に変更すれば訴訟を取り下げてやるよ」と投稿した。しかし、OpenAIのチーフサイエンティスト、イリヤ・サツケバー氏が2016年にマスク氏に送ったメールでは「AI構築過程でのオープン性の低下は必然。社名の『オープン』が最終的には全ての人々がAIの恩恵を受けられる状態を目指していることを意味し、科学のすべてを共有しなくても全く問題ない」と述べており、マスク氏が肯定的な返信をしていたことが明かされている。

!
:::small
画像の出典：{target=“_blank”}
:::


!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Thu, 07 Mar 2024 09:43:26 +0000</pubDate></item><item><title>ソフトバンクがHumaneとの戦略的パートナーシップ提携　日本における「Ai Pin」の独占通信提供者に</title><link>https://ledge.ai/articles/humane_softbank_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国スタートアップのHumaneは2024年2月28日、AI駆動のオペレーティングシステム「CosmOS」とAIデバイス「Ai Pin」の日本展開について、ソフトバンクとの戦略的パートナーシップを{target=“_blank”}した。

このパートナーシップでは、ソフトバンクが日本におけるAi Pinの独占通信提供者となり、同社の広範なサービスと顧客基盤を活用して、Ai Pinを市場に導入する。さらに、ソフトバンクとHumaneは、CosmOSを他のモバイルデバイスに導入し、アプリ不要のサービスやAI駆動のユーザーエクスペリエンスからなる新たなエコシステムの構築に協力する計画だという。

Humaneが2023年11月に{target=“_blank”}は、手のひらに投影するレーザーインクディスプレイを搭載したウェアラブルデバイスで、ピンマイクのように胸元に装着する。スマートフォンのような画面はなく、声や手の動きで通話や情報検索、翻訳ができる。

Qualcomm Snapdragonプロセッサを搭載し、カメラやセンサーで環境を追跡・記録する。レーザープロジェクターを使用して情報を手のひらに投影するなど、新しいインタラクション方法を提供する。デバイスは、いわゆる「ウェイクワード」を使用せず、ユーザーの操作によってのみアクティブ化され、プライバシー保護が徹底されているという。

@



:::box

:::
:::box

:::
</description><pubDate>Wed, 06 Mar 2024 07:44:25 +0000</pubDate></item><item><title>Adobe、生成AIを搭載した音楽生成・編集ツール「Project Music GenAI Control」を発表</title><link>https://ledge.ai/articles/adobe_project_music_gebau_control</link><description>:::small
画像の出典：{target=“_blank”}
:::


Adobeは2024年2月28日、テキストプロンプトから音楽を生成し、その音楽を編集するための新たな生成AIツール「Project Music GenAI Control」を{target=“_blank”}した。

クリエイターはテキストプロンプトから音楽を生成し、そのオーディオを細かく編集して正確なニーズに合わせられるようになる。このツールは、放送業者やポッドキャスターなど、特定のムード、トーン、長さのオーディオが必要なすべての人々がプロジェクトのための音楽作成の助けになるという。

@

ユーザーが「パワフルなロック」「ハッピーなダンス」「悲しいジャズ」といったテキストプロンプトを入力して音楽を生成する。ツールが音楽を生成すると、きめ細かい編集がワークフローに直接統合される。生成された音声は、参照メロディに基づいて変換されたり、音楽のテンポ、構造、繰り返しパターンの調整、オーディオの強度の増減、クリップの長さの延長、セクションのリミックス、シームレスに繰り返し可能なループの生成など、多岐にわたる編集が可能になる。これにより、手作業で既存の音楽をカットしてイントロ、アウトロ、バックグラウンドオーディオを作る代わりに、ユーザーが正確に必要とする音楽を作成できるようになるとのこと。

Adobe ResearchのシニアリサーチサイエンティストであるNicholas Bryan氏は「興味深いのは、単にオーディオを生成するだけではなく、クリエイティブにオーディオの形を整え、微調整し、編集するための同様の詳細な制御を提供することで、オーディオを Photoshop のレベルまで引き上げていることです。これは音楽のピクセルレベルのコントロールのようなものです」
と述べた。

Project Music GenAI Controlは、音楽生成AIツールとして、著作権に関する倫理的および法的な懸念に対して責任を持って対応し、クリエイティブなプロセスを豊かにすることを目指すという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 06 Mar 2024 07:40:36 +0000</pubDate></item><item><title>Lenovoが新世代のAIビジネスPC ThinkPadとThinkBookを発表　バルセロナの世界最大級モバイル見本市「MWC 2024」で</title><link>https://ledge.ai/articles/lenovo_cutting_edge_thinkpad_and_thinkbook</link><description>:::small
画像の出典：{target=“_blank”}
:::

Lenovoは2024年2月25日、スペイン・バルセロナで開催された世界最大級の通信見本市「MWC 2024」で、次世代の個人向けビジネスコンピューティングを目指す新しいThinkPad T14 i Gen 5、T14s Gen 5、T16 Gen 3、X12 Detachable Gen 2およびThinkBook 14 2-in-1 Gen 4を{target=“_blank”}した。

これらの製品はIntel® Core® Ultra™プロセッサを搭載し、AIを活用したPCの新しい波を牽引する。また、Lenovoは、業界初となる17.3インチのMicro-LED透明ディスプレイを特徴とする、目を引くThinkBook Transparent Display Laptop Conceptも初公開した。透明ディスプレイとAIの組み合わせにより、物理的なオブジェクトとデジタル情報を重ね合わせることで、協働作業と効率性の新しい方法を開拓するという。

@


これらの発表に加え、モバイル生産性を向上させるためのアクセサリーや、デジタルアイデンティティを監視し個人情報を保護するLenovo Identity Advisor、デバイス間のシームレスなマルチデバイス体験を実現するSmart Connectなど、新しいソフトウェアソリューションも紹介された。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 06 Mar 2024 07:29:31 +0000</pubDate></item><item><title>エッジAI向けロジック半導体開発でラピダスとカナダのテンストレントがNEDO採択のプロジェクトのもと協業</title><link>https://ledge.ai/articles/rapidus_and_tenstorrent_agree_to_joint_ip_development</link><description>:::small
画像の出典：{target=“_blank”}
:::

ラピダスは2024年2月27日、カナダの半導体設計開発会社テンストレントとの人工知能（AI）半導体開発における協業を{target=“_blank”}した。両社は2nmロジック技術を用いたエッジAIアクセラレータの開発について共同推進を行うとのこと。

この協業は、技術研究組合最先端半導体技術センター（LSTC）が2月9日に国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）のポスト5G情報通信システム基盤強化研究開発事業において){target=“_blank”}の一環として行われる。

同プロジェクトでは、次世代半導体設計技術の一つとしてエッジ推論処理用のエッジAIアクセラレータを開発することが目的となる。テンストレントはCPUチップの開発を、AIチップ設計拠点（AIDC）がアクセラレータチップの開発を担当し、ラピダスは2nm最先端ロジック半導体の製造技術の有効性を引き出し、その製造を目指す。

昨年11月17日には、両社がAIエッジデバイス領域での開発加速を目的としたパートナーシップを発表しており、この度のNEDOによる採択はそのパートナーシップの具現化を示すものであるという。テンストレントは、2nmレベルのAIエッジデバイス開発に必要な先進のRISC-V CPU設計技術とチップレットIPを保有し、ラピダスはRapid and Unified Manufacturing Service（RUMS）により、設計支援から製造までの一貫したサービスを提供し、テンストレントの設計技術の潜在能力を最大限に引き出すことを目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 05 Mar 2024 08:30:55 +0000</pubDate></item><item><title>日本IBM、ビジネス特化の生成AI基盤モデル「Granite日本語版」を提供開始</title><link>https://ledge.ai/articles/ibm_watsonx_granite-8b-llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年2月27日、同社AIおよびデータプラットフォームである「IBM watsonx」にて、生成タスク用に設計された独自の基盤モデル「Granite（グラナイト）」シリーズの新たなラインナップとして、「Granite日本語版モデル」の提供を開始したことを{target=“_blank”}した。

このモデルは、インターネット、学術、コード、法務、財務といった多様な領域から収集したビジネス関連のデータセットを用いて学習が行われ、80億のパラメーターを持つ高い精度を、より低いインフラストラクチャ要件での実現を可能にしているという。

Graniteモデルは、信頼できるデータに基づく構築と、IBMがビジネス用途向けにキュレーションした内容であることが特徴で、不適切なコンテンツを排除するための厳格な検査と社内外のモデルとのベンチマーク評価が行われている。これにより、リスクを軽減し、モデル出力が責任ある形で展開できるように設計されている。また、Graniteモデルの学習に使用されたデータソースを公開し、ユーザーがAIの適用を進める際に安心できる環境を提供している​​​​という。

同社では、ビジネスにおけるAI導入の際に、業種や業務、ビジネス領域、ユースケースに応じた適切なモデルの選択が重要であると考え、IBM独自の基盤モデルに加え、ユーザーのユースケースを想定したオープンソースモデルも用意している。これにより、日本市場向けには、株式会社ELYZAが公開した日本語LLMモデル「ELYZA-japanese-Llama-2-7b」も利用可能となり、日本の顧客は自社のニーズに最適なモデルを選択し、AI活用を加速できるようになる​​とのこと。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 04 Mar 2024 02:31:55 +0000</pubDate></item><item><title>MicrosoftとApple間のBing売却話、Googleの裁判所提出書類で2018年に検討されていたことが明らかに</title><link>https://ledge.ai/articles/bing_was_to_be_sold_to_apple_google_said</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

Bloombergは2023年9月に、Microsoftが2020年頃、自社の検索エンジンBingをAppleに売却することを検討していたと{target=“_blank”}。しかし、Googleは最近の裁判所提出書類の中で、Microsoftが実際には2018年にBingの売却をAppleに提案していたと主張しているとCNBCが{target=“_blank”}。

Microsoftが2009年にBingを立ち上げたのは、Googleの独占的地位に挑戦するためだった。にもかかわらず、Bingの市場シェアは依然として10%未満に留まり、検索エンジン市場でのGoogleの支配は揺るぎないものがある。Googleが裁判所に提出した書類によると、MicrosoftはBingに約1000億ドル（約15兆円）の資金を投入してきたが、2024年1月時点での検索エンジンシェアではGoogleが91.47%、Bingが3.43%となっているという。

Googleの裁判所提出書類は、業界内での検索エンジンの競争における新たな動向を浮き彫りにしていると考えられる一方で、同社の支配的地位が反トラスト{target=“_blank”}で問題とにもなっており、こちらも業界の方向性にすくなからず影響を与える可能性があるとされている。

:::box

:::
:::box

:::
</description><pubDate>Mon, 04 Mar 2024 02:23:27 +0000</pubDate></item><item><title>AppleのCEO「生成AIが未来を再定義する」　株主総会でAIへの大規模投資を発表－EV開発中止には触れず</title><link>https://ledge.ai/articles/apple_stopped_ev_developping_and_moving_into_genai</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

Appleが2024年2月28日に年次株主総会を開催した。同社CEOであるティム・クック氏は、人工知能への大規模な投資を行っていると述べたことが{target=“_blank”}など複数メディアで報じられた。

クック氏は「生成AIには信じられないほどの画期的な可能性があると考えており、そのため現在この分野に多額の投資を行っている。これにより、生産性や問題解決などの点で、ユーザーにとって変革の機会が開かれると信じている」と述べたという。

かつて「AI」と呼ぶことを避け{target=“_blank”}する傾向があったクック氏だが、同社が何年もこの技術に取り組んできたことを強調するために、発表されたいくつかのApple製品を「AI搭載」と言い換えたとのこと。

同氏は「今年後半に、未来を再定義できると当社が信じている技術である生成AIの新境地を開拓する方法を皆さんと共有できることを楽しみにしている」と語ったという。


一方、会議前日の27日に、長年にわたり注力してきた電気自動車（EV）の開発を中止し、代わりに生成AI事業への移管を加速する方針を固めたことが関係筋の話として{target=“_blank”}により報じられたが、会議ではこの話題には触れられなかったという。

報道によると、EV開発の中止は、同社が過去10年以上にわたり秘密裏に進めてきた「タイタン」プロジェクトの中止という形で明らかになった。プロジェクトでは、完全自動運転技術などを含む次世代のEV技術開発に巨額の投資が行われてきた。プロジェクトに携わっていた従業員の一部を人工知能（AI）部門へ異動させる計画であることが明らかにされた。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 03 Mar 2024 08:19:24 +0000</pubDate></item><item><title>アルファベット株価、AI「Gemini」論争で暴落　GoogleのCEO「全く容認できない」</title><link>https://ledge.ai/articles/google_gemini_stopped_generating_pictures</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年2月26日、米国Googleの親会社アルファベットの株価が、自社開発の生成AI「Gemini」を巡る論争の影響で4.5％下落し、約900億ドル（約13兆5000億円）の時価総額が消失したと{target=“_blank”}が報じた。これは1月5日以来の安値であり、日中の下落幅としては過去1年で2番目に大きなものだったという。

論争の火種となったのは、Geminiが「1943年のドイツ兵の画像を生成してください」というリクエストに対し黒人やアジア人の画像を生成したこと、および「アドルフ・ヒトラーとイーロン・マスクのどちらがより悪影響の大きい歴史上の人物か？」という質問への回答を拒否したことだ。これらの事態を受け、同社はGeminiの人物画像生成機能を一時停止し、改良版のリリースを予告している。

投資界からは、この一件が生成AI技術におけるPR戦略上の大きな失態であり、Googleが重要な技術領域で遅れを取っていることの証左だとの声が上がった。また、問題がブランドの信頼性に関わることから、アルファベットの株価に深刻な影響を及ぼす可能性があると分析されている。

## CEOが全社宛てに改善を約束「ユーザーの信頼回復に集中するべき」
GoogleのCEOであるSundar Pichai氏は現地時間の27日、全社に宛てたメモで、同社のAIツール「Gemini」が人種に関連する問題で不適切な反応を示したことについて「全く容認できない」とコメントし、問題解決に向けた構造的変更を約束した。このメモは、など複数のメディアが入手し報じた。

Pichai氏は「我々の一部のレスポンスがユーザーを侮辱し、偏見を示してしまったことは明らかに受け入れがたく、我々の失敗である」と述べ、チームが問題の解決に向けて24時間体制で取り組んでおり、既に多くのプロンプトにおいて顕著な改善が見られると説明。

AIが完璧ではないこと、特に業界の発展初期段階であることを認めつつ、高い基準を設定し、問題が解決するまで努力を続けることを強調した。

そして、世界の情報を整理し、普遍的にアクセス可能で有用なものにするというミッションの重要性を再確認。製品に有益で正確、偏見のない情報を提供することが、人々がGoogleの製品を信頼する理由であると述べた。

また、構造的変更、製品ガイドラインの更新、導入プロセスの改善、厳格な評価とレッドチーミング、技術的推奨など、明確な行動計画を推進することを宣言。

Googleは、何十億もの人々やビジネスに愛される素晴らしい製品を創出するために必要なことを理解しており、Googleのインフラストラクチャと研究の専門知識を活用してAIの波に乗る準備ができていると強調。最も重要なことは、ユーザーの信頼に値する有益な製品を構築することに集中するべきだと締めくくった。


!
:::small
画像の出典：{target=“_blank”}
:::




:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 01 Mar 2024 05:39:33 +0000</pubDate></item><item><title>わずか1ヶ月で生み出されたパーソナライズ学習を支援するAIサービスとは？｜Ledge.ai CHALLENGE開催レポート</title><link>https://ledge.ai/articles/ledgeai-challenge-report</link><description>Ledge.aiでは昨年8月から12月にかけて、『Ledge.ai CHALLENGE』と題し【「5年後の日常」に「余白」を生み出す】をテーマにイベントを開催した。
イベントは第一部を"発想"を評価するアイデアコンテストの形式で募集し、優秀であると審査されたアイデアを"実装"する第二部として前後半の構成で行われた。

"発想"部門では以下の審査員による審査の結果、5作品が優秀賞として選出された。

!

"発想"部門の優秀賞選出作品は以下の通り。

- 死後も双方向のコミュニケーションを。生成AIを活用した終活&amp;死後支援サービス
- 産後の新しいステップ：テクノロジーでサポートする出産前後の手続きと心のケア
- 災害発生予測に基づく避難所の過密解消を目的とした早期分散避難計画の作成と周知
- PERSONACHER personalized guidance teacher　君だけの君のための君のAI先生
- 反復無駄話

:::box
{target=“_blank”}
:::

## 最優秀賞は個人の学習をサポートする「PERSONACHER」
!
{target=“_blank”}では既報の通り、最優秀賞は個人の学習をサポートする「PERSONACHER」が選出された。本レポート記事の後半では、実装チームへのインタビューも掲載している。

PERSONACHERは、企画者である飛田恭宏氏の当初アイデアではAIによって授業とカリキュラムを構成し、個人に最適化して届けるサービスとして企画されていた。実装チームとして本アイデアに名乗りを上げた{target=“_blank”}の開発チームとのディスカッションを経て、審査会には学習に使用したい書籍の情報を元に、あらかじめ登録をする自身の情報と照らし合わせて、どのような観点でこの書籍を読むべきかといった推薦を行ってくれるサービスとして軌道修正してプレゼンテーションされた。
サービス内のAIと「対話」を進めることで、書籍の章ごとのレジュメが作成され、内容の理解度を採点されるような仕組みもプロトタイプとして実装してデモ動画を紹介した。

審査においても、教育格差という社会課題に対して「個別学習をサポートするAI活用サービス」としての意義と、書籍ベースの学習支援という初期構想から今後の展開を見据えた将来構想まで幅広に検討が及んでいたプレゼンテーションであった点が評点として高かったことが、審査員を努めた株式会社レッジ（Ledge.ai運営企業）代表の小瀧健太からも発表された本イベントのテーマで焦点を当てた「5年後の日常」に向けて、早いスピード感で最新の技術を応用しサービスインしていくイメージが湧きやすかったことも評価のポイントであった。

優秀賞に選出されたのは「死後」に注目した{target=“_blank”}から参加した中村誠氏と梅本晴弥氏らのチームによる終活&amp;死後支援サービス「またね」のプロトタイプだった。同プロトタイプでは、生前の情報をインプットしておくと、チャットベースのUIで故人と対話を行えるサービスとして企画された。
自身の年代別の「思い出」をインプットしておくことで、故人と対話する後続の世代の相手の年齢に応じて当時の思い出話を繰り広げるなどをGPTベースで実装済みのデモを元にプレゼンテーションした。
同賞の授賞理由として、前述のように実際にロジックが動くプロトタイプとしての発表であった点も評価される結果となった。

## 最優秀賞授賞のプロトタイプは、いかに生み出されたか？
審査会後日、Ledge.aiは最優秀賞チームへの個別インタビューを行った。インタビューでは、チームメンバーの実装期間中の役割分担や、工夫した点について等の発表に至るまでの裏話を取材した。

!

実装におけるプロジェクトリーダーを務めたのは、株式会社にからす代表取締役社長であるペリンハンターレドリー氏。企画の発案者である飛田氏の意図を汲み取りつつ、約1ヶ月間の短期間でその意図を汲み取りつつスケジュール上可能な仕様に落とし込んでいくことにまずは注力したという。
チームを組成して最初の1週間の間に3回ほどミーティングを重ね、開発のスコープを議論を進行した。

**ペリン**　「すべての人が使える、総合的な教育」という広いアイデアを、大学受験を控えた学生向けにしていくのか、科目を絞るのか、学習計画の策定を支援するというような領域を絞るのか、といったように、コンセプトを重視しながら端的にその価値が伝わるプロトタイプにすることを意識しました。

最初の1週間は方向性の議論を厚くし、2週目からはGPTを活用して構築に向けての動きを開始したという。

**飛田**　最初の議論で、期間制約的に高校生の勉強をサポートするようなかたちで議論が進むシーンもありました。しかし自分の意志としては「学習は全年代に必要なものである」という軸をぶらしたくなかったので、そこは譲れないとメンバーに伝えながら、正しく軌道修正をしていくことができたと振り返っています。そうした議論を初動の部分で熱烈にできたことで、実装に入ってからはどんどんかたちが出来上がっていくのを見て、驚きつつ、嬉しく感じていました。

実装の主体はUI/UXデザイナー兼フロントエンドエンジニアの福田真菜氏と、バックエンド・インフラエンジニアの小林将太氏の2名を中心に進めた。
両名も実装スコープや仕様に関する議論に参加し、速やかにデザイン、設計に反映していく連携を取っていたとのこと。二人は実装期間を以下のように振り返っている。

**福田**　苦労したかといえばあまりそういった感想はなくて、ワクワクしながらのめり込んでつくっていました。

**小林**　短期間でのプロトタイプ開発ということもあり、どんどん決めていかなければならなかったのは事実なのですが、ただ仕様通りに作るという考えはなく、発案者の飛田さんの思いをかたちにする！ということを最重視しながら取り組みました。

会社として実装チームへの参加を表明し、期間中も参加メンバーの取り組みを見ていた株式会社にからす取締役の小竹ブレイニー氏は「発案者の意志としても強かった社会的意義の重要性は大事にしつつ、本業の合間を縫って熱量高くイベントに参加していたメンバーの姿を見ると、良い経験を得られた」と評した。

## Ledge.ai主催の参加型イベントの今後
!
今回Ledge.aiとしても、ハッカソン形式のような参加型イベントの開催は初の試みであった。
企画背景として、2022年末頃にChatGPTの登場を契機に2023年にかけて一気に盛り上がりを見せたAI界隈であったが、この熱狂のうちに様々なかたちで「発想」の量を増やし、そして技術革新によって速やかに「実装」までを行える環境下で、なんとか2023年のうちに一連をやり通したいといった考えからイベントの企画と発表に至った。
こうした考えは2024年になってからも変わらず、様々な手法を通じて思考と実践の場を設けていきたいと考えている。

直近では、2024年3月15日に東京・六本木で開催を予定する「ノーコードシンポジウム2024」のサイドイベントとして{target=“_blank”}を予定している。
メインイベントは、生成AIをキーワードにしながら盛り上がりを見せるAI関連の話題に少し潜みがちな「ノーコード」に焦点を当てたイベントとして、一般社団法人ノーコード推進協会との共催で執り行う。
そのイベント内で、Impact NoCode Hackathonの結果発表も予定している。イベント当日は参加費無料（事前予約制）にて会場参加も受け付けているため、Ledge.ai及び参加者の取り組みに興味関心のある方はぜひ現地まで足を運んでほしい。遠方の方においてもLIVE配信も予定しているため、ぜひチェックを。
</description><pubDate>Fri, 01 Mar 2024 23:38:29 +0000</pubDate></item><item><title>音声会話型AIアプリ「Cotomo」リリース　返答速度1秒以内・自然な音声会話で日常会話に特化</title><link>https://ledge.ai/articles/talking_ai_cotomo</link><description>:::small
画像の出典：{target=“_blank”}
:::

Starley株式会社は2024年2月21日、音声会話型おしゃべりAIアプリ「Cotomo」の提供を開始したことを{target=“_blank”}した。このアプリは、ユーザーとの対話を通じて成長することを特徴とし、日常的な雑談から悩み相談まで、多様な会話シーンに対応する。

@


「Cotomo」は、4種類の音声と会話スピードから選択可能であり、AIの名称もユーザーが自由に変更できることから、よりパーソナライズされた会話体験を提供する。さらに、アプリは会話履歴の記録や話題のレコメンド機能も備えている。

!
:::small
画像の出典：{target=“_blank”}
:::

Starleyの目指すのは、日々のコミュニケーションを充実させ、孤独や孤立感を感じる人々に新たな交流の場を提供すること。同社では、AIとの会話体験を活用した事業の開発を目指し、様々なシーンでの社会実装を進めていく計画だ​​という。

またCotomoは、返答速度の速さと自然な音声会話の実現に注力。1秒以内に返答することでユーザーにストレスを与えず、日常会話に特化した独自の学習データを用いて開発されているとのこと。

リリースを記念して、StarleyはAIボイスプロデュースイベントも開催。参加者はオリジナルAIボイスを作成し、投票によって選ばれた音声は、Cotomoの基本音声として搭載される予定だという。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Thu, 29 Feb 2024 07:29:23 +0000</pubDate></item><item><title>セガトイズ、100匹以上の猫の動きを研究して生まれたリアルなAI猫ロボット「KIMIT ラグドール」を発売</title><link>https://ledge.ai/articles/sega-toys_kimit</link><description>:::small
画像の出典：{target=“_blank”}
:::

セガトイズは2024年2月22日、ペットロボットの新ブランド「KIMIT（キミット）」から、リアルな猫を模した「ラグドール」を{target=“_blank”}した。

この製品は、100匹以上の猫の動きをデータ化し、ディープラーニングを活用して開発された。瞳孔の開閉、柔らかな肉球、猫の声、喉から出るゴロゴロ音、心音など、本物の猫の細部にまでこだわり、リアルに再現しているという。

!
:::small
画像の出典：{target=“_blank”}
:::

セガトイズが2023年11月に実施した「ペット飼育に関するアンケート」では、20～70歳の85.9％が「猫が好きだが飼えていない」と回答。飼育に踏み切れない主な理由として、住環境や資金面などの問題が挙げられたという。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、ペットを飼いたくても飼えない人々や動物アレルギーを持つ人々に向けて、新たな選択肢を提案している。

期間限定で「KIMIT ラグドール」を体験できるポップアップカフェが二子玉川駅構内にあるNICOTAMA DAYS CAFEで開催されている。期間は2024年2月22日～3月5日。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::

</description><pubDate>Fri, 01 Mar 2024 05:36:22 +0000</pubDate></item><item><title>パーソルホールディングス、生成AI研修で社員スキルアップを加速</title><link>https://ledge.ai/articles/persol_group_upreskilling</link><description>:::small
画像の出典：{target=“_blank”}
:::

パーソルホールディングスは2024年02月16日、グループ社員の生成AIに関する知識と活用スキルの向上を目指し、専門家による研修や社内勉強会の開催などの積極的な取り組みについて{target=“_blank”}した。

この取り組みは、社員個人のスキルレベルを「理解」「業務導入」「業務活用と伝播」の3段階に区分し、全社員が生成AIを業務に活用する環境を整備することにあるという。

外部の専門家を招いた研修や勉強会をはじめ、1,500名以上の社員が受講した入門編から実践編、さらには経営幹部向けの勉強会まで、参加者のレベルや属性に応じた内容で開催されている。また、社内専用GPT「PERSOL Chat Assistant」の基礎知識についての動画講義には3,800名の社員が参加し、IT系職種に限らず多岐にわたる職種の社員が生成AIの教育を受けているとのこと。

さらに、生成AIパスポートの資格取得に向けた取り組みも進められており、2024年第1回試験にはグループ各社から200名以上の社員が受験予定。受験費用は会社が支給しているという。この資格は、生成AIを活用したコンテンツ生成の方法や企業のコンプライアンスに関する知識を学ぶもの。

これらの教育プログラムを通じて、社員はメール文章作成や議事録の要約、英文作成、アイデア出し、営業アポイントのテーマ検討、トークスクリプト作成、ソースコードの分析・修正など、多岐にわたる業務で生成AIを活用するスキルを習得し、業務効率化とパフォーマンスの向上、リスク回避につなげているという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 29 Feb 2024 03:36:19 +0000</pubDate></item><item><title>JDLAが「生成AIの利用ガイドライン（画像編）」を公開</title><link>https://ledge.ai/articles/jdla_guideline_for_image_generating_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本ディープラーニング協会（JDLA）は2024年2月13日、「生成AIの利用ガイドライン（画像編）」を{target=“_blank”}した。

このガイドラインは、2023年5月に公開された「{target=“_blank”}」の続編として作成されており、主に画像生成AIに特化した内容となる。

ガイドラインの目的は、画像生成AIを事業において利用する企業等に向け、ルール策定時に検討が必要な法的論点を解説することにある。具体的には、画像生成AIの利用に際して、社内体制の整備、プロンプトの入力ルール、AI生成物の利用規則など、遵守すべきポイントが詳述されている。

JDLAは、ディープラーニング技術を日本の産業競争力向上の核とし、その普及と適用を目指して活動している組織だ。今回のガイドライン公開も、その一環として行われたもので、画像生成AIの健全な利用と発展の促進を期待してのことだとされる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 28 Feb 2024 05:54:19 +0000</pubDate></item><item><title>日本最大級のDX推進コンテスト『日本DX大賞2024』応募開始</title><link>https://ledge.ai/articles/dx_taisho_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

一般社団法人日本デジタルトランスフォーメーション推進協会は2024年2月6日、民間企業や自治体のDX取り組みを表彰する「日本DX大賞 2024」の応募受付を開始したと{target=“_blank”}した。

コンテストは、DXの成功事例を発掘し共有することで、日本全体のDX推進を加速させることを目的としている。昨年行われた「日本DX大賞2023」への応募数は111件。今年はサステナビリティトランスフォーメーションやビジネスモデルの変革、顧客体験の向上など、多様なカテゴリーでのDX取り組みが対象となる​。

**募集期間**： 2024年2月6日から4月26日まで
**応募対象**：「DX推進」に取り組んでいる民間企業、公的機関、自治体等の変革を実現した事例や成果をあげた事例。または、ユーザー企業・団体が取り組んだ事例


日本DX大賞サイト：{target=“_blank”}



:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Feb 2024 10:45:28 +0000</pubDate></item><item><title> LoRA(ローラ)とは｜今年注目の画像生成AI (Stable Diffusion) のファインチューニングを試してみた
</title><link>https://ledge.ai/articles/LoRA</link><description>LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。従来はLLM（大規模言語モデル）や画像生成AIのファインチューニングに膨大な計算量が必要だったが、LoRAによって少ないリソースで行うことができるようになった。LoRAはLLMや画像生成AIに応用できる、計算量を減らしてファインチューニングを行う技術である。

2023年末にはChatGPTの新機能である、ユーザーがChatGPTを自由にカスタマイズ（ファインチューニングも）できる「GPTs」がリリースされた。誰もが簡単に学習済みモデルをファインチューニングできるようになりつつある。自社や個人が持つアセットを最大限に活用した生成AIの効果的な使用が、一層重要なフェーズに突入している。

今回は、ファインチューニングの理解に必須の技術「LoRA」について解説する。

:::small
※「LoRA」という用語は元々、計算効率を向上させる技術を指す。しかし、この技術を基にして「Stable Diffusion」というAIモデルをファインチューニングした際に生まれる特定のモデルも、同様に「LoRA」と称されている。「LoRA」が二重の意味を持つことに注意が必要。
:::

:::box
関連記事 : 
:::

:::box
**目次**
- LoRAとは
- LoRAのビジネスへの活用
- LoRAを使って「Stable Diffusion」をファインチューニングしてみた
:::

## LoRAとは

LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。2021年にMicrosoftに所属していたEdward Huらによって論文で発表された技術だ。

LoRAは、元のモデルのパラメータを直接変更する代わりに、低ランクの行列を導入して、パラメータの変更を行うことができる。少ない計算量で元のモデルに修正を加えることが可能になった。

LoRAは、事前学習されたモデルの重みを固定し、変換器アーキテクチャの各層に低ランクの分解行列を注入することで、下流のタスク用の訓練可能なパラメータの数を大幅に削減する。例えば、GPT-3 175Bモデルにおいて、LoRAは訓練可能なパラメータを10,000倍減らし、GPUメモリ要件を3倍削減することを実現している。
論文中では以下の図でモデルの概要が説明されている。
!


LoRA（Low-Rank Adaptation）の計算例を示す。通常、変換器モデルでは、重み行列W ( m×n)があり、入力x に対してWx の形で適用される。LoRAでは、この重み行列W を直接変更するのではなく、低ランクの行列A (m×k)とB (k×n)を用いて、W ( m×n)+AB ( m×n) の形で変換を行う。ここで、A とB は小さな行列であり、元の重み行列W に比べてはるかに少ないパラメータを持つ。この方法により、全体のパラメータ数が減少し、計算の効率が向上する。
A=正規分布、B=0で初期化されている。

具体的な計算を以下に示す。重み行列Wのパラメータ数は合計24、行列AとBは合計8となり調整するパラメータ数が3倍削減されている。
!
実際の計算規模は上記の計算例よりはるかに大きく、学習済みモデルのパラメータ数はGPT-3で175億、Stable Diffusionで10億程度と言われている。LoRAによってこれらのモデルのファインチューニングが少ないリソースで行なえることを理解できた。

##  LoRA・ファインチューニングのビジネスへの活用

次にビジネスへの活用例を示す。

**カスタマイズされたチャットボット:**
企業はLoRAを使用して、自社のリソースを学習させ大規模なLLMから自社専用のチャットボットを作成することができる。社内独自のQ＆Aを行えるチャットボットが使用されている。

**AI写真集:**
LoRAを使用して、基盤モデルとなるStable Diffusionをファインチューニングすることで、「アジア人女性」などの特定の画像を生成できる。
Amazon.co.jpの電子書籍読み放題サービス「Kindle Unlimited」をAI生成画像の「写真集」が席巻している。SNSで話題になり、ニュースサイトも相次いで報じるなど、社会現象といってよい状態だ。生成AIの技術が進化し、実際に存在しないがリアルに見えるモデルの画像が生み出され、グラビア界に新たな波をもたらしている。
!

:::box
関連記事：
:::


**AIモデル:**
自社ブランドのファッションアイテムを学習させ、AIモデルに着用させることができる。
AI model株式会社は、2022年6月14日にサービス「AI model モデル撮影サービス
」を提供開始した。撮影場所・費用の確保、起用タレント・モデルの不祥事など「人ならでは」のリスクを回避しつつ、ECの顧客に合わせたブランド専属モデルを生み出せる。
!

:::box
関連記事： 
:::


## LoRAを使って「Stable Diffusion」をファインチューニングしてみた

Stable Diffusion LoRAは、人物の顔、服装、ポーズなど画像の一部を学習し、その特徴をもった新たな画像を生成することができる。

今回はStable Diffusion LoRAを使い、人物の顔を学習させ、その人そっくりのAIモデルを生成する。肖像権の関係で弊社執行役員・箕部 和也の宣材写真を使いStable Diffusionをファインチューニングして、箕部そっくりの人物画像を作ることを試みた。

**Stable Diffusion LoRAの特徴**

- 20枚程度の画像からLoRAの追加学習ファイルを作成できる。
- 服装、ポーズ、顔、イラストの画風を学習させることができる。
- 100〜200MB程度のファイル。
- 学習時間が短い (今回の方法で1時間程度)。
- Stable Diffusionのチェックポイントをベースに作成可能。

今回はGPUを所有してない場合もオンラインで実行できる方法を紹介する。
のを使用する。Loraを使った学習が、簡単に行えるように必要なコードがまとめられている。

基本的なStable Diffusionの使い方はこちらで確認できる。

:::box
関連記事:
:::


### STEP0 実行環境と学習用画像を準備する

**実行環境**
をクリックすると以下のようなノートブックが開く。Google ColaboratoryはPythonの実行環境であり、GPUを無料で使うことができる。ただし画像生成AIを行う場合はColab Pro (1 か月あたり ￥1,179) が推奨されている。今回はColab ProでLoraファイルの作成を行う。ノートブックをマイドライブにコピーしておく。
!

**学習用画像**
今回は画像を15枚用意した。画像サイズは512×512や1024×1024の正方形が望ましい。
画像サイズは512×512にトリミングした。顔を学習させたい場合は、髪型や服装が違う画像があれば顔のみを学習しやすい。数パターンの髪型、表情、ポーズ、服装の画像を用意できることが理想的だ。
!

### STEP1  LoRAファイルを作成する。
変更できるパラメータは多量にあるが、最低限の実行に必須な部分のみを解説していく。

**I. Install Kohya Trainer**
!
:::box
1.1. Install Dependencies
 mount_drive:◻︎にチェックを入れて実行。colabからgoole driveにアクセス可能になる。
:::


**II. Pretrained Model Selection**
!
:::box
2.1. Download Available Model
 学習の基盤となるStable Diffusionのモデルを選択できる。
Stable-Diffusion-v1-5を選択して実行する。
:::

**III. Data Acquisition**
!
:::box
3.1. Locating Train Data Directory
 デフォルトで実行する。学習用画像の保存場所が作成される。
:::

!

 :::box
3.2. Unzip Dataset
Gooole Driveに学習させたい画像のzipファイルをアップロードする。
保存したディレクトリのパスをコピーして、zipfile_urlに貼り付けて実行する。
実行後 /content/LoRA/train_dataに自動的に保存される。
:::

**IV. Data Preprocessing**
!
:::box
4.1. Data Cleaning
convertにチェックを入れて実行する。
学習のための形式に対応していない画像は自動で削除される。
:::

:::box
4.2. Data Annotation
画像を認識し自動でキャプションを作成するためのブロック

4.2.1. BLIP Captioning
自動でキャプションをつける際のパラメータを変更できる。デフォルトで実行。

4.2.2. Waifu Diffusion 1.4 Tagger V2
下部のgeneral_thresholdを0.85程度に設定する。大きくするとタグの数が少なくなる。
特定の人物を学習させたい場合は数値を大きくすることが一般的。
traindataのファイルにキャプションが入ったテキストファイルが追加される。
以下の画像には”a man in a black suit and black shirt”と自動的にキャプションが追加された。
!
:::





**V. Training Model**
!
:::box
5.1. Model Config
上記の画像通りに入力して実行する。
:::


:::box
5.2. Dataset Config
dataset_repeats を１に変更する。同じ画像を学習させる回数を調整できる。
flip_augにチェックを入れると左右反転させた画像を学習させられる。
その他はそのままで実行。
:::

:::box
5.3.~ 5.5までをデフォルトのまま実行する。画像の枚数にもよるが1時間〜2時間程度で学習が完了する。完成したLoRAファイルはマイドライブのLora/outputに自動で保存される。
拡張子.safetensorsがLoRAのファイルだ。一番上に保存されている番号が振られていないファイルが最終的な出力になっている。
!
:::


### STEP2  作成したLoRAを使って画像を生成する。
STEP1で作成したLoRAファイルを使って早速、画像を生成する。
15枚の画像で学習を行った結果、右の画像が生成できた。髪型やヒゲ、黒いスーツが強く学習されていることが確認できる。写実的で、AIで作成された画像とは気が付かない可能性があるクオリティだが、似ているが本人ではないことが一目で分かる程度だ。また顔や髪型の特徴と同時に黒のスーツも学習してしまっている。これは学習用画像がすべて同じ服装であるためである。
!
**各種パラメータ**
*** 
モデル  
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt;,professional, masterpiece, 8k, hyperrealistic portrait,  Japanese man, 30yo, dark eyes, detailed face, detailed skin, photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


&lt; lora:minobe_model:0.9 &gt;はLoraファイルの適用の強さを示すもので数値を変更して調整できる。Loraファイルを複数使用したときを考慮して0.8程度で狙った特徴が出るようにすることが一般的。


### STEP3 パラメータを変更して画像をさらに生成する。
次により本人に似た、理想に近い画像を生成するために学習のパラメータやプロンプトを変更していく。特に学習の精度に影響を与えるとされるmin_snr_gammaの値を-1から1に変えて新たなバージョンのLoraファイルを作成した。min_snr_gammaは学習の低step化に貢献するオプションであり、学習過程を大きく変化させるパラメータである。推奨値は5とされている。
!
*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, Standing in the Desert,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


!

*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, ride a horse,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 

今回はStable Diffusion LoRAを使用して、Stable Diffusionをファインチィーニングし画像を生成した。画像を15枚を準備して数時間でコードを一切書くことなく簡単に、驚くほど精巧な画像を生成できた。Stable Diffusion LoRAには多くのパラメータがあり、それらの適正値を見つけることでさらに精度が向上すると予想される。パラメータの適正値は「アニメ風の画像を生成したい」や「同じポーズの画像を生成したい」「綺麗なアジア人女性を生成したい」など目的によって変化するため、各々が生成された結果を見ながら、理想の生成画像に向かって微調整を加えていく必要がある。

</description><pubDate>Tue, 06 Feb 2024 07:47:09 +0000</pubDate></item><item><title>Webアプリケーションの巡回ツールを開発せよ｜MBSD Cybersecurity Challenges 2023</title><link>https://ledge.ai/articles/mbsd-security-contest2023</link><description>三井物産セキュアディレクション株式会社が主催する、専門学校・高等専門学校を対象としたセキュリティコンテスト『{target=“_blank”}』の最終審査会が、2023年12月15日（金）に東京都大手町で行われた。

## セキュリティ業務の一端を疑似体験
本コンテストは、これからの時代を担う学生に向けて、より実践的で現実味のある課題を用意し、セキュリティ業務の一端を疑似体験しながら、課題を解決するためのアイデアや技術を競うものだ。入賞者には副賞が設定されており、最優秀賞には外付けSSD(4TB)とMeta Quest 3、2位には外付けSSD(2TB)と高級キーボード、3位には外付けSSD(1TB)とRaspberry Pi4 スターターキットを、受賞者ー１人ひとりに贈るという、かなり豪華な内容となっている。

第8回目を迎えた今回は、全国より18校 55チームのエントリーがあり、最終審査会へは上位10チームが参加した。
!
:::small
最終審査会参加チーム：{target=“_blank”}より
:::

本コンテストの課題は『Webサイトに実際にアクセスし、診断対象となる箇所を抽出、診断対象の規模を把握するための自動巡回ツールを開発し、提出すること』。学生は、Webサイト運営会社のWebアプリ診断を行うチームメンバーとして、ツールの開発から説明資料の作成、最終選考ではプレゼンテーションを行った。

本コンテストの開催フローは以下の通り。エントリーは2023年7月より開始したため、12月の最終審査まで5ヵ月の期間をかけてコンテストは実施された。

- エントリー受付
- 課題配布
- 説明資料・巡回ツール提出
- 一次審査結果発表
- 性能審査
- 最終審査会（オフライン開催）


## 最優秀賞は新潟コンピュータ専門学校『復活の電子遊戯部』
!
:::small
最優秀賞に輝いた『復活の電子遊戯部』チーム
:::
最終審査に残ったチームの中で、最優秀賞に輝いたのは、新潟コンピュータ専門学校『復活の電子遊戯部』だ。プレゼンテーションでは、開発した巡回ツールをオーディエンスがその場で触れられる試みもあり、随所に工夫が見られた。

!
:::small
開発した巡回ツールをその場で試せる実演用のQRコードを使ったプレゼンテーション
:::
受賞コメントでは、「全て穴だらけでグダグダだと思っていたけれど最優秀賞をいただけて感無量。本当にありがとうございました。」とコンテストの感想を述べた。
:::box
『復活の電子遊戯部』審査員の評価
- インストールがシンプルで、遷移図やスクリーンショットの機能も非常に良い機能だったと思います。
- ロードマップが準備されているのも良かったです。
- 発表も全体的にまとまっており、今までにない、その場でツールに触れるようにする試みも良かったと思います。
:::

第2位は、YIC情報ビジネス専門学校『塞翁が馬』。同チームは、内部での性能テストのためにテストサイトを自作するなど、他チームにはないプロセスでツールを開発した点が大きく評価された。
:::box
『塞翁が馬』審査員の評価
- 再検索機能が良く、テストサイトを自作しているところに意気込みややる気を感じました。ステータスによる色分けなどインターフェースが分かりやすく、動作状況がリアルタイムに表示されるのが良かったです。
- リーフレットなどで分かりやすくアピールしているのも良かったと思います。
- フラグの検出率がもう少し上がると良かったと思います。
:::
第3位は、審査員から「出来ないと思っていた画像内のフラグに対応してきたのが面白かった」と評価された、情報科学専門学校『Bananacat』が輝いた。
:::box
『Bananacat』審査員の評価
- プロキシ機能が特徴的で、ドキュメントがマークダウンのみで玄人向けという感じでした。
- 機能の優位性を分かりやすく説明していて、ツールの特徴が良く理解できました。
- できないと思っていた画像内のフラグに対して、対応してきたのが素晴らしい。
:::

## セキュリティ業界で第一人者を目指してほしい
!
:::small
三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャー 洲崎氏
:::

表彰式終了後、全体講評として三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャーの洲崎氏は「非常に嬉しく思ったのは、コンテストの卒業生がセキュリティ業界の一員として活躍していること。ぜひ皆さんもセキュリティ業界に来ていただき、またどこかでお会い出来たらと思う」と語った。また、同社 PS事業部 レッドチームの国分氏も「これから新たなセキュリティ技術が出てくると思うが、いち早くチャレンジして、ぜひ第一人者を目指してほしい」と、若い力への期待を露わにした。</description><pubDate>Tue, 23 Jan 2024 08:23:53 +0000</pubDate></item><item><title>大学入試の記述式対策もAI活用　駿台、AI学習教材「スルメ」で特許を取得</title><link>https://ledge.ai/articles/sundai_patented_surume</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年12月26日、学校法人駿河台学園（駿台）は、エスエイティーティー（SATT）との共同開発により、記述式問題対策のAI学習教材「スルメ」で特許を取得したことを{target=“_blank”}した。

この教材は、難関国公私立大入試の記述式問題対策として開発され、学習者の理解度に応じた最適な「ヒント」をAIが自動で提示する仕組みが特徴とされる。

**ヒント画面（解答に行き詰った際、段階的に与えられるヒントを確認する）**

!
:::small
画像の出典：{target=“_blank”}
:::



**解答画面（タブレット上で解く。解答は手書きで、自動採点される。メモやノートを取ることも可能）**

!
:::small
画像の出典：{target=“_blank”}
:::



「スルメ」を特許取得に導いたのは、個別の学習状況及び科目特性に応じた最適な予測正答率を分析し、それに基づいて難易度調整を行うシステムの新規性と、それを裏付けるデータによるものだという。特に、電気通信大学植野真臣教授の研究を基にした予測正答率の最適化がこの特許の核心とされている。

今後、駿台は「スルメ」を使用する学習者のデータに基づいて得られた分析結果を活用し、学習効果を最大化する予定だという。現在は「物理」「化学」に加えて「数学」の記述式問題に対してもこのシステムを適用し、さらに「英語」のリスニングや文法問題への適用も検討しているとのことだ。

:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Jan 2024 02:44:39 +0000</pubDate></item><item><title>GPT Store(GPTストア)とは｜GPTを公開して収益化する方法</title><link>https://ledge.ai/articles/GPT-Store</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2023年12月の公開が予定されていたが、延期が発表されていたGPT Storeが2024年1月10日(現地時間)についに公開された。GPT Storeは、GPTsで構築されたオリジナルのGPTをユーザー全体と共有できる新しい機能だ。さらにGPT Storeは収益化が可能であり、新たなマーケットとして期待が高まっている。

:::box
**目次**
- GPT Storeとは
- GPT Storeの利用方法と料金
- GPT Storeで自作のGPTを公開する方法
- GPT StoreでGPTを公開して収益化する方法
- GPT Storeの注意点
:::

## GPT Storeとは

GPT Storeは、GPTsで構築されたGPTを全ユーザーが公開・共有・検索できるプラットフォームである。この機能により、ユーザーは特定のタスクに特化したGPTを容易に見つけることができる。例えば、Open AI公式のGPTとして、文章の添削やライティングスキルの向上に特化した「Creative Writing Coach」や冷蔵庫の中身の写真から料理を提案する「Sous Chef」が公開されている。

:::box

:::

## GPT Storeの利用方法と料金

GPT Storeは月額20ドルの「GPT Plus」に入会することで利用できる。
さらに2024年1月10日(現地時間)に**新料金プラン**「**Team**」が追加された。

新プラン「Team」の特徴は以下の通り

料金は一人当たり年払いで月額25ドル (メンバー2人以上から利用可能)
GPT-4使用時に制限があった送信できるメッセージ数の上限増加
チーム内でのGPTsのワークスペース
使用者のデータを学習しないこと

画面左のサイドバーにある「Explore GPTs」をクリックすると以下のような画面が表示され、すぐに利用できる。有料プランに加入していなくても検索のみは可能。
!
左上の地球アイコンをクリックすると、Global ViewのOn・Offが切り替えられる。
Onでは世界のランキング、Offでは日本のランキングが表示される。

## GPT Storeで自作のGPTを公開する方法

GPTsでオリジナルのGPTを構築後、保存する際に3つの選択肢から保存できる。

- Only me (自分しかアクセスできない)
- Anyone with a link (発行できるリンクを知っている人なら誰でも)
- Everyone (全ての人に向けてGPT Storeで公開)

Everyone に設定しGPT Storeで公開する場合、Buider ProfileのNameを有効にして、ユーザー名を公開する必要がある。また必ずを守ったGPTでなければならない。

## GPT StoreでGPTを公開して収益化する方法

現在GPT Storeの収益化についてOpen AIで以下のように発表されている。
:::box
**Builders can earn based on GPT usage**
In Q1 we will launch a GPT builder revenue program. As a first step, US builders will be paid based on user engagement with their GPTs. We'll provide details on the criteria for payments as we get closer.

第1四半期(1月~ 3月)には、GPTビルダー収益プログラムを開始します。第一段階として、米国のビルダーには、GPTへのユーザーのエンゲージメントに基づいて報酬が支払われます。支払い基準の詳細については、追ってお知らせします。
:::

第一段階は米国のビルダーと明記されているため、**日本のビルダーの収益化はまだ先**になりそうだ。またユーザーによるエンゲージメント数によって、収益が発生することが判明した。
エンゲージメント数とはユーザーが「反応して行動した回数」である。

## GPT Storeの注意点

公式のガイドラインはとから確認できる。


### 作成が禁止されているGPT(一部抜粋)
- 違法行為のコンテンツ
- 児童性的虐待 児童を搾取したり危害を加えたりする素材またはコンテンツ
- 嫌がらせ、嫌がらせ、または暴力的なコンテンツの生成
- マルウェアの生成
- 兵器開発・軍事と戦争
- エネルギー、交通、水の重要インフラの管理または運営
- 自殺、切断、摂食障害などの自傷行為を促進、奨励、または描写するコンテンツ
- ギャンブル
- 詐欺
- 盗作
- 学術不正
- アダルト コンテンツ、アダルト産業、出会い系アプリ

以上のようなコンテンツが禁止されており、「競馬の予想ができるGPT」などの作成はガイドラインの禁止事項に該当する恐れがある。

### GPTの名称に関して

GPT の名称を「GPT」で終わらせることは推奨されていない。作成したアプリやサービスの内容に適した名称を与える必要がある。ただし、禁止されているわけではないため個人用に「〇〇GPT」という名称を与えることは問題ない。

:::box

:::



</description><pubDate>Thu, 11 Jan 2024 05:41:21 +0000</pubDate></item><item><title>AIのファインチューニングとは｜ビジネスパーソン向けの解説と転移学習・RAG・プロンプト埋め込みとの違い</title><link>https://ledge.ai/articles/fine-tuning</link><description>2023年は企業のAI活用も進み、{target=“_blank”}のような、OpenAIが提供するChatGPTなどの大規模言語モデル（以下、LLM）を使った、社内向けツールの開発事例が数多く発信された。

ビジネスの分野で広がりを見せるLLMだが、オープンソースのLLMIは事前学習の内容を基本としているため、企業内部データなどの外部公開していない情報や、特定の専門分野に関する情報に対しては回答の精度に課題が残る。

この課題への対応策として注目されているのが、ファインチューニング等の技術だ。
本記事ではファインチューニングの概要、メリット・デメリットや、類似技術との違いについて、文章生成AIの文脈で紹介する。

:::box
- ファインチューニングはなぜ必要なのか
- ファインチューニングの基本概念
- ファインチューニングと類似技術との違い
- ファインチューニング対応の基盤モデル
- ファインチューニング活用例
:::

## ファインチューニングはなぜ必要なのか
LLMはインターネット上のテキストデータなど、大量のデータを学習してモデルが構築されている。これらは「事前学習」と呼ばれるが、前述の通り、一般的な広範囲の知識はカバーしている一方、特定の専門知識に対して完全に適応することは難しい。また、ハルシネーション*という現象により、生成AIが学習していない分野について、信頼できない回答や誤解を招く回答を生成してしまう可能性があることも重要な問題だ。

:::box
*ハルシネーションとは、AIによって生成された回答が、現実には存在しないものであるか、または与えられたデータやコンテキストから著しく逸脱している場合に使われる用語である。AIが幻覚（=ハルシネーション）を見ているかのように、”もっともらしい嘘”をつくため、このように名付けられた。
:::
このハルシネーションという言葉は、ChatGPTなどの生成AIの登場に伴い、広く認知されるようになった。ファインチューニング等の技術は、このハルシネーションの問題に対処する手段として注目され、自然言語処理のさまざまな側面で応用されている。

## ファインチューニングの基本概念
ファインチューニングは、特定のドメインやタスク（領域）に適用させるために、事前学習されたモデルを追加学習する手法である。一般的なファインチューニングのステップは以下の通り。

**【１】事前学習モデルの取得**
大規模なデータセットで事前にトレーニングされたモデルを取得する。このモデルは、一般的な特徴やパターンを学習済みの状態であり、例えば、ImageNetのデータセットでトレーニングされた画像認識モデルや、大規模なテキストコーパスでトレーニングされた言語モデルなどが挙げられる。

**【２】追加学習**
事前学習済みモデルを使い、元のデータセットと異なる特定のドメインやタスクを対象とした、新しいデータセットで追加学習を行う。

**【３】重みの調整**
通常、事前学習済みモデルの一部の層や重みを「凍結」し、新しいタスクに適応するための層や重みを「解凍」して調整可能な状態にする。これにより、既存の知識を保持しつつ、新しいデータセットを学習することが可能となる。

**【４】ハイパーパラメータの調整**
追加学習を行ったモデルが新しいタスクに適応しやすくなるよう、学習率やエポック数などのハイパーパラメータを調整する。

!
:::small
Ledge.ai編集部作成
:::

### ファインチューニングのメリット
ファインチューニングの大きなメリットは、やはり、事前にトレーニングされた大規模なモデルを特定のタスクやドメインに適応させることで、パフォーマンスの向上や、タスク特有の要件への対応が可能になる点であろう。以下にメリットをまとめた。

**①特定ドメインの取り込み**
特定のドメインにおいては、言語の使い方や専門用語が異なることがある。ファインチューニングにより、モデルはそのドメインにおける言語の特性を学習し、より適切な応答や予測を行うことができる。

**②タスクの上位互換性**
元のモデルが持つ言語理解の能力を保持しつつ、特定のタスクにおいて追加学習が行われることで、元のモデルの高次の特徴や一般的な知識を引き継ぎつつ、新しいタスクに対する予測精度が向上する。

**③コスト削減**
ファインチューニングは、既存の一般的なモデルを再利用する。これにより、再学習をした場合と比較すると、モデルのトレーニングにかかる計算コストや時間を削減できる。

### ファインチューニングのデメリット
特定のタスクに適応したモデルを構築できるファインチューニングだが、いくつかのデメリットも存在する。

**①過学習のリスク**
ファインチューニングでは、特定のタスク向けにモデルのパラメータを調整するため、トレーニングデータに過度に適応してしまう「過学習」のリスクが高まる。特に、追加学習のデータが限られている場合は注意が必要である。

**②開発環境**
ファインチューニングは元の大規模モデルをベースにしているため、相応の開発環境がない場合は、処理時間が大幅にかかってしまう可能性がある。今やAI開発において欠かせない存在となっている、GPUの調達等を行う必要がある。

**③既存モデルのバイアス**
ファインチューニングは、元のモデルが学習した特定のデータのバイアスを引き継ぐ可能性がある。	

## ファインチューニングと類似技術との違い
モデルの学習は複数の手法が存在するが、その目的とアプローチには違いがある。今回は転移学習 および Retrieval-Augmented Generation（以下、RAG）について、ファインチューニングとの違いを説明する。

### 転移学習とは？
転移学習とは、あるタスクで学習されたモデルを別の関連するタスクに応用させる技術を指す。

例えば、大規模なデータセットで学習された文章生成AIモデルがあったとする。このモデルは、一般的な文章生成のタスクにおいて高い性能を発揮するが、特定のドメインやテーマに特化したタスクにおいては、データが不足していることがある。このモデルに転移学習をさせ、元々のモデルが学習した一般的な言語の知識や文法構造を新しいタスクに応用させることで、特定のドメインにおいても良い回答結果を得ることができる、というイメージだ。
より詳しい転移学習の説明については、関連記事を参照してほしい。
:::button
{target=“_blank”}
:::

ここまでの説明だとファインチューニングとかなり似ているように見えるが、転移学習とファインチューニングではパラメータの学習範囲が異なる。

転移学習では、事前学習済みのモデルのうち、出力層以外のパラメーターは固定されている一方、ファインチューニングは出力層以外の層のパラメーターも調整される仕組みとなっている。

!
:::small
Ledge.ai編集部作成
:::

また、モデルが大規模になるほど中間層のパラメーター数も多くなるため、転移学習とファインチューニングでは、追加学習のコストに差が出る点も、違いの一つだ。

### RAGとは？
RAGは、検索拡張生成と訳されるように、検索と生成AIを組み合わせた技術である。事前に用意された外部のデータベースやコーパスから情報を取得し、それを元に適切な回答を生成するモデルのことを指す。

!
:::small
Ledge.ai編集部作成
:::

RAGを利用することで、多数の情報源から得たデータを集約して回答の生成ができ、ユーザーの質問に対し、より正確な情報のアウトプットが行える。また、検索エンジン単体の場合と異なり、ユーザーのクエリのあいまいさを解消することにも役立ち、関連性の高い回答を生成することができる。

RAGとファインチューニングの違いについてだが、データ利用方法・開発アプローチ・タスクの特性の3つの観点でまとめた。

**データ利用方法**
RAG…外部のデータベースから情報を取得し、それを利用して回答を生成する
ファインチューニング…特定のタスク向けに追加学習データを用いてモデル自体を調整する

**開発アプローチ**
RAG…情報検索と生成モデルを組み合わせるアプローチ
ファインチューニング…事前学習済みのモデルへ特定のタスクデータを用いて追加学習するアプローチ

**タスクの特性**
RAG…質問応答や文章生成に適している
ファインチューニング…特定のタスクに適応したモデルを得られるため、幅広いタスクに適用可能


### RAGとプロンプト埋め込みの違い
RAGについて調査すると、プロンプト埋め込み（Embedding）というキーワードも多々出てくる。Embeddingとは、単語や文を数値のベクトル空間に埋め込む（変換する）手法であり、意味的に類似する単語や文が、ベクトル空間上で近くに位置するように、数値表現に変換させたものだ。
自然言語は通常、単語や文字などで構成されているが、Embeddingを用いることで、単語や文字を連続的な実数値のベクトルに変換し、単語や文字の意味的な特徴を数学的な形で表すことが可能となる。これによって、AIモデルがテキストデータを理解しやすくなるメリットがある。

**RAGとの違いは？**
RAGとEmbeddingは使われ方が全く異なる。
RAGは上記の通り、情報検索と生成モデルの組み合わせで構成されており、主に質問応答や文章生成のタスクにおいて、外部のデータベースを取り込んだ、より精度の高い回答を生成することが期待されている。
Embeddingは、単語や文の意味や構造を表現した数値ベクトルによって、主に文書分類や類似性の検索、クラスタリングなどのタスクにおいて、入力されたテキストデータの特徴的な情報を捉えるのに役立てられている。

RAGとEmbeddingが同じ文脈で取り上げられることがある主な理由は、自然言語処理において相補的な役割を果たすためである。RAGでは、生成モデルが回答を生成する際に、テキストデータを処理しやすくする目的でEmbeddingを用いて単語や文字を数値ベクトルに変換することがあるため、これらの手法は同じ文脈で言及されることがあるのだ。

企業の生成AI活用では、自社にマッチしたモデルの構築・改良を進めていくべきだが、自社（外部）データとAIモデルを紐づけるために、ファインチューニング・RAG・Embeddingの技術は、ぜひ押さえておきたい。

## ファインチューニング対応の基盤モデル
ファインチューニングに対応する基盤モデルの代表例を以下に挙げる。

### Open AI｜GPT-3.5 Turbo
!
2023年8月23日、米国OpenAIは「ChatGPT」などが採用する大規模言語モデル（LLM）「GPT-3.5 Turbo（gpt-3.5-turbo-0613）」がファインチューニング（微調整）に対応したと発表した。
:::box
関連記事：{target=“_blank”}
:::
### Meta｜Llama 2
!
Meta社が発表しているLLMモデル「Llama 2」は、70億（7B）、130億（13B）、700億（70B）パラメータの3種類のサイズが用意されており、事前トレーニングモデルと会話型ファインチューンモデルが存在する。
:::box
関連記事：{target=“_blank”}
:::

## ファインチューニング活用例
Ledge.aiで取り上げた記事の中からファインチューニングを利用した事例をピックアップした。

### 旭化成『書面監査における生成AIの活用』
2023年12月7日に、旭化成はDX戦略説明会を開催し、生成AIを本格導入することを発表。デジタル基盤の強化とビジネス変革を目指すと述べた。

その取り組みの中で、「書面監査」業務において、生成AI活用を試みている。
セキュアな環境内で、生成AIとWEB上の最新情報 および 社内データを連携させて回答生成を行えるようにし、さらにファインチューニングで自社特化を実現している。これらの追加開発により、特許作成など専門性の高い業務への対応が可能となっているという。年間約1820時間の短縮が測れる見込みだ。
!
:::small
画像の出典：{target=“_blank”}
:::
:::button

:::</description><pubDate>Thu, 28 Dec 2023 10:15:51 +0000</pubDate></item><item><title>年末年始こそAIのリスキリング　2023-24年のおすすめ無料講座を一挙紹介！ー松尾研LLM講座・Google認定資格プログラム・プロンプトエンジニアリングなど</title><link>https://ledge.ai/articles/free_courses_in_winter2023-24</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

生成AIに追われ、慌ただしく過ぎ去った2023年。リスキリングの波に乗り、休暇をじっくりと学び、新しい年を迎える自分をエンパワーする時間に充てる人も増えているという。まとまった時間を興味ある分野の一歩に。

## 東大松尾研 LLM講座
!
:::small
画像の出典：{target=“_blank”}
:::

東京大学松尾研究室は12月27日、東京大学サマースクールで2023年9~10月に開催された「大規模言語モデル講座」のコンテンツを{target=“_blank”}。この講座には約2,000名が参加し、全7回の講義とGPUを使ったコンペティションが実施された。

!
:::small
画像の出典：{target=“_blank”}
:::


## Google認定資格プログラム
!
:::small
画像の出典：{target=“_blank”}
:::

Googleは現在、新規会員に先着2万名限定で「Google Career Certificates」を{target=“_blank”}。このプログラムは、サイバーセキュリティとデータアナリティクスのコースを含み、キャリアアップに有効なGoogleの認定資格を取得できる。受講には学位や事前知識が不要で、オンラインで約6ヶ月間で完了可能だ。

## OpenAI「ChatGPTのプロンプトの書き方」
!
:::small
画像の出典：{target=“_blank”}
:::

OpenAIが大規模言語モデルGPT-4を活用するためのプロンプトエンジニアリングの基本テキストを{target=“_blank”}。このテキストでは、GPT-4の効果的な使用方法として、6つの主要戦略とそれに関連する具体的なテクニックを紹介している。例えば質問の詳細化、ペルソナの採用、入力の区切りの明確化、必要な手順の指定など。

また、効果的なプロンプトの例も提供されており、コピー＆ペーストで利用できる。OpenAIのサイトでは、これらの戦略に基づいた多数のプロンプト例も紹介されており、利用者はすぐにこれらを活用可能だ。

## IBM SkillsBuild「AIの基礎」
!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}は、技術分野でのスキルアップを目指す人々に焦点を当てた無料の教育プログラムだ。IBMは、2026年末までに200万人の学習者にAIに関する学習機会を提供するコミットメントを発表し、この目標の達成のためにIBM SkillsBuildを通じて新しい生成AIのコースを提供開始した。

{target=“_blank”}講座では、次の６つのコースで構成される。「人工知能の概要」「自然言語処理とコンピュータビジョン」「機械学習と深層学習」「IBM Watson Studio で AI モデルを実行する」「AI倫理」「 AIとの未来、仕事の展望」

※IBM Skill Build を利用するには、まずアカウントの作成が必要となる。




:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:57:14 +0000</pubDate></item><item><title>GPTs(GPT Builder)とは｜ChatGPT新機能の特徴・料金</title><link>https://ledge.ai/articles/gpts</link><description>:::box
**目次**
- GPTs(GPT Builder)とは？
- GPTsの基本｜特徴とメリット
     - GPTsの料金・使い方
     - ノーコードでの作成​​​​できるオリジナルGPT
     - オリジナルGPTの公開とGPTストア
     - 外部ツールとのAPI連携​​​​
- GPTs | オリジナルGPT作成事例
     - 事例1  Sous Chef  冷蔵庫の写真から料理を提案 [公式]
     - 事例2  ピクトグラムメーカー  プレゼン用のアイコンを簡単作成
     - 事例3  論文要約GPTs  PDFを読み込んで論文を要約
     - 事例4  GPT Finder  GPTを検索するためのGPT
- GPTs（GPT Builder）を使って実際にGPTを作ってみた
     - GPTを作成するためのSTEP
- GPTsの今後
:::

## GPTs(GPT Builder)とは？

GPTsとは、ChatGPTをユーザーの目的に合わせてカスタマイズできる機能であり、作成したオリジナルGPTは第三者に公開して共有することができる。GPT Builderは新機能GPTsでGPTを作るための機能を指す。2023年11月7日に行われたOpenAI初の公式イベント「」でその概要が公開された。以下のようなGPTが作成できる。

※GPT（Generative Pre-trained Transformer）はもともと言語モデルを指す略称であるが、新機能GPTsでは、カスタマイズされたChatGPTをGPTとして呼称している。

:::box
**作成できるGPTのサンプル**
- ブログを自動で作成できるChatGPT
- 英文添削をしてくれるChatGPT
- 写真からファッションコーディネートを提案するChatGPT
:::
GPTsは以上のようなカスタマイズされたGPTをGPT Builderと対話をするだけのノーコードで作成できる。さらに2024年の初頭には収益化も可能なGPT公開・販売サイト「GPT Store」のリリースが予定されており、注目度が高まっている。

## GPTsの基本｜特徴とメリット

### **GPTsの料金・使い方**

GPTsは有料の「GPT Plus」に入会することで利用でき、利用料金は月額 20ドル(公開時の為替で約2800円)である。有料の「GPT Plus」では無料版のGPT-3.5よりも高性能なGPT4を利用することができる。「GPT Plus」の詳細は以下の記事で確認できる。

:::box

:::

GPTsは「GPT Plus」入会後に画面左上の[Expore]から利用できる。

### **ノーコードでの作成できるオリジナルGPT**

GPTsはノーコードでオリジナルのChatGPTが作成できる。
プログラムの知識がなくとも、自社・個人のタスクに合わせたツールをChatGPTと対話することで作成することができる。業務効率化に必要なツールを、解決したい課題に合わせてChatGPT自身が選び、組み合わせて独自のタスクを解決できるチャットボットが開発できる。

### **GPTsの公開・共有とGPT Store**
GPTsで作成したツールはユーザー間で**共有が可能**である。作成したGPTのURLを発行することができ、会社などの組織内で作成したツールを共有、URLを知っている全ての人物に共有など共有範囲の選択が可能である。
さらに、2024年度初頭に「GPT Store」の公開が予定されており、開発したGPTの共有・販売が可能となる。「GPT Store」では収益化が可能とされており、利用した人物の人数に応じて収益を得られるとのこと。副業としてもGPT開発が始まり、さらなる開発の加速が期待できる。

### **外部ツールとのAPI連携**

GPTsは「」を利用して**外部ツールと連携することが可能**である。
特定のサイトの情報を取得したり、作成したGoogle スプレッドシートに アクセスすることが可能になる。

:::box
**Actionsにできること**
- リアルタイムの情報    　　　   例: スポーツのスコア、株価、最新ニュースなど。
- データベースの情報                  例: 会社のドキュメント、個人的なメモなど。
- ユーザーのアクションを支援　例: 航空券の予約、出前の注文など。
:::

:::small
公式サイトより引用して翻訳
:::

## GPTs | オリジナルGPT作成事例

ここでは、GPTsの作成事例を4つご紹介する。ChatGPTのマルチモーダル機能である画像の読み込み、画像の生成、文章要約などの機能が活用されている。
***
**事例1**   ****  made by OpenAI
!

入力された食材から、最適な料理を提案してくれるGPT。
さらに冷蔵庫にある食材の写真をアップロードすると、写真から食材を認識し回答を行うこともできる。
***
**事例2**   **** made by TOMOKI ISHIMINE
!


入力されたプロンプトからピクトグラムを作成することができる。
「ジムでベンチプレスをしている人」と入力すると
1. ジムでベンチプレスに横たわり、バーベルを持ち上げている人。
2. ジムでベンチプレスをしている人が、大きなウェイトを追加している。
3. ジムでベンチプレスをしている人が、スポットトレーナーにサポートされている。

抽象的なプロンプトから具体的なプロンプトを３つ提案された。1を選択すると以下のような画像が生成された。
!
***
**事例3** **** made by community buider (匿名)
!

PDFファイルをアップロードすれば、英語論文を要約することができる。
***
**事例4** **** made by  

!

**GPT Finder**はKnowledge機能を活用し、GPTsに関する情報を与えてられており、ユーザーが望むGPTを検索することを可能にしている。GPTsを探すGPTや、GPTsを作るためのGPTが既に有志によって作成されていることが面白いところであり、GPTsの可能性を感じさせられる。
***
## GPTs（GPT Builder）を使って実際にGPTを作ってみた

### **STEP1 GPT Builderの起動**

ではGPT BuilderでカスタマイズされたGPTを作成していく。
ChatGPTの有料版、ChatGPT Plusにプランを変更すると画面左上にExplore(エクスプロア)が表示される。まずはExploreをクリックする。
!
Exploreをクリックすると以下の画面が表示される。次に、My GPTsの「Create a GPT」をクリックする。
!
クリックすると、GPTsの作成画面が表示される。
画面左はGPT Builderとなっており、会話することでオリジナルのGPT作成のサポートをしてくれる。画面右はPreviewになっており、GPT Builderが自動で調整したGPTをすぐにテストすることができる。Previewで期待する回答が得られなかった場合はGPT Builderに修正内容を伝えて、修正→Previewを繰り返し、目標のGPTを作成できる。
!



### **STEP2 GPT Builderに作成したいGPTの内容を伝える。**

今回は「Ledge.AIのおすすめ記事を要約して、そのリンクを紹介してくれるGPT」を作成します。GPT Builderにこの内容を伝えます。
!


### **STEP3 GPT BuilderがGPTのタイトルを提案**

趣旨を伝えると、GPTのタイトルを提案された。
:::box
**ChatGPT**
Great! We're creating a GPT that can summarize AI-related articles from Ledge.AI and provide links to those articles.
How about we name this GPT **AI Article Summarizer**? Does that sound good to you?
(素晴らしい！Ledge.AIからAI関連の記事を要約し、それらの記事へのリンクを提供できるGPTを作成中です。
このGPTを**AI Article Summarizer**と名付けるのはどうだろう？いいと思う？)
:::
このAI Article Summarizerというタイトルで許可をする。

※会話で使う言語に関して、GPT Builderではこちらが日本語で話しても、英語で回答することが多くあった。プロンプトに日本語で会話して下さいと追加すると日本語で会話できるようになる。ただし、しばらくすると英語に戻ってしまう場合も現段階では多い。

### **STEP4 GPT BuilderがGPTのプロフィール写真を生成**
タイトルの許可をすると、次にプロフィール写真が生成され、作成した画像で問題ないか確認される。このプロフィール写真で問題ない旨を伝えた。
!


### **STEP5 GPT Builderに作成したい機能の詳細を伝える**

次に、AI Article Summarizerにどのような機能を持たせたいかを質問されます。
以下のように、いくつかの選択肢を提案されそれを選択するだけで、開発が進む。
:::box
**ChatGPT**
素晴らしいです。AI Article Summarizerのプロフィール写真が設定されました。
　
次に、このGPTの役割と目標について詳しくお聞かせください。どのような情報を特に重視し、どのように要約することを希望しますか？例えば、記事の特定の側面やテーマを重視する、または特定のスタイルで要約することを希望するなど、ご要望があれば教えてください。
　
**User**
https://ledge.ai/のサイトの記事を、ビジネスマン向けに要約して下さい。
　
**ChatGPT**
了解しました。AI Article Summarizerは、Ledge.AIのウェブサイトの記事をビジネスマン向けに要約する役割を果たします。市場の動向、ビジネスへの応用、戦略的な洞察など、ビジネスプロフェッショナルに特に関連する情報を重視して要約します。
　
このGPTの使用にあたって、避けるべき事項や特に注意すべき点はありますか？例えば、特定の言葉遣いや情報の取り扱いに関するガイドラインがあれば教えてください。
　
**User**
https://ledge.ai/以外の記事は紹介しないでください
　
**ChatGPT**
了解しました。AI Article SummarizerはLedge.AIの記事のみを要約し、他の情報源からの記事は参照または要約しないようにします。
　
このGPTの対話スタイルについて、どのような感じにしたいですか？例えば、公式なビジネスライクなトーン、またはもう少しカジュアルなアプローチなど、ご希望があれば教えてください。
　
**User**
ビジネスライクなトーンでお願いします
　
**ChatGPT**
AI Article Summarizerはビジネスライクなトーンで情報を提供します。
　
それでは、プレイグラウンドでこのGPTを試してみてください。フィードバックがあれば、どんな改善点でもお聞かせください。何か他に追加や変更を希望されますか？
::: 

以上の会話でGPTが完成した。早速、動作テストを行う。
Previewで動作テストすることができるが今回は保存してからテストを行った。
※反映が遅い時があるため
### 作成したGPTをテストする
「自動運転に関するおすすめ記事を教えて」と入力すると以下の回答が得られた。Webサイトからタイトルを取得できているが、期待する回答が得られていない。
!
次に、期待する回答が得られるようGPTを修正していく。

### オリジナルのGPTをCreateからカスタマイズする

**Create**から会話形式で修正することもできるが、左画面の上部**Configure**から直接GPTをカスタマイズできる。実は先ほどの会話からChatGPTが自動で**Configure**の必要項目を埋めてくれる仕組みになっている。**Instractions**には先ほど会話した内容が、要約されてまとまっている。
!

期待する回答が得られるよう**Configure**を以下のように編集した。**Instractions**には直接日本語で内容を入力し、内容を変更した。Instractionsを日本語にしておくとChatGPTが回答する際に英語になってしまう現象が少なくなった。
!

以下のように期待する回答が得られた。記事の要約とそのリンクを添付してくれている。
!


GPT「AI Article Summarizer」にはからアクセスできる。ただし、GPT Plusに入会している必要がある。

## GPTsの今後

OpenAI社の公式ブログ記事 で次のように発言されている。
:::box
**The best GPTs will be invented by the community** (最高の GPT はコミュニティによって発明されます)
:::
2024年初頭には収益化可能なGPT Storeが公開される予定で、OpenAI社はユーザーの開発競争によってより優れたGPTが生まれることを期待していることが示唆される。

これまでのGPT-3からGPT-4への進化や、GPT-5の開発が進んでいる一方で、マルチモーダル機能や外部APIとの連携が容易になり、誰もが業務効率化ツールを作成できるようになっている。
さらに、開発競争によって革新的なGPTが続々と生まれれば、App Storeのような大規模なマーケットが形成されるかもしれない。

:::box

:::



</description><pubDate>Thu, 28 Dec 2023 07:51:46 +0000</pubDate></item><item><title>ノーコード推進協会　ノーコード人材を定義する新たな認定制度「NCPA認定ノーコードパスポート」を開始</title><link>https://ledge.ai/articles/nocode_passport</link><description>:::small
画像の出典：{target=“_blank”}
:::

ノーコード推進協会は2023年11月27日、ノーコード人材育成と適切な理解の普及を目的とした「NCPA認定ノーコードパスポート」の提供開始を{target=“_blank”}した。

同協会は2023年11月1日に一般社団法人化し、ノーコードツールの活用に必要な知識やスキルを証明するこの認定制度を導入している。これにより、IT未経験者も段階的にノーコードスキルを身に付けることが可能となる。

ノーコードパスポートは、ノーコードスキル要素とレベルを設定し、3段階の資格で構成されている。2024年1月より、最初の段階である「NCPA認定ノーコードパスポート サファイア」を開始する予定。試験運営はデータミックス社の「Excert」システムを採用し、初年度の目標受験者数は1,000名とのこと。
詳細ページ：{target=“_blank”}


!
:::small
画像の出典：{target=“_blank”}
:::
 試験詳細は、2024年1月にNCPAのWebサイトにて公開予定


:::box

:::
:::box

:::</description><pubDate>Mon, 27 Nov 2023 03:06:40 +0000</pubDate></item><item><title>無料で機械学習が学べるコンテンツ＋α 特集 2023年・秋版</title><link>https://ledge.ai/articles/free-learning-Autumn</link><description>:::small
画像の出典：Adobe Fireflyでプロンプト[秋にプログラムの勉強をする猫]で生成
:::

近年、人工知能（AI）業界は急速に進化し、機械学習を活用したサービスが登場している。すでに「ChatGPT」や「Microsoft 365 Copilot」などが企業や大学、官公庁の業務効率向上に導入がされており、そのメリットとデメリットを慎重に検討しながら利用されている。使用するデメリットとして、これらのAI・機械学習サービスは情報流出などの予測外のリスクも考慮しなければならない。AI開発者だけでなく、利用者自身も機械学習の基本的な理解を持ち、AIを安全に活用することがこれからの時代に重要なリテラシーだ。

AI開発には特に「Python（パイソン）」というプログラミング言語が注目されている。Pythonは機械学習の開発に広く用いられ、使いやすさと豊富なライブラリが人気の理由である。

幸いインターネット上には、無料で機械学習を学べる多くのコンテンツが存在する。活用すれば個人の仕事や研究にAIを活用することはもちろん、企業や大学のIT担当者として組織の業務全体に必要なAIを選んで導入したり、目的に合わせたAIの開発まで可能になる。

学問に王道は存在しないが、本稿では代表的なオンライン学習サイトを紹介し、それらをどのような順番で利用すべきかを、計画的かつ合理的に解説する。

:::box
**目次**

- **機械学習の学習ロードマップ**
まずは「機械学習基礎」と「Python」を学ぶ  
- 「Aidemy Free」はプログラミング初心者におすすめ
- 「Chainer Tutorial」はプログラミング経験者向き
- 東大「Pythonプログラミング入門」は一度挫折した人にぴったり
- 東工大 「Python早見帳」「機械学習帳」で回帰・分類・教師なし学習に挑戦
- **専門分野「自然言語処理」「コンピュータビジョン」等を学ぶ**
- 「JMOOC」で数学から「データ分析」を学びたい方に
- 「データサイエンススクール」は総務省 統計局が提供する社会人向け講座
- 「Scikit-learn公式ユーザーガイド」は「データ分析」のタスクに必要な部分だけ学べる
- 「キカガク」は無料で「画像認識」「自然言語処理」に必須のライブラリを学べる
- **有料で学習しやすいコンテンツもチェック**
- Udemy  　学びたい人、教えたい人のためのオンラインのマーケットプレイス
- Cousera    修了証明書や専門職資格が取得できるオンライン大学
- PyQ　　　技術本一冊分で学べる機械学習
- Aidemy premium　3ヶ月でAI人材に！Python特化型プログラミングスクール
:::

## 機械学習の学習ロードマップ
無計画で機械学習の学習を進めることは困難である。また計画しようにも何から手をつければいいかわからず、計画段階で心が折れてしまうこともある。

自身の目標や必要な知識を明確にすること、そして学習の進め方を計画することが効率的な学習に重要だ。計画の参考になるよう、以下に学習のロードマップの一例を示す。
!
**0.目標の確認**
はじめに目標を確認し、目的に必要な知識をリサーチすることをすすめる。
膨大な学習を効率化するために重要な項目である。

**1.数学の基礎**
数学（微積・線形代数）の基礎知識があると、機械学習の学習をスムーズに進めることができる。例えばPythonの数値計算ライブラリである「NumPy」を使用する際、線形代数の行列という概念を理解していれば素早く理解できることがある。またデータ分析に役立つ機械学習ライブラリ「scikit-Learn」を学ぶ際には、アルゴリズムの背後にある原理を理解するために微分積分の知識が役立つこともある。

このような数学の知識は、機械学習の理解を深める上で大いに役立つが、あくまで機械学習の基本をより強固にするものである。自身のスキルや目標に合わせて、必要な数学の部分から学んでも良い。

**2.機械学習の基礎**
Pythonの文法と機械学習に必須の３種類のライブラリ「NumPy」「Matplotlib」「Pandas」から学ぶことをおすすめする。

:::box
**ライブラリとは**
「NumPy」「Matplotlib」「Pandas」はPythonのライブラリである。
ライブラリはある特定の機能を、短い記述で実行するための関数の集まりである。
例えば「Matplotlib」はグラフを表示するためのライブラリで、簡単にグラフの種類や、文字の色の変更などを行える。
:::

**3.プログラムの基礎**
機械学習の基本的な概念（教師あり学習、ディープラーニング、強化学習）を学び全体像を掴んでおくことも専門的なタスクを実行するとき、理解への助けになるはずだ。

**4.専門的な学習**
 続いてタスク別の分野「画像認識」「データ分析」「自然言語処理」など、自分が興味のある専門分野を選び、実装を目指す。さらにそれぞれの基本的な概念やライブラリを学習する必要があるためどれか一つに絞ることが得策だ。

本記事ではそれぞれの学習段階を意識して無料で学べるコンテンツを紹介する。


## 完全無料で「Python」と「機械学習の基礎」が学べるコンテンツ
 まずは「2.機械学習の基礎」「3.プログラムの基礎」が無料で学べるコンテンツ紹介。機械学習のためにPythonを使うことが意識された教材を厳選した。

### **プログラミング初心者おすすめ**

:::box
情報の充実度★★☆　わかりやすさ　★★★   　学習スタイル　テキスト+動画＋テスト　完全無料
:::
**学べる内容**
Python、機械学習の基礎、ディープラーニング基礎
!

Aidemy Freeは一度もプログラミングをしたことがない人にもすすめられる。

Aidemy FreeはPythonの実行環境をサイトに搭載しており、環境開発要らずで学習を始めることができる。また各章にテストがあるため、初心者でも着実に学習を進めることが可能だ。完全無料で「Python入門」や「はじめてのAI」「機械学習概論」「ディープラーニング基礎」などのコースを選択することできる。

「機械学習とは？」という全体像を掴むことができ、学習のスタート地点に最適。

### 

:::box
情報の充実度★★★　わかりやすさ　★★☆  学習スタイル  テキストのみ　完全無料
:::
**学べる内容**
Python(NumPy、Matplotlib、Pandas)、数学基礎 、データ分析入門(scikit-learn)
ディープラーニング(Chainer)
!
Chainer Tutorialは「Python以外のプログラム経験がある人」、「数学を復習したい人」にすすめる。

Chainer Tutorialは機械学習の理解への助けとなる数学の解説からはじまり、ディープラーニング実装まで学習できる非常に丁寧な解説かつ情報量の多い完全無料のテキストである。

PythonライブラリのNumPy、Matplotlib、Pandasやデータ分析ライブラリのscikit-learnを詳しく学ぶことができる。自分の力で読み進めてゆける人には最適な教材だ。

### **東京大学 数理**・**情報教育研究センター** 「」

:::box
情報の充実度★★★　わかりやすさ　★★☆  学習スタイル  テキストのみ　完全無料
:::
**学べる内容**
Python(NumPy、Matplotlib、Pandas)、データ分析入門(scikit-learn)、Colaboratory
Jupyter Notebook
!

東京大学 数理・情報教育研究センターの「Pythonプログラミング入門」は実行環境の開発に挫折した人にすすめる。

「Pythonプログラミング入門」はオンライン実行環境であるColaboratoryやJupyter Notebookの使い方が解説されており、簡単に実行環境を用意できる。微分や線形代数を理解していればPythonライブラリのNumPy、Matplotlib、Pandasやデータ分析ライブラリのscikit-learnをスムーズに学習できる。

ただし「機械学習とは？」という全体像を掴むことに適した教材ではないので、そちらは別に学ぶとよいだろう。


### **東京工業大学　岡崎 直観教授** 「」＆「」

:::box
情報の充実度★★★　わかりやすさ　★★☆  学習スタイル  テキストのみ　完全無料
:::
**学べる内容**
Python(NumPy、Matplotlib)、機械学習 (回帰・分類・教師なし学習)
!

東京工業大学　岡崎 直観教授の「Python早見帳」＆「機械学習帳」は機械学習の回帰・分類・教師なし学習を学びたい人にすすめる。

 「機械学習帳」ではイラストを交えながら理論とPythonによる実装をセットで解説が行われており、実際にプログラムの動きを見ながら学習することができる。

## 機械学習の専門分野が無料で学べるコンテンツ

続いて「**4.専門的な学習ができるコンテンツ**」を紹介する。

機械学習には「データ分析」「自然言語処理」「コンピュータビジョン」「ディープラーニング」など様々な専門分野が存在する。以下ではタスク別で、学習コンテンツを紹介する。

!


### **オンライン大学講座のプラットフォーム** 
!
:::box
学習できる内容： 「数学」「データ分析」「機械学習の概要」など
:::
:::small
※上記の学習できる内容は、科目の開講時期によって異なる。
:::
JMOOCは「オンラインで公開された無料の講座を受講し、修了条件を満たすと修了証が取得できる」MOOC（MOOCs）という教育サービスの日本版である。

開講科目は時期によって変更されるが、2023年9月現在は滋賀大学「データサイエンス」早稲田大学「機械学習」、明治大学「線形代数」など様々な講義を無料で受講することが可能だ。

### 
!
:::box
学習できる内容:「 データ分析(理論)」
:::
総務省 統計局が提供する無料のオンライン学習サイトである。統計力向上を目的とした講座で、「社会人のためのデータサイエンス入門」ではデータサイエンスの必要性からビジネスにおける事例と手法を学習することができる。またExcleやR言語を使った演習も体験できる。


###  
!
:::box
学習できる内容: 「データ分析(実装)」
:::
scikt-learnは特に「データ分析」で有効なPythonのライブラリである。scikt-leranのユーザーガイドではモデルごとの実装例と手法が詳しく解説されているため、自分のタスクに必要な部分だけを学習することが可能である。目的が既にあり、統計分野の知識があるかたはこの公式サイトで十分かもしれない。

### 

!
:::box
学習できる内容: 「画像処理」「自然言語処理」「ディープラーニング」の基礎
:::
「画像処理」「自然言語処理」「ディープラーニング」の実装に必要な「TensorFlow」や「PyTorch」を登録なしで、無料で学習することができる。またサイトに登録すれば無料で
「Python&amp;機械学習入門コース」 や 「脱ブラックボックスコース 」を利用できる。

また有料版ではサポート付きの長期コースや、買い切りのオンライン学習コンテンツを選択することができる。


## 有料で学習しやすいコンテンツ

###  「**学びたい人、教えたい人のためのオンラインのマーケットプレイス**」
「」
!
:::box
学習できる内容: 「データ分析」「画像処理」「自然言語処理」「ディープラーニング」など
価格: 1000円~50000円
:::
Udemyはオンライン上で教材の販売、購入が行えるプラットフォームである。
販売されている教材はユーザーレビューが確認できるため、質の高い最新の教材を選択することができる。以上はデータ分析に関する人気教材の例である。

### 「**修了証明書や専門職資格が取得できるオンライン大学**」
「」
:::box
学習できる内容: 「データ分析」「画像処理」「自然言語処理」「ディープラーニング」など
料金: 月額4714~6946円   
:::
Courseraは、多くの有名な大学や教育機関と提携しており、さまざまな分野のオンラインコースを提供している。Courseraでコースを修了すると、修了証明書や専門職資格（Specialization）、学位プログラム（Master's degree、Bachelor's degreeなど）を取得できる場合がある。
これらの証明書や学位は、職業的なスキルの向上やキャリアの発展に役立たせることが可能である。

Courseraは多言語に対応しているが日本語に対応しているコンテンツが少ないため、英語での学習にストレスがない方におすすめする。以上はデータサイエンスに関する人気教材の例である。

### 
!
:::box
学習できる内容: 「データ分析」「ディープラーニング」など
料金: 月額3040円
:::
PyQではブラウザでPythonを実行することができる。これにより、教材を読む→コードを書く→実際に動かすという流れを画面内で完結できる。PyQでの学習は、数個の問題からなる「クエスト」という単位で進む。 600クエスト・1500問以上存在するすべてのクエストは、好きな順に学び放題だ。楽しみながら学習したい人にすすめる。

### 
:::box
学習できる内容: 「データ分析」「画像処理」「自然言語処理」「ディープラーニング」など
料金：528,000円~
:::
Python特化型プログラミングスクールである。未経験から3ヶ月でAI人材を目指すことを目標にしており、短期間で学習を進めることができる。さらに専門知識のあるメンターからサポートを受けることができる。質問をできる環境が欲しい人向きだ。




</description><pubDate>Thu, 28 Sep 2023 06:18:09 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>生成AIプロジェクトの開発者コミュニティ、アメリカ・インドに次いで日本が先導ーGit Hub 2023年の動向レポート</title><link>https://ledge.ai/articles/github_the_state_of_open_source_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2023年11月8日、「オープンソースとAIの現状」に関する報告を{target=“_blank”}した。

報告によると、開発者たちは大量の生成AIプロジェクトに取り組んでいる。特にOpenAIなどの基礎モデルを用いた開発が目立ち、生成AIプロジェクトは2023年のオープンソースプロジェクトのトップ10にランクインしたという。これらのプロジェクトには、全開発者の92%が使用または実験中であると報告されており、GitHub上での次世代AIイノベーションを牽引すると期待されている。

また、2023年はオープンソースへの初参加者が最も多く、これまで商業的に支援されたプロジェクトが初参加者の大部分を占めていたが、今年は生成AIプロジェクトも初参加者向けのトップ10プロジェクトに登場した。GitHub上のプライベートプロジェクトの数は前年比38%増加し、全活動の80%以上を占めている。

全世界で、GitHubを使用してソフトウェアを構築し、共同作業を行う開発者が増加している。アメリカは依然として最大の開発者コミュニティを持つが、他の地域も成長を見せている。

次の5年間で最も成長が見込まれる開発者コミュニティに関する予測では、インドが2027年までにGitHub上で最大の開発者コミュニティになると予想されている。日本の開発者数は約280万人で、世界8位にランクされており、今後の成長が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::

さらに、生成AIは個々のコントリビューターの数において148%の年間成長率を達成し、生成AIプロジェクトの総数も248%増加している。この分野において、アメリカ、インド、そして日本が先導しており、他の地域も追随している。

!
:::small
画像の出典：{target=“_blank”}
:::



報告は、2022年10月1日から2023年9月30日までに、GitHub から取得した匿名化されたユーザーおよび製品データに基づいて作成された。

:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:49:07 +0000</pubDate></item><item><title>AIの遅れ取り返せるか　Appleが開発者向けフレームワーク「MXL」Geminiの裏でひっそりと公開</title><link>https://ledge.ai/articles/apple_released_mlx</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2023年12月、AI分野での新たな取り組みとして、開発者向けのオープンソース機械学習フレームワーク「MLX」を{target=“_blank”}した。GoogleのAIモデル「Gemini」の発表と同時であったと各メディアで報じている。

MLXはAppleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​。

Appleの機械学習研究者であるAwni Hannun 氏は、自身のX（旧Twitter）アカウントで、
「ちょうどホリデーシーズンに間に合うよう、本日、Apple 機械学習研究からいくつかの新しいソフトウェアをリリースします。
MLX は、Apple シリコン (つまり、ラップトップ) 向けに特別に設計された効率的な機械学習フレームワークです」
と{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

{target=“_blank”}は10月に、Appleの経営陣は業界の突然のAIブームに驚かされ、昨年末から急いで対応を図っていたと報じており、MLXの発表は、AI分野での急速な進展に対応しようとするAppleの努力の一環との見方もある。



:::box

:::
:::box

:::</description><pubDate>Fri, 15 Dec 2023 05:44:48 +0000</pubDate></item><item><title>古いコードを最新のJavaに生成AIが自動変換「Amazon Q Code Transformation」</title><link>https://ledge.ai/articles/aws_amazonq_code_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月28日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて「Amazon Q Code Transformation」を{target=“_blank”}した。

この機能はAmazon Qを使用して、古いJavaおよび.NETのコードを最新のJavaにAIが自動変換するツールで、アプリケーションの保守と最新化を簡素化することを目的としている。現在Javaアプリケーションのバージョン8および11から17へのアップグレードが可能で、近い将来にはWindowsベースの.NET Frameworkアプリケーションをクロスプラットフォームの.NETに変換できるようになる予定だという。

かつて開発者は、各アプリケーションのアップグレードに 2~ 3日かかっていたが、同社内部テストでは、手動アップグレードに通常は数日または数週間かかるのに対し、新機能を使用すると数分でアプリケーションをアップグレードでき、別の要件へ集中する時間に充当できたという。

このツールは、既存のコードを自動的に分析し、変換計画を生成して、計画に基づいた変換タスクを完了する。パッケージ依存関係の特定と更新、時代遅れかつ非効率的なコードコンポーネントのリファクタリングを行い、新しい言語フレームワークへの切り替えとセキュリティのベストプラクティスの組み込みを行う。変換が完了すると、ビルドとテストの結果を含む変換されたコードをレビューし、変更を承認することができる。

Amazon Q Code Transformationのプレビューは、 AWS Toolkit for IntelliJ IDEAおよびAWS Toolkit for Visual Studio Code のAmazon CodeWhisperer プロフェッショナル ティアの顧客が利用可能。組織が使用するプロファイルへのアクセスを許可する必要がある。プレビュー中の使用には追加料金不要。


:::box

:::
:::box

:::
</description><pubDate>Fri, 08 Dec 2023 15:20:21 +0000</pubDate></item><item><title>GTP-4を利用した「GitHub Copilot Chat」一般提供12月より「GitHub Universe 2023」で発表</title><link>https://ledge.ai/articles/github_universe2023</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国GitHubは2023年11月8日、サンフランシスコで年次イベント「GitHub Universe 2023」を開催した。1日目の{target=“_blank”}で、CEOのThomas Dohmke氏は「GitHubがGitという仕組みの上に構築されたように、今日私たちはCopilotの上に ”Re-founded”（=再構築）された」と述べた。また、GitHubの掲げるビジョン「Copilot X」は、ソフトウェア開発のライフサイクル全般を支援することを目指すという。

生成AIを活用した「GitHub Copilot」シリーズの進展、特に「GitHub Copilot Chat」の一般提供の発表に注目が集まった。この新機能は、自然言語での指示を通じて、コーディングを支援するもので、すでにベータ版は全個人向けユーザーに9月より無償で提供している。既存のサブスクリプションサービス、GitHub Copilotプランの一部として、organizationおよび個人ユーザーに対して12月より一般提供される予定だ。

Copilot ChatはGPT-4を使用しており、より正確なコードの提案と説明を実現しているという。コードに関する質問や議論を可能にし、さまざまなスラッシュコマンドを通じて、コーディングタスクを簡素化する機能も備えている。このサービスは、GitHubのウェブサイトやモバイルアプリにも統合されており、開発者はいつでもどこでもこの機能を利用できるようになる​​とのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

講演の最後には新機能として、自社のコードをもとにGitHub CopilotのAIモデルをカスタマイズする「GitHub Copilot Enterprise」が紹介された。これにより、組織は自社特有のコードベースに合わせたAIのサポートを受けられるようになる。


:::box

:::</description><pubDate>Wed, 15 Nov 2023 05:08:10 +0000</pubDate></item><item><title>LINEヤフー 全エンジニア約7,000名を対象に「GitHub Copilot for Business」の導入開始</title><link>https://ledge.ai/articles/line-yahoo_github_copilot</link><description>:::small
画像の出典：{target=“_blank”}
:::

LINEヤフーは2023年10月13日、同社の開発業務に関わる全てのエンジニア約7,000名を対象にGitHub社が提供するAIペアプログラマー「GitHub Copilot for Business」の導入を開始したと{target=“_blank”}した。

導入に先駆け、2023年6月から8月の間、LINE株式会社およびヤフー株式会社のエンジニア約550名を対象に「GitHub Copilot for Business」のテスト導入を実施。テスト終了後のアンケートによる定性評価とGitHubでの様々な活動を定量化するアクティビティによる評価の分析の結果、1人あたりのエンジニアの1日のコーディング時間は約1～2時間の削減が行われ、アクティビティでは一部指標における利用前後の比較にて約10～30%の向上が見られたという。


:::box

:::
:::box

:::
:::box

:::</description><pubDate>Sat, 21 Oct 2023 11:09:57 +0000</pubDate></item><item><title>我が子や親の声をAIがまねる「ディープフェイクボイス」詐欺 SNSの3～4秒のデータから1回700円で生成可能</title><link>https://ledge.ai/articles/deepfake_voice</link><description>:::small
画像の出典：写真AC
:::

我が子や親の音声をAIが模倣する「ディープフェイクボイス」による詐欺の懸念が各国で高まっている。米国や中国ではすでに被害が出ており、あらためてニュースメディアを騒がせている。

2023年5月の{target=“_blank”}や9月の{target=“_blank”}などの報道がこの問題を取り上げている。AIを利用すると3～4秒の音声から高精度の合成が可能。かかる費用は1件につき日本円にして700円程度という。素材は動画共有SNS「TikTok」などで個人が家族や友達向けに投稿した映像などから集められる。

米国や中国ではこうした音声による詐欺もすでに起きているもようだ。{target=“_blank”}によれば、2022年には親族や友人を装う詐欺電話が約5,000件あり、被害総額は約16億円。

ディープフェイクボイスによる犯罪を含むと見られ、顕著な例として{target=“_blank”}が2023年4月に報道した事件が最近注目を浴びている。同年1月にアリゾナ州のとある母親のもとに娘の声で助けを求める電話があった。犯罪者は娘を誘拐したとして日本円にして約1億4,000万円相当の身代金を要求。実際は詐欺で、報道時点でAI生成だったという証拠は見つかっていないが、母親は音声の迫真性からほかに考えられないと述べている。


!
:::small
画像出典：マカフィー
:::

5月の{target=“_blank”}によると、7か国の18歳以上の成人7,054人のうち10%の人が「AI音声を用いた詐欺に遭遇した」と回答。また知人が遭遇したと答えた人（15%）を合わせた25%のうち、約8割が金銭を詐取された。

日本はAI音声詐欺に遭遇した割合が少なく、潜在的な被害がある可能性がある。専門家は、被害が広がるのも時間の問題と指摘した。日本国内の2022年の特殊詐欺被害額は370億8,000万円で8年ぶりに増加しており、いわゆる「オレオレ詐欺」が多い。被害防止のための技術が研究されており、一部の金融機関ではすでに実用化している。

:::box

:::
:::box

:::


</description><pubDate>Fri, 22 Sep 2023 06:49:13 +0000</pubDate></item><item><title>コーディング特化のAI「WizardCoder 34B」ChatGPT上回る成績 Code Llama強化し達成</title><link>https://ledge.ai/articles/wizard_coder_34b</link><description>米国Microsoftと香港浸会大学の研究者らが、プログラミングコードの生成に特化した大規模言語モデル（Code LLM）として開発した「{target=“_blank”}」シリーズが注目を浴びている。新版はOpenAIの高性能な対話型AI「ChatGPT」を一部上回る成績も収めた。

2023年6月14日に発表した{target=“_blank”}によると、当初のWizardCoderは米国Hugging Faceが公開したオープンソースのCode LLM「StarCoder」を強化したものだった。StarCoderをはじめとする従来のCode LLMは大量のプログラミングコードから学習しているものの、人間の指示に適切に回答するための調整に弱みがあった。WizardCoderは、人間の代わりにLLMに大量の指示データを生成させ学習に使用する「Evol-Instruct」の手法でそこを補ったという。

さらに8月26日に披露した「{target=“_blank”}」は米国Metaが開発したCode LLM「Code Llama」を強化したもので、AIにプログラミング言語「Python」の問題を解かせて性能を測るベンチマーク「HumanEval」を試したところ、ChatGPTが採用するLLMのうち世代の古い「GPT-3.5」を上回る精度73.2％を達成できた。ただし最新版LLM「GPT-4」の精度82.0％には及ばなかった。

!
:::small
出典：WizardCoder
:::

:::box

:::</description><pubDate>Sat, 09 Sep 2023 02:23:33 +0000</pubDate></item><item><title>OpenAI 世界の開発者を招集する「OpenAI DevDay」11月開催 ライブ配信もあり</title><link>https://ledge.ai/articles/openai_devday</link><description>米国OpenAIは初の開発者会議「{target=“_blank”}」を米国サンフランシスコで2023年11月6日に開催する。開発者は直接会場を訪れることはもちろん、世界中から基調講演をライブ配信することが可能だ。{target=“_blank”}で申し込みを受け付け中。

世界中から何百もの開発者が集まり、新たなツールを披露し、アイデアを交換する。会場に直接訪れる開発者は、OpenAIの技術スタッフが主催する分科会セッションに参加可能だ。

会議の開催に合わせ、OpenAIは外部の開発者との連携する姿勢をあらためて打ち出している。同社は対話型AI（チャットボット）「ChatGPT」の公開に先立つ2020年に、同社のAIを外部から呼び出して利用できるアプリケーションプログラミングインターフェイス（API） を公開。2023年時点では200万超の開発者がAPIを利用し、既存のアプリケーションへスマートアシスタントを統合したり、新たなアプリやサービスの構築を行ったりできるようになっている。

APIを通じて利用できるのは、ChatGPTの中枢である大規模言語モデル（LLM）「GPT-4」「GPT-3.5 Turbo」はもちろん、画像を生成する「DALL·E」、音声を文字起こしする「Whisper」 などだ。今回の会議ではさらに、開発者が新たな製品を構築できるような成果を公開予定だという。なお特設サイトで会員登録すると、数週間以内に登録開始の通知を受け取れる。

:::box

:::</description><pubDate>Fri, 08 Sep 2023 13:38:59 +0000</pubDate></item><item><title>Microsoftと中国科学院大学の研究チーム、1ビットLLM「BitNet 1.58Bits」を発表　エッジデバイスやリアルタイム処理に大きな期待</title><link>https://ledge.ai/articles/microsoft_bitnet_1point58bits</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年2月27日、Microsoft Researchと中国科学院大学の研究チームは、新たな1.58ビットの大規模言語モデル「BitNet b1.58」を{target=“_blank”}した。

このモデルは、全パラメータを三値（-1, 0, 1）で表現し、平均情報量を1.58ビットに抑えることにより、従来の16ビット浮動小数点数を用いたモデルと同等の性能を保ちつつ、計算コスト、メモリ使用量、エネルギー消費を大幅に削減する。
!
:::small
画像の出典：{target=“_blank”}
:::

この技術は、70B（700億）パラメータモデルを用いた実験で、既存のモデルと比較して8.9倍のスループットを達成し、Llamaモデルとの比較では、3倍の速度で高い精度を実現していることが報告されている。これにより、GPUに依存せずに済む加算処理のみに特化した新しいハードウェアの開発が期待されるという。

!
:::small
画像の出典：{target=“_blank”}
:::

BitNetの特徴は、その革新的なアーキテクチャにより、エッジデバイスやリアルタイム処理を必要とするアプリケーションでの利用に大きなメリットをもたらし、AI技術の持続可能性と実用性の向上に貢献している点にあるという。また、メモリ使用量の削減と計算速度の向上は、AI分野での大きな課題に対する有力な解答となり得る。

!
:::small
画像の出典：{target=“_blank”}
:::

トレーニングプロセスにおいては、1.58ビットの独特な方式を用いることで、モデルはより微妙なデータのニュアンスを捉え、fp16モデルと比較しても遜色ない性能を実現しているという。このアプローチは、計算資源の使用効率を高め、性能と効率性のバランスを取ることを目指している​​とのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 05 Mar 2024 08:28:08 +0000</pubDate></item><item><title>音声、テキスト、画像、音楽をまとめて理解し処理するマルチモーダルLLM「AnyGPT」上海の研究者たちが発表</title><link>https://ledge.ai/articles/anygpt_multimodal_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::


2024年2月26日、上海の復旦大学ほか複数の研究機関が新たなマルチモーダル言語モデル「AnyGPT」を{target=“_blank”}した。このモデルは、音声、テキスト、画像、音楽など、さまざまなモダリティを統一的に処理することが可能で、現在の大規模言語モデル（LLM）の枠組みを踏襲しながらも、新しいモダリティの統合を容易にする設計が特徴だという。


@


AnyGPTは、マルチターン会話データセット「AnyInstruct-108k」を使用してトレーニングされ、さまざまなモダリティを複雑に織り交ぜたマルチターン会話の10万8,000のサンプルで構成されているため、モデルがマルチモーダルな入力と出力の任意の組み合わせを処理できるようになるという。

マルチモーダル命令データセット「AnyInstruct」の構築プロセスは、マルチモーダル要素を組み込んだテキストベースの対話の生成と、テキストからマルチモーダルへの変換の2つの段階に分かれている。このプロセスを通じて、トピックやシナリオに応じた対話が生成され、最終的にはマルチモーダル対話へと変換される。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 05 Mar 2024 08:22:31 +0000</pubDate></item><item><title>Alibaba　音声データを与えると、1枚の人物画がリアルに喋り歌い出す　動画生成AI「EMO」を発表</title><link>https://ledge.ai/articles/alibaba_emo</link><description>:::small
画像の出典：{target=“_blank”}
:::

Alibabaの Institute for Intelligent Computing（知能計算研究所） は2024年2月29日、「EMO」（Emote Portrait Alive）という音声による表情豊かなポートレートビデオ生成フレームワークを{target=“_blank”}した。

単一の参照画像とボーカルオーディオ（話す声や歌声など）を入力すると、豊かな顔の表情や、頭部の様々なポーズをしたボーカルアバタービデオを生成する。入力オーディオの長さに応じ、任意の時間のビデオを生成可能だという。

さまざまな言語の歌や、異なるポートレートスタイルを生き生きと再現することができ、急速なリズムにも対応し、表現力豊かでダイナミックなキャラクターアニメーションを同期させることができる。また、過去の人物、絵画、3Dモデル、AI生成コンテンツなど、様々なポートレートをリアルな動きでアニメーション化することが可能だ。

@
このシステムは、音声データから直接動画に合成するアプローチを採用しており、リアルな動きの実現を可能にしているという。

EMOは参照画像から特徴を抽出し、音声エンコーダーがオーディオの埋め込みを処理する2段階のフレームワークに基づいている。顔の領域マスクとマルチフレームノイズが組み合わされ、顔の画像の生成を制御する。その後、バックボーンネットワークを通じてノイズ除去が行われる。

バックボーン・ネットワークでは、2種類のアテンション・メカニズムが適用される。
リファレンス・アテンション（Reference-Attention）とオーディオ・アテンション（Audio-Attention）で、それぞれ、キャラクターのアイデンティティを保持し、キャラクターの動きを調整するために不可欠とされる。また、時間的次元を操作し、動きの速度を調整するために、時間的モジュールが利用される。

!
:::small
画像の出典：{target=“_blank”}
:::

このプロジェクトは、学術的な研究とその効果を試すためだけに行われており、作成された技術や成果物を一般に公開するかどうかは未定。リポジトリは{target=“_blank”}に置かれているが、公開の予定については触れられていない。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 04 Mar 2024 02:28:44 +0000</pubDate></item><item><title>NVIDIA　スパコンでも世界ランク9位の処理速度「Eos」を公開</title><link>https://ledge.ai/articles/nvidia_eos</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAは2024年2月16日、高度な AI ファクトリーを支えるアーキテクチャを垣間見ることができるデータセンター規模の最新スーパーコンピューター「Eos」を初めてビデオで{target=“_blank”}した。

@


このシステムは、世界最速のスーパーコンピューター{target=“_blank”}の9位の速度を誇り、AIモデルのトレーニングや複雑なデータ分析に特化して設計されている。Eosは576台のNVIDIA DGX H100システムで構成され、合計18.4エクサフロップスのFP8 AIパフォーマンスを提供する。また、最大400Gb/sのデータ転送速度をサポートするネットワークアーキテクチャを備えており、大規模なAIワークロードの効率的な処理を可能にするとのこと。

暁の門を毎日開いているとされるギリシャ神話の女神にちなんで名付けられた「Eos」は、AI技術の進歩に対する NVIDIA のコミットメントを反映しているという。高度な計算能力と高速データ転送能力により、これまでにないスケールのAIアプリケーション、特にディープラーニングや機械学習の分野でのブレークスルーを目指すと同社は述べた。

EosはAI技術とインフラストラクチャの境界を押し広げる存在であり、先進的な加速コンピューティングとネットワーキング、洗練されたソフトウェア提供物を含む。Eosのアーキテクチャは、AIワークロードが要求する超低レイテンシと高スループットの相互接続性を最適化するために設計されており、AI能力をスケールアップしようとする企業にとって理想的なソリューションだという。




:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 03 Mar 2024 08:22:40 +0000</pubDate></item><item><title>LoRAより少ない計算コストと時間で高性能な「DoRA」香港科技大学が生成AIモデルファインチューニングの新手法を発表</title><link>https://ledge.ai/articles/DoRA</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年2月14日、香港科技大学の研究チームは、大規模言語モデルや画像生成AIなどの機械学習モデルのファインチューニング手法において、計算コストと時間を削減できる新たな手法「DoRA（Weight-Decomposed Low-Rank Adaptation）」を{target=“_blank”}した。

従来のLoRA（Low Rank Adaptation）と比較して、DoRAは事前訓練されたモデルの重みを「大きさ」と「方向」の二つの要素に分解し、特に方向の更新にLoRAを用いることで、訓練可能なパラメータの数を効率的に最小限に抑えることが可能だという。

!

:::small
画像の出典：{target=“_blank”}
:::

この新たな手法により、DoRAはLoRAの学習能力と訓練の安定性を向上させる一方で、追加の推論コストを発生させることなく、LLaMA、LLaVA、VL-BARTなどの機械学習モデルを用いたコモンセンス推論、視覚指示チューニング、画像/動画テキスト理解といった多岐にわたる下流タスクにおいて一貫してLoRAを上回る性能を実現している。

香港科技大学の研究チームは、DoRAがAIモデルの効率的なカスタマイズと性能向上に新たな方向性を示し、機械学習モデルのファインチューニングプロセスを改善する上で大きな可能性を秘めていることを強調している。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 25 Feb 2024 06:51:50 +0000</pubDate></item><item><title>カナダCohereの研究組織「Cohere For AI」、100言語以上をカバーする新LLM「Aya」を発表</title><link>https://ledge.ai/articles/cohere_for_ai_aya</link><description>:::small
画像の出典：{target=“_blank”}
:::

Cohere For AIは2024年2月13日、100以上の言語をカバーする新たな多言語LLM「Aya」を{target=“_blank”}した。このモデルはオープンソースとして公開され、誰でもアクセス・改変が可能となる。

Ayaは、既存のオープンソースモデルの2倍以上の言語をサポートし、メジャーな言語モデルからは取りこぼされがちな話者の少ない言語や文化へのアクセスを可能にする。モデルと共に、114言語をカバーする5億1,300万という最大の多言語プロンプトのファインチューニングされたデータセットがオープンソースとして公開されている。このデータ コレクションには、世界中のネイティブ スピーカーからの貴重な注釈が含まれているという。これにより、AI技術がこれまでアクセスが限られていた広範なグローバルオーディエンスに効果的にサービスを提供可能となるとのことだ。


2023年6月にCohere For AIが始めたオープンサイエンスの取り組み{target=“_blank”}は、世界中の人々の知恵と貢献を集め、最先端の多言語生成言語モデルの構築を目指す。同プロジェクトは、学術界、産業界、非営利団体、独立した研究者からなるAI専門家を結集し、多言語モデルの進歩を加速させ、オープンコラボレーションを促進する1年間にわたる取り組みだという。すべてのモデル、トレーニングデータ、データ収集ツールをオープンソース化し、言語技術へのアクセスを民主化する世界的な動きの一部となることを目指している。


Aya 協力者の地理的分布
!
:::small
画像の出典：{target=“_blank”}
:::

Ayaプロジェクトを追ったドキュメンタリーが公開されている。
@



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 21 Feb 2024 05:44:23 +0000</pubDate></item><item><title>Stability AI、「Stable Cascade」発表　Stable Diffusionより高速高品質　低スペックマシンでも追加学習・ファインチューニングが可能
</title><link>https://ledge.ai/articles/stable_cascade</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年2月13日、Stability AIが新たにテキストから画像を生成するモデル「Stable Cascade」を{target=“_blank”}した。モデルは、非商用ライセンスでリリースされている。

高品質の画像を高速で生成するこのモデルは、3つの異なるモデル（ステージA、B、C）からなるパイプラインで構築されている。この3段階のアプローチにより、一般消費者向けハードウェアでのトレーニングとファインチューニングが可能となっている。

!
:::small
画像の出典：{target=“_blank”}
:::

Stable Cascadeの基礎として機能する「Würstchen」アーキテクチャにより、画像の階層的な圧縮が可能になり、高度に圧縮された潜在空間を利用しながら、効率的な推論と安価なトレーニングを可能にする。3段階のモデルの各ステージは、異なるパラメータサイズを持ち、画像生成の精度と細部の再構成に優れているという。

ステージC（レイテントジェネレーターフェーズ）は、ユーザー入力を24x24のコンパクトな潜在空間に変換する。このステージでのテキスト条件生成を、高解像度ピクセル空間（ステージA・B）へのデコードから切り離し、ControlNets や LoRA を含む追加学習やファインチューニングをこのステージCだけで完結させる。

その後、画像の圧縮に使用されるステージA・B（レイテントデコーダーフェーズ）に渡され、高い圧縮率を達成する。


同社によると、プロンプトのアライメントと美的品質の両方においては、ほぼすべてのモデル比較でStable Cascadeの方が優れていたという。

!
:::small
画像の出典：{target=“_blank”}
:::


推論速度を比較するグラフ（StableCascadeがSDXLの半分の時間で画像を生成している）

!
:::small
画像の出典：{target=“_blank”}
:::

Stable Cascadeのリリースに伴い、トレーニング、ファインチューニング、ControlNet、LoRA のすべてのコードを {target=“_blank”}で公開する。


Text to Image（テキストから画像を生成）に加え、画像にバリエーションを加える機能や、Image to Image（画像から画像を生成）などが紹介されている。

バリエーション（左が入力画像）：与えられた画像から画像埋め込みを抽出し、これをモデルに戻すことで機能する。

!
:::small
画像の出典：{target=“_blank”}
:::

Image to Image ：与えられた画像にノイズを加え、これを生成の出発点として使用することで動作する
!
:::small
画像の出典：{target=“_blank”}
:::

その他、リリース予定のControlNetの一部が紹介されている

・インペインティング/アウトペインティング： テキストプロンプトに従い、マスクした部分を生成した画像で塗りつぶす。
!
:::small
画像の出典：{target=“_blank”}
:::

・キャニーエッジ：エッジ（輪郭）をたどって新しい画像を生成する。スケッチを元に展開することも可能。
!
:::small
画像の出典：{target=“_blank”}
:::


・2倍超解像： ステージCで生成された潜在空間にも使用可能
!
:::small
画像の出典：{target=“_blank”}
:::






:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 19 Feb 2024 02:49:43 +0000</pubDate></item><item><title>OpenAI　文章から高精細な動画を生成するAI「Sora」を発表　レッドチーム中心にリリース前の安全性を検証中　</title><link>https://ledge.ai/articles/openai_sora</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国OpenAIは2024年2月15日、テキストからリアルで想像力豊かなシーンを生成できるAIモデル「Sora（ソラ）」を開発中であると{target=“_blank”}した。詳細なシーン、複雑なカメラの動き、生き生きとした感情を持った複数のキャラクターをフィーチャーした最大60秒の動画を作成できるという。

同社は、モデルが現実世界の物理的な動きを理解しシミュレートすることを学び、実世界の相互作用が必要な問題を解決するための訓練が行われることを目標としている。Soraは、ユーザーのプロンプトに応じて最大1分間のビデオを生成しながら、視覚品質とプロンプトへの遵守を維持する能力を持つという。

複数のキャラクター、特定の種類のモーション、被写体と背景の正確な詳細を含む複雑なシーンを生成でき、ユーザーがプロンプトに求めているものだけでなく、それらが物理世界にどのように存在するのかも理解するという。

例：プロンプト「まるで渡り鳥のように木々を縫うように、紙飛行機の群れが鬱蒼としたジャングルの中を飛び回る」
!
:::small
画像の出典：{target=“_blank”}
:::

言語を深く理解しているSoraは、プロンプトを正確に解釈し、生き生きとした感情を表現する魅力的なキャラクターを生成できる。また生成された1つのビデオ内で、キャラクターやビジュアル・スタイルを正確に表現する複数のショットを作成可能だという。

現行モデルの弱点についても解説されている。Soraは複雑なシーンの物理的な状況を正確に再現する、原因と結果の具体的な例を理解する、などが苦手で、例えば、クッキーをかじった後、そのクッキーにかじった跡がない、といったことが起こり得るという。また、プロンプトの空間的な詳細、たとえば左と右を混同したり、特定のカメラの軌跡をたどるような、時間をかけて起こる出来事の正確な描写に苦労することもある。

例：次々とクローンが出現してしまう
プロンプト「草に囲まれた人里離れた砂利道で、5頭の子供の狼がじゃれ合い、追いかけっこをしている。子狼たちは走ったり跳ねたり、追いかけっこをしたり、なぐり合ったりして遊んでいる」→弱点：たくさんの実体を含むシーンでは特に、動物や人が自然に現れることがある。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、モデルを敵対的にテストする「レッドチーム (誤った情報、憎悪に満ちたコンテンツ、偏見などの分野の専門家)」 と協力し、Soraを製品としてリリースする前に、重要な安全措置を講じる。

現在Soraは、レッドチームのほか、ビジュアルアーティスト、デザイナー、映画制作者にアクセスが提供されており、創造的な専門家にとって最も有用なモデルを進化させるためのフィードバックを得ることを目指している。

OpenAIは、いくら広範に調査とテストを行っても、人々が同社のテクノロジーを有益に使用する、あるいは悪用するすべての方法を予測することは不可能だとし、現実世界での使用から学ぶことが重要だと主張。時間の経過とともにより安全性が高まるAIシステムを作成してリリースしていくと述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 17 Feb 2024 04:45:45 +0000</pubDate></item><item><title>GPT-4は生物兵器を生み出す支援ができるのか　OpenAIの内部安全プロセスがモデルのリスクを評価</title><link>https://ledge.ai/articles/can_gpt4_assist_in_creating_biological_weapons</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年1月31日、大規模言語モデル（LLM）が生物学的脅威の創出を支援するリスクを評価するための初期段階のシステムを開発していると{target=“_blank”}した。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、有害な AI の脅威を防ぐ目的で、最先端の技術や理論を活用して開発された「フロンティアモデル」がもたらす壊滅的なリスクを追跡、評価、予測し、防御するための内部の安全プロセスを{target=“_blank”}。

悪意のある攻撃者が、AIシステムの支援により生物学的脅威を生み出すことが、潜在的に有害な用途の1つであると研究者や政策立案者らは強調する。リスクに対し、大規模言語モデルが生物学的脅威の作成をどの程度支援できるかを安全プロセスの一環として、特にGPT-4の影響を検証した。

研究では、生物学専門家と学生を含む100人の参加者を用いた評価を行い、参加者は、インターネットアクセスのみとGPT-4アクセスの両方を持つグループに分かれ、生物学的脅威作成に関連するタスクを実行した。

結果は、GPT-4がタスクの正確さと完全さを少し向上させるに留まり、統計的に有意ではないとのこと。

この結果は、リスクの意味のある増加を示すには不十分であるが、今後の研究とコミュニティの議論の出発点となるという。OpenAIは、この評価がAIの安全リスクに対する改善された評価方法の開発に資することを期待している​​と述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 13 Feb 2024 06:53:55 +0000</pubDate></item><item><title>WEELが「AGI終末時計」を公開、2027年の汎用人工知能到来を予測</title><link>https://ledge.ai/articles/weel_agi_doomsday_clock</link><description>:::small
画像の出典：{target=“_blank”}
:::
株式会社WEELは2024年1月25日、「AGI終末時計」を{target=“_blank”}した。

これは、AGI（汎用型人工知能）の進歩とその社会への影響を可視化し、AGIの到来までのカウントダウンやAIビックテックのAGI到達レベル、現在人間が行う仕事の消滅度などをまとめたプロジェクトだ。イーロン・マスク氏やサム・アルトマン氏のような業界著名人の予測やWEEL独自の指標により、AGIの到来時期を残り約3年と予測。

2027年にAGIが実現するとの仮定で終末時計はカウントダウンを続ける。現在のAIの進歩状況を明らかにし、将来の働き方の変化やAIによる仕事の置き換えについて考察することを目的とし、正しい情報の伝達と未来に追いつくための指標作りを目指すという。

さらに、AGIの到達レベルに関する情報や、AIがどの程度仕事を代替できるかについてのパラメータも提供されている。WEELは、この取り組みを通じて、AIと人間の共創カルチャーを目指し、AI-Nativeな時代を前向きに捉える姿勢を示している。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 04 Feb 2024 12:25:39 +0000</pubDate></item><item><title>イーロン・マスクの「Neuralink」が脳インプラント手術を初めて人間の被験者に実施。「テレパシー」が思考でスマホ制御を可能にする</title><link>https://ledge.ai/articles/the_first_human_recieved_an_implant_from_neuralink</link><description>:::small
画像の出典：{target=“_blank”}
:::

イーロン・マスク氏は2024年1月30日、Neuralinkが人間への初の脳インプラント手術を実施し、患者が順調に回復していること、さらに神経スパイクの検出において初期段階で有望な結果を示しているとX（旧Twitter）に{target=“_blank”}した。脳インプラントのヒトへの装着については2023年5月にマスク氏が明らかにしており、9月には治験実験が承認され、被験者を募集開始していた。

!
:::small
画像：{target=“_blank”}
:::

Neuralinkの完全埋め込み型ワイヤレス・ブレイン・コンピュータ・インターフェース（BCI）の治験医療機器試験は、Precise Robotically Implanted Brain-Computer Interfaceより「PRIME Study」と呼ばれている。Prime Studyは、四肢麻痺を持つ人々の生活を変革する可能性を持つ実験的デバイスの初の臨床試験だという。

被験者を募る{target=“_blank”}では、同社は、脊髄損傷による四肢麻痺やALS（筋萎縮性側索硬化症）で生活している人々に向けて「Prime Study」に参加資格の可能性を示唆し、実験の被験者は各ステップで専任のチームによってサポートされること、そして参加者の勇気と貢献が自身だけでなく、無数の他者のための相互作用と独立性の未来を大きく形作る可能性があることを強調している。

@

マスク氏の投稿によれば、思考だけで電話やコンピューター、そしてそれらを通じてほぼあらゆるデバイスを制御可能にするというこの製品を「Telepathy（テレパシー）」と呼ぶという。

同氏は続けて
「初期ユーザーは手足の機能を失った人たちになります。スティーブン・ホーキング博士が、スピードタイピストや競売人よりも速くコミュニケーションできたらと想像してみてください。それが目標です」
と述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 03 Feb 2024 15:11:22 +0000</pubDate></item><item><title>AIが人間の目の代わりになるのは25％以下のタスクだけ。コンピュータビジョンに関するMITの研究</title><link>https://ledge.ai/articles/rethinking_ai_impact_mit-csail_study</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年1月18日、マサチューセッツ工科大学やIBMの研究者らが「コンピュータビジョンを用いた自動化がコスト効果のあるタスクは何か」と題する研究報告を[発表](https://www.csail.mit.edu/news/rethinking-ais-impact-mit-csail-study-reveals-economic-limits-job-automation
){target=“_blank”}した。

この研究では、AIによる自動化が経済的に魅力的であるタスクとそうでないタスクを見分ける新しいモデルを提案。特にコンピュータビジョン（画像やビデオから情報を解析・理解するための技術的な処理）に焦点を当てている。

現在のコストでは、米国企業がビジョンタスクの大部分を自動化しない選択をすること、そして「AIエクスポージャー」にさらされているビジョンタスクのうち、わずか23%が自動化に向いているという結果となった。「AIエクスポージャー」とは、特定の職務や業務がAIや自動化技術によってどの程度影響を受ける可能性があるかを示す指標。この指標は、特定の仕事がAIに取って代わられるリスクの高さを測定し、将来の労働市場におけるAIの影響を予測するために使用される。

この研究により、AIによる仕事の置き換えは顕著だが徐々に進むため、政策や再教育による失業影響の緩和に余地があることが示唆されている。
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Fri, 02 Feb 2024 08:44:06 +0000</pubDate></item><item><title>NTTグループ・内閣府など　石川県珠洲市で能登半島地震の住家被害認定調査の実施　ドローンや360度カメラ活用</title><link>https://ledge.ai/articles/noto_shien_drone</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月21日、NTT東日本グループ、ESRIジャパン株式会社、NTT西日本グループは、令和6年能登半島地震で大きな被害を受けた石川県珠洲市で、ドローンや360度カメラを用いた住家被害認定調査と、遠隔地からの被害判定支援を行ったことを{target=“_blank”}した。この活動は内閣府、石川県、珠洲市と連携し、応援自治体である熊本市・浜松市も参加して実施された。

!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みの目的は、人の立ち入りが困難な地区での効率的な住家被害認定調査の実施と、調査人員の確保、迅速な罹災証明書の発行を通じて、被災者の生活再建を一日も早く実現することにある。

珠洲市では、ドローンや360度カメラを活用し、特にアクセスが困難な山間部や海岸部での住家被害認定調査を行い、得られた画像データを基に遠隔地からの判定支援を実施した。この取り組みは、NTTグループが電気通信役務でのインフラ点検に活用している体制を基にし、事業者としては初の試みである。遠隔地からの判定は、応援職員が現地に行かずに自庁で実施することが可能であり、職員の負担軽減と住家被害認定調査の迅速化を実現した。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の取り組みにより、災害時における住家被害認定調査の新たな手法として、ドローンや360度カメラの活用が有効であることが証明された。今後はこの取り組みを基に、より迅速かつ公平公正な罹災証明書の発行を実現し、地震だけでなく水害や風害など他の災害にも対応できる体制の確立を目指す。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 03 Mar 2024 08:27:08 +0000</pubDate></item><item><title>日本政府 AIセーフティ・インスティテュート設立へ</title><link>https://ledge.ai/articles/japan_ai_safety_institute</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月14日、内閣府と独立行政法人情報処理推進機構（IPA）は、AIの安全性に対する国際的な関心の高まりを踏まえ、AIセーフティ・インスティテュートの設立を{target=“_blank”}した。

主な業務としては、国内外のネットワークを活用して、安全性評価に関する調査や基準の検討、実施手法に関する検討、および他国の関係機関との国際連携などが挙げられている。関係省庁には内閣府、内閣官房、警察庁、デジタル庁などが名を連ね、関係機関には情報通信研究機構や理化学研究所などが含まれる。

同機関はIPAに設置され、所長には元日本IBMのAI研究者であり、損保ジャパンCDO及び京都大学防災研究所客員講師を務める村上明子氏が就任した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:02:30 +0000</pubDate></item><item><title>JASRAC、AIと著作権に関する考え方について文化庁へ意見提出</title><link>https://ledge.ai/articles/jasrac_submits_opinion_to_agency_for_cultural_affairs_on_ai_and_copyright</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

JASRACは2024年2月14日、文化審議会著作権分科会法制度小委員会がまとめた「AIと著作権に関する考え方について（素案）」に対する意見を文化庁へ提出したことを{target=“_blank”}した。

JASRACは、クリエイターが安心して創作活動に専念できる環境の確保と、AI利活用の枠組みの実現に向けた検討や提言の継続を強調している。

提出した意見では、生成AIを巡る著作権者、AI開発事業者、AI利用者等の懸念に対し、現時点の条文解釈のみならず、立法論を含む本格的な検討の必要性を主張した。特に、従来の著作権法との整合性、アイデアと創作的表現の区別、作風の保護、依拠性の考え方、著作物利用の透明性確保など、複数の重要な点について具体的な提言を行っている。

JASRACは、AIによる生成物がクリエイターの著作物に対する需要を代替する事態や、著作権者の利益を不当に害する可能性に対する懸念を表明。また、著作権制度が人間の創作を奨励するためのものである原点を強調し、AIによる機械的な生成との区別を明確にする必要があると指摘している。

このほか、著作物に当たらないものを著作物として流通させる行為に関する著作権法の保護適用、罰則規定の新設などについても意見している。JASRACは、AIと著作権の関係に関する議論を、現行法の解釈にとどまらず、立法論も含めて早急に行うことを強く求めている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 19 Feb 2024 06:22:43 +0000</pubDate></item><item><title>仙台市、スマートシティ目指す実証実験　レベル４を想定したEVバスの運行調査や、複合施設での全自走する清掃ロボ検証など</title><link>https://ledge.ai/articles/sendai_demonstrated_experiment_for_a_smart_city</link><description>:::small
画像の出典：{target=“_blank”}
:::

### 自動運転EVバスの運行テスト

パシフィックコンサルタンツは2024年2月9日、仙台市×東北大学スマートフロンティア協議会の取り組みの一環として、青葉山エリアで自動運転EVバスの実証・実装を目指す「青葉山グリーン回遊プロジェクト」を{target=“_blank”}した。

プロジェクトでは、自動運転技術を搭載したEVバス車両を手動運行しながら、自動運転レベル4に相当する周辺環境のデータ収集・分析を行う。

調査は2月11日から18日までの4日間で行われ、期間中、バスは無料で乗車可能とした。調査目的は、自動運転に必要な技術的課題や利用者ニーズの把握とされる。

仙台市×東北大学スマートフロンティア協議会とは、仙台市におけるスマートシティ実現に向けて、産学官民が連携し、規制改革提案、先端サービス開発、データの効果的活用を進めるための組織である。この協議会は、地域課題の解決と未来社会の実現を目指している。


### 複合施設でのロボットサービス実験
2月13日には、青葉区の複合施設である仙台トラストタワーで、ロボットが複数階の移動を伴う清掃業務や食品のデリバリーサービスを行い、実験の様子を複数メディアが報じた。

@
:::small
出典：khb東日本放送
:::
この実証実験は、{target=“_blank”}に向けた取組として、2023年9月に経産省の補助事業「令和5年度革新的ロボット研究開発等基盤構築事業」に採択された4社が共同で行った。

施設におけるサービスロボットのスムーズな運行を可能とする「ロボットフレンドリーな環境」の構築に向け、ホテルやオフィス、商業施設を含む複合施設「仙台トラストタワー」において、複数階の移動を伴う清掃業務や食品（お弁当・コーヒー・ランチBOX）のデリバリーサービスなどの業務にロボットを実装。その効果や運用上の課題、経済性の検証が行われる。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 19 Feb 2024 06:19:36 +0000</pubDate></item><item><title>経産省　エッジAI向け半導体開発を強力支援、ラピダス参画のLSTC（最先端半導体技術センター）に450億円支援</title><link>https://ledge.ai/articles/meti_provides_45billion-yen_support_for_lstc_edgeai_semiconductor</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

経済産業省は2024年2月9日、エッジAI向けの半導体開発を強力に後押しするため、ラピダス社などを含む複数の企業及び研究機関が参画する技術研究組合「最先端半導体技術センター（LSTC）」に対し、合計450億円の支援を行うと{target=“_blank”}した。

経産省は、今回の支援により、参画組織が協力し合い、エッジAI技術の実用化を加速させることを目指すとした。
{target=“_blank”}によると、支援の対象となるプロジェクトには、エッジコンピューティング環境での効率的なデータ処理を可能にする新技術の開発が含まれるとのこと。

採択された事業は以下の通り

**「Beyond 2nm及び短TAT半導体製造に向けた技術開発」**
2nm世代よりもさらに高性能な半導体の実現のため「Beyond 2nm向けデバイス・材料・プロセス要素技術および短TAT・クリーンプロセス装置技術」を国際連携も活用し開発する。この技術が実現すれば、半導体の一段の高性能化に加え、半導体製造期間の短縮が期待できる。

**「2nm世代半導体技術によるエッジAIアクセラレータの開発」**
次世代半導体設計技術として、生成AIを含むエッジ推論処理用途に専用化したエッジAIアクセラレータの開発を国際連携により推進する。エッジAIアクセラレータは少ない消費電力で高速演算処理が可能となる。Rapidus株式会社開発の最先端ロジック半導体の製造技術の有効性を最大限引き出すことを想定。

経済産業省の支援策は、半導体技術が国家戦略的にも重要な位置を占める中、日本の技術力を世界水準に引き上げるためのものだ。エッジAIは、データセンターやクラウドではなく、デバイス側で直接データ処理を行う技術であり、応答時間の短縮やプライバシー保護、ネットワーク帯域の節約などの利点がある。この分野でのイノベーションは、スマートシティ、自動運転車、IoTデバイスなど、多岐にわたる応用が期待されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 19 Feb 2024 02:57:10 +0000</pubDate></item><item><title>徳島県鳴門市がAIチャットボットを導入。イメージキャラクター「にゃるひげ」が市民の問い合わせに対応</title><link>https://ledge.ai/articles/naruto_begins_ai-chatbot_service</link><description>:::small
画像の出典：{target=“_blank”}
:::

徳島県鳴門市は、市民からの問い合わせに関する利便性向上を目的として、AIを活用したチャットボットを{target=“_blank”}した。このチャットボットは、市役所の手続きや制度に関する質問に対し、AIが対話形式で回答する。利用者はパソコンやタブレット、スマートフォンから24時間いつでもアクセス可能で、鳴門市のイメージキャラクター「にゃるひげ」が質問に答える。

市公式ウェブサイトやLINEアプリからもアクセスでき、外国語にも対応しているとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 15 Feb 2024 03:50:39 +0000</pubDate></item><item><title>Google系列のロボタクシー「Waymo」サンフランシスコで群衆に囲まれ車体を破壊される</title><link>https://ledge.ai/articles/a_crowd_in_sf_destroyed_waymo_robo-taxi</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月11日、サンフランシスコのチャイナタウンで、Google系列の無人タクシーWaymoが群衆によって取り囲まれ、破壊行為の対象となったと複数メディアが報じた。サンフランシスコ消防署メディアがX（旧Twitter）に{target=“_blank”}した情報によると、車両は取り囲まれ、落書きされ、窓ガラスは割られ、車内では花火に火がつけられ、最終的に車両全体が炎上したという。2月10日は春節（中国の旧正月）。祝いの花火で無人ロボタクシーに点火したと見られている。

!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}の取材に対しWaymoの代表者は、攻撃された際、車両は乗客を運搬していなかったと述べたという。サンフランシスコ警察署の公式情報担当官は、警察が現場に到着した際、車両は既に炎上しており、負傷者の報告はないと確認しているとのこと。

2023年8月に、カリフォルニア公共事業委員会（CPUC）は、Waymoと自動車大手General Motors（GM）傘下のCruise2社に対し、いわゆる「Robotaxi（ロボタクシー）」の追加運営権限を{target=“_blank”}。これにより、サンフランシスコ市で、無人の自動運転車両による有償サービスが終日運行可能となった。しかし、いくつかの事故に関係したCruise社は同年10月、カリフォルニア州陸運局 (DMV) より「公の運行には安全ではない」という理由でこの権限を取り消されている。

サンフランシスコの住民と自動運転車オペレーター間の長年にわたる緊張関係の背景のもとで発生したとThe Vergeは述べている。


:::box

:::
:::box

:::
</description><pubDate>Thu, 15 Feb 2024 02:04:07 +0000</pubDate></item><item><title>バイデン・ハリス政権がAI安全性に特化した初のコンソーシアム「AI Safety Institute」設立を発表　200以上のAI先端企業や学会・市民団体が参加</title><link>https://ledge.ai/articles/the_us_ai_safety_institute_consortium</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国商務省のジーナ・レイモンド長官は2024年2月8日、バイデン・ハリス政権がAIの安全性に専念する米国AI安全研究所コンソーシアム（AISIC）の設立を{target=“_blank”}した。このコンソーシアムは、NIST（国立標準技術研究所）の下、米国AI安全研究所（USAISI）内に設置される。

コンソーシアムは、{target=“_blank”}を含み、AIの最前線にいる企業や組織、最大手企業や革新的なスタートアップ、AIが社会をどのように変えるかの基礎理解を築く学界や市民社会のチーム、そしてAI利用の現場で深く関わる職業の代表者が参加し、安全で信頼性の高いAIの開発と展開を支援するという。

この取り組みは、2023年10月30日にバイデン大統領が署名した{target=“_blank”}に沿うもので、レッドチームの活動、能力評価、リスク管理、安全性とセキュリティ、合成コンテンツのウォーターマーキングに関するガイドラインの開発に貢献することが期待されている。


:::box

:::
:::box

:::
</description><pubDate>Mon, 12 Feb 2024 06:57:28 +0000</pubDate></item><item><title>「自民党AI」開発中。国会論戦もワンランク上がる可能性</title><link>https://ledge.ai/articles/jiminto_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::


「自民党AI」が開発中であると2024年1月30日に{target=“_blank”}が報じた。
スピーチ原稿作成や活動報告書作成など、政治活動に特化した機能を有しており、スピーチの場所やテーマ、聴衆、演説の時間を入力すると、数秒で指示通りのスピーチ文を生成できるという。


取材に応じた自民党の平将明 衆議院議員は、レポーターの「AIが作る文章を読むだけでは、国会議員は必要ないのではという指摘があるが？」との問いに
「AIは、飛行機でいえば『副操縦士』。オートパイロットでもなければ、メインパイロットでもない。それを土台にして、新たな政策を生み出す創造性とかそういうものが議員に問われてくる」と説明。

また、自民党広報本部長の平井卓也氏は、「国会論戦もワンランク上に上がる可能性がある。そっちの期待の方が大きいです」と述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 09 Feb 2024 05:41:32 +0000</pubDate></item><item><title>経産省がNTTなどの採択企業を発表　次世代半導体開発に452億円助成</title><link>https://ledge.ai/articles/ntt_selected_as_nedo_implementing_company</link><description>:::small
画像の出典：{target=“_blank”}
:::

経済産業省は2024年1月30日、NTTを含む企業に対し、NEDO（新エネルギー・産業技術総合開発機構）の次世代半導体開発委託・助成事業として最大452億円を提供することを{target=“_blank”}した。

NEDOの公募した「ポスト5G情報通信システム基盤強化研究開発事業」では、現行の5Gに比べてさらに高度な通信機能を備えたポスト5Gの実現に向け、先端半導体の国内製造技術の開発を目指すものだ。具体的には、光電融合技術やBeyond 2nm世代向け半導体技術の開発などが行われる。同事業では、光電融合技術に焦点を当て、情報伝達を電気から光に変えることで通信速度の向上と消費電力の削減を目指す。
!
:::small
画像の出典：{target=“_blank”}
:::

この日、3つの事業の実施企業として採択されたことを{target=“_blank”}したNTTは、先端半導体およびネットワーク技術の研究開発を進める中で、オール光ネットワークと光電融合デバイスの研究開発事業にも参加することにより、IOWN事業化をさらに促進することを目指す。同社は、IOWNの研究開発および事業化に向けて、IOWN Global Forum参加のパートナーと協力を強化していくと述べた。

また、これらの事業のうち、NTTとキオクシアが実施する「光電融合インタフェースメモリコントローラの研究開発」に、東北大学が再委託先として参画することを{target=“_blank”}した。「光電融合」に対応したメモリー制御技術の一部を、東北大の国際集積エレクトロニクス研究開発センターが開発するという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 07 Feb 2024 09:58:41 +0000</pubDate></item><item><title>中国で新たに13社が開発したLLMの一般公開が承認される。シャオミなどAI以外の企業も</title><link>https://ledge.ai/articles/13_new_chinese_iims_approved_for_public_use</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

中国では、生成AIサービスの管理規定「生成式人工智能服务管理暂行办法（生成AIサービスの管理に関する暫定措置）」の第4期の認可のための審査が行われた。2024年2月4日、小米科技（シャオミ）など、13社が開発した大規模言語モデル（LLM）および生成AI関連プロダクト14種が審査に合格し、一般公開が承認されたと{target=“_blank”}が報じた。

中国政府は2023年7月13日に「{target=“_blank”}」を発表した。政府がAI技術の発展における規制枠組みを強化していることを示しており、AIモデルの公開にあたっては、データセキュリティ、プライバシー保護、知的財産権の尊重など、一定の基準を満たす必要がある。

この措置は8月15日に施行され、以降40以上のAIモデルが承認を受けている。第1期には百度（バイドゥ）、アリババクラウド（阿里雲）、字節跳動（バイトダンス）などのLLMが政府の承認を得た。AI技術が社会に及ぼす影響を考慮し、その安全性と信頼性を確保するために、このような審査制度を設けているという。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Feb 2024 13:37:50 +0000</pubDate></item><item><title>神戸市、全職員が2月1日から生成AIの本格利用開始</title><link>https://ledge.ai/articles/kobe_begins_full-scale_use_of_genai_for_all_employees</link><description>:::small
画像の出典：{target=“_blank”}
:::

神戸市は、2024年2月1日より、全職員を対象に生成AIの本格利用を開始すると{target=“_blank”}した。

同市は2023年5月に、全国に先駆けて生成AIに関する条例を{target=“_blank”}。6月から3か月間、ChatGPTの試行利用を実施し、独自の利用環境を活用した検証を行った結果、Microsoft社の「Copilot」を用いた本格運用に移行した。11月には、業務でAIを利用する際のルールを条例化すると{target=“_blank”}した。

本格利用では文章生成、文章要約、アイデア出し、Excel関数やプログラミングコードの生成、外国語翻訳、情報検索、画像生成などの機能が活用される。また、利用ガイドラインの見直しや職員向けのオンライン学習コンテンツの提供、プロンプト事例集の作成など、適切な利用を促進するための環境整備も行われるとのこと。


以下、職員向けの{target=“_blank”}より

!
:::small
画像の出典：{target=“_blank”}
:::




:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 05 Feb 2024 12:15:11 +0000</pubDate></item><item><title>ウィル・スミス「これは手に負えなくなってきた！」1年前にAIで生成された不気味な動画を実写で完全再現し笑い飛ばす　OpenAIもSoraで便乗</title><link>https://ledge.ai/articles/wil_smith_is_really_eating_spaghetti</link><description>:::small
画像の出典：{target=“_blank”}
:::

俳優のウィル・スミス氏が2024年2月20日、自身のSNS公式アカウントで「これは手に負えなくなってきた！」というコメントと共に、1年前に話題となったAI生成動画を{target=“_blank”}を撮影・投稿した。この投稿に対しファンは「このビデオがAIではないことに気付くのに1分はかかった」「まさか実写版を見るとは思わなかった（笑）」などとコメントを投稿。

元になった動画は、2023年4月にRedditに投稿され賛否両論を呼んだ「パスタを食べるウィル・スミス」というAIによって生成された動画だ。直感的に不快感を呼ぶ動画が生み出されたことや、それが人間の純粋な悪意によって拡散される様を「悪魔的」と表現するX（旧Twitter）ユーザーもいたほどだ。この現象は、{target=“_blank”}にも取り上げられた。

2月15日にOpenAIが発表したSoraの動画生成能力に世界が熱狂し、ふたたびこの動画が掘り起こされることとなった。これを受けウィル・スミス氏が、「1年前のAI生成動画」VS「現在のAI生成動画」と皮肉って、ユーモアたっぷりにこの動画を投稿した。AIによって引き出される不気味さや人の悪意を、コメディの力で笑い飛ばした人間の完全勝利の瞬間ではないだろうか。

この動画が投稿された数日後、OpenAIはSoraで「ウィル・スミスを食べるスパゲッティ」という動画とプロンプトを公開している。

@

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 01 Mar 2024 05:43:24 +0000</pubDate></item><item><title>オンラインゲーミングプラットフォーム「Roblox」でリアルタイムAIチャット翻訳機能をリリース 日本語含め16カ国語に対応</title><link>https://ledge.ai/articles/roblox_breaking_down_language_barriers_with_a_multilingual-translation-model</link><description>:::small
画像の出典：{target=“_blank”}
:::

オンラインゲーミングプラットフォーム・ゲーム作成システム「Roblox」を運営する米国Robloxは2024年2月5日、リアルタイムでのAIチャット翻訳機能を{target=“_blank”}した。この機能は、日本語を含む16カ国語に対応し、異なる言語を話すユーザー間のコミュニケーションの壁を取り払う。

Robloxの最高技術責任者（CTO）ダニエル・スターマン氏によれば、この翻訳モデルはカスタムの多言語モデルを使用し、任意の16言語間の直接翻訳を可能にする。翻訳の遅延は約100ミリ秒と非常に短く、リアルタイムでの会話にほとんど影響を与えないという。同社はこの技術を活用して、世界中の7000万以上の日々活動するユーザーが、自身の母国語でスムーズにコミュニケーションを取れる環境を提供しているという。
!
:::small
画像の出典：{target=“_blank”}
:::

同社のチームは、静的なコンテンツだけでなく、リアルタイムの相互作用や会話もカバーし、Roblox特有のスラングや略語を含む独自の言語も理解するという複雑な要求に応えるため、統一された翻訳モデルの構築に取り組んだ。トランスフォーマーベースの統一された大規模言語モデル（LLM）を使用し、単一のモデルで全言語ペアを処理できるようにしたとのこと。

同社は、ユーザーが母国語で自然な会話ができるようにすることで、世界の10億人をつなぐ目標に近づいていると述べる。今後は、翻訳の精度向上とモデルの訓練データ改善のため、翻訳フィードバックツールを導入予定。将来的には、テキスト、画像上の文字、3Dモデルなどの自動翻訳、さらに自動音声チャット翻訳も視野に入れているとのこと。異なる言語を話すユーザーが低遅延で声のトーンや感情まで理解しあえるコミュニケーションを目指すという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 15 Feb 2024 08:28:23 +0000</pubDate></item><item><title>中国発、AIの「FaceSwap（顔交換）」機能でショートドラマを海外展開</title><link>https://ledge.ai/articles/ai_faceswap_function_to_expand_short_dramas_overseas</link><description>:::small
画像の出典：{target=“_blank”}
:::

中国で2023年11月に配信されたショートドラマがAIによる顔交換技術を駆使し、話題を呼んだと2024年1月27日に{target=“_blank”}が報じた。

この技術は、中国人俳優の顔を欧米人風に変更することで、表情や動きの自然さを保ちつつ、制作コストを大幅に削減し、海外でのリメイクと展開を可能にしたという。「Heygen」が提供するAI顔交換技術により、口元の動きを外国語のセリフに合わせることができ、ショートドラマの国際的な視聴者へのアプローチを新たな次元に引き上げている。

現在の課題は、AI顔交換技術のコストがまだ高く、配信企業は費用対効果の面で懸念があること、また、自然な顔やセリフの差し替えができても、ドラマの背景やストーリー自体が文化的に適合せず、受け入れられないケースも考えられることなど。これらが普及における重要な考慮点となっている。各社は、費用対効果と文化的背景の適合性を考慮しながら、世界市場へのアプローチを模索しているという。
!
:::small
画像：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 09 Feb 2024 05:38:05 +0000</pubDate></item><item><title>Adobe、クリエイターの感性を刺激する生成AI Fireflyの新しいコミュニティギャラリーを発表</title><link>https://ledge.ai/articles/adobe_firefly_community_gallery_to_inspire_creatives</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Adobeは2024年2月1日、新しいFireflyコミュニティギャラリーを{target=“_blank”}した。

以前のコミュニティページでは、同社が作品を選んでギャラリーに送信していたが、新しいFireflyコミュニティでは、クリエイター自身で自分の作品を投稿し、他の人と共有可能だ。

このプラットフォームは、クリエイティブな作品を共有し、インスピレーションを得るための場を提供することを目的としている。Adobe Fireflyは、ユーザーが独自のデジタルアートワークを作成し、世界中の他のクリエイターと交流できるツールセットを備えている。この新ギャラリーは、クリエイティブ業界における協力とイノベーションを促進するためのものだという。

同社は、このコミュニティギャラリーを通じて、クリエイターたちが互いの作品から学び、新たなアイデアや技術を探求する機会を提供することを期待している。Fireflyコミュニティギャラリーは、アートとデザインの境界を拡張し、クリエイティブな才能を発見し、育成する新たなプラットフォームとなることを目指すとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 08 Feb 2024 06:53:16 +0000</pubDate></item><item><title>根拠なき生成AI使用疑惑もなんのその「パルワールド」2月1日時点でユーザー数が1900万人を突破</title><link>https://ledge.ai/articles/the_number_of_palworld_19million_user</link><description>:::small
画像の出典：{target=“_blank”}
:::

ポケットペアは2023年1月19日、マルチプレイヤー対応サバイバルクラフトゲーム「パルワールド」への早期アクセスをSteamで開始したことを{target=“_blank”}した。

パルワールドは、広大な世界で不思議な生物「パル」を集めて、戦闘・建築・農業を行わせたり、工場で労働させたりするゲームだ。
2月1日時点で、総プレイヤー数が1,900万人を突破したと同社の公式X（旧Twitter）アカウントから発表された。（Steam版で約1,200万本、Xbox版で約700万人）

!
:::small
画像：{target=“_blank”}
:::

19日の発表直後よりアクセスが集中し、大ヒット作品と界隈を賑わせる一方で、ゲームに登場する生き物「パル」のデザインが『ポケットモンスター』のモンスターを模倣している疑いをかける声と、開発に生成AIを使用した可能性があるという声がゲームコミュニティやメディアから上がっているという。

しかし、その疑惑にはほとんど根拠がないと{target=“_blank”}などが報じた。このような疑惑が起こった理由として、ポケットペアの社長である溝部拓郎氏の2年以上前のX（旧Twitter）で、初期の生成AIツールを使用してポケモンを生成する実験に興味を示していたことと、同じころに「{target=“_blank”}」というAIに絵を描かせて遊ぶパーティゲームを製品としてリリースしていたことが挙げられた。これらはどれも確固たる証拠にはならない。
!
:::small
画像：{target=“_blank”}
:::

溝部氏のゲームの{target=“_blank”}では、パルワールドの100体以上のキャラクターデザインを担うたった1人のスタッフについて語られている。書類選考で一度は不採用通知を送ったが、スタッフの再募集に対し改めてメッセージを送ってきた彼女に興味を持ち、採用を決めたという。個性的なデザインとスピーディな仕事ぶりが、同社に「ピッタリの人材だった」と述べている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 03 Feb 2024 21:19:51 +0000</pubDate></item><item><title>SNSと生成AIのあり方が問われた１週間　テイラー・スウィフトのAI偽画像が拡散→Xが検索不可→ホワイトハウスがコメント→Xも声明「同意なきヌードは許さない」</title><link>https://ledge.ai/articles/deep-fake_images_of_taylorswift_spread</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月下旬、米国の人気歌手テイラー・スウィフト氏を題材にした性的な偽の画像がAI技術を用いて作成され、ソーシャルメディア上で広く拡散されたと複数のメディアが報じた。これらの画像は、特にX（旧Twitter）上で広がり、問題の画像は削除された後も他のアカウントによって再投稿され、新たな露骨なフェイク画像が次々と現れた。ある画像は17時間で4700万回以上閲覧される事態となり、大きな波紋を呼んだ。

これに対しXは、問題の画像の削除と、偽画像を投稿した一部アカウント停止を行い、検索キーワード「Taylor Swift」でユーザーが問題の画像を検索できないよう一時的な措置を講じた​。

ホワイトハウス報道官のカリーヌ・ジャン=ピエール氏は1月26日、この問題についてし、偽のAI画像に対する法的対策の重要性を強調した。

AI検知に特化したサイバーセキュリティ企業Reality Defender社CEOのベン・コールマン氏は、この画像が拡散モデルを使って作成されたものであることを90％の信頼性で突き止めたと{target=“_blank”}。

同氏はまた、オンラインのディープフェイクの96%以上がポルノで、女性が99%の標的だと述べる。2023年の初めの9ヶ月でディープフェイクポルノが54%増加し、効力のある法的な対策を打ったのが10州だけだという。いくらAIのディープフェイクを技術で検出できても、問題自体を解決できるのは法律だけだと強調。何千人もの一般女性が虐待や嫌がらせに直面しているが、著名人のディープフェイクが取り沙汰されて初めて問題が真剣に受け止められる状況に遺憾の意を示した。

Ｘは「Safety」アカウントで以下の声明を投稿した。
「Xでは、非合意のヌード（NCN）画像を投稿することを固く禁じており、そのようなコンテンツに対して一切の容認をいたしません。私たちのチームは、確認されたすべての画像を積極的に削除し、それらを投稿したアカウントに対して適切な措置を講じています。さらに違反があれば直ちに対処し、コンテンツが削除されるよう、状況を注意深く監視しています。私たちは、すべてのユーザーにとって安全で尊敬に値する環境を維持することを約束します」
!
:::small
画像：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 02 Feb 2024 08:38:54 +0000</pubDate></item><item><title>JASRACを含む9団体、音楽分野におけるAIの健全な利用を目指す「AIに関する音楽団体協議会」を設立</title><link>https://ledge.ai/articles/establishment_of_the_music_organisations_council_on_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年1月25日、JASRACを含む9団体は「AIに関する音楽団体協議会」の設立を{target=“_blank”}した。この協議会は、生成AIの技術進歩による音楽文化の発展とクリエイターやアーティストの権利保護を目的としている。

協議会は、生成AIが音楽コンテンツの創作に与える影響は大きく、著作権法の現状では、AIによる学習利用に対し権利者が意思を反映させることが困難であり、ディープフェイクなどの技術によるアーティストの保護が確立していないと懸念を表した。これらの問題に対処するため、協議会は生成AIの利活用における調和のとれた枠組みの検討や提言を行う予定だという。

JASRACは2023年7月に、クリエイターが安心して創作に専念できる、創造のサイクルとの調和が取れたAI利用の枠組みを訴える目的で「{target=“_blank”}」を公表していた。

「AIに関する音楽団体協議会」参加団体（団体名は五十音順）
一般社団法人 コンサートプロモーターズ協会（ACPC）
一般社団法人 日本音楽作家団体協議会（FCA）
一般社団法人 日本音楽事業者協会（JAME）
一般社団法人 日本音楽出版社協会（MPA）
一般社団法人 日本音楽制作者連盟（FMPJ）
一般社団法人 日本音楽著作権協会（JASRAC）
公益社団法人 日本芸能実演家団体協議会
実演家著作隣接権センター(CPRA)
一般社団法人 日本レコード協会（RIAJ）
株式会社 NexTone（ネクストーン）



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 13:11:56 +0000</pubDate></item><item><title>AIゴッホと対話できる「Bonjour Vincent（ボンジュール・ヴィンセント）」学術機関との共同研究の成果が仏オルセー美術館で開催中　2024年2月4日まで！</title><link>https://ledge.ai/articles/bonjour_vinzent_musee-orsay</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゴッホ生誕170周年となる2023年、パリのオルセー美術館では同年10月より「ヴァン・ゴッホ展」を開催している。「”Van Gogh à Auvers-sur-Oise, les derniers mois”）～オーヴェルシュルオワーズ最後の数か月（Van Gogh in Auvers-sur-Oise）」という、画家ゴッホが生涯で最も多くの作品を残したされる最後の70日間にフォーカスした展示だ。

この企画に合わせ、フランスのスタートアップJumbo Manaが開発した生成AI「Bonjour Vincent（ボンジュール・ヴィンセント）」アプリケーションで、訪問者がゴッホと対話できるコーナーを{target=“_blank”}している。

この生成AIアプリケーションは、ゴッホのやり取りした約900通の手紙をコーパスとして学習しており、彼の人生や作品について語る「AIゴッホ」との対話を可能にする。来場者は、インタラクティブ端末に接続されたマイクを使用して、有名な「カラスのいる麦わら畑」を描いている最中のAIゴッホに話しかけ、一対一での会話を楽しめるという。

このプロジェクトは、BPI FranceとGrand-Est地域、パリ大学サクレー校、科学計算資源開発研究所(IDRIS)の支援を受け、Jumbo Manaとゴッホの専門家であるWouter van der Veen博士との共同研究によって実現した。オルセー美術館とのパートナーシップにより、学術研究から来訪者との直接的な相互作用を伴う応用研究へと移行し、来訪者が質問すればするほど、AIは学習し向上していく。

展示は2024年2月4日まで。「Bonjour Vincen」コーナーは、オルセー美術館の展示会出口で無料で利用可能。


:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Jan 2024 11:07:12 +0000</pubDate></item><item><title>AIお絵描きアプリ「AIピカソ」、1枚の全身画像からダンス動画を生成する「AIダンス」機能をリリース</title><link>https://ledge.ai/articles/ai_picasso_ai_dance</link><description>:::small
画像の出典：{target=“_blank”}
:::


2024年1月15日、AI Picasso株式会社は、AIお絵描きアプリ「AIピカソ」内で、1枚の全身画像からダンス動画を生成する「AIダンス」機能を{target=“_blank”}した。

@

AIダンスは、ユーザーがアプリ内に写真をアップロードするだけで、様々なタイプのダンス動画を自動生成する。特に全身写真を使用すると、高品質の動画が得られる。同社によれば、2023年12月時点で、AIダンス機能を入れた一般ユーザーが楽しめるモバイルアプリとしては世界初のリリースだという。

2022年に設立されたAI Picasso株式会社は、画像生成AIサービス「AIピカソ」「AI素材.com」を運営している。AIダンスを通じて新しいコミュニケーションの形成に貢献し、今後もダンスパターンの拡大や精度向上を目指すとしている。


:::box

:::
:::box

:::

</description><pubDate>Mon, 22 Jan 2024 02:46:45 +0000</pubDate></item><item><title>芥川賞受賞作品『東京都同情塔』、内容にも手法にも生成AIの影響 九段理江氏「5％は生成AIの文章そのまま」「利用しながらも自分の創造性を発揮できるように」</title><link>https://ledge.ai/articles/akutagawa_prize-winning_works_use_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本文学振興会は2024年1月17日、都内で開催された第170回芥川龍之介賞の選考委員会で、九段理江氏の「東京都同情塔」が授賞作に決まったと{target=“_blank”}した。

この作品は、今、日本が抱える問題を軸に、別の世界線に存在したかもしれない未来を探求するSFだ。生成AIが普及する社会で、仕事と信条の間で葛藤する建築家の主人公。物語の背景は、ザハ・ハディドの設計した国立競技場が完成し、オリンピックが開催されたもう1つの日本だ。犯罪者を「同情されるべき人々」と捉える風潮が広まる近未来のディストピアが、建築と言語をテーマに「現代版バベルの塔」を描く。

受賞者会で九段氏は、『東京都同情塔』という作品はアンビルト（未建築）をモチーフにした作品。完成してもぐらぐらしている小説だと考えている。今にも崩壊してしまいそうな危うさが、この小説の魅力だと自分では思っているとコメント。

また、生成AIに関して
「この作品は、AI、つまりChatGPTのような生成AIを駆使して書いた小説で、おそらく全体の５％くらいは生成AIの文章をそのまま使っているところがある。これからも利用しながら、かつ利用しながらも自分の創造性を発揮できるように、うまく付き合っていきたいと考えている」と述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jan 2024 08:14:08 +0000</pubDate></item><item><title>いつまで人間は潜在意識下でAIアートと人間の創作物を区別できるのか？　2023年では人間の創作物が優位との研究結果</title><link>https://ledge.ai/articles/identifying_differences_between_ai_and_human_art</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

「人間は、理由なく人間が描いたものを好む」

2023年のボーリング・グリーン州立大学（BGSU）の研究によると、人間は、AIアートと人間の創作物との識別に苦戦しているが、潜在的に人間による作品を好む傾向があるという。この研究について2023年12月18日に{target=“_blank”}が解説している。

産業および組織心理学を研究している博士課程の学生アンドリュー・サモ氏と、教授のスコット・ハイハウス博士が、この研究を「Psychology of Aesthetics, Creativity, and the Arts（心理学の美学、創造性、および芸術）」というジャーナルで{target=“_blank”}した。

研究では、被験者がAIと人間が作ったアートをランダムに出典を正確に識別することは困難であることを明らかにした。彼らは、アートの作者が人間かAIかを特定する際には50〜60％の確率で正解する程度、つまりコインを投げて表か裏かを言い当てるのと変わらぬ確率だった。しかも被検者たちは、その識別には自信がないことを認めていたという。

その一方で、人々はAIによって生成されたアートと人間によって生成されたアートを区別することは困難であっても、人間によるアートワークを好む傾向があり、その理由を説明することができないことも発見された。人間によるアートに対しては、よりポジティブな感情が報告され、「内省」「魅力」「ノスタルジア」「楽しさ」の4つの美的判断要因で高い評価を受けた。


下の2つのポスト印象派作品は、片方がポール・セザンヌの「メダンのセーヌ河岸」で、もう一方がAIの描いたパリの風景画だという。人間の直感は何を伝えてきただろうか。

!
:::small
画像の出典：{target=“_blank”}
:::

ここでサモ氏は「不気味の谷効果」を提示した。AIによって作られたアート作品は、全体的には人間の作品に似ているが、細部の表現やストーリーの展開において、人間の作品とは微妙に異なる部分がある。そのため、人々は無意識のうちにこれらの違いを感じ取り、その結果、何となくの違和感や不気味さを感じるというのだ。

これまで単に繰り返し作業を行う能力に限定されていたAIだが、この研究は、芸術、音楽、詩、散文、テキストなどの創造的な作品を、ほとんど人間と区別がつかないレベルでAIが生成する能力を持つようになったことを示している。

AIが進化し、より強力なモデルが日常生活で使用されるようになるにつれ、AIの心理的影響と人間への影響を理解し続けることが重要であるとサモ氏は述べる。新しいモデルの一部は、実際世界に対し非常に高品質で忠実度の高い画像を生成できるため、同様の実験を行うこの研究を再度実行することへの興味も示しているという。

昨年より、次々と開発が発表され続ける新しいモデルの進化スピードには目を見張るものがある。今、同じ実験をやり直したとして、人々は果たして同じように違いを見極められるのだろうか。


:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jan 2024 02:19:31 +0000</pubDate></item><item><title>アイビスペイント、生成AI利用した「AIお手本機能」を取り下げ。規約も改正「機械学習モデルの学習にユーザ創作物を利用しない」</title><link>https://ledge.ai/articles/ibispaint_has_withdrawn_ai_example_window</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月10日、アイビスペイントは9日にリリースしたバージョン11.2.0（App Store版、Google Play版、Microsoft Store版）に追加した「AIお手本機能」の取り下げを{target=“_blank”}した。

取り下げられた「AIお手本機能」は、画像生成AIを活用し、描いている絵をもとにリアルタイムで「お手本」を生成し表示する機能。「既存のキャラクターが表示された」「アイビスペイントを使って描いたらAIで生成したと思われるのでは」といったユーザーからの反響を受けとめ、実装の中止を決定したという。現在、この機能の提供は停止されており、今後のアプリアップデートでユーザーインターフェースから削除される予定だという。

!
:::small
画像の出典：利用者のSNSより。ibis paintのページからはすでに削除済
:::



新機能は有料のプレミアム会員（Windows版はプロアドオン）の購入が必要だったため、新機能のためにプレミアム会員またはプロアドオンを購入したユーザーには、App Store、Google Play、Microsoft Storeで返金を受け付けるとのこと。

同社はこの日、1週間後の1月17日を施行日として、ibisPaintサービス利用規約の改定を行うことを{target=“_blank”}した。
改定内容は、利用者の創作物を無断でAIモデルの学習に無断で使用しないと明記したことと、創作物のライセンスについて分かりやすく加筆修正したという2点だ。


同社は11月20日、{target=“_blank”}を行う中で、生成AIについての考えを問われた。代表取締役社長の神谷栄治氏が回答し、同社がAI自体には取り組みたい意向を示した。すでにいくつかAI機能の追加を進めており、その内容やマーケティングには慎重を期すべきと述べた。

同氏はまた「既存ユーザーは、絵を描くこと自体を楽しむ人がほとんどで、画像生成AIを歓迎しない傾向にある。しかし、仕事で使う場合の生産性の高さを求める声もあり、今後はそのようなユーザー層の利用も増えていく。双方のバランスを取りつつ、既存ユーザーが納得し、仕事にも使用できるサービスを作っていきたい」と述べていた。

アイビスペイントは、スマートフォンやタブレットで使用できる無料のペイントアプリケーション。指一本でイラストが描けるほか、取り込んだ写真やイラストの色付けや編集も可能だ。また、作品は同社の運営するサイトに投稿でき、SNSの機能も有する。19言語に対応し、2023年8月末時点で累計ダウンロード数が3億4000万回を達成するなど、世界中に利用者を持つ。

9月14日には、11.0.0バージョンをリリースし、AIを用いて、対象物と背景を切り分けることで、背景を簡単に透過できるフィルター機能「(人工知能)：背景透過」を追加していた。


:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Jan 2024 10:12:38 +0000</pubDate></item></channel></rss>