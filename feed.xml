<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Tue, 16 Apr 2024 07:20:41 +0000</lastBuildDate><item><title>約60%の学生が就活でチャットAIを活用、前年度から20％増加　2025年卒大学生を対象にマイナビが調査</title><link>https://ledge.ai/articles/mynavi2024_research</link><description>:::small
画像の出典：{target=“_blank”}
:::

株式会社マイナビは2025年卒業予定の大学生を対象に実施した「マイナビ2025年卒大学生活動実態調査（3月）」の結果を4月5日に{target=“_blank”}した。

「対話形式で生成系AIが質問に答えるサービス（「ChatGPT」等）」の利用経験を聞いたところ、就職活動以外も含め利用したことがある割合は59.7％（前年比20.5ポイント増加）と半数以上が利用経験者であることが分かった。その中で就職活動で利用したことがある割合は35.2％（前年比16.8ポイント増加）となり、生成系AIの利用がより一般的になり様々な場面で利用機会が広がっている。

一方{target=“_blank”}によると、企業側は就職活動での生成系AIを利用したサービス活用について「使い方に気を付けたうえで活用してほしい」という意見が4割を超えている。情報の信憑性など利用においては注意が必要だが、利用方法次第でスキルのひとつに繋がるとも考えられる。
!
:::small
画像の出典：{target=“_blank”}
:::

調査は2024年3月25日から3月31日に2025年3月卒業予定の全国の大学生、大学院生を対象としWebアンケートを実施。有効回答数は2,963名。

:::box

:::
:::box

:::
</description><pubDate>Tue, 16 Apr 2024 07:20:41 +0000</pubDate></item><item><title>英半導体Arm、性能を4倍に向上させたエッジAI向け新NPU（ニューラル・プロセッシング・ユニット）「Ethos-U85」を発表</title><link>https://ledge.ai/articles/arm_ethos-u85</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月9日、英半導体のアームは、高性能エッジAIアプリケーション向けに設計された最新世代のプロセッサ「Arm Ethos-U85 NPU」と、新しいIoTリファレンスデザイン・プラットフォーム「Arm Corstone-320」を{target=“_blank”}した。

Ethos-U85は、前世代比で性能を4倍に、エネルギー効率を20%向上させた。ファクトリー・オートメーション、民生用カメラ、スマートホーム用カメラなど、高性能が求められるアプリケーションに最適とされる。NPUは、TensorFlow LiteやPyTorchといったAIフレームワークをサポートし、Transformerネットワークおよび畳み込みニューラルネットワーク（CNN）のAI推論に対応しているという。

また、Arm Corstone-320プラットフォームは、Arm Cortex-M85 CPU、Mali-C55イメージシグナルプロセッサー、そしてEthos-U85 NPUを組み合わせたもので、リアルタイムの画像分類や物体認識、スマートスピーカーを通じた自然言語翻訳対応の音声アシスタントなど、多岐にわたるエッジAIアプリケーションの高い性能要求に応える設計とのこと。

同社のシニア・バイスプレジデントでIoT事業部門のジェネラル・マネージャー、ポール・ウィリアムソン氏は、「エッジAIの導入と拡大を容易にするためには、ソフトウェア開発者が新たなAIフレームワークやライブラリと容易に連携できる必要がある」と述べている。同社は、開発者が既存の投資を活用しながら、シームレスな開発体験を提供することを目指すという。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 16 Apr 2024 06:36:36 +0000</pubDate></item><item><title>生成AIとは何者なのか？　その革新性について気鋭のAIベンチャー創業者に聞く</title><link>https://ledge.ai/articles/generativex-2024-interview-1</link><description>2022年11月に登場したChatGPTは世界に衝撃を与えた。それ以降、現在に至るまでテクノロジー業界の話題はChatGPTに代表される生成AI一色に染まっていたといっても過言ではない。

生成AIとは何者なのか。従来のAIと何が決定的に異なり、なぜこれほどまでに世の中を席巻したのか。生成AIの革新性と社会的インパクトについて、2023年に創業したAIベンチャーGenerativeX共同創業者で取締役CSOの上田 雄登氏に聞いた。

## AIの道を選んだのは「技術で社会にインパクトを与えたかった」から
**――まず、上田さんのご経歴やAIとの関わりについて教えてください。**

**上田**：大学生の頃は工学部にいて、カーボンナノチューブの研究などを行っていました。ですから、当時からAIについて学んでいたというわけではないんです。私がやりたかったのは社会にダイレクトにインパクトを与えることで、そのためには技術がビジネスとしっかり結びつかなければならないと考えていました。

そこで大学卒業後に選んだのが、工学系研究科技術経営戦略学専攻（松尾豊研究室）です。そこは「技術を経営やビジネスに活かし、実社会を変えていく」という思想を持った研究室で、私もその考え方に惹かれました。とはいえ、やはり技術自体は相変わらず好きでしたし、技術への憧れもありました。松尾豊研究室は技術経営戦略学専攻の中では技術寄りの研究室で、それもよかったですね。

**――技術といっても様々ありますが、なぜAIに関する松尾豊研究室を選ばれたのでしょうか。**

**上田**：当時はそんなにAI、AIと言っていたわけではないのですが、割とビジネスに近い技術ですし、より社会にインパクトを与えられそうだなと思ったのが理由です。ともかく、重視したのは社会実装できるかという点です。技術がいくらすごくても、社会に広がっていかないと理想が妄想で終わってしまいますから。

## 生成AIは従来型のAIと比べて何が革新的だったのか
**――その意味で、2022年11月に登場したChatGPTをはじめとする生成AIは社会に大きなインパクトを与えているといえます。ただ、生成AIの登場以前からすでにAIは社会の至るところで活用されています。そうした従来型のAIと生成AIは何が違うのでしょうか。**

**上田**：生成AIが革新的だった点は2つあります。1つは生成するテキストの精度の高さです。これまでにも対話型のAIは存在していましたが、生成AIの応答はそうした従来型の対話AIを過去のものにしてしまうほど高いクオリティでした。

なぜそんなことが可能になったのか。その理由は生成AIの学習方法にあります。従来型のAIの場合、学習のためのデータを与える際に「アノテーション」という作業が必要でした。アノテーションとはデータに「ラベル」をつけることです。たとえば「GenerativeX」であれば「会社名」というラベルをつけたり、「上田 雄登」であれば「人名」というラベルをつけたりして、AIに「それが何なのか」を教えてやる必要があったのです。従来型のAIを訓練するための教師データはそのように作成されていました。

ただ、この方法は人がアノテーションを行わないといけないため、どうしても教師データを大量に用意しにくく、AIの精度があまり高くならない欠点がありました。要は人間がボトルネックになってしまっていたのです。

**――一方で生成AIの学習方法はどのようなものなのでしょうか。**

**上田**：生成AIは「自己教師あり学習」という学習方法を用いています。これは、アノテーションでラベルをつけることなく、とにかく大量のデータを用意してAIに学習させる方法です。

**――ラベルをつけなくても精度は上がるのですか？**

**上田**：むしろ精度はより高まります。ポイントは「大量のデータ」という部分です。たとえば「吾輩は猫である」という文章の「猫である」を隠して「吾輩は◯◯◯◯」という問題文を用意します。これをAIに解かせるのです。国語の穴埋め問題のようなものですね。するとAIは大量に学習したデータをもとに、「吾輩は」の続きが「猫である」と予測し、「吾輩は猫である」という回答を導き出します。これを「自己教師あり学習」と呼びます。自己教師あり学習は人がアノテーションする必要がないため、自動的に問題を大量に作れるのがメリットです。

もっとも、単純に大規模なデータを用意するだけでいいかというと、そうではありません。もう1つ重要な要素が「スケール則」です。これは、学習に使用するコンピューティングリソースやパラメータなどを大きくすればするほど、AIの性能が高くなるという法則です。

**――学習データの量だけでなく、それを扱うための環境も重要なのですね。**

**上田**：AIの性能が高くなると、そこに技術とお金が集まります。技術とお金が集まればさらに学習環境が大規模になっていき、AIの性能が上がっていく。そうした規模の経済のもと、AIがどんどん学習して賢くなっていった結果、高い精度で応答できる生成AIが誕生したわけです。面白いですよね。生成AIが学習しているデータは、私たちがインターネットを通じて吐き出し続けたテキストデータです。人の知性が生み出したテキストから、生成AIという“知性のようなもの”が生まれてきたという点は非常に興味深いです。

**――考えてみれば、人間の赤ちゃんや子どもだって大人の発する言葉や文字で学習するわけですからね。**

**上田**：そうですね。言ってしまえば、生成AIは大量の文章を学習することで「続き」を予測しているだけです。でも、もしかしたら「予測」こそ知性の本質かもしれませんよ。赤ちゃんだって大人の行動を見て学習し、次に何をするか、何を言うかを予測しているはずです。だからこそ、大人が予測から外れた行動をとったりするとケラケラ笑ったりするわけですからね。

!

## 誰もが「完成したAI」を使えるようになった
**――生成AIの革新的な点は2つあるとのことでした。もう1つは何でしょうか。**

**上田**：「完成したAI」が誰でも使えるようになったという点です。これまで企業が従来型のAIを使って何かプロジェクトをやろうと思ったら、まずはやりたいことに適したAIをつくるところから始めなければなりませんでした。必要なデータを用意し、それをAIに学習させて訓練を行い、ようやくやりたいタスクを実行できるAIが完成していたわけです。

一方で、生成AIはそのプロセスが不要です。なぜなら、生成AIはすでにあらゆるデータを学習済みの状態で提供されているからです。新たにモデル開発を行うことなく、多くの用途に対応できます。しかも「マルチモーダル」といって、テキストだけでなく画像や音声など様々な形式のインプットにも対応し、アウトプットできるように進化しています。

――たしかに従来型のAIは特定の用途に特化しているものがほとんどでしたが、生成AIはそれ1つで様々な用途に対応できます。

**上田**：移動手段でたとえるなら、これまでは行きたい場所に移動する場合、道路を作るところから始めなければなりませんでした。しかし生成AI登場以降は、すでに道路、それも高速道路が敷いてある状態になっているようなものです。それも、あらゆる方向に伸びているので、あとは車で走るだけです。

**――逆に従来型のAIの方が優れている点はないのでしょうか。**

**上田**：本当に特定の機能に特化させたい場合は従来型のAIの方が向いていることもあるでしょうね。たとえば「明日の天気を予測する」ことだけをやらせたいなら、生成AIよりも専用のAIを使った方がいいと思います。ただ、そのAIの立ち位置は「ツール」に留まるものです。ツールは確かに特定の用途に限れば人間よりも能力を発揮しますが、それだけです。生成AIは時に人の話し相手となり、示唆を与えることすら可能です。ツールのように「人に使われる」だけでなく、「人を使う」ことすらありえるのが生成AIなのです。その意味で、生成AIは単なるツールではなく、より「人間」に近づいているような印象があります。

!

## 生成AI規制論はナンセンス、使いながらルールを整備すべき
**――ChatGPTが登場した2022年11月から現在に至るまで、世の中は生成AIの話題でもちきりでした。生成AIに関する様々なニュースが世間を賑わせましたが、上田さんが注目されているトピックはありますか。**

**上田**：各国の対応の違いは印象的でしたね。欧米では規制論も出ましたが、私は生成AIのような大きな動きが出てきたとき、それを規制することでコントロールするのは無理だと思います。リスクを気にする気持ちもわかりますが、かつてのインターネットがまさにそうでしたよね。爆発的にインターネットが普及する裏で様々なリスクが顕在化し、それまでにはなかった事件も起こりました。しかし、だからといって進歩を止めることはできません。もちろん、クリティカルに影響を受けてしまう人がいる場合は、きちんと対応していく必要はありますが。

考えてみてほしいのですが、リスクがあるからといって車を規制している国があるでしょうか。あるいは電気を規制している国はあるでしょうか。おそらく、車だって開発された最初の頃はルールもあやふやで、皆が思い思いに道を走らせていたはずです。その結果、事故などのリスクが見えてきて、そこに対応する形でルールが整備されていったわけです。道を整備しましょう、もう少し車を頑丈にしましょう、運転免許制度を作りましょうといったように。

ルールを決めたり規制したりするのは、そうやって新しい技術を使い倒しながら、あるいは使い倒した後であるべきです。

**――ちなみに生成AIといえば、テキスト以外にもイラストや写真など様々なコンテンツを生成するAIも登場しました。そちらはどうご覧になっていますか。**

**上田**：イラストや写真は見た目にインパクトがありますから、SNSなどでも盛り上がりましたね。ただ、私はそのブームを見て、むしろ「言語」の重要性をより強く認識しました。人間が社会を構成し、コミュニケーションを図るうえで、言語は絶対に欠かせないものなんです。人間が「思考」するとき、言語を使わない人はいませんから。

**――生成AIは今後、世の中にどんなインパクトを与えるとお考えでしょうか。**

**上田**：生成AIの登場で、まるで水が土にしみこんでいくように、「AI」という存在が社会にしみわたっていくと考えています。先ほど申し上げたように、従来型のAIはほしい機能を実現するために狙いすまして作り上げるものでした。いわば巨大な建造物を造るようなものです。しかし、生成AIはそうではなく、もうすでにすべての人の目の前に存在しています。「これに使いたい」と思えば、すぐに使えます。学習データを集める必要もないし、アノテーションする必要もありません。

生成AIにより、AIは「当たり前にあるもの」になっていくでしょう。たとえばインターネットも以前は「インターネットを使う」と意識して使っていましたが、今はそんなこと意識せずに自然に使っていますよね。それが「しみわたる」ということであり、AIもそうなっていくでしょう。</description><pubDate>Tue, 26 Mar 2024 02:25:27 +0000</pubDate></item><item><title>GPTやGeminiに続け！画像が読めるLLMが次々と　イーロン・マスク氏の「Grok」とNTTの「tsuzumi」　画像認識機能を搭載した最新AI技術を発表</title><link>https://ledge.ai/articles/grok1-5v_tsuzumi_multimordalized</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月12日に、イーロン・マスク氏率いるxAI社とNTTが、それぞれの大規模言語モデル（LLM）「Grok」と「tsuzumi」に画像認識機能を新たに搭載したことを発表した。

4月9日にOpenAIが、画像やビジュアルコンテンツの理解が可能なビジョン機能を搭載したマルチモーダルAIモデル「GPT-4 Turbo with Vision」を API で一般公開したばかりだ。

## xAI.ai「Grok-1.5V」文書、図表、写真などの視覚情報を処理

「Grok-1.5V」は、xAIが開発したマルチモーダルモデルで、従来のテキスト処理能力に加え、文書、図表、スクリーンショット、写真など幅広い視覚情報の解析が可能となった。この進化により、Grokは日常の物理的な世界を理解する能力において、他のモデルと比較しても顕著な性能を発揮するという。

特に、新たに導入された「RealWorldQA」ベンチマークでは、実世界の空間認識能力を測定し、その結果が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::



**図を解読しPythonコードを生成する例**
!
:::small
画像の出典：{target=“_blank”}
:::

**現実世界の空間理解機能を示す例**!
:::small
画像の出典：{target=“_blank”}
:::

同社は、マルチモーダルな理解と生成機能の両方を進歩させることは、宇宙を理解できる有益な AGI を構築するための重要なステップだと述べる。今後数か月間で、画像、音声、ビデオなどのさまざまなモダリティにわたって、両方の機能が大幅に改善される予定だという。



## NTT「tsuzumi」視覚情報を含む文書を理解　DX対応のコア技術として期待
同じ日に{target=“_blank”}のあったNTTの「tsuzumi」は、テキストベースの情報だけでなく、図表やアイコンなど視覚情報も含む文書を総合的に理解する能力を備えているとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

この技術は、文書画像を言語モデルの表現に変換する新しいアダプタ技術を用いており、任意の視覚読解タスクに対して高い指示遂行能力を示している。これにより、オフィス作業や専門文献の読書補助など、多岐にわたる分野での応用が期待されている。


**LLMの推論能力を活用した視覚読解技術の概要図**
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 16 Apr 2024 07:05:35 +0000</pubDate></item><item><title>マイクロソフト、日本のAI及びクラウド基盤増強に4400億円投資
</title><link>https://ledge.ai/articles/microsoft_to_invest_in_ai_and_cloud_in_japan</link><description>:::small
画像の出典：{target=“_blank”}
:::

マイクロソフトは2024年4月10日、日本のAI及びクラウド基盤強化のために今後2年間で4400億円（29億米ドル）を投資すると{target=“_blank”}した。

この取り組みは、DXとAIの活用を加速し、日本経済の活性化に貢献することを目的とする。投資内容には、リスキリングの機会提供、研究拠点の新設、サイバーセキュリティ分野での日本政府との連携強化が含まれているとのことだ。

マイクロソフト副会長兼プレジデントのブラッド・スミス氏と日本マイクロソフト代表取締役社長の津坂美樹氏は、岸田文雄首相の米国訪問に合わせてこの計画を発表した。同社は1978年に日本に事業拠点を設置して以来、日本との関係を深めてきた。今回の投資は、そのコミットメントを更に強化するものだという。

同社は経済産業省が展開する、基盤モデル開発支援のための生成AI開発力強化を図るプロジェクト{target=“_blank”}にも協力しており、引き続き日本の AI 及びデジタル技術活用推進に貢献すると述べた。

新たに東京に設立される研究拠点では、AIとロボティクス、社会とウェルビーイングの課題解決を目指し、科学的探究を進める。これにより、マイクロソフトリサーチは、日本国内外の大学や研究機関との連携を深め、AI研究の新たな進展を目指す。

また、投資には非正規雇用を含む300万人へのリスキリングの機会提供も含まれる。同社は、世界各国で AI スキルを活用した職務への雇用を希望する女性を多数支援しており、多様な背景を持つ人々がAIスキルを身につけ、高度な技術職に就けるよう支援する「Code; Without Barriers」プログラムを日本で初めて実施する。同様に、スタートアップ企業への支援や学校教育の充実も図るとした。

サイバーセキュリティ分野では、日本政府との連携を強化し、国家安全保障のための技術的解決策の提供に努めるとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 16 Apr 2024 06:33:41 +0000</pubDate></item><item><title>PIXTAが生成AI学習用素材としてコンテンツ販売へ　オプトアウト申請は4月22日までに</title><link>https://ledge.ai/articles/pixta_dataset_for_learning_genai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月8日、ストックフォトサービス大手のPIXTAは、同社の画像コンテンツを生成AIの学習用データとして販売開始することを{target=“_blank”}した。

これまで同社は、クリエイター提供の画像を、顔認証などの画像認識AI等の学習用データとして{target=“_blank”}が、生成AIについては提供に慎重な姿勢を示していた。しかし、顧客からの多数の問い合わせとビジネスチャンスを背景にこのたび方針転換したという。

販売されるコンテンツには、写真、イラスト、動画が含まれ、これらは定額制サービスの一環として2024年4月22日の時点で提供されるものが対象である。オプトアウトを希望するクリエイターは、同日正午までに専用フォームを通じて手続きを行う必要がある。

販売形態として、同社は個別のライセンス契約を顧客と結ぶことを想定しており、一般には不特定多数への提供は予定していない。また、生成AI用の学習データとして販売されるコンテンツから得られる収益の一部はクリエイターに還元される。

同社は受領した売上（税抜）から自社の費用を控除した後の80%を取り、残り20%をクリエイター側の取り分としている。この還元は年度ごとに集計され、翌年の1月末日までにクレジットとして付与されるとのこと。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 07:49:52 +0000</pubDate></item><item><title>GoogleがAI動画制作アプリ「Google Vids」を発表　Gemini for Google Workspaceによる機能強化　6月リリース予定</title><link>https://ledge.ai/articles/google_cloud_next24_google_vids</link><description>:::small
画像の出典：{target=“_blank”}
:::

Gppgleは2024年4月9～11 日で開催されたGoogleの年次イベント「Google Cloud Next '24」で、WorkspaceのAI動画制作アプリ「Google Vids」を{target=“_blank”}した。

このアプリは、プレゼンテーションやプロモーションビデオの制作を容易にするAI駆動のツールで、Google Docs、Sheets、Slidesと並ぶ製品群に加わるという。6月にWorkspace Labsを通してリリースされる予定とのことだ。


@



Google Vidsは、ユーザーが簡単に編集可能なストーリーボードを生成し、選択したスタイルに基づいてストックビデオ、画像、背景音楽からシーンを組み合わせてビデオの初稿を作成する機能を持つ。また、事前設定されたボイスオーバーやユーザー自身の声を使用して、メッセージを効果的に伝えるサポートも提供するという。

ユーザーは「Start with a template」機能で、多様なテンプレートから選択し、初稿を自動生成する「Help me create」機能を利用して、動画制作のプロセスを迅速化できる。さらに、生成されたスクリプトや事前設定されたボイスオーバーを利用して、ビデオに声を付けることが可能である。

同社は、Google Vidsが、職場でのコミュニケーションやプレゼンテーションを強化し、誰もが効果的なストーリーテラーになるための支援を提供するという。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Mon, 15 Apr 2024 07:45:03 +0000</pubDate></item><item><title>SlackもついにAI本格導入　英米ではプロンプトなしで使える要約機能が人気　「Slack AI」日本語版が明日4/17から提供開始</title><link>https://ledge.ai/articles/slack_ai_release</link><description>:::small
画像の出典：{target=“_blank”}
:::

セールスフォース・ジャパンは「Slack AI」日本語版を2024年4月17日から提供開始することを{target=“_blank”}した。これまでのSlack上に蓄積した履歴から必要な情報を即座に「検索」と「要約」ができ、マウス操作やタップ操作を行うだけで誰でも簡単にAIサポートを得られるという。

大規模な組織で力を発揮するのが「回答の検索」機能。AIを活用した検索機能により会社規定や過去のプロジェクト実績の確認、特化したメンバーを探すといった質問に対して個別にカスタマイズされた回答が即座に得られる。
!
:::small
画像の出典：{target=“_blank”}
:::

要約機能を使用すれば膨大な情報の中から日付範囲や未読メッセージなど条件を指定して調べることができ、物事の状況を簡単に把握することができる。なお、アクセス可能なデータは利用者が閲覧できるチャンネルのみ。ユーザーが限られるプライベートチャンネルは利用者が参加しているチャンネルのみが検索、要約の対象となり不参加のチャンネルは対象外となる。
!
:::small
画像の出典：{target=“_blank”}
:::

業務の流れの中で様々なアプリと連携させ、業務プロセス自動化も行えるSlack AI。すでに2月に英語での導入が先行しているアメリカ・イギリスでは「要約」機能が一番多く使用されているという。

:::box

:::</description><pubDate>Mon, 15 Apr 2024 03:04:35 +0000</pubDate></item><item><title>OpenAIが東京オフィス「OpenAI Japan」開設を発表　日本語特化版「GPT-4 Customized for Japanese」を手土産に</title><link>https://ledge.ai/articles/openai_japan_tokyo_office</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年4月15日、アジア初の拠点となる東京オフィスを開設すると{target=“_blank”}した。

新拠点を通じて同社は、日本政府、地元企業、研究機関と連携し、日本独自のニーズに応える安全なAIツールの開発を進める計画だという。東京は、その技術力、サービス文化、革新を受け入れるコミュニティの存在により、アジアでの第一拠点として選ばれた。

CEOのサム・アルトマン氏は、「日本は長い歴史を通じて、人々と技術が協力し、多くを成し遂げてきた。AIが、人々をより創造的で生産的になることを助け、まだ想像されていない新しい産業に広範囲に価値を提供することを加速できると信じている」と述べた。

OpenAI Japanの新社長には長﨑忠雄氏が就任した。アマゾン・ウェブ・サービス（AWS）の日本法人で長年社長を務めた同氏が、日本市場での事業と市場への取り組みを率いる。

## 高コスパ・高パフォーマンスの日本語特化版GPT-4を提供

日本市場における長期的なコミットメントの一環として、同社は日本の企業に対し、日本語に最適化されたGPT-4カスタムモデル「GPT-4 Customized for Japanese」の早期アクセスを提供している。

このモデルは、日本語のテキストの翻訳と要約において優れたパフォーマンスを発揮し、コストパフォーマンスも高く、前モデルに比べて最大3倍の速度で動作するという。英語学習アプリ「Speak」は、この技術を利用して、ユーザー（生徒）が間違えた際のチューター（指導者）の説明速度を2.8倍に向上させ、トークンコストを47%削減しているとのこと。カスタムモデルは、数か月以内にAPIで広くリリースされる予定。

!
:::small
画像の出典：{target=“_blank”}
:::

同社はすでに、ダイキン、楽天、TOYOTA Connectedなどの先導企業とも連携し、複雑なビジネスプロセスの自動化、データ分析の支援、内部報告の最適化を進めている。

地方自治体もこの技術を活用し始めており、横須賀市は公共サービスの効率化を図るためにChatGPTを導入している。同市はすでにほぼ全ての市職員にChatGPTアクセスを提供し、80%が生産性の向上を報告している。さらに、横須賀市は東京都や神戸市を含む21の地方自治体とネットワークを形成し、政府におけるChatGPTの使用法のベストプラクティスを共有している。

同社はまた、日本政府がG7広島AIプロセスを主導し、AI政策の実施に取り組んでいることに触れ、今後も日本のAIポリシーにおけるグローバルな議論に貢献し、地域社会の課題解決にAIを活用することで、人間の尊厳、多様性と包摂性、持続可能な社会の実現を目指していくと述べた。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 14:19:35 +0000</pubDate></item><item><title>Googleが「Gemini for Google Cloud」を発表　クラウド内での生産性向上を実現</title><link>https://ledge.ai/articles/gemini_for_google_cloud</link><description>:::small
画像の出典：{target=“_blank”}
:::



Googleは2024年4月10日、Google Cloudの製品ポートフォリオに最新の生成AI技術「Gemini」を組み込んだことを{target=“_blank”}した。

これは、開発者、Google Cloudサービス、そしてアプリケーション向けの次世代AIアシスタントで、Googleの最新のGeminiモデル群を利用して、チームはクラウド内でより多くの作業を効率的に行えるようになるという。

!
:::small
画像の出典：{target=“_blank”}
:::

Gemini for Google Cloudは、産業界をリードする可用性を持ち、堅牢なセキュリティ、コンプライアンス、プライバシー制御を備えたエンタープライズレディなAI機能を提供する。

特に、新たに発表された「Gemini Code Assist」は、VS CodeやJetBrainsなどの人気コードエディタで開発者がアプリケーションを高速かつ高品質に構築できるようAIによる支援を行う。これにより、オンプレミス、Gitlab、Github、Bitbucket、複数のリポジトリにまたがるプライベートコードベースをサポートするという。

さらに、「Gemini Cloud Assist」や「Gemini in Security Operations」など、クラウドチームがアプリケーションのライフサイクルを設計、運用、最適化するのを助ける新しい機能も紹介された。

これらのツールは、Google Cloudのリソースを理解し、新しい設計の作成、ワークロードの展開、アプリケーションの管理、問題のトラブルシューティング、パフォーマンスとコストの最適化を支援する。

Googleは新たな機能を通して、Googleは開発者の創造性を解放し、生産性を向上させることにコミットし、業界全体のイノベーション加速を目指すという。


:::box

:::
:::box

:::
</description><pubDate>Sun, 14 Apr 2024 13:35:27 +0000</pubDate></item><item><title>Spotify がプロンプトでプレイリストを生成できる「AIプレイリスト機能」を英豪のプレミアムユーザーにベータ版で提供開始</title><link>https://ledge.ai/articles/spotify_ai_playlist_beta</link><description>:::small
画像の出典：{target=“_blank”}
:::

Spotifyは2024年4月7日、プレミアムユーザー向けに新たな音楽発見ツール「AI Playlist」のベータ版を提供開始したことを{target=“_blank”}した。このサービスは現在、英国とオーストラリアのAndroidおよびiOSユーザーを対象に展開されている。

AI Playlist とは、ユーザーがチャットに特定のプロンプトを入力することで新しいプレイリストを簡単に作成できる機能だ。例えば、「アレルギーの季節を乗り切るリラックス・ミュージック」、「主人公になった気分になれるプレイリスト」など、多様なアイデアからプレイリストを生成するという。

Spotifyのパーソナライゼーション技術とAIを組み合わせたこのツールは、ジャンル、ムード、アーティスト、年代を組み合わせたプロンプトで最も成功したプレイリストを提供する。まだベータ版であるため、Spotifyは今後もこの新機能に対する改善を重ねていく予定だ。

AI Playlistへのアクセス方法は以下の通り。Spotifyモバイルアプリを開き、画面右下の「Your Library」を選択。そこから右上の「+」ボタンをタップし、「AI Playlist」を選ぶ。提案されたプロンプトを選択するか、独自のプロンプトを入力する。Spotifyが提案するトラックをプレビューし、選曲を調整後、「Create」をタップすると、新しいプレイリストがライブラリに自動保存される。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box
[関連記事：元Apple社員ら設立のBrilliant Labsが新しいスマートグラス「Frame」を発表。マルチモーダル生成AI搭載
](https://ledge.ai/articles/brilliant_labs_frame)
:::
:::box

:::

</description><pubDate>Sat, 13 Apr 2024 13:25:25 +0000</pubDate></item><item><title>OpenAI、画像理解可能な「GPT-4 Turbo with Vision」を「OpenAI API」で公開、GPT-4 Turboの機能向上も</title><link>https://ledge.ai/articles/openai_gpt4_turbo_with_vision</link><description>:::small
画像の出典：{target=“_blank”}
:::


OpenAIは現地時間の2024年4月9日、マルチモーダルAIモデル「GPT-4 Turbo with Vision」を API で一般公開したことを、同社のX公式アカウントで{target=“_blank”}した。このモデルは、既存のGPT-4 Turboの機能に加え、画像やビジュアルコンテンツの理解が可能なビジョン機能を搭載している。

GPT-4 Turbo with Visionは、テキストだけでなく画像情報も処理できるため、開発者はテキストと画像のために別々のモデルを呼び出す必要がなくなり、作業プロセスの簡略化が可能となる。これにより、開発者はより幅広いユースケースに対応するアプリケーションを効率的に開発できるようになるという。

例えば、完全自律型AIソフトウェアエンジニアのは、さまざまなコーディング タスクにビジョンを使用する GPT-4 Turbo を搭載している。Xでは、OpenAIの開発アカウントがそのデモの様子を動画で投稿し、紹介した。

!
:::small
画像の出典：{target=“_blank”}
:::

その他にも、健康・フィットネスアプリ「Healthify」では、ユーザーの食事写真をスキャンし、写真認識を通じて栄養情報を提供しており、食事管理の精度を向上させている様子を紹介。

!
:::small
画像の出典：{target=“_blank”}
:::

12日、同社はさらに、ChatGPTの有料ユーザー向けに「GPT-4 Turbo」の新モデルが利用可能になったことを{target=“_blank”}した。

このモデルでは、文章作成、数学、論理的推理、コーディングの能力が向上しており、特にChatGPTでの文章作成では、返答がより直接的で簡潔になり、会話語を多用するよう改善されている。このモデルはChatGPT Plus、Team、Enterprise、APIで利用可能。ソースはGitHubで{target=“_blank”}されている。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Fri, 12 Apr 2024 12:25:34 +0000</pubDate></item><item><title>NVIDIA、生成AI分野の技術者向けにプロフェッショナル認定制度を新設</title><link>https://ledge.ai/articles/nvidia_genai_professional_certification</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAは2024年3月14日、生成AIに関するプロフェッショナル認定制度を新たに提供開始することを{target=“_blank”}した。

この認定制度は、生成AI技術の開発者がその技術的な信頼性を確立できるように設計されている。NVIDIAによれば、この新しい認定制度は、同社が初めて提供するプロフェッショナル向けのものであり、大規模言語モデル（LLM）とマルチモーダルワークフロースキルの習熟度を測ることを目的としている。

この制度には、2種類のアソシエイトレベルの認定が用意されており、GTC 2024イベント以降に利用可能になる予定だ。GTC 2024は、3月18日から21日まで開催されるNVIDIAのイベントで、現地参加者は認定試験に備えるための推奨トレーニングにアクセスできるとのこと。

NVIDIAのデベロッパープログラム担当バイスプレジデント、グレッグ・エステス氏は、「NVIDIAの目標は、皆さまのスキルアップを支援し、資格を持つプロフェッショナルの能力を磨き、個人がその熟練度を証明できるようにすることにより、雇用市場で競争優位を得られるようにすること」とコメントしている。

この認定制度の開始は、生成AI技術の発展と普及に伴い、この分野で活動する技術者が自身の技術力を証明し、業界での地位を確立するための重要な機会を提供するものだという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 17 Mar 2024 05:03:19 +0000</pubDate></item><item><title>Anthropic、チャットAI「Claude 3」向け公式プロンプト集を公開</title><link>https://ledge.ai/articles/anthropic_claude3_prompt_library</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月11日、AIスタートアップのAnthropicは、同社が開発したチャットAI「Claude 3」向けの公式プロンプト集を{target=“_blank”}した。

現在64種類の使用例が集められているこのプロンプト集は、「プロンプトライブラリ」でアクセス可能だ。公開されたプロンプト集は、英語と日本語の両方に対応しており、ユーザーはこれを利用してClaude 3の応用範囲を広げることができる。

プロンプトライブラリには、クリエイティブな執筆、データ分析、キャラクターロールプレイといった様々な用途に合わせたプロンプトが含まれている。Anthropicは、このライブラリを通じて、Claude 3を最大限に活用するためのガイドラインを提供し、ユーザーが特定のタスクを効果的に達成できるよう支援している。

また、Anthropicは「{target=“_blank”}」も公開しており、プロンプトの作成とテストのプロセスを通じて、Claude 3のパフォーマンスをさらに向上させる方法について説明している。これにより、ユーザーはより具体的なユースケースに対してClaude 3の応答を微調整することが可能となる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:21:11 +0000</pubDate></item><item><title>パーソルホールディングス、生成AI研修で社員スキルアップを加速</title><link>https://ledge.ai/articles/persol_group_upreskilling</link><description>:::small
画像の出典：{target=“_blank”}
:::

パーソルホールディングスは2024年02月16日、グループ社員の生成AIに関する知識と活用スキルの向上を目指し、専門家による研修や社内勉強会の開催などの積極的な取り組みについて{target=“_blank”}した。

この取り組みは、社員個人のスキルレベルを「理解」「業務導入」「業務活用と伝播」の3段階に区分し、全社員が生成AIを業務に活用する環境を整備することにあるという。

外部の専門家を招いた研修や勉強会をはじめ、1,500名以上の社員が受講した入門編から実践編、さらには経営幹部向けの勉強会まで、参加者のレベルや属性に応じた内容で開催されている。また、社内専用GPT「PERSOL Chat Assistant」の基礎知識についての動画講義には3,800名の社員が参加し、IT系職種に限らず多岐にわたる職種の社員が生成AIの教育を受けているとのこと。

さらに、生成AIパスポートの資格取得に向けた取り組みも進められており、2024年第1回試験にはグループ各社から200名以上の社員が受験予定。受験費用は会社が支給しているという。この資格は、生成AIを活用したコンテンツ生成の方法や企業のコンプライアンスに関する知識を学ぶもの。

これらの教育プログラムを通じて、社員はメール文章作成や議事録の要約、英文作成、アイデア出し、営業アポイントのテーマ検討、トークスクリプト作成、ソースコードの分析・修正など、多岐にわたる業務で生成AIを活用するスキルを習得し、業務効率化とパフォーマンスの向上、リスク回避につなげているという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 29 Feb 2024 03:36:19 +0000</pubDate></item><item><title>JDLAが「生成AIの利用ガイドライン（画像編）」を公開</title><link>https://ledge.ai/articles/jdla_guideline_for_image_generating_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本ディープラーニング協会（JDLA）は2024年2月13日、「生成AIの利用ガイドライン（画像編）」を{target=“_blank”}した。

このガイドラインは、2023年5月に公開された「{target=“_blank”}」の続編として作成されており、主に画像生成AIに特化した内容となる。

ガイドラインの目的は、画像生成AIを事業において利用する企業等に向け、ルール策定時に検討が必要な法的論点を解説することにある。具体的には、画像生成AIの利用に際して、社内体制の整備、プロンプトの入力ルール、AI生成物の利用規則など、遵守すべきポイントが詳述されている。

JDLAは、ディープラーニング技術を日本の産業競争力向上の核とし、その普及と適用を目指して活動している組織だ。今回のガイドライン公開も、その一環として行われたもので、画像生成AIの健全な利用と発展の促進を期待してのことだとされる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 28 Feb 2024 05:54:19 +0000</pubDate></item><item><title>日本最大級のDX推進コンテスト『日本DX大賞2024』応募開始</title><link>https://ledge.ai/articles/dx_taisho_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

一般社団法人日本デジタルトランスフォーメーション推進協会は2024年2月6日、民間企業や自治体のDX取り組みを表彰する「日本DX大賞 2024」の応募受付を開始したと{target=“_blank”}した。

コンテストは、DXの成功事例を発掘し共有することで、日本全体のDX推進を加速させることを目的としている。昨年行われた「日本DX大賞2023」への応募数は111件。今年はサステナビリティトランスフォーメーションやビジネスモデルの変革、顧客体験の向上など、多様なカテゴリーでのDX取り組みが対象となる​。

**募集期間**： 2024年2月6日から4月26日まで
**応募対象**：「DX推進」に取り組んでいる民間企業、公的機関、自治体等の変革を実現した事例や成果をあげた事例。または、ユーザー企業・団体が取り組んだ事例


日本DX大賞サイト：{target=“_blank”}



:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Feb 2024 10:45:28 +0000</pubDate></item><item><title> LoRA(ローラ)とは｜今年注目の画像生成AI (Stable Diffusion) のファインチューニングを試してみた
</title><link>https://ledge.ai/articles/LoRA</link><description>LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。従来はLLM（大規模言語モデル）や画像生成AIのファインチューニングに膨大な計算量が必要だったが、LoRAによって少ないリソースで行うことができるようになった。LoRAはLLMや画像生成AIに応用できる、計算量を減らしてファインチューニングを行う技術である。

2023年末にはChatGPTの新機能である、ユーザーがChatGPTを自由にカスタマイズ（ファインチューニングも）できる「GPTs」がリリースされた。誰もが簡単に学習済みモデルをファインチューニングできるようになりつつある。自社や個人が持つアセットを最大限に活用した生成AIの効果的な使用が、一層重要なフェーズに突入している。

今回は、ファインチューニングの理解に必須の技術「LoRA」について解説する。

:::small
※「LoRA」という用語は元々、計算効率を向上させる技術を指す。しかし、この技術を基にして「Stable Diffusion」というAIモデルをファインチューニングした際に生まれる特定のモデルも、同様に「LoRA」と称されている。「LoRA」が二重の意味を持つことに注意が必要。
:::

:::box
関連記事 : 
:::

:::box
**目次**
- LoRAとは
- LoRAのビジネスへの活用
- LoRAを使って「Stable Diffusion」をファインチューニングしてみた
:::

## LoRAとは

LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。2021年にMicrosoftに所属していたEdward Huらによって論文で発表された技術だ。

LoRAは、元のモデルのパラメータを直接変更する代わりに、低ランクの行列を導入して、パラメータの変更を行うことができる。少ない計算量で元のモデルに修正を加えることが可能になった。

LoRAは、事前学習されたモデルの重みを固定し、変換器アーキテクチャの各層に低ランクの分解行列を注入することで、下流のタスク用の訓練可能なパラメータの数を大幅に削減する。例えば、GPT-3 175Bモデルにおいて、LoRAは訓練可能なパラメータを10,000倍減らし、GPUメモリ要件を3倍削減することを実現している。
論文中では以下の図でモデルの概要が説明されている。
!


LoRA（Low-Rank Adaptation）の計算例を示す。通常、変換器モデルでは、重み行列W ( m×n)があり、入力x に対してWx の形で適用される。LoRAでは、この重み行列W を直接変更するのではなく、低ランクの行列A (m×k)とB (k×n)を用いて、W ( m×n)+AB ( m×n) の形で変換を行う。ここで、A とB は小さな行列であり、元の重み行列W に比べてはるかに少ないパラメータを持つ。この方法により、全体のパラメータ数が減少し、計算の効率が向上する。
A=正規分布、B=0で初期化されている。

具体的な計算を以下に示す。重み行列Wのパラメータ数は合計24、行列AとBは合計8となり調整するパラメータ数が3倍削減されている。
!
実際の計算規模は上記の計算例よりはるかに大きく、学習済みモデルのパラメータ数はGPT-3で175億、Stable Diffusionで10億程度と言われている。LoRAによってこれらのモデルのファインチューニングが少ないリソースで行なえることを理解できた。

##  LoRA・ファインチューニングのビジネスへの活用

次にビジネスへの活用例を示す。

**カスタマイズされたチャットボット:**
企業はLoRAを使用して、自社のリソースを学習させ大規模なLLMから自社専用のチャットボットを作成することができる。社内独自のQ＆Aを行えるチャットボットが使用されている。

**AI写真集:**
LoRAを使用して、基盤モデルとなるStable Diffusionをファインチューニングすることで、「アジア人女性」などの特定の画像を生成できる。
Amazon.co.jpの電子書籍読み放題サービス「Kindle Unlimited」をAI生成画像の「写真集」が席巻している。SNSで話題になり、ニュースサイトも相次いで報じるなど、社会現象といってよい状態だ。生成AIの技術が進化し、実際に存在しないがリアルに見えるモデルの画像が生み出され、グラビア界に新たな波をもたらしている。
!

:::box
関連記事：
:::


**AIモデル:**
自社ブランドのファッションアイテムを学習させ、AIモデルに着用させることができる。
AI model株式会社は、2022年6月14日にサービス「AI model モデル撮影サービス
」を提供開始した。撮影場所・費用の確保、起用タレント・モデルの不祥事など「人ならでは」のリスクを回避しつつ、ECの顧客に合わせたブランド専属モデルを生み出せる。
!

:::box
関連記事： 
:::


## LoRAを使って「Stable Diffusion」をファインチューニングしてみた

Stable Diffusion LoRAは、人物の顔、服装、ポーズなど画像の一部を学習し、その特徴をもった新たな画像を生成することができる。

今回はStable Diffusion LoRAを使い、人物の顔を学習させ、その人そっくりのAIモデルを生成する。肖像権の関係で弊社執行役員・箕部 和也の宣材写真を使いStable Diffusionをファインチューニングして、箕部そっくりの人物画像を作ることを試みた。

**Stable Diffusion LoRAの特徴**

- 20枚程度の画像からLoRAの追加学習ファイルを作成できる。
- 服装、ポーズ、顔、イラストの画風を学習させることができる。
- 100〜200MB程度のファイル。
- 学習時間が短い (今回の方法で1時間程度)。
- Stable Diffusionのチェックポイントをベースに作成可能。

今回はGPUを所有してない場合もオンラインで実行できる方法を紹介する。
のを使用する。Loraを使った学習が、簡単に行えるように必要なコードがまとめられている。

基本的なStable Diffusionの使い方はこちらで確認できる。

:::box
関連記事:
:::


### STEP0 実行環境と学習用画像を準備する

**実行環境**
をクリックすると以下のようなノートブックが開く。Google ColaboratoryはPythonの実行環境であり、GPUを無料で使うことができる。ただし画像生成AIを行う場合はColab Pro (1 か月あたり ￥1,179) が推奨されている。今回はColab ProでLoraファイルの作成を行う。ノートブックをマイドライブにコピーしておく。
!

**学習用画像**
今回は画像を15枚用意した。画像サイズは512×512や1024×1024の正方形が望ましい。
画像サイズは512×512にトリミングした。顔を学習させたい場合は、髪型や服装が違う画像があれば顔のみを学習しやすい。数パターンの髪型、表情、ポーズ、服装の画像を用意できることが理想的だ。
!

### STEP1  LoRAファイルを作成する。
変更できるパラメータは多量にあるが、最低限の実行に必須な部分のみを解説していく。

**I. Install Kohya Trainer**
!
:::box
1.1. Install Dependencies
 mount_drive:◻︎にチェックを入れて実行。colabからgoole driveにアクセス可能になる。
:::


**II. Pretrained Model Selection**
!
:::box
2.1. Download Available Model
 学習の基盤となるStable Diffusionのモデルを選択できる。
Stable-Diffusion-v1-5を選択して実行する。
:::

**III. Data Acquisition**
!
:::box
3.1. Locating Train Data Directory
 デフォルトで実行する。学習用画像の保存場所が作成される。
:::

!

 :::box
3.2. Unzip Dataset
Gooole Driveに学習させたい画像のzipファイルをアップロードする。
保存したディレクトリのパスをコピーして、zipfile_urlに貼り付けて実行する。
実行後 /content/LoRA/train_dataに自動的に保存される。
:::

**IV. Data Preprocessing**
!
:::box
4.1. Data Cleaning
convertにチェックを入れて実行する。
学習のための形式に対応していない画像は自動で削除される。
:::

:::box
4.2. Data Annotation
画像を認識し自動でキャプションを作成するためのブロック

4.2.1. BLIP Captioning
自動でキャプションをつける際のパラメータを変更できる。デフォルトで実行。

4.2.2. Waifu Diffusion 1.4 Tagger V2
下部のgeneral_thresholdを0.85程度に設定する。大きくするとタグの数が少なくなる。
特定の人物を学習させたい場合は数値を大きくすることが一般的。
traindataのファイルにキャプションが入ったテキストファイルが追加される。
以下の画像には”a man in a black suit and black shirt”と自動的にキャプションが追加された。
!
:::





**V. Training Model**
!
:::box
5.1. Model Config
上記の画像通りに入力して実行する。
:::


:::box
5.2. Dataset Config
dataset_repeats を１に変更する。同じ画像を学習させる回数を調整できる。
flip_augにチェックを入れると左右反転させた画像を学習させられる。
その他はそのままで実行。
:::

:::box
5.3.~ 5.5までをデフォルトのまま実行する。画像の枚数にもよるが1時間〜2時間程度で学習が完了する。完成したLoRAファイルはマイドライブのLora/outputに自動で保存される。
拡張子.safetensorsがLoRAのファイルだ。一番上に保存されている番号が振られていないファイルが最終的な出力になっている。
!
:::


### STEP2  作成したLoRAを使って画像を生成する。
STEP1で作成したLoRAファイルを使って早速、画像を生成する。
15枚の画像で学習を行った結果、右の画像が生成できた。髪型やヒゲ、黒いスーツが強く学習されていることが確認できる。写実的で、AIで作成された画像とは気が付かない可能性があるクオリティだが、似ているが本人ではないことが一目で分かる程度だ。また顔や髪型の特徴と同時に黒のスーツも学習してしまっている。これは学習用画像がすべて同じ服装であるためである。
!
**各種パラメータ**
*** 
モデル  
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt;,professional, masterpiece, 8k, hyperrealistic portrait,  Japanese man, 30yo, dark eyes, detailed face, detailed skin, photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


&lt; lora:minobe_model:0.9 &gt;はLoraファイルの適用の強さを示すもので数値を変更して調整できる。Loraファイルを複数使用したときを考慮して0.8程度で狙った特徴が出るようにすることが一般的。


### STEP3 パラメータを変更して画像をさらに生成する。
次により本人に似た、理想に近い画像を生成するために学習のパラメータやプロンプトを変更していく。特に学習の精度に影響を与えるとされるmin_snr_gammaの値を-1から1に変えて新たなバージョンのLoraファイルを作成した。min_snr_gammaは学習の低step化に貢献するオプションであり、学習過程を大きく変化させるパラメータである。推奨値は5とされている。
!
*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, Standing in the Desert,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


!

*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, ride a horse,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 

今回はStable Diffusion LoRAを使用して、Stable Diffusionをファインチィーニングし画像を生成した。画像を15枚を準備して数時間でコードを一切書くことなく簡単に、驚くほど精巧な画像を生成できた。Stable Diffusion LoRAには多くのパラメータがあり、それらの適正値を見つけることでさらに精度が向上すると予想される。パラメータの適正値は「アニメ風の画像を生成したい」や「同じポーズの画像を生成したい」「綺麗なアジア人女性を生成したい」など目的によって変化するため、各々が生成された結果を見ながら、理想の生成画像に向かって微調整を加えていく必要がある。

</description><pubDate>Tue, 06 Feb 2024 07:47:09 +0000</pubDate></item><item><title>Webアプリケーションの巡回ツールを開発せよ｜MBSD Cybersecurity Challenges 2023</title><link>https://ledge.ai/articles/mbsd-security-contest2023</link><description>三井物産セキュアディレクション株式会社が主催する、専門学校・高等専門学校を対象としたセキュリティコンテスト『{target=“_blank”}』の最終審査会が、2023年12月15日（金）に東京都大手町で行われた。

## セキュリティ業務の一端を疑似体験
本コンテストは、これからの時代を担う学生に向けて、より実践的で現実味のある課題を用意し、セキュリティ業務の一端を疑似体験しながら、課題を解決するためのアイデアや技術を競うものだ。入賞者には副賞が設定されており、最優秀賞には外付けSSD(4TB)とMeta Quest 3、2位には外付けSSD(2TB)と高級キーボード、3位には外付けSSD(1TB)とRaspberry Pi4 スターターキットを、受賞者ー１人ひとりに贈るという、かなり豪華な内容となっている。

第8回目を迎えた今回は、全国より18校 55チームのエントリーがあり、最終審査会へは上位10チームが参加した。
!
:::small
最終審査会参加チーム：{target=“_blank”}より
:::

本コンテストの課題は『Webサイトに実際にアクセスし、診断対象となる箇所を抽出、診断対象の規模を把握するための自動巡回ツールを開発し、提出すること』。学生は、Webサイト運営会社のWebアプリ診断を行うチームメンバーとして、ツールの開発から説明資料の作成、最終選考ではプレゼンテーションを行った。

本コンテストの開催フローは以下の通り。エントリーは2023年7月より開始したため、12月の最終審査まで5ヵ月の期間をかけてコンテストは実施された。

- エントリー受付
- 課題配布
- 説明資料・巡回ツール提出
- 一次審査結果発表
- 性能審査
- 最終審査会（オフライン開催）


## 最優秀賞は新潟コンピュータ専門学校『復活の電子遊戯部』
!
:::small
最優秀賞に輝いた『復活の電子遊戯部』チーム
:::
最終審査に残ったチームの中で、最優秀賞に輝いたのは、新潟コンピュータ専門学校『復活の電子遊戯部』だ。プレゼンテーションでは、開発した巡回ツールをオーディエンスがその場で触れられる試みもあり、随所に工夫が見られた。

!
:::small
開発した巡回ツールをその場で試せる実演用のQRコードを使ったプレゼンテーション
:::
受賞コメントでは、「全て穴だらけでグダグダだと思っていたけれど最優秀賞をいただけて感無量。本当にありがとうございました。」とコンテストの感想を述べた。
:::box
『復活の電子遊戯部』審査員の評価
- インストールがシンプルで、遷移図やスクリーンショットの機能も非常に良い機能だったと思います。
- ロードマップが準備されているのも良かったです。
- 発表も全体的にまとまっており、今までにない、その場でツールに触れるようにする試みも良かったと思います。
:::

第2位は、YIC情報ビジネス専門学校『塞翁が馬』。同チームは、内部での性能テストのためにテストサイトを自作するなど、他チームにはないプロセスでツールを開発した点が大きく評価された。
:::box
『塞翁が馬』審査員の評価
- 再検索機能が良く、テストサイトを自作しているところに意気込みややる気を感じました。ステータスによる色分けなどインターフェースが分かりやすく、動作状況がリアルタイムに表示されるのが良かったです。
- リーフレットなどで分かりやすくアピールしているのも良かったと思います。
- フラグの検出率がもう少し上がると良かったと思います。
:::
第3位は、審査員から「出来ないと思っていた画像内のフラグに対応してきたのが面白かった」と評価された、情報科学専門学校『Bananacat』が輝いた。
:::box
『Bananacat』審査員の評価
- プロキシ機能が特徴的で、ドキュメントがマークダウンのみで玄人向けという感じでした。
- 機能の優位性を分かりやすく説明していて、ツールの特徴が良く理解できました。
- できないと思っていた画像内のフラグに対して、対応してきたのが素晴らしい。
:::

## セキュリティ業界で第一人者を目指してほしい
!
:::small
三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャー 洲崎氏
:::

表彰式終了後、全体講評として三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャーの洲崎氏は「非常に嬉しく思ったのは、コンテストの卒業生がセキュリティ業界の一員として活躍していること。ぜひ皆さんもセキュリティ業界に来ていただき、またどこかでお会い出来たらと思う」と語った。また、同社 PS事業部 レッドチームの国分氏も「これから新たなセキュリティ技術が出てくると思うが、いち早くチャレンジして、ぜひ第一人者を目指してほしい」と、若い力への期待を露わにした。</description><pubDate>Tue, 23 Jan 2024 08:23:53 +0000</pubDate></item><item><title>大学入試の記述式対策もAI活用　駿台、AI学習教材「スルメ」で特許を取得</title><link>https://ledge.ai/articles/sundai_patented_surume</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年12月26日、学校法人駿河台学園（駿台）は、エスエイティーティー（SATT）との共同開発により、記述式問題対策のAI学習教材「スルメ」で特許を取得したことを{target=“_blank”}した。

この教材は、難関国公私立大入試の記述式問題対策として開発され、学習者の理解度に応じた最適な「ヒント」をAIが自動で提示する仕組みが特徴とされる。

**ヒント画面（解答に行き詰った際、段階的に与えられるヒントを確認する）**

!
:::small
画像の出典：{target=“_blank”}
:::



**解答画面（タブレット上で解く。解答は手書きで、自動採点される。メモやノートを取ることも可能）**

!
:::small
画像の出典：{target=“_blank”}
:::



「スルメ」を特許取得に導いたのは、個別の学習状況及び科目特性に応じた最適な予測正答率を分析し、それに基づいて難易度調整を行うシステムの新規性と、それを裏付けるデータによるものだという。特に、電気通信大学植野真臣教授の研究を基にした予測正答率の最適化がこの特許の核心とされている。

今後、駿台は「スルメ」を使用する学習者のデータに基づいて得られた分析結果を活用し、学習効果を最大化する予定だという。現在は「物理」「化学」に加えて「数学」の記述式問題に対してもこのシステムを適用し、さらに「英語」のリスニングや文法問題への適用も検討しているとのことだ。

:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Jan 2024 02:44:39 +0000</pubDate></item><item><title>GPT Store(GPTストア)とは｜GPTを公開して収益化する方法</title><link>https://ledge.ai/articles/GPT-Store</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2023年12月の公開が予定されていたが、延期が発表されていたGPT Storeが2024年1月10日(現地時間)についに公開された。GPT Storeは、GPTsで構築されたオリジナルのGPTをユーザー全体と共有できる新しい機能だ。さらにGPT Storeは収益化が可能であり、新たなマーケットとして期待が高まっている。

:::box
**目次**
- GPT Storeとは
- GPT Storeの利用方法と料金
- GPT Storeで自作のGPTを公開する方法
- GPT StoreでGPTを公開して収益化する方法
- GPT Storeの注意点
:::

## GPT Storeとは

GPT Storeは、GPTsで構築されたGPTを全ユーザーが公開・共有・検索できるプラットフォームである。この機能により、ユーザーは特定のタスクに特化したGPTを容易に見つけることができる。例えば、Open AI公式のGPTとして、文章の添削やライティングスキルの向上に特化した「Creative Writing Coach」や冷蔵庫の中身の写真から料理を提案する「Sous Chef」が公開されている。

:::box

:::

## GPT Storeの利用方法と料金

GPT Storeは月額20ドルの「GPT Plus」に入会することで利用できる。
さらに2024年1月10日(現地時間)に**新料金プラン**「**Team**」が追加された。

新プラン「Team」の特徴は以下の通り

料金は一人当たり年払いで月額25ドル (メンバー2人以上から利用可能)
GPT-4使用時に制限があった送信できるメッセージ数の上限増加
チーム内でのGPTsのワークスペース
使用者のデータを学習しないこと

画面左のサイドバーにある「Explore GPTs」をクリックすると以下のような画面が表示され、すぐに利用できる。有料プランに加入していなくても検索のみは可能。
!
左上の地球アイコンをクリックすると、Global ViewのOn・Offが切り替えられる。
Onでは世界のランキング、Offでは日本のランキングが表示される。

## GPT Storeで自作のGPTを公開する方法

GPTsでオリジナルのGPTを構築後、保存する際に3つの選択肢から保存できる。

- Only me (自分しかアクセスできない)
- Anyone with a link (発行できるリンクを知っている人なら誰でも)
- Everyone (全ての人に向けてGPT Storeで公開)

Everyone に設定しGPT Storeで公開する場合、Buider ProfileのNameを有効にして、ユーザー名を公開する必要がある。また必ずを守ったGPTでなければならない。

## GPT StoreでGPTを公開して収益化する方法

現在GPT Storeの収益化についてOpen AIで以下のように発表されている。
:::box
**Builders can earn based on GPT usage**
In Q1 we will launch a GPT builder revenue program. As a first step, US builders will be paid based on user engagement with their GPTs. We'll provide details on the criteria for payments as we get closer.

第1四半期(1月~ 3月)には、GPTビルダー収益プログラムを開始します。第一段階として、米国のビルダーには、GPTへのユーザーのエンゲージメントに基づいて報酬が支払われます。支払い基準の詳細については、追ってお知らせします。
:::

第一段階は米国のビルダーと明記されているため、**日本のビルダーの収益化はまだ先**になりそうだ。またユーザーによるエンゲージメント数によって、収益が発生することが判明した。
エンゲージメント数とはユーザーが「反応して行動した回数」である。

## GPT Storeの注意点

公式のガイドラインはとから確認できる。


### 作成が禁止されているGPT(一部抜粋)
- 違法行為のコンテンツ
- 児童性的虐待 児童を搾取したり危害を加えたりする素材またはコンテンツ
- 嫌がらせ、嫌がらせ、または暴力的なコンテンツの生成
- マルウェアの生成
- 兵器開発・軍事と戦争
- エネルギー、交通、水の重要インフラの管理または運営
- 自殺、切断、摂食障害などの自傷行為を促進、奨励、または描写するコンテンツ
- ギャンブル
- 詐欺
- 盗作
- 学術不正
- アダルト コンテンツ、アダルト産業、出会い系アプリ

以上のようなコンテンツが禁止されており、「競馬の予想ができるGPT」などの作成はガイドラインの禁止事項に該当する恐れがある。

### GPTの名称に関して

GPT の名称を「GPT」で終わらせることは推奨されていない。作成したアプリやサービスの内容に適した名称を与える必要がある。ただし、禁止されているわけではないため個人用に「〇〇GPT」という名称を与えることは問題ない。

:::box

:::



</description><pubDate>Thu, 11 Jan 2024 05:41:21 +0000</pubDate></item><item><title>AIのファインチューニングとは｜ビジネスパーソン向けの解説と転移学習・RAG・プロンプト埋め込みとの違い</title><link>https://ledge.ai/articles/fine-tuning</link><description>2023年は企業のAI活用も進み、{target=“_blank”}のような、OpenAIが提供するChatGPTなどの大規模言語モデル（以下、LLM）を使った、社内向けツールの開発事例が数多く発信された。

ビジネスの分野で広がりを見せるLLMだが、オープンソースのLLMIは事前学習の内容を基本としているため、企業内部データなどの外部公開していない情報や、特定の専門分野に関する情報に対しては回答の精度に課題が残る。

この課題への対応策として注目されているのが、ファインチューニング等の技術だ。
本記事ではファインチューニングの概要、メリット・デメリットや、類似技術との違いについて、文章生成AIの文脈で紹介する。

:::box
- ファインチューニングはなぜ必要なのか
- ファインチューニングの基本概念
- ファインチューニングと類似技術との違い
- ファインチューニング対応の基盤モデル
- ファインチューニング活用例
:::

## ファインチューニングはなぜ必要なのか
LLMはインターネット上のテキストデータなど、大量のデータを学習してモデルが構築されている。これらは「事前学習」と呼ばれるが、前述の通り、一般的な広範囲の知識はカバーしている一方、特定の専門知識に対して完全に適応することは難しい。また、ハルシネーション*という現象により、生成AIが学習していない分野について、信頼できない回答や誤解を招く回答を生成してしまう可能性があることも重要な問題だ。

:::box
*ハルシネーションとは、AIによって生成された回答が、現実には存在しないものであるか、または与えられたデータやコンテキストから著しく逸脱している場合に使われる用語である。AIが幻覚（=ハルシネーション）を見ているかのように、”もっともらしい嘘”をつくため、このように名付けられた。
:::
このハルシネーションという言葉は、ChatGPTなどの生成AIの登場に伴い、広く認知されるようになった。ファインチューニング等の技術は、このハルシネーションの問題に対処する手段として注目され、自然言語処理のさまざまな側面で応用されている。

## ファインチューニングの基本概念
ファインチューニングは、特定のドメインやタスク（領域）に適用させるために、事前学習されたモデルを追加学習する手法である。一般的なファインチューニングのステップは以下の通り。

**【１】事前学習モデルの取得**
大規模なデータセットで事前にトレーニングされたモデルを取得する。このモデルは、一般的な特徴やパターンを学習済みの状態であり、例えば、ImageNetのデータセットでトレーニングされた画像認識モデルや、大規模なテキストコーパスでトレーニングされた言語モデルなどが挙げられる。

**【２】追加学習**
事前学習済みモデルを使い、元のデータセットと異なる特定のドメインやタスクを対象とした、新しいデータセットで追加学習を行う。

**【３】重みの調整**
通常、事前学習済みモデルの一部の層や重みを「凍結」し、新しいタスクに適応するための層や重みを「解凍」して調整可能な状態にする。これにより、既存の知識を保持しつつ、新しいデータセットを学習することが可能となる。

**【４】ハイパーパラメータの調整**
追加学習を行ったモデルが新しいタスクに適応しやすくなるよう、学習率やエポック数などのハイパーパラメータを調整する。

!
:::small
Ledge.ai編集部作成
:::

### ファインチューニングのメリット
ファインチューニングの大きなメリットは、やはり、事前にトレーニングされた大規模なモデルを特定のタスクやドメインに適応させることで、パフォーマンスの向上や、タスク特有の要件への対応が可能になる点であろう。以下にメリットをまとめた。

**①特定ドメインの取り込み**
特定のドメインにおいては、言語の使い方や専門用語が異なることがある。ファインチューニングにより、モデルはそのドメインにおける言語の特性を学習し、より適切な応答や予測を行うことができる。

**②タスクの上位互換性**
元のモデルが持つ言語理解の能力を保持しつつ、特定のタスクにおいて追加学習が行われることで、元のモデルの高次の特徴や一般的な知識を引き継ぎつつ、新しいタスクに対する予測精度が向上する。

**③コスト削減**
ファインチューニングは、既存の一般的なモデルを再利用する。これにより、再学習をした場合と比較すると、モデルのトレーニングにかかる計算コストや時間を削減できる。

### ファインチューニングのデメリット
特定のタスクに適応したモデルを構築できるファインチューニングだが、いくつかのデメリットも存在する。

**①過学習のリスク**
ファインチューニングでは、特定のタスク向けにモデルのパラメータを調整するため、トレーニングデータに過度に適応してしまう「過学習」のリスクが高まる。特に、追加学習のデータが限られている場合は注意が必要である。

**②開発環境**
ファインチューニングは元の大規模モデルをベースにしているため、相応の開発環境がない場合は、処理時間が大幅にかかってしまう可能性がある。今やAI開発において欠かせない存在となっている、GPUの調達等を行う必要がある。

**③既存モデルのバイアス**
ファインチューニングは、元のモデルが学習した特定のデータのバイアスを引き継ぐ可能性がある。	

## ファインチューニングと類似技術との違い
モデルの学習は複数の手法が存在するが、その目的とアプローチには違いがある。今回は転移学習 および Retrieval-Augmented Generation（以下、RAG）について、ファインチューニングとの違いを説明する。

### 転移学習とは？
転移学習とは、あるタスクで学習されたモデルを別の関連するタスクに応用させる技術を指す。

例えば、大規模なデータセットで学習された文章生成AIモデルがあったとする。このモデルは、一般的な文章生成のタスクにおいて高い性能を発揮するが、特定のドメインやテーマに特化したタスクにおいては、データが不足していることがある。このモデルに転移学習をさせ、元々のモデルが学習した一般的な言語の知識や文法構造を新しいタスクに応用させることで、特定のドメインにおいても良い回答結果を得ることができる、というイメージだ。
より詳しい転移学習の説明については、関連記事を参照してほしい。
:::button
{target=“_blank”}
:::

ここまでの説明だとファインチューニングとかなり似ているように見えるが、転移学習とファインチューニングではパラメータの学習範囲が異なる。

転移学習では、事前学習済みのモデルのうち、出力層以外のパラメーターは固定されている一方、ファインチューニングは出力層以外の層のパラメーターも調整される仕組みとなっている。

!
:::small
Ledge.ai編集部作成
:::

また、モデルが大規模になるほど中間層のパラメーター数も多くなるため、転移学習とファインチューニングでは、追加学習のコストに差が出る点も、違いの一つだ。

### RAGとは？
RAGは、検索拡張生成と訳されるように、検索と生成AIを組み合わせた技術である。事前に用意された外部のデータベースやコーパスから情報を取得し、それを元に適切な回答を生成するモデルのことを指す。

!
:::small
Ledge.ai編集部作成
:::

RAGを利用することで、多数の情報源から得たデータを集約して回答の生成ができ、ユーザーの質問に対し、より正確な情報のアウトプットが行える。また、検索エンジン単体の場合と異なり、ユーザーのクエリのあいまいさを解消することにも役立ち、関連性の高い回答を生成することができる。

RAGとファインチューニングの違いについてだが、データ利用方法・開発アプローチ・タスクの特性の3つの観点でまとめた。

**データ利用方法**
RAG…外部のデータベースから情報を取得し、それを利用して回答を生成する
ファインチューニング…特定のタスク向けに追加学習データを用いてモデル自体を調整する

**開発アプローチ**
RAG…情報検索と生成モデルを組み合わせるアプローチ
ファインチューニング…事前学習済みのモデルへ特定のタスクデータを用いて追加学習するアプローチ

**タスクの特性**
RAG…質問応答や文章生成に適している
ファインチューニング…特定のタスクに適応したモデルを得られるため、幅広いタスクに適用可能


### RAGとプロンプト埋め込みの違い
RAGについて調査すると、プロンプト埋め込み（Embedding）というキーワードも多々出てくる。Embeddingとは、単語や文を数値のベクトル空間に埋め込む（変換する）手法であり、意味的に類似する単語や文が、ベクトル空間上で近くに位置するように、数値表現に変換させたものだ。
自然言語は通常、単語や文字などで構成されているが、Embeddingを用いることで、単語や文字を連続的な実数値のベクトルに変換し、単語や文字の意味的な特徴を数学的な形で表すことが可能となる。これによって、AIモデルがテキストデータを理解しやすくなるメリットがある。

**RAGとの違いは？**
RAGとEmbeddingは使われ方が全く異なる。
RAGは上記の通り、情報検索と生成モデルの組み合わせで構成されており、主に質問応答や文章生成のタスクにおいて、外部のデータベースを取り込んだ、より精度の高い回答を生成することが期待されている。
Embeddingは、単語や文の意味や構造を表現した数値ベクトルによって、主に文書分類や類似性の検索、クラスタリングなどのタスクにおいて、入力されたテキストデータの特徴的な情報を捉えるのに役立てられている。

RAGとEmbeddingが同じ文脈で取り上げられることがある主な理由は、自然言語処理において相補的な役割を果たすためである。RAGでは、生成モデルが回答を生成する際に、テキストデータを処理しやすくする目的でEmbeddingを用いて単語や文字を数値ベクトルに変換することがあるため、これらの手法は同じ文脈で言及されることがあるのだ。

企業の生成AI活用では、自社にマッチしたモデルの構築・改良を進めていくべきだが、自社（外部）データとAIモデルを紐づけるために、ファインチューニング・RAG・Embeddingの技術は、ぜひ押さえておきたい。

## ファインチューニング対応の基盤モデル
ファインチューニングに対応する基盤モデルの代表例を以下に挙げる。

### Open AI｜GPT-3.5 Turbo
!
2023年8月23日、米国OpenAIは「ChatGPT」などが採用する大規模言語モデル（LLM）「GPT-3.5 Turbo（gpt-3.5-turbo-0613）」がファインチューニング（微調整）に対応したと発表した。
:::box
関連記事：{target=“_blank”}
:::
### Meta｜Llama 2
!
Meta社が発表しているLLMモデル「Llama 2」は、70億（7B）、130億（13B）、700億（70B）パラメータの3種類のサイズが用意されており、事前トレーニングモデルと会話型ファインチューンモデルが存在する。
:::box
関連記事：{target=“_blank”}
:::

## ファインチューニング活用例
Ledge.aiで取り上げた記事の中からファインチューニングを利用した事例をピックアップした。

### 旭化成『書面監査における生成AIの活用』
2023年12月7日に、旭化成はDX戦略説明会を開催し、生成AIを本格導入することを発表。デジタル基盤の強化とビジネス変革を目指すと述べた。

その取り組みの中で、「書面監査」業務において、生成AI活用を試みている。
セキュアな環境内で、生成AIとWEB上の最新情報 および 社内データを連携させて回答生成を行えるようにし、さらにファインチューニングで自社特化を実現している。これらの追加開発により、特許作成など専門性の高い業務への対応が可能となっているという。年間約1820時間の短縮が測れる見込みだ。
!
:::small
画像の出典：{target=“_blank”}
:::
:::button

:::</description><pubDate>Thu, 28 Dec 2023 10:15:51 +0000</pubDate></item><item><title>年末年始こそAIのリスキリング　2023-24年のおすすめ無料講座を一挙紹介！ー松尾研LLM講座・Google認定資格プログラム・プロンプトエンジニアリングなど</title><link>https://ledge.ai/articles/free_courses_in_winter2023-24</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

生成AIに追われ、慌ただしく過ぎ去った2023年。リスキリングの波に乗り、休暇をじっくりと学び、新しい年を迎える自分をエンパワーする時間に充てる人も増えているという。まとまった時間を興味ある分野の一歩に。

## 東大松尾研 LLM講座
!
:::small
画像の出典：{target=“_blank”}
:::

東京大学松尾研究室は12月27日、東京大学サマースクールで2023年9~10月に開催された「大規模言語モデル講座」のコンテンツを{target=“_blank”}。この講座には約2,000名が参加し、全7回の講義とGPUを使ったコンペティションが実施された。

!
:::small
画像の出典：{target=“_blank”}
:::


## Google認定資格プログラム
!
:::small
画像の出典：{target=“_blank”}
:::

Googleは現在、新規会員に先着2万名限定で「Google Career Certificates」を{target=“_blank”}。このプログラムは、サイバーセキュリティとデータアナリティクスのコースを含み、キャリアアップに有効なGoogleの認定資格を取得できる。受講には学位や事前知識が不要で、オンラインで約6ヶ月間で完了可能だ。

## OpenAI「ChatGPTのプロンプトの書き方」
!
:::small
画像の出典：{target=“_blank”}
:::

OpenAIが大規模言語モデルGPT-4を活用するためのプロンプトエンジニアリングの基本テキストを{target=“_blank”}。このテキストでは、GPT-4の効果的な使用方法として、6つの主要戦略とそれに関連する具体的なテクニックを紹介している。例えば質問の詳細化、ペルソナの採用、入力の区切りの明確化、必要な手順の指定など。

また、効果的なプロンプトの例も提供されており、コピー＆ペーストで利用できる。OpenAIのサイトでは、これらの戦略に基づいた多数のプロンプト例も紹介されており、利用者はすぐにこれらを活用可能だ。

## IBM SkillsBuild「AIの基礎」
!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}は、技術分野でのスキルアップを目指す人々に焦点を当てた無料の教育プログラムだ。IBMは、2026年末までに200万人の学習者にAIに関する学習機会を提供するコミットメントを発表し、この目標の達成のためにIBM SkillsBuildを通じて新しい生成AIのコースを提供開始した。

{target=“_blank”}講座では、次の６つのコースで構成される。「人工知能の概要」「自然言語処理とコンピュータビジョン」「機械学習と深層学習」「IBM Watson Studio で AI モデルを実行する」「AI倫理」「 AIとの未来、仕事の展望」

※IBM Skill Build を利用するには、まずアカウントの作成が必要となる。




:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:57:14 +0000</pubDate></item><item><title>GPTs(GPT Builder)とは｜ChatGPT新機能の特徴・料金</title><link>https://ledge.ai/articles/gpts</link><description>:::box
**目次**
- GPTs(GPT Builder)とは？
- GPTsの基本｜特徴とメリット
     - GPTsの料金・使い方
     - ノーコードでの作成​​​​できるオリジナルGPT
     - オリジナルGPTの公開とGPTストア
     - 外部ツールとのAPI連携​​​​
- GPTs | オリジナルGPT作成事例
     - 事例1  Sous Chef  冷蔵庫の写真から料理を提案 [公式]
     - 事例2  ピクトグラムメーカー  プレゼン用のアイコンを簡単作成
     - 事例3  論文要約GPTs  PDFを読み込んで論文を要約
     - 事例4  GPT Finder  GPTを検索するためのGPT
- GPTs（GPT Builder）を使って実際にGPTを作ってみた
     - GPTを作成するためのSTEP
- GPTsの今後
:::

## GPTs(GPT Builder)とは？

GPTsとは、ChatGPTをユーザーの目的に合わせてカスタマイズできる機能であり、作成したオリジナルGPTは第三者に公開して共有することができる。GPT Builderは新機能GPTsでGPTを作るための機能を指す。2023年11月7日に行われたOpenAI初の公式イベント「」でその概要が公開された。以下のようなGPTが作成できる。

※GPT（Generative Pre-trained Transformer）はもともと言語モデルを指す略称であるが、新機能GPTsでは、カスタマイズされたChatGPTをGPTとして呼称している。

:::box
**作成できるGPTのサンプル**
- ブログを自動で作成できるChatGPT
- 英文添削をしてくれるChatGPT
- 写真からファッションコーディネートを提案するChatGPT
:::
GPTsは以上のようなカスタマイズされたGPTをGPT Builderと対話をするだけのノーコードで作成できる。さらに2024年の初頭には収益化も可能なGPT公開・販売サイト「GPT Store」のリリースが予定されており、注目度が高まっている。

## GPTsの基本｜特徴とメリット

### **GPTsの料金・使い方**

GPTsは有料の「GPT Plus」に入会することで利用でき、利用料金は月額 20ドル(公開時の為替で約2800円)である。有料の「GPT Plus」では無料版のGPT-3.5よりも高性能なGPT4を利用することができる。「GPT Plus」の詳細は以下の記事で確認できる。

:::box

:::

GPTsは「GPT Plus」入会後に画面左上の[Expore]から利用できる。

### **ノーコードでの作成できるオリジナルGPT**

GPTsはノーコードでオリジナルのChatGPTが作成できる。
プログラムの知識がなくとも、自社・個人のタスクに合わせたツールをChatGPTと対話することで作成することができる。業務効率化に必要なツールを、解決したい課題に合わせてChatGPT自身が選び、組み合わせて独自のタスクを解決できるチャットボットが開発できる。

### **GPTsの公開・共有とGPT Store**
GPTsで作成したツールはユーザー間で**共有が可能**である。作成したGPTのURLを発行することができ、会社などの組織内で作成したツールを共有、URLを知っている全ての人物に共有など共有範囲の選択が可能である。
さらに、2024年度初頭に「GPT Store」の公開が予定されており、開発したGPTの共有・販売が可能となる。「GPT Store」では収益化が可能とされており、利用した人物の人数に応じて収益を得られるとのこと。副業としてもGPT開発が始まり、さらなる開発の加速が期待できる。

### **外部ツールとのAPI連携**

GPTsは「」を利用して**外部ツールと連携することが可能**である。
特定のサイトの情報を取得したり、作成したGoogle スプレッドシートに アクセスすることが可能になる。

:::box
**Actionsにできること**
- リアルタイムの情報    　　　   例: スポーツのスコア、株価、最新ニュースなど。
- データベースの情報                  例: 会社のドキュメント、個人的なメモなど。
- ユーザーのアクションを支援　例: 航空券の予約、出前の注文など。
:::

:::small
公式サイトより引用して翻訳
:::

## GPTs | オリジナルGPT作成事例

ここでは、GPTsの作成事例を4つご紹介する。ChatGPTのマルチモーダル機能である画像の読み込み、画像の生成、文章要約などの機能が活用されている。
***
**事例1**   ****  made by OpenAI
!

入力された食材から、最適な料理を提案してくれるGPT。
さらに冷蔵庫にある食材の写真をアップロードすると、写真から食材を認識し回答を行うこともできる。
***
**事例2**   **** made by TOMOKI ISHIMINE
!


入力されたプロンプトからピクトグラムを作成することができる。
「ジムでベンチプレスをしている人」と入力すると
1. ジムでベンチプレスに横たわり、バーベルを持ち上げている人。
2. ジムでベンチプレスをしている人が、大きなウェイトを追加している。
3. ジムでベンチプレスをしている人が、スポットトレーナーにサポートされている。

抽象的なプロンプトから具体的なプロンプトを３つ提案された。1を選択すると以下のような画像が生成された。
!
***
**事例3** **** made by community buider (匿名)
!

PDFファイルをアップロードすれば、英語論文を要約することができる。
***
**事例4** **** made by  

!

**GPT Finder**はKnowledge機能を活用し、GPTsに関する情報を与えてられており、ユーザーが望むGPTを検索することを可能にしている。GPTsを探すGPTや、GPTsを作るためのGPTが既に有志によって作成されていることが面白いところであり、GPTsの可能性を感じさせられる。
***
## GPTs（GPT Builder）を使って実際にGPTを作ってみた

### **STEP1 GPT Builderの起動**

ではGPT BuilderでカスタマイズされたGPTを作成していく。
ChatGPTの有料版、ChatGPT Plusにプランを変更すると画面左上にExplore(エクスプロア)が表示される。まずはExploreをクリックする。
!
Exploreをクリックすると以下の画面が表示される。次に、My GPTsの「Create a GPT」をクリックする。
!
クリックすると、GPTsの作成画面が表示される。
画面左はGPT Builderとなっており、会話することでオリジナルのGPT作成のサポートをしてくれる。画面右はPreviewになっており、GPT Builderが自動で調整したGPTをすぐにテストすることができる。Previewで期待する回答が得られなかった場合はGPT Builderに修正内容を伝えて、修正→Previewを繰り返し、目標のGPTを作成できる。
!



### **STEP2 GPT Builderに作成したいGPTの内容を伝える。**

今回は「Ledge.AIのおすすめ記事を要約して、そのリンクを紹介してくれるGPT」を作成します。GPT Builderにこの内容を伝えます。
!


### **STEP3 GPT BuilderがGPTのタイトルを提案**

趣旨を伝えると、GPTのタイトルを提案された。
:::box
**ChatGPT**
Great! We're creating a GPT that can summarize AI-related articles from Ledge.AI and provide links to those articles.
How about we name this GPT **AI Article Summarizer**? Does that sound good to you?
(素晴らしい！Ledge.AIからAI関連の記事を要約し、それらの記事へのリンクを提供できるGPTを作成中です。
このGPTを**AI Article Summarizer**と名付けるのはどうだろう？いいと思う？)
:::
このAI Article Summarizerというタイトルで許可をする。

※会話で使う言語に関して、GPT Builderではこちらが日本語で話しても、英語で回答することが多くあった。プロンプトに日本語で会話して下さいと追加すると日本語で会話できるようになる。ただし、しばらくすると英語に戻ってしまう場合も現段階では多い。

### **STEP4 GPT BuilderがGPTのプロフィール写真を生成**
タイトルの許可をすると、次にプロフィール写真が生成され、作成した画像で問題ないか確認される。このプロフィール写真で問題ない旨を伝えた。
!


### **STEP5 GPT Builderに作成したい機能の詳細を伝える**

次に、AI Article Summarizerにどのような機能を持たせたいかを質問されます。
以下のように、いくつかの選択肢を提案されそれを選択するだけで、開発が進む。
:::box
**ChatGPT**
素晴らしいです。AI Article Summarizerのプロフィール写真が設定されました。
　
次に、このGPTの役割と目標について詳しくお聞かせください。どのような情報を特に重視し、どのように要約することを希望しますか？例えば、記事の特定の側面やテーマを重視する、または特定のスタイルで要約することを希望するなど、ご要望があれば教えてください。
　
**User**
https://ledge.ai/のサイトの記事を、ビジネスマン向けに要約して下さい。
　
**ChatGPT**
了解しました。AI Article Summarizerは、Ledge.AIのウェブサイトの記事をビジネスマン向けに要約する役割を果たします。市場の動向、ビジネスへの応用、戦略的な洞察など、ビジネスプロフェッショナルに特に関連する情報を重視して要約します。
　
このGPTの使用にあたって、避けるべき事項や特に注意すべき点はありますか？例えば、特定の言葉遣いや情報の取り扱いに関するガイドラインがあれば教えてください。
　
**User**
https://ledge.ai/以外の記事は紹介しないでください
　
**ChatGPT**
了解しました。AI Article SummarizerはLedge.AIの記事のみを要約し、他の情報源からの記事は参照または要約しないようにします。
　
このGPTの対話スタイルについて、どのような感じにしたいですか？例えば、公式なビジネスライクなトーン、またはもう少しカジュアルなアプローチなど、ご希望があれば教えてください。
　
**User**
ビジネスライクなトーンでお願いします
　
**ChatGPT**
AI Article Summarizerはビジネスライクなトーンで情報を提供します。
　
それでは、プレイグラウンドでこのGPTを試してみてください。フィードバックがあれば、どんな改善点でもお聞かせください。何か他に追加や変更を希望されますか？
::: 

以上の会話でGPTが完成した。早速、動作テストを行う。
Previewで動作テストすることができるが今回は保存してからテストを行った。
※反映が遅い時があるため
### 作成したGPTをテストする
「自動運転に関するおすすめ記事を教えて」と入力すると以下の回答が得られた。Webサイトからタイトルを取得できているが、期待する回答が得られていない。
!
次に、期待する回答が得られるようGPTを修正していく。

### オリジナルのGPTをCreateからカスタマイズする

**Create**から会話形式で修正することもできるが、左画面の上部**Configure**から直接GPTをカスタマイズできる。実は先ほどの会話からChatGPTが自動で**Configure**の必要項目を埋めてくれる仕組みになっている。**Instractions**には先ほど会話した内容が、要約されてまとまっている。
!

期待する回答が得られるよう**Configure**を以下のように編集した。**Instractions**には直接日本語で内容を入力し、内容を変更した。Instractionsを日本語にしておくとChatGPTが回答する際に英語になってしまう現象が少なくなった。
!

以下のように期待する回答が得られた。記事の要約とそのリンクを添付してくれている。
!


GPT「AI Article Summarizer」にはからアクセスできる。ただし、GPT Plusに入会している必要がある。

## GPTsの今後

OpenAI社の公式ブログ記事 で次のように発言されている。
:::box
**The best GPTs will be invented by the community** (最高の GPT はコミュニティによって発明されます)
:::
2024年初頭には収益化可能なGPT Storeが公開される予定で、OpenAI社はユーザーの開発競争によってより優れたGPTが生まれることを期待していることが示唆される。

これまでのGPT-3からGPT-4への進化や、GPT-5の開発が進んでいる一方で、マルチモーダル機能や外部APIとの連携が容易になり、誰もが業務効率化ツールを作成できるようになっている。
さらに、開発競争によって革新的なGPTが続々と生まれれば、App Storeのような大規模なマーケットが形成されるかもしれない。

:::box

:::



</description><pubDate>Thu, 28 Dec 2023 07:51:46 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>生成AIプロジェクトの開発者コミュニティ、アメリカ・インドに次いで日本が先導ーGit Hub 2023年の動向レポート</title><link>https://ledge.ai/articles/github_the_state_of_open_source_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2023年11月8日、「オープンソースとAIの現状」に関する報告を{target=“_blank”}した。

報告によると、開発者たちは大量の生成AIプロジェクトに取り組んでいる。特にOpenAIなどの基礎モデルを用いた開発が目立ち、生成AIプロジェクトは2023年のオープンソースプロジェクトのトップ10にランクインしたという。これらのプロジェクトには、全開発者の92%が使用または実験中であると報告されており、GitHub上での次世代AIイノベーションを牽引すると期待されている。

また、2023年はオープンソースへの初参加者が最も多く、これまで商業的に支援されたプロジェクトが初参加者の大部分を占めていたが、今年は生成AIプロジェクトも初参加者向けのトップ10プロジェクトに登場した。GitHub上のプライベートプロジェクトの数は前年比38%増加し、全活動の80%以上を占めている。

全世界で、GitHubを使用してソフトウェアを構築し、共同作業を行う開発者が増加している。アメリカは依然として最大の開発者コミュニティを持つが、他の地域も成長を見せている。

次の5年間で最も成長が見込まれる開発者コミュニティに関する予測では、インドが2027年までにGitHub上で最大の開発者コミュニティになると予想されている。日本の開発者数は約280万人で、世界8位にランクされており、今後の成長が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::

さらに、生成AIは個々のコントリビューターの数において148%の年間成長率を達成し、生成AIプロジェクトの総数も248%増加している。この分野において、アメリカ、インド、そして日本が先導しており、他の地域も追随している。

!
:::small
画像の出典：{target=“_blank”}
:::



報告は、2022年10月1日から2023年9月30日までに、GitHub から取得した匿名化されたユーザーおよび製品データに基づいて作成された。

:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:49:07 +0000</pubDate></item><item><title>AIの遅れ取り返せるか　Appleが開発者向けフレームワーク「MXL」Geminiの裏でひっそりと公開</title><link>https://ledge.ai/articles/apple_released_mlx</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2023年12月、AI分野での新たな取り組みとして、開発者向けのオープンソース機械学習フレームワーク「MLX」を{target=“_blank”}した。GoogleのAIモデル「Gemini」の発表と同時であったと各メディアで報じている。

MLXはAppleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​。

Appleの機械学習研究者であるAwni Hannun 氏は、自身のX（旧Twitter）アカウントで、
「ちょうどホリデーシーズンに間に合うよう、本日、Apple 機械学習研究からいくつかの新しいソフトウェアをリリースします。
MLX は、Apple シリコン (つまり、ラップトップ) 向けに特別に設計された効率的な機械学習フレームワークです」
と{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

{target=“_blank”}は10月に、Appleの経営陣は業界の突然のAIブームに驚かされ、昨年末から急いで対応を図っていたと報じており、MLXの発表は、AI分野での急速な進展に対応しようとするAppleの努力の一環との見方もある。



:::box

:::
:::box

:::</description><pubDate>Fri, 15 Dec 2023 05:44:48 +0000</pubDate></item><item><title>古いコードを最新のJavaに生成AIが自動変換「Amazon Q Code Transformation」</title><link>https://ledge.ai/articles/aws_amazonq_code_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月28日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて「Amazon Q Code Transformation」を{target=“_blank”}した。

この機能はAmazon Qを使用して、古いJavaおよび.NETのコードを最新のJavaにAIが自動変換するツールで、アプリケーションの保守と最新化を簡素化することを目的としている。現在Javaアプリケーションのバージョン8および11から17へのアップグレードが可能で、近い将来にはWindowsベースの.NET Frameworkアプリケーションをクロスプラットフォームの.NETに変換できるようになる予定だという。

かつて開発者は、各アプリケーションのアップグレードに 2~ 3日かかっていたが、同社内部テストでは、手動アップグレードに通常は数日または数週間かかるのに対し、新機能を使用すると数分でアプリケーションをアップグレードでき、別の要件へ集中する時間に充当できたという。

このツールは、既存のコードを自動的に分析し、変換計画を生成して、計画に基づいた変換タスクを完了する。パッケージ依存関係の特定と更新、時代遅れかつ非効率的なコードコンポーネントのリファクタリングを行い、新しい言語フレームワークへの切り替えとセキュリティのベストプラクティスの組み込みを行う。変換が完了すると、ビルドとテストの結果を含む変換されたコードをレビューし、変更を承認することができる。

Amazon Q Code Transformationのプレビューは、 AWS Toolkit for IntelliJ IDEAおよびAWS Toolkit for Visual Studio Code のAmazon CodeWhisperer プロフェッショナル ティアの顧客が利用可能。組織が使用するプロファイルへのアクセスを許可する必要がある。プレビュー中の使用には追加料金不要。


:::box

:::
:::box

:::
</description><pubDate>Fri, 08 Dec 2023 15:20:21 +0000</pubDate></item><item><title>GTP-4を利用した「GitHub Copilot Chat」一般提供12月より「GitHub Universe 2023」で発表</title><link>https://ledge.ai/articles/github_universe2023</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国GitHubは2023年11月8日、サンフランシスコで年次イベント「GitHub Universe 2023」を開催した。1日目の{target=“_blank”}で、CEOのThomas Dohmke氏は「GitHubがGitという仕組みの上に構築されたように、今日私たちはCopilotの上に ”Re-founded”（=再構築）された」と述べた。また、GitHubの掲げるビジョン「Copilot X」は、ソフトウェア開発のライフサイクル全般を支援することを目指すという。

生成AIを活用した「GitHub Copilot」シリーズの進展、特に「GitHub Copilot Chat」の一般提供の発表に注目が集まった。この新機能は、自然言語での指示を通じて、コーディングを支援するもので、すでにベータ版は全個人向けユーザーに9月より無償で提供している。既存のサブスクリプションサービス、GitHub Copilotプランの一部として、organizationおよび個人ユーザーに対して12月より一般提供される予定だ。

Copilot ChatはGPT-4を使用しており、より正確なコードの提案と説明を実現しているという。コードに関する質問や議論を可能にし、さまざまなスラッシュコマンドを通じて、コーディングタスクを簡素化する機能も備えている。このサービスは、GitHubのウェブサイトやモバイルアプリにも統合されており、開発者はいつでもどこでもこの機能を利用できるようになる​​とのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

講演の最後には新機能として、自社のコードをもとにGitHub CopilotのAIモデルをカスタマイズする「GitHub Copilot Enterprise」が紹介された。これにより、組織は自社特有のコードベースに合わせたAIのサポートを受けられるようになる。


:::box

:::</description><pubDate>Wed, 15 Nov 2023 05:08:10 +0000</pubDate></item><item><title>イーロンマスク率いるニューラリンクのライバル会社「シンクロン」が脳インプラント臨床試験の患者募集を始める</title><link>https://ledge.ai/articles/synchrone_launches_patient_registry</link><description>:::small
画像の出典：{target=“_blank”}
:::

脳波を用いたデジタルデバイス操作技術を開発する米国企業シンクロンは2024年4月8日、運動障害を持つ患者の機能回復を目指す脳インプラント「Stentrode」の臨床試験に向けた患者登録の開始を{target=“_blank”}した。

患者、ケアギバー、臨床医が一堂に会し、Brain-Computer Interface（BCI）がどのように人々の移動能力を向上させるかを学ぶためのコミュニティ中心の取り組みだという。

シンクロンの技術は、脳の神経コードを解読し、デジタルデバイスを操作するための運動意図を復元する新しいアプローチである。同社のCEOであるトム・オックスリー氏は「BCI技術により運動障害を持つ個人が独立性を回復できるようになり、日常のタスクをより簡単かつ効率的に行えるようになることは、この技術の革命的な前進である」と述べた。

同社の技術は、脳の自然な「ハイウェイ」である血管を利用し、侵襲的な脳手術を避けながら装置を脳に埋め込むことが可能だという。Stentrode装置は、頚静脈を通じて最小侵襲で脳の運動皮質に挿入される。

この装置は脳の運動意図を検出し、無線で外部デバイスへ信号を送信することで、患者はデジタルデバイスを自由自在に操作可能とのこと。ニューラリンクと異なり、シンクロンは開頭手術を必要としない治療法を提供している点が特徴となる。

脳マシンインターフェース市場において、シンクロンはニューラリンクとの競争を通じて、より多くの患者に新たな希望を提供する可能性を探求している。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 07:31:56 +0000</pubDate></item><item><title>「光る君へ」をAIで紐解く　大阪工業大学が『源氏物語』をAIで学習するシステム「おしゃべり源氏物語」を開発</title><link>https://ledge.ai/articles/oit_ai_genji_monogatari</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月5日、大阪工業大学の情報科学部ネットワークデザイン学科、矢野浩二朗教授が主導する研究チームは、複数のAI技術を組み合わせた『源氏物語』学習支援システム「おしゃべり源氏物語 －生成AIで学ぶ『源氏物語』－」を開発したことを{target=“_blank”}した。

このシステムは、音声入力やチャットを介して『源氏物語』に関するユーザーの質問に対し、AIが回答するもの。プロジェクトには、AmiVoiceやOpenAIのChat APIを含む6種類のAI技術が利用されており、和歌のリズム認識や発音タイミングの調整など、具体的な技術的工夫が行われた。また、『源氏物語』専用のデータベースを用いることで、高い精度の回答生成を実現している​という。

同システムは２月下旬から４週間、東京富士美術館で開催された展覧会に出展され、約3000人の来場者が体験した。このときのフィードバックを受け、矢野教授とそのチームは性能の改良を重ね、今後も更なる改善を続けるとのこと。

矢野教授は、「AIを用いることで、千年以上前の文学作品を現代の技術でどのように再解釈し、活用するかの一例を示すことができた」とコメントしている​​。このAIシステムを更に発展させ、パブリックなデータを用いた「Open 光源氏 AI」として他の施設でも展示を行う方針だという。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Apr 2024 13:21:02 +0000</pubDate></item><item><title>Anthropicの研究論文：LLMが訓練された安全策を回避する「脱獄」技術の発表　「今のうちに取り組むべき課題」</title><link>https://ledge.ai/articles/anthropic_many_shot_jailbreaking</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

「Claude3」の開発企業 Anthropicは2024年4月3日、大規模言語モデル（LLM）の安全対策を回避する「脱獄」技術「Many-shot Jailbreaking」に関する研究論文を{target=“_blank”}した。

この技術は、LLMが処理する情報量の増加、特にコンテキストウィンドウの拡大を利用するものだという。2023年初頭には長いエッセイ程度（約4,000トークン）であったコンテキストウィンドウは、現在では数百倍に拡大し、複数の長編小説相当（1,000,000トークン以上）サイズに及ぶ。

Many-shot Jailbreaking とは、偽の対話を含む大量のテキストをプロンプトとして使用し、モデルが訓練された安全機構を回避して危険または不適切な反応を引き出す技術だ。この技術が特に効果的なのは、コンテキストウィンドウの大幅な拡張により、プロンプト内で提供される情報の量が増えることで、モデルがコンテキスト内学習の過程で新たな行動パターンを採用するためだという。

研究では、偽の対話が含まれていると、モデルが安全に訓練されているにもかかわらず、最終的な危険なリクエストに対して回答を提供することが示された。

!
:::small
画像の出典：{target=“_blank”}
:::

この脆弱性は、特にLLMで効果的であり、その成功率は攻撃の長さに比例して増加する。Anthropicによれば、この技術は、同社のモデルだけでなく、他のAI企業のモデルにも有効であることが示された。技術の詳細は事前に他のAI開発者に説明され、システムに対する対策が実施されている。

Anthropicは、この研究を公開することが、問題の早期解決に寄与し、他のAI研究者との協力を促進し、長期的なコンテキストウィンドウを利用した潜在的な攻撃からモデルを守るための戦略を加速することにつながると考えていると述べている。この研究は、今後のモデルにおいて深刻な害を引き起こす可能性のある脱獄を防ぐために、今のうちに取り組むべき時であるとも強調している。

公式な論文は{target=“_blank”}から



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Apr 2024 12:02:42 +0000</pubDate></item><item><title>Apple　次世代Siriか？音声アシスタントが画面上のコンテキストを「見て」理解できるAI「ReALM」を発表</title><link>https://ledge.ai/articles/apple_realm</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2024年4月3日、ユーザーのスクリーン上に表示される情報を理解し、より自然なインタラクションを実現する新たなAIシステム「ReALM（Reference Resolution As Language Modeling）」を{target=“_blank”}した。この技術は、音声アシスタントがユーザーからの指示に基づき特定のアクションを実行するための、画面上の物体や文脈を「視覚的に理解する」能力を持つ。

ReALMは、ユーザーのスクリーン上に表示されるエンティティ、会話中に参照されるエンティティ、および背景で実行されるプロセスからのエンティティといった、さまざまなタイプのエンティティに対して参照解決を行うタスクを中心に設計されている。

たとえば、画面のコンテキストを「見て」理解し、ユーザーが「この取引先に電話する」と言った場合、ページ上に表示される取引相手の電話番号を認識し、追加の指示なしにその番号に自動で電話をかける機能を実現するという。

!
:::small
画像の出典：{target=“_blank”}
:::

ReALMの開発には、合成データやアノテーションを利用したデータセットが使用され、各データポイントにはユーザークエリとエンティティのリストが含まれる。これらのデータを用いて、画面上のコンテキストをテキストとして解析し、適切なエンティティを識別する。特に、ReALMはGPT-3.5およびGPT-4と比較してベンチマークされ、小規模モデルでGPT-4と同等の性能を達成し、大規模モデルではそれを大きく上回る結果を示したという。

!
:::small
画像の出典：{target=“_blank”}
:::


Appleは2024年のうちにAI関連で新たな発表をするとCEOのティム・クック氏が発言をしている。その発表が開発者会議「WWDC」となるのではと見られている。ReALMは果たして次なるのSiriとなるのだろうか。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Apr 2024 07:11:44 +0000</pubDate></item><item><title>中国が世界のAIトップ研究者の半数を輩出していることが明らかに　米シンクタンクのグローバルAIタレントトラッカー2.0の最新調査</title><link>https://ledge.ai/articles/macropolo_the_global_ai_talent_tracker2023</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月6日、シカゴ - ポールソン研究所のシンクタンクであるMacroPoloは、グローバルAIタレントトラッカー2.0の最新版を{target=“_blank”}し、AI分野でトップレベルの研究者たちの動きや集中地域に関する洞察を提供した。

「トップレベル」の判断には、Neural Information Processing Systems カンファレンス (NeurIPS) で承認された論文著者のデータ サンプルが用いられている。NeurIPSは、AIカンファレンスの中でも特に高い評価を受けており、ニューラルネットワークとディープラーニングの理論的進歩に特に焦点を当てた研究が多く発表されている。その選択性と人気はAI分野の進歩を示す重要な指標となっており、2019年以降、投稿論文数は2倍に増加しているものの、論文採択率は2019年は21.6％、2022年は約25％と低く、難易度の高い学会とされている。

2023年の最新調査によると、AI研究で世界の上位20％に位置するトップ研究者のほぼ半数が中国出身であることが明らかになった。中国は、AI分野でのトップ研究者の育成とその活躍の場への貢献で、アメリカや他の西洋諸国に匹敵、あるいはそれを上回る速度で成長しているという。

### トップレベルの AI 研究者の出身国 (学位に基づく上位20%)
!
:::small
画像の出典：{target=“_blank”}
:::

グローバルAIタレントトラッカー2.0のアップデートによると、2019年の調査と比較して、米国は依然としてトップレベルのAI人材の主要な就職先であり、米国と中国出身の研究者がトップレベルのAI人材の75%を占めている。

### 米国の機関で働くトップレベルAI 研究者の主要出身国
!
:::small
画像の出典：{target=“_blank”}
:::

中国は、成長する自国のAI産業の需要に応えるために国内のAI人材プールを拡大しており、より多くの中国人人材が国内産業で働くようになっている。そして、インドもまた、一流のAI研究者の重要な輸出国であると同時に、人材を国内に留める能力が高まっているという。

2022年には、インドのAI研究者の5分の1がインド内で働くことを選択しており、トップレベルのAI研究者の全体的な機動性が低下している傾向が見られるとのこと。これは、より多くのトップレベルの人材が母国に留まることを選んでいることを示しており、グローバルなAI人材の流れに変化の兆しが表れている。

### トップレベルのAI研究者が出身国で働く割合の変化
!
:::small
画像の出典：{target=“_blank”}
:::

### トップレベルの AI 研究者 (上位 ~20%) が勤務する主要国
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Apr 2024 13:41:28 +0000</pubDate></item><item><title>Google Research、1枚の画像から話す人物の動画を生成するAI「VLOGGER」を発表</title><link>https://ledge.ai/articles/google_reserch_vlogger</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google Researchは2024年3月13日、人物の単一画像から話す動画を生成するAIシステム「VLOGGER」を{target=“_blank”}した。

VLOGGERは、確率的拡散モデルと空間及び時間的制御を統合した新しいアーキテクチャにより、口元の動きだけでなく全顔の表情変化や手のジェスチャーまで表現可能な可変長の高品質動画を生成する。

MENTORと呼ばれる80万アイデンティティを含む大規模なデータセットを用いたトレーニングにより、個々の人物に対して再トレーニングする必要がなく、多様でリアルな動画の生成を実現しているという。

!
:::small
画像の出典：{target=“_blank”}
:::

VLOGGERのフレームワークは、音声からビデオへの一対多マッピングをモデル化するために確率的拡散モデルに基づいた２段階のパイプラインで構成されている。

最初のネットワークは、オーディオ波形を入力として受け取り、目標ビデオの長さにわたる視線、顔の表情、及びポーズを制御する中間ボディモーションコントロールを生成する。

次のネットワークは、大規模な画像拡散モデルを拡張した時間的画像から画像への変換モデルであり、予測されたボディコントロールを取って、対応するフレームを生成する。特定のアイデンティティにプロセスを条件付けるために、ネットワークはまた、人物の参照画像も取る。



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Mon, 01 Apr 2024 02:35:43 +0000</pubDate></item><item><title>「Soraのようなモデルを完全オープンソースで」シンガポールのAI企業 HPC-AI Technology が「Open-Sora 1.0」をリリース </title><link>https://ledge.ai/articles/open_sora_hpc_ai_technology</link><description>:::small
画像の出典：{target=“_blank”}
:::

シンガポールに本社を持つHPC-AI Technology は2024年3月17日、テキストから動画を生成するモデル「Open-Sora 1.0」を{target=“_blank”}した。

この技術は、最新のDiffusion Transformer（DiT）アーキテクチャに基づき、PixArt-αというオープンソースのText-to-Image モデルを拡張し、ビデオ生成を可能にする。同社はこのモデルのアーキテクチャ、訓練済みモデル、トレーニングとデータ準備のプロセスの詳細を{target=“_blank”}し、誰でも無料で使用可能とした。

@



Open-Sora 1.0の開発は、ビデオ生成技術の進化を目的としており、訓練プロセスは3つのフェーズから成り立っている。初期フェーズでは、大規模なイメージデータの事前訓練を通じて、ビデオの事前訓練コストを削減する。次に、ビデオデータに対する大規模な事前訓練を行い、最終的には高品質のビデオデータでファインチューニングを施し、生成されるビデオの質を大幅に向上させる。この段階的アプローチにより、より効率的に高品質のビデオ生成を実現している​という。

!
トレーニング再現スキーム
:::small
画像の出典：{target=“_blank”}
:::

さらに、Open-Sora 1.0では、ビデオの前処理に関しても技術的なハードルを下げるためのサポートが提供されている。公開ビデオデータセットのダウンロードや、長いビデオを短いクリップに分割するスクリプトが提供されており、開発者は簡単に自分のデータセットに基づいてビデオ/テキストのペアを生成することができる​​​​。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 30 Mar 2024 12:07:53 +0000</pubDate></item><item><title>脳インプラント術後患者の様子を「Neuralink」がライブ配信　四肢麻痺患者が脳で思考しカーソルを動かす</title><link>https://ledge.ai/articles/neuralink_live_streaming_of_post-operative_brain_implant_patient</link><description>:::small
画像の出典：{target=“_blank”}

:::

イーロン・マスク氏が率いるスタートアップ企業Neuralinkニューラリンクは2024年3月21日、同社が開発したコンピュータと脳を直接つなぐインターフェースの被験者1号となる患者のインタビューをX（旧Twitter）でライブ配信した。

@



四肢に麻痺を持つ29歳の男性、ノーランド・アーボー氏は、この技術を用いて10年ぶりに手足を動かさずにコンピュータゲームをプレイするなど、日常生活に革新をもたらす体験をしている。

イーロン・マスク氏は1月30日、Neuralinkが人間への初の脳インプラント手術を実施し、患者が順調に回復していること、さらに神経スパイクの検出において初期段階で有望な結果を示しているとX（旧Twitter）で{target=“_blank”}。2023年5月に、脳インプラントを人間に対して装着するとマスク氏が述べ、9月には治験実験が承認された。

被験者第１号としてこの手術を受けたノーランド氏は、約10年前にフリーダイビングの事故でC4とC5を脱臼し、以来完全な四肢麻痺の状態にあった。しかし、同社のデバイスのおかげで、彼は思考だけでコンピュータ画面上のカーソルを動かし、チェスや『Civilization VI』といったゲームを楽しむことができるようになったという。

このデバイスは、脳の信号を読み取り、それをコンピュータのコマンドに変換することで操作を可能にする。ノーランド氏は、この技術を使って日常生活での多くの制約を克服し、新たな自由を手に入れたと語る。彼は、自分の思考だけで画面上でカーソルを自在に動かす体験を「魔法のような体験」と表現し、技術の可能性に大きな期待を寄せている。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 29 Mar 2024 05:34:15 +0000</pubDate></item><item><title>GoogleとFitbitがGeminiベースの健康アドバイザーAI「Personal Health LLM」を共同開発</title><link>https://ledge.ai/articles/google_fitbit_personal_health_llm</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

Googleは2024年3月19日、毎年行われる Google Health イベント「The Check Up」で、AIが同社の製品、研究、パートナーシップ全体で健康の未来をどのように再考しているかを{target=“_blank”}。

ヘルスケア分野における生成AIの進歩として、同社は子会社であるFitbitと協力し、「Gemini」ベースの対話型AIをFitbitアプリに搭載する計画を{target=“_blank”}した。

Fitbitは、歩数、心拍数、睡眠の質、階段の昇降の歩数など、個人のフィットネスに関連する様々なデータを測定するウェアラブルデバイスを提供するアメリカの企業だ。2007年にカリフォルニア州サンフランシスコで設立され、アクティビティトラッカー、スマートウォッチ、ワイヤレス接続可能な技術などを開発する。Googleが2019年にFitbitを買収し傘下に置いた。

新しいAIモデル「Personal Health Large Language Model (LLM)」は、FitbitとGoogleが共同で開発し、匿名化された健康データに基づいてGemini モデルLLMをファインチューニングしたもの。ユーザーの健康データを処理して、個々に合わせたウェルネスコーチを提供するという。

Personal Health LLMは、FitbitのウェアラブルデバイスやGoogle Pixelによって収集された睡眠パターン、ワークアウトの強度、その他の生理学的データを分析し、ユーザーが自分のルーティンを最適化するための実用的なヒントや調整をアドバイスする。例えば、睡眠品質の変動を検出した場合、ワークアウトの強度変更を提案するなど。

!
:::small
画像の出典：{target=“_blank”}
:::

Googleは実践テストを使用したパフォーマンスをテストしており、現在のモデルは既に良好な成績を収めているという。同社は Personal Health LLM の構築を続け、さらに多くの研究を共有する予定だと述べた。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 29 Mar 2024 02:25:57 +0000</pubDate></item><item><title>Stability AIが「Stable Video 3D」を発表 　単一画像から「回しても形が崩れない」3Dビデオ生成を実現</title><link>https://ledge.ai/articles/stable_video_3d</link><description>:::small
画像の出典：{target=“_blank”}
:::

Stability AIは2023年3月19日、単一の画像から高品質な3Dビデオを生成できる新技術「Stable Video 3D」(SV3D)を{target=“_blank”}した。

2023年11月に発表された{target=“_blank”}を基盤としている。
12月にリリースされた{target=“_blank”} と比較し、品質とマルチビューが大幅に改善され、Zero123-XLなどの他のオープンソースの代替製品よりも優れているという。

!
:::small
画像の出典：{target=“_blank”}
:::

SV3Dには「SV3D_u」「SV3D_p」という２つのバリアント（異なるバージョン）がある。
- **SV3D_u**：カメラのコンディショニングなしで単一の画像入力に基づいて軌道ビデオを生成する
- **SV3D_p**：SVD3_u の機能を拡張したもの。単一画像と軌道ビューの両方に対応し、指定されたカメラパスに沿って3Dビデオを作成する

2023年12月に同社は「Stability AIメンバーシップ」を{target=“_blank”}している。メンバーシップに加入することでStable Video 3Dの商用利用が可能となる。非商用利用の場合はHugging Faceからモデルウェイトをダウンロードでき、{target=“_blank”}も閲覧可能だ。

!

:::small
画像の出典：{target=“_blank”}
:::


この技術は、従来の新規ビュー合成（NVS）の問題、特に限定されたパースペクティブや出力の不一致を克服し、どの角度からでも一貫したビューを提供する。また、3D Neural Radiance Fields （NeRF）とメッシュ表現の最適化を利用して、直接生成された3Dメッシュの品質を向上させる。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Mon, 25 Mar 2024 06:36:20 +0000</pubDate></item><item><title>Sakana AI　異なるAI基盤モデルを融合させ新しいモデルを構築する「モデルマージの進化的最適化」を公開</title><link>https://ledge.ai/articles/sakanaai_evolutionary_model_merge</link><description>:::small
画像の出典：{target=“_blank”}
:::

Sakana AIは2024年3月21日、進化や集合知など自然界の原理を応用して、基盤モデルの開発を自動化し、効率化する手法「Evolutionary Optimization of Model Merging Recipes （モデルマージの進化的最適化）」を{target=“_blank”}した。

社会や経済が様々な専門知識を持つ個体の集まりで成り立っているように、AIも異なる専門性を持つ多数の小さなシステムが互いに補完し合う集合体として発展していると同社は述べる。既にオープンソースAIエコシステムでは、このような動向が見られ、新しい専門性を補うモデルが開発されているという。

Sakana AI の提案する「進化的モデルマージ」は、この考えを具体化し、実際に異なる専門性を持つモデルのマージに成功したとのこと。これまでは困難とされた「非英語言語と数学」「非英語言語と画像」の組み合わせにおいても、自動的に新たな方法を発見することに成功したという。
!

:::small
画像の出典：{target=“_blank”}
:::

同社はこの手法により、大規模言語モデル（EvoLLM-JP-v1）・画像言語モデル（EvoVLM-JP-v1）・画像生成モデル（EvoSDXL-JP-v1）の3つのモデルを実験的に構築し、各モデルが複数のベンチマークで高い性能を示したと述べた。


### １．EvoLLM-JP：数学的推論が可能な日本語の大規模言語モデル（LLM）
日本語数学LLMとして構築したモデルだが、数学だけでなく、日本語の全般的な能力も高い。パラメータ数は7Bと小型であるにも関わらず、同サイズのモデルと比較し最高の性能を達成し、さらに70Bパラメータの日本語LLMの性能も上回った。汎用の日本語LLMとしても十分な性能を持つと同社はいう。


下図は、LLMの日本語で数学の問題を解く性能の比較。MGSM-JAのカラムが正答率を示す。モデル1〜3は元のモデル、モデル4〜6は最適化されたマージモデル。モデル7〜10は比較のために高性能な既存LLMのスコアを掲載。
!
:::small
画像の出典：{target=“_blank”}
:::

LLMの日本語の全般的な能力の比較。Avgカラムが9タスクでのスコアの平均値であり、これが大きいほど日本語の全般的な能力が高いとされる。
!
:::small
画像の出典：{target=“_blank”}
:::


### ２．EvoVLM-JP：日本語で対話可能な画像言語モデル（VLM）
日本語VLMとして構築されたこのモデルは、日本文化に特有の知識にも対応でき、日本の画像と日本語のテキストを利用したベンチマークでも最高の結果を達成した。

これらのモデルは{target=“_blank”}で公開され、EvoVLM-JPについては、{target=“_blank”}も用意されている。


＜EvoVLM-JPの応答例＞英語VLMの場合は緑と回答する。日本の慣習では信号機の進行許可は「青信号」と表現されるため、日本語に特化したEvoVLM-JPは「青です」と回答する。
!
:::small
画像の出典：{target=“_blank”}
:::

### ３．EvoSDXL-JP：高速な日本語画像生成モデル
日本語に対応し日本スタイル画像を生成可能なSDXLモデルを、わずか数ステップで推論が実行出来るように進化的アルゴリズムにより最適化することで、日本語プロンプト対応の高速画像生成モデルを構築。現時点では論文には含まれておらず、近日中の発表予定とのこと。

日本語プロンプト対応の高速画像生成モデルEvoSDXL-JPで生成した画像の例。プロンプトは「味噌ラーメン、最高品質の浮世絵、葛飾北斎、江戸時代。」など。
!
:::small
画像の出典：{target=“_blank”}
:::


Sakana AIの取り組みは、日本に根差したAIラボとして、高品質な基盤AIモデルを開発することを目指すと述べた。今後は、{target=“_blank”}の支援を受け、進化的アプローチと集合知能を融合させた基盤モデル開発に取り組むとのこと。この支援により、大規模GPUスーパーコンピューターを利用した研究開発を加速する計画だという。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 24 Mar 2024 11:30:01 +0000</pubDate></item><item><title>京都ATRに新しい実験環境「ロボットスケートパーク」誕生　スケボーする人間の動きを学習し、人型ロボが再現</title><link>https://ledge.ai/articles/nedo_atr_cyborg_ai_challenge</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、京都府精華町に位置する国際電気通信基礎技術研究所（ATR）内に、世界初の「ロボットスケートパーク」が設立され、その{target=“_blank”}が行われた。

この施設は、スケートボードをする人の動きを人型ロボットが再現する実験に特化しており、スケートボードの基本技術である「ポンピング」などの動作を、AIの学習に基づき人型ロボットが実演し、人間の運動能力と脳波・筋電などの生体信号の計測を行う。得られたデータは、複雑な動きを指示できる高度なAIの開発に生かされるという ​​​​。

ロボットスケートパークは、国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）の支援を受け、ATRが京都大学、産総研と共同で開発を進めている。人とAIの共進化を目的とした世界初の実験環境として、人やロボットが安全にスポーツを楽しめる設備や、人の筋肉や脳の機能を計測できるシステムが整備されている。また、人とロボットの運動を比較し類似性を視覚的に評価できるソフトウェアの開発も行われている​​​​。

今後ATRは、2024年度「NEDO懸賞金活用型プログラム」の中で、「ロボットスケートパーク」で収集したデータを活用したコンテストの開催を予定しており、これにより「サイボーグAI」に関する基本技術の開発を加速させる計画だという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 23 Mar 2024 14:33:04 +0000</pubDate></item><item><title>イスラエル国防軍、AI標的システム「ラベンダー」を使用してガザのターゲットを特定</title><link>https://ledge.ai/articles/lavender_ai_israeli_army_gaza</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

イスラエル国防軍（IDF）が「Lavender（ラベンダー）」と呼ばれるAI標的システムを利用して、ガザ地区の攻撃ターゲットを特定している事実が2024年4月3日の{target=“_blank”}をはじめ、複数の報道により明らかにされた。

このシステムは、ガザ地区に居住する約230万人のデータを分析し、ハマスまたはパレスチナ・イスラム聖戦（PIJ）の活動家である可能性を数値で評価し、特定の個人を自動的に暗殺対象としてリストアップしているという。

ラベンダーは、ハマス関連の活動家やその関連地点を特定するために開発され、37,000人以上の個人を「キルリスト」に含めるほどの大規模な監視と分析を行っている。このシステムによるリストは、個々の詳細な検証を経ずに作成され、実際の攻撃命令として採用されている。報告によると、このリストに基づく攻撃では、低ランクのハマス活動家であっても、その居住する家族を含む民間人の死亡を多数許容しているとのこと。

IDFはこれらの報道に対して、ラベンダーが単なる情報集約と分析のツールであり、最終的な攻撃決定には人間が介入して個々の事案を評価していると反論しているが、実際の操作においてはほとんどが自動化されているとの証言が相次いでいるという。

AI技術を利用して、ターゲットの選定や攻撃の実行など特定の軍事的決定を人間の関与なしに自律的に行うことができ、致死性を有する「完全自律型兵器」に関して、{target=“_blank”}は2023年12月に、自律型致死兵器システム（LAWS）自律型兵器システムに関する国際的な合意に基づく規則と制限への支持を表明。新たな決議案を日本や米国など152カ国の賛成で採択している。中国や北朝鮮はじめ、イスラエルなど11か国が棄権した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 01:27:37 +0000</pubDate></item><item><title>米ワシントン州、銃撃事件の裁判「AIで強化した動画は証拠として認めない」高等裁判所の裁定</title><link>https://ledge.ai/articles/judge_blocks_ai_enhanced_video</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

ワシントン州の裁判所が「AI技術を使用して強化されたビデオを法廷での証拠として使用することを禁じる」という初めての裁定を下した。2024年4月3日に現地の各メディアが報じたこの判決は、キング郡高等裁判所の裁判官、リロイ・マッカロー判事によって出された。事件は、2021年にシアトル近郊のバーの外で起きた銃撃事件に関連しており、被告のジョシュア・プロカは3人の命を奪い、2人を負傷させたとされている。

プロカ被告の弁護団は、携帯電話の映像をAIで強化して明確化し、裁判での証拠として提出しようと試みた。しかし、この強化されたビデオは元の映像にないデータを加えたり、削除したりしており、実際の出来事を正確に反映していると証明する方法がないため、問題が発生した。さらに、AIの使用によって映像が「視覚的には魅力的に見えるが、実際のシーンを正確に表していない」という懸念が専門家から提起された​という。

マッカロー判事は、AI技術が「AIが示すべきだと考える」内容を不透明な方法で表現するため、その証拠を採用することは陪審員を混乱させ、証言の信頼性を損なう恐れがあると述べた。この決定は、AIの法廷での扱いについての重要な前例となり、今後の類似の裁判において参考とされる可能性が高い。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Apr 2024 13:15:16 +0000</pubDate></item><item><title>佐川急便など、レベル3.5飛行による東京都が推進するドローン宅配便配送プロジェクトを実施</title><link>https://ledge.ai/articles/sagawa_drone_parcel_delivery_project_by_tokyo</link><description>:::small
画像の出典：{target=“_blank”}
:::

佐川急便は2024年3月29日、イームズロボティクス、日本気象協会、サンドラッグと共に、山間地域の利便性向上に向けたドローンレベル3.5飛行による宅配便配送の実証実験を東京都青梅市において実施したことを{target=“_blank”}した。

四者は東京都が推進する「ドローン物流サービス社会実装促進事業」の支援対象として2022年7月28日に選定され、以降共同でプロジェクトを進めている。ドローンによる配送サービスの社会実装を目指し、山間地域での生活利便性の向上と持続可能な配送システムの構築が目的だという。

プロジェクトでは、国土交通省により2023年12月に制度化されたドローンレベル3.5飛行を利用し、宅配便配送の実証実験を行った。青梅市の山間地域で、ドローンから受取人が直接荷物を受け取る運用や、災害時の救援物資輸送を想定した配送実験が実施された。

!
:::small
画像の出典：{target=“_blank”}
:::

実証実験は2024年2月26日から3月8日にかけて平日10日間の予定で行われ、天候の影響を受けたものの、5日間は実施可能であった。期間中、イームズロボティクス社製のLAB6150を使用し、1日最大3往復6フライトを実施した。このドローンは、最大ペイロードが10kgであり、大きな荷物の輸送も可能である。

東京都内で初めて実施されたこのレベルのドローン飛行による宅配便配送実験では、地域住民からの高い関心と支持を得た。実際にドローンから荷物を受け取った住民を対象にしたアンケートでは、96％の人が今後もドローン配送を利用したいと回答しており、その有効性が示されたという。


:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Apr 2024 10:04:47 +0000</pubDate></item><item><title>大阪市、全庁で生成AIの業務活用を開始 — 効率化と品質向上を目指す</title><link>https://ledge.ai/articles/osaka_city_begins_using_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

大阪市は2024年4月1日、生成AIの全庁業務活用を{target=“_blank”}した。

大阪市はこれまで、民間事業者との共同検証や試行利用を通じ、生成AIの本格利用に向けた検討と取り組みを進めてきた。このたび、ガイドラインの策定と安全な利用環境の整備を経て、生成AIを業務に活用することで業務の効率化と品質の向上を図るという。

生成AIの利用は、大阪市全職員（水道局及び学校園を除く）を対象に、4月1日より開始する。利用内容には、文章の要約・作成・添削、企画案のたたき台作成、翻訳などを含む。ただし、市民や事業者への直接的な行政サービス提供には使用しない。

議事録や膨大な資料の内容把握、文章の練り直しや誤字脱字の確認に要していた時間の短縮、ゼロからの企画案作成の労力軽減、外国人へのより伝わりやすい翻訳の提供といった業務効率化と品質向上が期待されるという。

利用環境は、Microsoft社の「Azure OpenAI Service」を基にした本市独自の環境で、利用者の入力データは保存されず、生成AIの学習データとしても再利用されない。また、様々なリスクへの対応として「大阪市生成AI利用ガイドライン」に則り利用されるとのこと。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Apr 2024 09:51:03 +0000</pubDate></item><item><title>米バイデン政権　連邦政府機関のAI利用の包括的指針を発表　AI利用のリスクから国民を保護する措置を義務付け</title><link>https://ledge.ai/articles/omb_policy_in_federal_agencies_use_of_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

米国行政管理予算局（OMB）は2024年3月28日、連邦政府機関がAIを利用する際に、リスクを緩和し、その利益を最大化することを目的とした指針を示す文書を[発表](https://www.whitehouse.gov/briefing-room/statements-releases/2024/03/28/fact-sheet-vice-president-harris-announces-omb-policy-to-advance-governance-innovation-and-risk-management-in-federal-agencies-use-of-artificial-intelligence/
){target=“_blank”}した。この指標は、2023年10月にバイデン大統領が署名した、安全で信頼性あるAI開発管理方針示す{target=“_blank”}に基づくものだ。

この指針文書では、特にリスク管理、透明性の向上、イノベーションの推進、人材拡充、ガバナンス強化の五つの主要な領域に焦点を当てている。

### ■リスク管理
連邦政府機関が米国民の権利や安全に影響を与える可能性のあるAIを使用する場合、2024年12月1日までに、アルゴリズムによる差別を防ぐなどの具体的なセーフガード措置を講じることを義務付けた。これには、空港の顔認証システムや連邦政府系病院の診断システムが含まれる。これらの保護措置を適用できない場合、AIシステムの使用を原則中止するとのこと。

具体的なケースとしては、
・空港で旅行者は、TSAの顔認識の使用からオプトアウトでき、列での位置を失うことなく遅延なく続行できる。
・連邦ヘルスケアシステムでAIが重要な診断決定を支援するために使用される場合、ツールの結果を検証し、医療アクセスの不平等を避けるために人間がプロセスを監視している。
などを挙げた。

### ■透明性の向上
連邦政府機関がAIの使用に関して一層の透明性を確保することが要求されている。公衆の権利や安全に影響を与える使用ケースを特定し、関連するリスクにどのように対処しているかを一覧に含め年次報告する。

### ■イノベーションの推進
気候変動対策、自然災害対応、公衆衛生の向上、公共交通機関の安全性向上など、AIを責任ある形で活用することが奨励されている。

### ■人材拡充
AI専門人材を連邦政府機関全体で新たに100人雇用する計画が立てられており、これには2024年4月のキャリアフェアの開催も含まれる。

### ■ガバナンス強化
各連邦政府機関がAIの使用に関する説明責任、リーダーシップ、監督を担保するために最高AI責任者を配置し、AIの使用を調整・管理するためのAIガバナンス委員会の設置が求められている。


ハリス副大統領は、これらの施策が世界的な行動のモデルになることを目指しており、AIの責任ある開発と利用に向けた国際基準の策定において、米国がリードすることを強調した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 04 Apr 2024 01:00:24 +0000</pubDate></item><item><title>フランスの競争委員会がGoogleに2億5,000万ユーロの罰金を科す　Geminiの学習データめぐり</title><link>https://ledge.ai/articles/related_rights_autorite_fines_google_eu250_million</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月20日、フランスの競争規制機関であるAutorité de la Concurrenceは、著作隣接権に関するライセンス契約の交渉過程における違反を理由に、Googleに対して2億5000万ユーロの罰金を科したことを{target=“_blank”}した。

この措置は、2019年4月17日のEUの著作権及び著作隣接権に関する指令を法令化する2019年7月24日のフランス法に基づき、報道機関、出版社、デジタルプラットフォーム間のバランスの取れた交渉条件を確立することを目的とした約束事項の一部を遵守していなかったためとされる。

Googleは、同社開発のマルチモーダルAI「Gemini（当時は ”Bard”）」に、報道機関や出版社から提供されたコンテンツを基盤モデルの学習に使用していたが、これらの利害関係者や競争委員会に事前通知を行っていなかったという。さらに、Geminiが使用するコンテンツを、他のGoogleサービスで保護されたコンテンツの表示に影響を与えずに、報道機関や出版社がその使用からオプトアウトできる技術的解決策を提案していなかったため、報道機関や出版社が関連権に基づく報酬を交渉する能力が妨げられていたと当局は主張した。

Autorité de la Concurrenceは、透明性、客観性、非差別の基準に基づく誠実な交渉、著作隣接権に対する報酬の透明な評価のための情報提供、およびGoogleと報道機関や出版社との他の経済的関係に影響を与えない交渉の保証を含む、約束事項の4つを遵守していないと判断したという。

これに対してGoogleは、欧州著作権指令に基づき、280のフランスのニュース出版社と450以上の出版物をカバーするライセンス契約を締結し、年間数千万ユーロを支払うという成果を上げているにも関わらず、この制裁を受けたと{target=“_blank”}で述べている。

同社はこの長期間にわたる問題を解決し、出版社との建設的な協力に焦点を当てたい意向だが、競争委員会が提起した問題に対する罰金額は、違反に対して不釣り合いに高額であると主張。また、複雑な規制環境と継続する法的行動が交渉を困難にし、将来のフランスにおける情報分野への投資を不確実にしていると指摘した。

この問題に対応するため、Googleは間接収入の計算方法の見直しを含む一連の改善策を約束しており、ニュースコンテンツの実際の経済価値に関するさらなる分析を進める予定だという。

フランス競争委員会との和解により、Googleは交渉過程での手続き上の問題に対処する措置を講じ、特定の出版社および出版物に関する批判に対応しているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 25 Mar 2024 15:56:53 +0000</pubDate></item><item><title>世田谷区のAIチャットボット「ヒデキ」を非エンジニアの職員がローコードで開発　絵文字を多用するポジティブおじさん誕生</title><link>https://ledge.ai/articles/setagaya_chatbot_hideki</link><description>:::small
画像の出典：{target=“_blank”}
:::

東京都世田谷区のDX推進担当課は2024年3月12日、ChatGPTを用いたAIチャットボット「Hideki（ヒデキ）」を開発したことを{target=“_blank”}した。

同課は、Microsoft Azure OpenAI Serviceを利用し、生成AI（ChatGPT）を活用する環境を構築。非エンジニア職の区職員が開発したMicrosoft Teams対応のチャットボットを全職員に提供開始した。このチャットボットは、外部委託なしで、セキュリティ要件を満たしつつ、3ヶ月で開発された。開発の背景には、区職員の業務効率化と区民の利便性向上の目的があるという。
!
:::small
画像の出典：{target=“_blank”}
:::

このチャットボットは、文章校正やWord/Excel操作に関する疑問解消、アイデアの壁打ちなど、多岐にわたる業務で活用されている。利用した職員127人のうち73%が生産性の向上を実感しており、通常業務では1日平均約34分、アイディアや企画の素案作成においては、1回当たり平均約77分の時間短縮が達成されたとのこと。

#### 職員アンケート
!
!
!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Fri, 22 Mar 2024 05:51:51 +0000</pubDate></item><item><title>G7産業・技術・デジタル大臣会合、イタリアで開催 - AIとデジタル政府の進展に焦点</title><link>https://ledge.ai/articles/g7_industry_technology_and_digital_ministreal_meeting</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月14日及び15日、イタリアのヴェローナとトレントで、G7産業・技術・デジタル大臣会合が{target=“_blank”}。

イタリアが議長国を務める中、会合にはG7各国の大臣のほか、招待国や関連国際機関が参加し、多岐にわたるテーマで議論が行われた。特に、公的部門におけるAIツールキットの開発、デジタル政府サービスの強化、国際データガバナンスの推進が主要議題となった。日本からは、河野デジタル大臣、長谷川総務大臣政務官、石井経済産業大臣政務官らが参加した。

G7各国は、公的部門での安全で信頼できるAIの利用を促進するため、リスクと機会のマッピング、有効な環境のサポートガイダンスを提供するAIツールキットの開発に合意した。これにより、政府による信頼できるAI開発をさらに支援するとのこと。加えて、デジタル政府サービス及びデジタル・アイデンティティの取り組みをまとめたCompendium（大綱）の作成に合意した。

また、「広島AIプロセス」の成果を前進させることを確認。開発途上国・新興経済国を含む主要なパートナー国や企業等からの認知及び支持の拡大を目指すとした。このプロセスでは、国際指針と国際行動規範の普及促進、行動規範の適用状況のモニタリングのツール・仕組みの開発、国際機関との連携が行われる予定だ。

会合では、昨年日本が議長国を務めたG7の成果を引き継ぐ形で、信頼性のある自由なデータ流通（DFFT）をさらに進捗させることを確認し、国際データガバナンスの強化が必要であるとの認識を共有したという。これにより、AIと相互関連性のあるデータやその流通について、G7として検討を進めることに合意を得た。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 20 Mar 2024 22:18:09 +0000</pubDate></item><item><title>AI規制法「AI Act」欧州議会が可決――世界初の包括的規制へ。2年以内に完全適用の見込み</title><link>https://ledge.ai/articles/eu_ai-act_approved</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月13日、欧州議会は基本的人権の保護とイノベーションの推進を目的とした、世界初の包括的な{target=“_blank”}した。

議会は2023年12月、理事会と共に、AIの安全性、基本的人権の尊重、民主主義の保護、ビジネスの繁栄と拡大を目的としたAI Actについておおむね{target=“_blank”}に至っており、その際の合意文書が議員らによって賛成523票、反対46票、棄権49票で承認された。

この規制は、高リスクAIによる基本的人権、民主主義、法の支配、環境持続性の保護を目的とし、イノベーションの促進と、欧州をこの分野のリーダーにすることを目指している。規則は、AIの潜在的リスクと影響レベルに基づいて義務を設定する。


法案は、AIによる基本的人権への潜在的な脅威を軽減し、ヨーロッパをAI分野のリーダーとして確立することを意図している。主にAIの潜在的リスクと影響のレベルに基づいた義務の確立で、市民の権利を脅かす特定のAIアプリケーションの使用を禁止する内容を含む。

具体的には、機密特性に基づく生体認証分類システムや、顔認識データベースを作成するためのインターネットや監視カメラ映像からの顔画像の対象外のスクレイピングなど、国民の権利を脅かす特定のAIアプリケーションを禁止する。

法執行機関による生体認識システムの使用は原則禁止されているが、特定の状況下での使用が許可される。これには厳格な条件が設定され、例えば、リアルタイム生体認識の使用は時間と地理的範囲に限定され、特定の事前の司法または行政の承認が必要とされる。

高リスクAIシステムに関しては、健康、安全、基本権への重大な潜在的害を低減するための明確な義務が規定されており、透明性の確保や人間の監視が求められる。また、一般目的AI（GPAI）システムは特定の透明性要件を満たさなければならず、EU著作権法への準拠やトレーニングに使用されたコンテンツの詳細な要約の公開が義務付けられている。

この法案の可決により、EUはAIの安全な使用と基本的価値観への尊重を世界に向けて示した。イノベーションと中小企業（SME）への支援措置も盛り込まれ、国家レベルでの規制サンドボックスの設置や実世界テストが推進されることで、市場投入前のAI開発が促進される予定だ。

本法案は、まだ弁護士言語校正チェックを受ける必要があり、最終的な採択は立法期間終了前に予定されている。公式ジャーナルに掲載されてから20日後に発効し、その後24ヶ月以内に完全に適用される見込みだという。


:::box

:::
:::box

:::
</description><pubDate>Sun, 17 Mar 2024 05:00:07 +0000</pubDate></item><item><title>富山県、生成AIとマルチモーダルAIによる職員の働き方改革を検証ーーインテックと共同で実証実験</title><link>https://ledge.ai/articles/toyama-intec_working_with_gen_and_multimodal_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

富山県とインテックは2023年9月から2024年3月にかけて、生成AIおよびマルチモーダルAIを用いた働き方改革の実証実験を共同で実施したことを{target=“_blank”}した。この実証実験は、自治体職員の業務効率化を目指し、書類のデータ化、書類検索、データの活用の3つの分野に焦点を当てた。

このプロジェクトは、富山県が抱える地域課題をデジタルソリューションで解決する事例の創出や、ビジネスモデルの構築によってDX推進することを目的とした同県による事業「Digi-PoC TOYAMA」に採択された。

実証実験の結果、データ検索では約97%の高い割合で目的のファイルを正確に検索でき、利用者が特別なスキルを必要とせずに結果を簡単に理解できる点が高く評価された。また、データの活用では、約86%の割合で利用可能なシナリオを作成でき、シナリオ検討および作成時間の大幅な削減に成功し、利用者の業務的、心理的負担の軽減が期待できることが明らかになった。

インテックは、自治体への事業展開には、データ利用の安全性や正確性を更に向上させる必要があるとも指摘されていることも踏まえ、これまで自治体業務で培った知見と最新の技術を組み合わせ、他団体へのサービス展開を進めていく予定だという。

本プロジェクトの{target=“_blank”}が、2024年3月28日に「Digi-PoC TOYAMA」の下で開催予定とのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 12 Mar 2024 05:27:15 +0000</pubDate></item><item><title>NTTグループ・内閣府など　石川県珠洲市で能登半島地震の住家被害認定調査の実施　ドローンや360度カメラ活用</title><link>https://ledge.ai/articles/noto_shien_drone</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月21日、NTT東日本グループ、ESRIジャパン株式会社、NTT西日本グループは、令和6年能登半島地震で大きな被害を受けた石川県珠洲市で、ドローンや360度カメラを用いた住家被害認定調査と、遠隔地からの被害判定支援を行ったことを{target=“_blank”}した。この活動は内閣府、石川県、珠洲市と連携し、応援自治体である熊本市・浜松市も参加して実施された。

!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みの目的は、人の立ち入りが困難な地区での効率的な住家被害認定調査の実施と、調査人員の確保、迅速な罹災証明書の発行を通じて、被災者の生活再建を一日も早く実現することにある。

珠洲市では、ドローンや360度カメラを活用し、特にアクセスが困難な山間部や海岸部での住家被害認定調査を行い、得られた画像データを基に遠隔地からの判定支援を実施した。この取り組みは、NTTグループが電気通信役務でのインフラ点検に活用している体制を基にし、事業者としては初の試みである。遠隔地からの判定は、応援職員が現地に行かずに自庁で実施することが可能であり、職員の負担軽減と住家被害認定調査の迅速化を実現した。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の取り組みにより、災害時における住家被害認定調査の新たな手法として、ドローンや360度カメラの活用が有効であることが証明された。今後はこの取り組みを基に、より迅速かつ公平公正な罹災証明書の発行を実現し、地震だけでなく水害や風害など他の災害にも対応できる体制の確立を目指す。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 03 Mar 2024 08:27:08 +0000</pubDate></item><item><title>日本政府 AIセーフティ・インスティテュート設立へ</title><link>https://ledge.ai/articles/japan_ai_safety_institute</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月14日、内閣府と独立行政法人情報処理推進機構（IPA）は、AIの安全性に対する国際的な関心の高まりを踏まえ、AIセーフティ・インスティテュートの設立を{target=“_blank”}した。

主な業務としては、国内外のネットワークを活用して、安全性評価に関する調査や基準の検討、実施手法に関する検討、および他国の関係機関との国際連携などが挙げられている。関係省庁には内閣府、内閣官房、警察庁、デジタル庁などが名を連ね、関係機関には情報通信研究機構や理化学研究所などが含まれる。

同機関はIPAに設置され、所長には元日本IBMのAI研究者であり、損保ジャパンCDO及び京都大学防災研究所客員講師を務める村上明子氏が就任した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:02:30 +0000</pubDate></item><item><title>200名を超えるアーティストが署名「AIで音楽の価値を下げるな」ビリー・アイリッシュ、ノラ・ジョーンズ、ボン・ジョヴィなど参加の団体が権利保護を呼びかける声明</title><link>https://ledge.ai/articles/200_artists_urge_tech_platforms_stop_devaluing_music</link><description>:::small
画像の出典：{target=“_blank”}
:::

Artist Rights Alliance（ARA）は2024年4月2日、200人以上のアーティストの支持を受けて、AI開発者、テクノロジー企業、プラットフォーム、デジタル音楽サービスに対し、人間のアーティストの権利を侵害し価値を減じるAIの使用を停止するよう呼びかける公開書簡を{target=“_blank”}した。

ビリー・アイリッシュ、ノラ・ジョーンズ、ジョン・ボン・ジョヴィ、ケイティ・ペリー、スティービー・ワンダーなどを含む200名以上の著名アーティストがこの書簡に署名している。書簡では、AIがアーティストの芸術に「現実的な脅威」をもたらすと指摘し、音楽業界におけるAIの非倫理的な使用を非難している。

AIに関連する脅威は、ディープフェイクやボイスクローニングなどが注目を集めているが、この書簡では、AIが人間の音楽作品を無断で利用してAI「コピーキャット」を訓練・製作する行為や、AI「サウンド」を使って印税の負担を薄める行為といった、深刻で無責任な使用例が指摘されている。

ARAのエグゼクティブディレクター、ジェン・ジェイコブセン氏は、音楽ストリーミングサービスの普及によりアーティストが生計を立てることが難しくなっている現状を説明。「AIが生成する『ノイズの洪水』と戦うことは、アーティストとファンの両方にとって、音楽エコシステム全体の価値を下げる」と述べ、AI技術の責任ある使用をテクノロジー企業に呼びかけている。

公開書簡の一部には以下のように記されている。

「誤解なきように言うが、我々は、責任を持って使用された場合、AIが人間の創造性を前進させ、音楽ファンにとって新しく興奮する体験の発展と成長を可能にする莫大な潜在力を持っていると信じている。残念ながら、一部のプラットフォームや開発者が、創造性を破壊し、アーティスト、ソングライター、ミュージシャン、権利保持者を脅かすためにAIを使用している。」

「我々は、プロのアーティストの声や肖像を盗むAIの捕食的な使用、創作者の権利を侵害する行為、音楽エコシステムを破壊する行為に対して保護を求める。すべてのデジタル音楽プラットフォームや音楽サービスに対して、アーティストとソングライターの人間芸術を損なうか置き換えるAI音楽生成技術、コンテンツ、ツールの開発や展開を行わないよう誓約することを求める」と訴えている。

この公開書簡は、音楽におけるAIの責任ある使用について世界中で活発な議論が行われている中で発表された。すでにテネシー州は「公開の権利」を強化するいわゆるELVIS法を制定しており、同法は正式に「Likeness Voice and Image Security Act」と呼ばれている。類似の立法が米国議会および複数の米国州で議論されている。


## 署名したアーティストのリスト
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Apr 2024 11:40:17 +0000</pubDate></item><item><title>Stability AI　音楽生成AI「Stable Audio 2.0」にバージョンアップ　最大3分間の高品質なフルトラックを生成　Audio-to-Audio機能も</title><link>https://ledge.ai/articles/stable_audio_2-0</link><description>:::small
画像の出典：{target=“_blank”}
:::

Stability AIは2024年4月3日、オーディオ生成AI「Stable Audio 2.0」を{target=“_blank”}した。新しいモデルは、44.1KHzステレオで最大3分間の高品質なフルトラックを生成可能。ユーザーは自然言語のプロンプトを使用してオーディオサンプルをアップロードし、これを様々なサウンドに変換できる。

@



{target=“_blank”}との大きな違いは、特にオーディオからオーディオへの生成機能を導入した点にある。これにより、アーティストやミュージシャンは自らのオーディオサンプルをアップロードし、自然言語によるプロンプトを通じて変換することが可能となった。さらに、このモデルはイントロ、展開、アウトロを含む構造化されたコンポジションを含む楽曲を生成できるという。Stable Audio では45秒だった曲の長さも、2.0になり最長で3分間まで生成できる。

現在、{target=“_blank”}で無料で利用でき、将来的にはStable Audio APIでも利用可能となる。

### Audio-to-Audio Feature Demo
@


1.0モデルと同様、2.0は音楽、効果音、シングルインストゥルメントステムを含む800,000以上のオーディオファイルからなるAudioSparxのデータでトレーニングされている。オプトアウトのリクエストに対応し、クリエイターへの公正な報酬を保証することにも重点を置く。

オーディオアップロードに際しては、著作権侵害を防ぐためにAudible Magicと提携し、そのコンテンツ認識（ACR）技術を利用しているとのこと。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 09 Apr 2024 14:46:35 +0000</pubDate></item><item><title>OpenAI「Sora」をハリウッドに売り込み中か</title><link>https://ledge.ai/articles/openaii_pitches_sora_to_hollywood</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

OpenAIはロサンゼルスの映画スタジオ、メディア幹部、タレントエージェンシーと会合を持ち、エンターテインメント業界でパートナーシップを築こうとしている。関係者によると、映画制作者に同社の動画生成AI「Sora」を作品に組み込むよう奨励していると2024年3月22日に{target=“_blank”}が報じている。

2月下旬にOpenAIは最高執行責任者（COO）のブラッド・ライトキャップ氏を中心に、ハリウッドでの紹介対話を予定しており、同氏は数人の同僚とともに、ユーザーからのテキストプロンプトに基づき、長さ約1分までのリアルな動画を生成できる未発表の新サービス「Sora」の機能を実演したとのこと。その数日後、同社CEOのサム・アルトマン氏が、アカデミー賞の週末にロサンゼルスで開かれたパーティーに出席。OpenAIは、すでにいくつかの有名な俳優や監督にSoraへのアクセスを許可しているという。

既に映画製作者やスタジオではAIが活用されており、新しいツールの有望性の認識も得ている一方で、AIが人々の生活に与える影響に対し懸念を表明する声も存在する。ハリウッドでは2023年、脚本家と俳優がAIの使用に関する保護を求めてストライキに突入し、両組合はAIの使用方法についていくつかのセーフガードを確保した。メディア企業もまた、OpenAIのトレーニングデータに制作物が使用されることを警戒する動きが見られる。

2024年2月に発表されたSoraはまだ研究プレビューの段階で、価格は未定。テキストから動画を生成するサービスは、AIスタートアップのRunwayが先行しているという。業界ではすでに数百万人に利用されており、映画編集者も動画を作成し、視覚効果を作るために利用しているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 06 Apr 2024 12:29:42 +0000</pubDate></item><item><title>自分の楽曲をAIユニットに歌わせちゃおう！AI歌声ライブラリ「LAUGH DiAMOND」シリーズ　コナミより発売</title><link>https://ledge.ai/articles/konami_laugh_diamond</link><description>:::small
画像の出典：{target=“_blank”}
:::

コナミデジタルエンタテインメントは2024年4月1日、AI歌唱エンジンを用いた音声合成ソフト「VoiSona」向けのAI歌声ライブラリ「LAUGH DiAMOND」シリーズを{target=“_blank”}した。

同シリーズは、実在のシンガーの歌声をディープラーニング技術で学習したもので、音声合成ソフト「VoiSona」に歌詞と音符を入力することで楽曲制作が可能だ。

「LAUGH DiAMOND」シリーズの特徴は、声のモデルとなったシンガーの歌声や表現の特徴を忠実に再現し、人間らしい温かみのある歌声を表現できること、また、複数のシンガーとの組み合わせでユニット曲を容易に作成できることにある。これにより、声が混ざり合うことなく、ユニゾンでも美しいハーモニーを奏でることが可能となるという。

ライブで輝くことを夢見るシンガーグループ「LAUGH DiAMOND」の4キャラクター、「山田花音」「風祭朝陽」「篁響季」「小紫桃果」をイメージしており、声のモデルには声優の木戸衣吹さん、熊沢世莉奈さん、鈴木杏奈さん、白河みずなさんが起用されている。これら4名のコメントも公式サイトで公開されている。

発売を記念し、4月27日から28日にかけて千葉・幕張メッセで開催される「ニコニコ超会議2024」に参加予定であり、公式Xアカウントを通じて続報が待たれている。「LAUGH DiAMOND」シリーズの今後の展開にも注目が集まる。

キービジュアルでは、大きな舞台でのライブを夢見て路上ライブをする無名の「LAUGH DiAMOND」が描かれており、持ち歌がない彼女たちが楽曲に飢えている様子が伝えられている。クリエイターには、彼女たちに曲を提供し、夢の舞台に一歩近づけるよう呼びかけている。



:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Apr 2024 13:44:26 +0000</pubDate></item><item><title>OpenAI　動画生成AI「Sora」を使ったアーティストたちの映像作品を公開　AIは創造的プロセスに革新をもたらすのか</title><link>https://ledge.ai/articles/openai_sora_first_impressions</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年3月25日、動画生成AI「Sora」を使ったアーティストたちによる映像作品と、彼らが初めてSoraを使用した所感やフィードバックを{target=“_blank”}した。

Soraは、テキストからリアルで想像力豊かなシーンを生成できるAIモデルとして{target=“_blank”}され、世界を揺るがせた。モデルは現在のところ一般公開には至らず、ビジュアルアーティスト、デザイナー、クリエイティブディレクター、映画制作者などに対して、アクセスを提供している。同社は、こうした制作者たちのフィードバックを受けながら、創造プロセスをどのように支援できるかを学びつつ、モデルの改善を続けているという。ㅤ
ㅤㅤ
## shy kids – “Air Head”
@
トロントを拠点とするshy kidsはマルチメディア制作会社で、風船男のショートフィルムにSoraを活用した。

監督の Walter Woodman氏は「Soraは現実に見えるものを作り出す能力に優れているが、私たちを興奮させるのは、完全に超現実的なものを作り出す能力。抽象表現主義の新時代だ」と語る。

より広い業界に向けて言えば「胸からはちきれそうな物語を持つ世界中の人々が、ついにその中身を世界に見せる機会を得た」と述べる。  ㅤ
ㅤㅤ
## Paul Trillo, Director – “Abstract”
@
「Abstract」を制作したPaul Trillo氏は、アーティスト、作家、映画監督として多方面で活躍する。

同氏は「Soraが最もパワフルなのは、古いものを複製するのではなく、そうしなければ見る機会がなかったであろう新しく不可能なアイデアに命を吹き込むときだ」とコメントしている。

そして、Soraを使った制作は「映画監督として鎖に縛られていないと感じた初めての経験。時間やお金、他人の許可に縛られることなく、大胆でエキサイティングな方法でアイデアを出し、実験できる」と述べた。ㅤ
ㅤㅤ
### 「奇妙さ」こそSoraの強み
デジタルAR/XRアーティストの Don Allen Stevenson III氏は、Soraの「奇妙さ」を最大の強みとして挙げ、これが彼の創造性を純粋に集中させ、即時のビジュアライゼーションと迅速なプロトタイピングの世界を解き放つと述べている。Soraによって、従来の物理法則や思考の慣習に縛られない作品を制作することが可能になり、クリエイターたちは技術的な障壁よりも創造性に焦点を当てることができるようになった。これにより、これまでにないストーリーテリングやアート作品が生まれる土壌が整えられている。

彼の作品や、その他のアーティストの映像作品は、{target=“_blank”}で紹介されている。ㅤ
ㅤㅤ
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 30 Mar 2024 12:11:22 +0000</pubDate></item><item><title>Google DeepMind とリバプールFCが共同開発した「TacticAI」を発表ーーサッカー戦術をAIがアシストする</title><link>https://ledge.ai/articles/google-deepmaind_tactic-ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMind は2024年3月19日、リバプールFCとの間で数年にわたる共同研究の一環として、コーナーキックに関する戦術アドバイスを提供できるAIシステム「TacticAI」が開発されたことを、学術誌 Nature Communications に{target=“_blank”}した。

このシステムは、特にコーナーキックに焦点を当て、予測および生成AIを通じて専門家に戦術的洞察を提供する。TacticAIは、コーナーキックに関する限られたゴールドスタンダードデータを使用しながらも、幾何学的ディープラーニングアプローチを用いて、より一般化されたモデルの作成を支援し、最先端の結果を達成したという。

TacticAIは、プレミアリーグで行われた7,176回のコーナーキックのデータを分析し、選手をノードとして扱うグラフベースのアプローチを用いて、各選手間の複雑な相互作用と異なるコーナーキック設定の潜在的な結果をモデリングした。この方法により、どの選手がボールを受ける可能性が最も高いか、あるいはシュートを試みる可能性が高いかなど、様々なシナリオを予測し、チームパフォーマンスの向上に役立つ戦術的な推奨を提供する。

!
図(A) コーナーキックの状況をグラフ表示に変換する方法
図(B) TacticAI が与えられたコーナーキックをどのように処理するか
:::small
画像の出典：{target=“_blank”}
:::

リバプールFCのサッカー専門家からは、TacticAIの提案が実際のゲームプレイシナリオと区別がつかないほどであり、専門家たちは既存の戦術よりもTacticAIの戦略を90%の高い割合で好むという非常に肯定的な評価がなされた​​。また、このAIモデルは従来の技術よりもリバプールのコーチによって2倍有用と評価され、攻撃者の特定や守備時の注意散漫な選手の指摘に特に効果的であるとされている​​。




:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 29 Mar 2024 05:49:14 +0000</pubDate></item><item><title>YouTube、生成AIなどによる改変・合成コンテンツのラベル表示機能を順次導入</title><link>https://ledge.ai/articles/youtube_disclosing_ai_generated_content</link><description>:::small
画像の出典：{target=“_blank”}
:::

YouTubeは2024年3月19日、クリエイターが作成したコンテンツが改変または合成によって作成された場合、その事実を視聴者に開示するための新しいツールをYouTube Creator Studioに導入したと{target=“_blank”}した。

生成AIがストーリーボードのアイデア出しや創作工程のサポートツールとして活用される中、コンテンツが改変や合成によって作られたものかどうかについて、視聴者が求める透明性を確保するためのものだ。

### ラベル付けが必要とされるコンテンツ
- 実在する人物のように見せている： デジタル改変により、ある人物の顔を実在する別の人物の顔に置き換えたり、合成した人物の声を動画のナレーションに使用したりしているコンテンツ
- 実際の出来事や場所の映像を改変している： 実在する建物で火事が発生しているように見せたり、実在する都市景観を実際とは違って見えるよう改変したりしているコンテンツ
- 現実的な風景を生成している： 実在する都市に向かって移動している竜巻など、架空の大きな事件をリアルに描写したコンテンツ

視聴者が実際の人物、場所、出来事と勘違いしやすいようなリアルに見えるコンテンツに対して、クリエイターが改変または合成されたメディア（生成AIを使用したものを含む）で作成したことを開示する必要がある。ただし、明らかに非現実的であるコンテンツ、アニメーション、特殊効果が含まれるコンテンツ、または制作作業をサポートする目的で生成AIを使用したコンテンツについては、開示の必要はない。

この取り組みは、昨年11月に発表された{target=“_blank”}のアプローチの一環として、情報開示要件やラベル表示、プライバシー侵害の申し立てが更新されるなど、YouTubeのAI製品および機能に責任をもって組み込まれるよう徹底されている。

### ラベル付けが不要なケース
開示が求められる主なケースは、実在する人物のように見せかけたデジタル改変コンテンツ、実際の出来事や場所を改変したコンテンツ、現実的な風景を生成したコンテンツなどが該当する。しかし、生産性を高めるために生成 AI を使用している場合や、以下のような合成したメディアが非現実的な場合や、改変の重要度が低い場合は開示不要。

- アニメーションや、ファンタジーの世界でユニコーンに乗っている人間など、明らかに非現実的なコンテンツ
- 色の調整や照明
- フィルタ背景ぼかしやビンテージ調などの特殊効果
- 美肌加工フィルターやその他の視覚効果


このラベル表示機能は、今後段階的に導入予定だという。最初はスマートフォンの YouTube アプリ、続いてパソコンとテレビで視聴する YouTube 上でも順次展開していく予定。

将来的には、この情報を開示しないクリエイターに対する措置も検討予定で、改変または合成されたコンテンツが混乱や誤解を生む可能性がある場合は、クリエイターが情報を開示していなくても YouTube がラベルを追加するなどのケースも想定しているという。


:::box

:::
:::box

:::
</description><pubDate>Sun, 24 Mar 2024 11:41:00 +0000</pubDate></item><item><title>「相棒 season22」最終回は「ディープフェイク右京」登場。人間は生成AIに置き換えられるのか</title><link>https://ledge.ai/articles/aibou22_ai-ukyo</link><description>:::small
画像の出典：{target=“_blank”}
:::

人気ドラマ「相棒 season22」の{target=“_blank”}が2024年3月13日に放送され、生成AIによるフェイク動画が登場し、話題となった。このエピソードでは、俳優の水谷豊氏が演じる主人公「杉下右京」が喋る謎の動画が、AIによって生成されたものであった、という筋書きだ。

「相棒」シリーズにおいて、テクノロジーと事件を組み合わせた話題は珍しくない。過去には、ダークウェブを利用した犯罪や、ライブ配信中の事件の謎解きなど、現実社会の技術進化を反映したエピソードが多数放送されてきたという。

今回の「AI右京」を中心に据えたストーリーは、生成AIの急速な進化が現実世界に与える影響に焦点を当てた。特に、フェイク動画の拡散によって生じる混乱は、社会に新たな脅威をもたらす可能性があることをドラマが明らかにしたといえる。

テレ朝POSTに掲載された{target=“_blank”}で、水谷氏は生成AIと人間の関係について問われ、自身の考えを述べた。

「フェイク動画を生み出す人間は世界中にいるが、AIが人の心を表現できるとは思わない。人間がAIに置き換えられることは最終的にはないけれど、悪用はできてしまう」

同氏はまた、生成AIが引き起こす影響の一例として、ハリウッドの脚本家や俳優たちがAIによる影響を懸念し、ストライキに至った事例を引き合いに出した。AIに対するネガティブな捉え方とその背景に触れ、AIを悪用するのではなく、人間にとってプラスになる使い方を模索するべきだと語った。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 18 Mar 2024 02:52:18 +0000</pubDate></item><item><title>生成AIが作った脚本での朗読劇「AIラブコメ」公演中止へ　AIの無断学習・著作権問題などの意見が寄せられ </title><link>https://ledge.ai/articles/a_reading_play_with_an_ai-generated_script_cancelled</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月9日、舞台公演の企画提案などを行うLol（ロル）は、3月13日から上演予定だった朗読劇「～AI朗読劇～AIラブコメ」の公演中止を{target=“_blank”}した。生成AIを駆使して創り出された朗読劇の公演が予定されていたが、生成AI利用に伴う学習や著作権に関する意見が寄せられ「関係者たちに多大なる迷惑が掛かる危険がある」という理由から中止を余儀なくされたという。

公演では、AIが生成した脚本に基づく19人の声優による朗読が予定されていた。脚本のみならず、キービジュアルなどのデザインにもAI技術が用いられており、生成AIアプリに複数のキーワードを入力して得られた成果物に、クリエイターが手を加えて仕上げる手法が採られていた。同社「AIは、人間のクリエイターに力を与え、補強するために使われるツール」という日本俳優連盟と文化庁の立場に共感し、この企画を同様の精神で進めていたと説明している。

しかし、企画の進行に伴い、SNSでは生成AIの利用に対する批判や不安が社会から寄せられた。特に、無断学習・搾取問題や著作権に関する懸念が公演中止の主要な要因となった。Lol社は公演中止を発表する際、「一部の方々に意図せず不信感・不安感を与えてしまう結果となった」とし、関係者や出演者への迷惑を避けるために中止を決定したという。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 15 Mar 2024 11:52:42 +0000</pubDate></item><item><title>中国CCTV、AI活用した水墨画風アニメ「千秋詩頌」を放映開始</title><link>https://ledge.ai/articles/cctv_chinese_poem_animation</link><description>:::small
画像の出典：{target=“_blank”}
:::

中国国営の中央テレビ（CCTV）は、杜甫や李白、孟浩然など唐代の詩人の人生を、AIを活用し「水墨画の世界風」をテーマにしたアニメーション作品「千秋詩頌（千秋の詩への頌歌）」の放映を2024年2月26日に{target=“_blank”}。

中国中央ラジオテレビ局の「CCTVオーディオメディアモデル」を利用し、独自に開発した生成AI技術により、CCTV-1と人教社が共同で制作にあたる。小学生の国語の教科書にある詩をアニメ化する試みで、200首を超える古詩を基に展開される。エピソードは26個、各7分間で構成され、唐代の詩人たちの人生や自然風景、中華風の建築物を淡い色使いで描き出しているという。

「千秋詩頌」は、中国の伝統詩とその背景話を紹介することで、視聴者に中国の水墨画を連想させる映像体験を提供している。このプロジェクトは、中国中央放送テレビ総台のAI技術を駆使し、詩の内容や歴史的背景に基づき、詩の世界観や感情をできる限り忠実に再現する試みだという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 09 Mar 2024 11:07:48 +0000</pubDate></item><item><title>「AIに怯えて暮らすか、活用して生きていくか」三池崇史監督「AIと共に最高の映画を作る会」キックオフイベント開催</title><link>https://ledge.ai/articles/miike_ai_movie_project</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月2日、地方創生やイノベーションをテーマに前橋市で開催された「UPDATE EARTH2024@前橋」にて、映画監督・三池崇史氏のプロジェクト「AIと共に最高の映画を作る会」のキックオフイベントが{target=“_blank”}された。

株式会社AI-Actsが、2023年12月27日から2024年2月19日の期間、同プロジェクトに向け、AI映画への出演者オーディション、AI映画制作スタッフ向けのAI技術コンテスト参加者を{target=“_blank”}していた。

!
:::small
画像の出典：{target=“_blank”}
:::

三池監督は「私たちは今、AIの正体を掴めず、"怯えて暮らす"のか、"活用して生きていく"のか、その岐路に立っている。そこで、AIと共に新たな映画を創り出すことに挑戦する仲間を募る」と述べ、AI映画への出演者向けのオーディションとAI映画制作スタッフ向けのAI技術コンテストを開催することで、映画制作の新たな地平を開くことを目指しているという。

イベント当日は、監督の三池崇史氏とデジタルコンテンツプロデューサーの小畑正好氏が登壇し、監督の本プロジェクトへの想いや、小畑氏によるAI技術進化の紹介などが行われた。

また、AI映画出演者の最終オーディションと結果発表、AI映画制作スタッフによるAI技術の実演とデモンストレーションの紹介、オーディションとコンテストのノミネート作品の発表と、動画の展示、その他、本プロジェクト参加メンバーによる交流会などが行われたとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Fri, 08 Mar 2024 07:03:08 +0000</pubDate></item><item><title>ウィル・スミス「これは手に負えなくなってきた！」1年前にAIで生成された不気味な動画を実写で完全再現し笑い飛ばす　OpenAIもSoraで便乗</title><link>https://ledge.ai/articles/wil_smith_is_really_eating_spaghetti</link><description>:::small
画像の出典：{target=“_blank”}
:::

俳優のウィル・スミス氏が2024年2月20日、自身のSNS公式アカウントで「これは手に負えなくなってきた！」というコメントと共に、1年前に話題となったAI生成動画を{target=“_blank”}を撮影・投稿した。この投稿に対しファンは「このビデオがAIではないことに気付くのに1分はかかった」「まさか実写版を見るとは思わなかった（笑）」などとコメントを投稿。

元になった動画は、2023年4月にRedditに投稿され賛否両論を呼んだ「パスタを食べるウィル・スミス」というAIによって生成された動画だ。直感的に不快感を呼ぶ動画が生み出されたことや、それが人間の純粋な悪意によって拡散される様を「悪魔的」と表現するX（旧Twitter）ユーザーもいたほどだ。この現象は、{target=“_blank”}にも取り上げられた。

2月15日にOpenAIが発表したSoraの動画生成能力に世界が熱狂し、ふたたびこの動画が掘り起こされることとなった。これを受けウィル・スミス氏が、「1年前のAI生成動画」VS「現在のAI生成動画」と皮肉って、ユーモアたっぷりにこの動画を投稿した。AIによって引き出される不気味さや人の悪意を、コメディの力で笑い飛ばした人間の完全勝利の瞬間ではないだろうか。

この動画が投稿された数日後、OpenAIはSoraで「ウィル・スミスを食べるスパゲッティ」という動画とプロンプトを公開している。

@

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 01 Mar 2024 05:43:24 +0000</pubDate></item></channel></rss>