<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.aiビジネスカテゴリ</title><link>https://ledge.ai/categories/business/</link><description>Ledge.aiのビジネスカテゴリの最新記事</description><language>ja</language><lastBuildDate>Wed, 30 Aug 2023 10:54:10 +0000</lastBuildDate><item><title>MicrosoftがAIを攻撃する専門組織「AIレッドチーム」ノウハウも公開 他社にも設立呼びかけ</title><link>https://ledge.ai/articles/microsoft_ai_red_team</link><description>:::small
画像はSDXL1.0によりLedge.aiが生成
:::
米国Microsoft は2023年8月7日、公式ブログで「AIレッドチーム」の実践に関する知見を{target=“_blank”}した。自社のAIをあえて攻撃する組織を作り上げ、セキュリティ上の弱点を見つけ出す取り組みだ。

サイバーセキュリティの世界ではシステムの防御役「Blue Team（ブルーチーム）」とは別に攻撃役「Red Team（レッドチーム）」を作り、模擬的に戦わせることで弱点を見つけ、本当の攻撃がある前に対策をとる手法が広がっている。

Microsoftは2018年から「AIレッドチーム」を動かし、自社のAIなどの弱点を探っている。例えば生成AI検索「Bing AI Chat（新しいBing）」の公開前に、Microsoft社内の数十人のセキュリティと責任あるAI（Responsible AI、RAI）の専門家でAIレッドチームを作り、何百時間にもわたって調査をした。このような場合にはBing AI Chatのようなアプリケーションと、背後で動く大規模言語モデル（LLM）「GPT-4」の両方を標的に2段階で取り組む必要があるという。

まずGPT-4に攻撃をしかけることで弱点や限界を見つけることは、GPT-4そのものの将来の改良に役立つだけでなく、どんなアプリに適しているのかを把握する上でも有益だった。Bing AI Chatへの攻撃ではGPT-4を検索に組み込んでも障害が起きないかを確認できた。

今回Microsoftは経験を活かし、AIレッドチームが従来のレッドチームとどこが似ていて、どこが異なるのかをセキュリティ専門家向けに説明。より多くの組織がAIレッドチームを作り、さらに既存のレッドチームをよりうまく活用できるようにする参考として、5つの知見を紹介している。

!

**１．AIレッドチームの役目はより広範囲:**
AIレッドチームは従来のレッドチームと異なりセキュリティ脆弱性だけでなく、RAI問題を取り扱わねばならない。AIが示すさまざまな固定観念など公平性の問題や、暴力の賛美をはじめとする有害な情報についても調査する必要がある。

**２．AIレッドチームは悪意の人物だけでなく善意の人物が引き起こす問題にも注目する:**
例えば新しいBingでは、悪意の人物がセキュリティに焦点を当てた技術や不正なプログラムでAIを破壊する可能性だけでなく、いかに一般人がAIとの対話で有害な情報を生成するかにも注目せねばならなかった。この点が悪意の人物の行動のみに注目する従来のレッドチームとは異なる。AIレッドチームでは、より広範なペルソナ（想定する人物像）を対象にする。

**３．AIは絶えず進化している:**
AI常に変化する。LLMの場合、開発者はフィードバックに基づいてメタプロンプト（機械学習モデルへの基礎となる命令）を変更することがある。伝統的なソフトウェア・システムに比べAIは急速に変化するため、AIレッドチームは攻撃を繰り返し仕掛け、体系的で自動化した測定システムを確立し、時間をかけて監視することが重要。

**４．生成AIに対しては複数回の試行が必要:**
生成AIのふるまいは確率によって決まり、同じ入力を複数回実行すると、異なる出力が得られる可能性がある。AIレッドチームも同じ操作で複数回の攻撃を実施する必要がある。初回の攻撃が失敗しても、次回以降の同じ攻撃が成功してしまう場合を考慮せねばならない。攻撃に対する結果が決定的になる従来のレッドチームとの違いだ。

**５．AIの問題を緩和するには多層防御が必要:**
AIに起こる問題を緩和するためには、単一の方法ではなく複数の手段を組み合わせる必要がある。潜在的に有害な情報に目印をつけておくためにAIの「分類器（Classifier）」を使用することや、人間との対話が危険な方向へずれてゆかないよう「メタプロンプト」を使用して行動を誘導することを含む。多層防御が重要という点については、既存のレッドチームと似通う。

:::box

:::
:::box

:::
</description><pubDate>Wed, 30 Aug 2023 10:54:10 +0000</pubDate></item><item><title>渦中のAP通信「生成AIを記事執筆に使用しない」ガイドライン公表 ただしOpenAIとは協力</title><link>https://ledge.ai/articles/ap_standards_around_generative_ai</link><description>米国AP通信は2023年8月16日、{target=“_blank”}を公表した。生成AIを記事執筆には使用しないとあらためて明言した。同社は7月に対話型AI（チャットボット）「ChatGPT」を開発するOpenAIとライセンス契約を結んで注目を浴びたところ。

APは公式ブログで「我々は、報道における正確性、公平性、迅速性を重視しており、AIを注意深く使用することでその価値を向上でき、働き方にも貢献できると考えている」と前置きした。

そのうえで「AP通信のジャーナリストの中心的な役割は変わらず、AIがその代替になり得るとは考えない。ジャーナリストは、共有する情報の正確性と公平性について責任を負わねばならない」と述べた。

APとOpenAIが結んだライセンス契約では、OpenAIがAPのテキストアーカイブの一部に対する使用許諾を得て、APはOpenAIの技術と製品の専門知識を活用できる。しかし、APは公開する記事などの作成に生成AIは使用しない。

またAIが生成する内容は未確認の情報源として扱うとし、公開時にはAPの編集上の判断と情報源に関する基準を適用する。AIで写真、動画、音声の要素を改変しないこと、AIが虚偽を描写したと疑いうるあるいはそう証明済みのA画像も配信しないことを明確にした。

ただし、ただしAIが生成したイラストや芸術作品が記事の主題になる場合、その旨を明記している限り使用できるとした。

APは社内の記者たちに、機密情報や機微情報をAIに入力しないよう強く求めている。また、外部から受け取った素材についてはAIが生成したものをを含んでいないか確認するよう注意を促しているという。素材の出典を確認したり、逆画像検索を行ったり、信頼できる報道機関で類似の素材を使用していないか確認を怠らないこと、また資料の信憑性に疑念がある場合は使用しないよう求めているとのこと。

:::box

:::
:::box

:::</description><pubDate>Wed, 30 Aug 2023 02:16:51 +0000</pubDate></item><item><title>Naver 独自の大規模言語モデル「Hyper CLOVA X」発表 チャットボットやAI検索も</title><link>https://ledge.ai/articles/hyper_clova_x</link><description>韓国Naverは2023年8月24日、ソウル市で生成AI技術と事業戦略を中心としたカンファレンス「DAN 23」を開催した。のチェ・スヨン代表が、大規模言語モデル（LLM）「{target=“_blank”} X」、対話型AI（チャットボット）「{target=“_blank”}」、生成AI検索「CUE」の3つの{target=“_blank”}した。

このうちCLOVA Xは創作、要約、推論、翻訳、コーディングなどをベースに多様な回答を提供できる対話型AIで、質問と回答を連続して続けられる。Naver内外の様々なサービスをアプリケーション・プログラミング・インターフェイス（API）でつなぐ「スキル」機能を導入し、LLMだけでは限界がある回答を補完してゆくことが可能。NaverはもちろんLINEやFacebookのアカウントで利用登録を受け付けている。

なおNaverは60万台以上のサーバーを収容でき、単一企業としてはアジア最大規模をうたうデータセンターを11月に世宗（セジョン）特別自治市で開設予定だとも明らかにした。

:::box

:::
:::box

:::</description><pubDate>Wed, 30 Aug 2023 08:46:05 +0000</pubDate></item><item><title>Googleいよいよ検索に生成AIを導入 日本でも「SGE」試験運用開始</title><link>https://ledge.ai/articles/google_releases_sge_japanese_version</link><description>米国Googleは生成AIを組み込んだ検索サービス「Search Generative Experience（SGE）」の日本語版を試験運用開始したと、2023年8月30日にした。検索技術の研究組織「Search Labs」の公式サイトでGoogleアカウントを使って登録を済ませると、数日中にパソコン向けWebブラウザ「Chrome」またはiPhoneやAndroidスマートフォン向けの「Google」アプリケーションから利用できるようになる。なお即座に使える場合もある。

GoogleのSGEは5月から米国などで始まり、順次機能の拡充が進んできた。すでに米国Microsoftの生成AI検索「Bing AI Chat（あるいは新しいBing）」が2月に登場し、日本語に対応していることを考えると慎重な動きだった。

新たに試験運用を開始したSGEの日本語版では例えば「残暑見舞いはいつ頃送る? 」という質問をすると、「残暑見舞いは、立秋（8月7日）から8月末頃までの間に送るのが一般的です」といった回答があらわれる。検索の結果見つかった複数のWebサイトの情報をAIが簡潔にまとめた概要だ。表示を切り替えれば概要のどの部分どのWebサイトの情報に基づくのかを参照できる。概要の下には通常の検索結果が続く。

!

さらに「残暑見舞いに何を送ったら喜ばれますか？」「残暑見舞いのマナーは？」といった続く質問の候補も一覧できる。気になった候補を選択すると対話形式で知りたい情報を掘り下げてゆける。候補の代わりに自分で考えた質問をすることも可能だ。いずれの場合はSGEは質問の流れを一定程度覚えているため、自然なかたちでやりとりを続けられる。

なおSGEはGoogleが開発した大規模言語モデル（LLM）を採用しているが、性能に限界があるため検索が常に正しく機能するとはいえず、今後さらに更新予定。当面、検索結果では常にAIがまとめた概要を表示するのではなく、特定の質問だけにとどまるという。このほかSGEも専用枠に広告を表示するが、ほかの部分と区別できるように「スポンサー」と明記する。

:::box

:::
:::box

:::</description><pubDate>Wed, 30 Aug 2023 07:30:48 +0000</pubDate></item><item><title>NVIDIA 純利益9倍・売上高2倍で過去最高 生成AI需要増で 第2四半期決算
</title><link>https://ledge.ai/articles/nvidia_settlement</link><description>米国NVIDIAは2023年8月23日に、2024年度第2四半期（2023年5月～7月）決算を{target=“_blank”}した。生成AIの開発競争が激化しており、AI向け半導体製品の需要が拡大。売上高、純利益とも過去最高を更新した。

売上高は過去最高の135億1,000万ドルで、第1四半期比で88%、前年同期比で101%増加。またデータセンターの売上高は103億2,000万ドルを記録、第1四半期比で141%、前年同期比で171% 増加した。

米国会計基準（GAAP）にもとづく希薄化後1株当たり純利益は2.48ドルで、第1四半期比202％増、前年同期比854％増。 非GAAP基準の希薄化後1株当たり純利益は2.70ドルで、第1四半期比148%増、前年同期比429%増となった。

同社の Jensen Huang（ジェンセン・ファン）創業者兼最高経営責任者（CEO）は「当四半期中、大手クラウドサービスプロバイダーは大規模なNVIDIA H100 AI インフラストラクチャを発表した。大手エンタープライズ ITシステムおよびソフトウェアプロバイダーはNVIDIA AIをあらゆる業界に提供するためのパートナーシップを発表した。生成型AIの導入競争は続いている」と述べている。

:::box

:::
:::box

:::
</description><pubDate>Wed, 30 Aug 2023 01:55:25 +0000</pubDate></item><item><title>MicrosoftはAIを使った人のデータを監視 新規約に明記</title><link>https://ledge.ai/articles/microsoft_terms_revision</link><description>:::small

:::

 米国Microsoftがサービス規約の最新版を2023年7月30日に{target=“_blank”}した。同社の消費者向け製品、Webサイト、サービスを使用する際に適用となるもので、これまで記載のなかったAIサービスに関する文言が追加している。この規約の発効日は9月30日を予定している。
 
新設の「AI サービス」に関する項目では以下の5つを掲げている。

1つ目は「リバース エンジニアリング」。モデル、アルゴリズム、およびシステムの基盤となるコンポーネントを見つけるためにMicrosoftのAIサービスを使用することを禁じる。例えばモデルの「重み付け（weight）」を調べて削除しようとしてはならない、としている。

2つ目は「データの抽出」。明示的な許可のある場合を除いて、MicrosoftのAIサービスに対しWebスクレイピング、WebハーべスティングなどのWebデータ抽出方法を使用することを禁じる。

3つ目は「AIサービスからのデータ使用に対する制限」。MicrosoftのAIサービスやそのデータを使用して、ほかのAIサービスを直接と間接問わず作成、訓練または改善することを禁じる。

4つ目は「お客様のコンテンツの使用」。Microsoftは不正または有害な使用や出力を監視、防止する目的で、AIサービスへの入力とAIサービスからの出力を処理し、保存する。

5つ目は「第三者の申し立て」。例えば利用者がAIサービスで出力した内容について、第三者から著作権侵害などの申し立てがあった場合、責任はMicrosoftではなく利用者自身が単独で負うとしている。なお著作権関連に限定しない法令が対象とのこと。


:::box

:::
:::box

:::


</description><pubDate>Tue, 29 Aug 2023 07:16:37 +0000</pubDate></item><item><title>ChatGPTの法人版「ChatGPT Enterprise」登場 高速GPT-4を無制限に利用可 入力内容は学習に使用せず</title><link>https://ledge.ai/articles/chatgpt_enterprise</link><description>:::small
画像出典：OpenAI
:::
米国OpenAIは、2023年8月28日に対話型AI（チャットボット）「ChatGPT」の法人版「ChatGPT Enterprise」の{target=“_blank”}した。セキュリティとプライバシーの保護水準が高く、入力したデータやプロンプト（文章による指示）をAIの学習に使わない仕様という。米国公認会計士協会のセキュリティ統制基準「SOC 2」にも準拠し、全ての会話を送受信や保存時に暗号化する。

{target=“_blank”}ではまた、OpenAI最新の大規模言語モデル（LLM）「GPT-4」を無制限に利用できる。3万2,000トークン（語彙）の入力を一度に行える。通常版の4倍の長さの文章やファイルをより効率よく処理可能。動作速度も最大2倍に向上している。

これに加え通常版で「コードインタープリター」という名称で導入していたデータ解析機能も無制限に利用できる。市場データを処理する金融研究者、調査結果を解析するマーケティング担当者、データの抽出・変換・書き出し（ETL）用簡易プログラムを調整するデータ サイエンティストなどが数秒で作業を終えられるとのこと。

さらに、組織の必要に応じてChatGPTをカスタマイズ可能。テンプレートを活用し、共同作業や特定のワークフローを構築することが手軽になる。完全なカスタマイズを求める場合、ChatGPTの機能を外部から呼び出すためのアプリケーション・プログラミング・インターフェイス（API）の無料クレジットも利用できる。

なお公式サイトでは「ChatGPT Enterprise」の料金体系を掲載しておらず、OpenAIの営業部門に直接問い合わせるよう案内している。

:::box

:::
:::box

:::
</description><pubDate>Tue, 29 Aug 2023 06:53:13 +0000</pubDate></item><item><title>Zoom 顧客の映像や音声をAI学習に使用の恐れ 批判受け1週間で2度規約改訂</title><link>https://ledge.ai/articles/zoom_updated_terms_of_service_twice_in_a_week</link><description>2023年8月6日に、ビデオ会議アプリケーション「Zoom」の新{target=“_blank”}に関し「利用者のデータをAIの学習に利用できることになっている」と報じたStackDiaryの{target=“_blank”}について、米国の複数メディアが取り上げた。インターネット上の騒然とした反応を受けて開発元の米国Zoom Video Communicationsは1週間で2度にわたり規約を改訂する事態となった。

焦点となったのは、最初に報道があった時点の規約のセクション10.2と10.4。Zoomが利用者のデータ、特にビデオ会議などによって残る「サービス生成データ」の利用に関する広範な権利を持つことを示し、AIや機械学習（ML）といった用途にも言及していた。

Zoomはすでに規約の該当部分を変更したものの、内容についてはさまざまなWebサイトの過去の情報を保存する「{target=“_blank”}」などから確認可能だ。該当部分は3月から8月初旬まで存在したことがわかる。

Zoomは8月7日に事態に対応するため1度目の規約改訂を実施。Eric Yuan（エリック・ユアン）創業者兼最高経営責任者（CEO）は8日にSNS「LinkedIn」で、利用者のデータを同意なくAI学習に使用しないとし、製品を改善しAIを訓練するためのコンテンツの共有についてオプトイン（事前承認）を求めるようになっていることが操作画面から確認できると{target=“_blank”}。

しかし以降も事態は収束せず、8月11日の2度目の規約改訂で、Zoomはデータ使用慣行を明確にし、AIの訓練に会議の音声、動画、チャットなどの内容を使用しないことを強調した。

StackDiaryのAlex Ivanovs氏は、今回の事態は当初から起こるべきではなかったと指摘。AIの学習にデータを使用する場合、事前の告知はもちろんオプトアウト（事後不承認）の選択肢は必須との立場を示した。

:::box

:::
:::box

:::</description><pubDate>Mon, 28 Aug 2023 08:50:55 +0000</pubDate></item><item><title>Meta 声を吹き込むと翻訳するAI「SeamlessM4T」日本語など100言語対応 人間のような「空耳」で誤訳も</title><link>https://ledge.ai/articles/meta_seamless_m4t</link><description>:::small
画像出典：seamless.metademolab.com
:::
Metaは2023年8月22日、音声を入力することで「文字起こし」「別言語への翻訳」「別言語への吹き替え」を実行するAI「{target=“_blank”}」を発表した。日本語を含む多言語に対応する。実際にデモを試すと話した内容の大意を自然なかたちで指定の言語に翻訳し、読み上げるが、人間のような「空耳」や訳し間違いもするようだ。

同AIでは以下のことが可能だ。

・約100種類の言語の音声認識
・約100種類の言語の音声からテキストへの翻訳
・約100種類の言語の音声から英語を含む36種類の言語の音声への翻訳
・約100種類の言語のテキストからテキストへの翻訳
・約100種類の言語のテキストから英語を含む35種類の言語の音声への翻訳

SeamlessM4Tはオープンサイエンスの考えにより、研究ライセンスのもと公開されており、研究者や開発者が該当の技術を活用できる。さらに史上最大というオープンマルチモーダル翻訳データセット「SeamlessAlign」のメタデータも公開された。マイニングによる合計27万時間の音声とテキストのデータで構成されている。

Metaによると、往年のSF小説『銀河ヒッチハイク ガイド』に登場する「Babel Fish（バベル フィッシュ）」のような世界規模の翻訳機の構築はまだ困難。音声から音声、音声からテキストへの翻訳の仕組みがまだ世界の言語の一部にしか対応していないためだ。SeamlessM4Tはそのような問題点の克服、エラーや遅延の減少、翻訳の効率と品質の向上が目標として掲げられている。

今回の技術は、2022年に公開された200の言語に対応する機械翻訳モデル「No Language Left Behind（NLLB）」や、文字体系のない言語である福建語の音声ー音声翻訳システム「Universal Speech Translator」、1,100種類以上の言語の音声認識、言語識別、音声合成を行う研究用モデル「Massively Multilingual Speech」などの実績にもとづく。

なおSeamlessM4Tは{target=“_blank”}が公開されている。実際に機能を試してみると、例えば「私は犬を飼っています。将来的には猫とインコも飼いたいです」と音声入力した場合、前半部分が「私は犬を買っています」と訳された。あらためて「私は犬を飼育しています。将来的には猫とインコも飼育したいです」と入力し、英語・韓国語・ポルトガル語を選択すると、以下画像のような結果が出た。
!
:::small
画像出典：seamless.metademolab.com
:::
「インコ」が「monkey」と訳された。なお吹き替え音声は、再生ボタンをクリックすれば再生できる。

:::box

:::
:::box

:::</description><pubDate>Mon, 28 Aug 2023 06:58:00 +0000</pubDate></item><item><title>VMWareとNVIDIA 生成AIをクラウドに置かず使える 「VMware Private AI Foundation with NVIDIA」</title><link>https://ledge.ai/articles/vmware_nvidia</link><description>米国VMwareはNVIDIAと協力し、生成AIをクラウドに置かなくても構築、運用できる基盤として「{target=“_blank”}」を投入する。2023年8月22日に年次イベント「VMware Explore 2023 Las Vegas」で明らかにした。

VMware Private AI Foundation with NVIDIAは、オンプレミス環境をクラウド環境のように運用できるソフトウエア定義データセンター（SDDC）基盤「VMware Cloud Foundation」とAI開発環境「NVIDIA AI Enterprise」を統合したもの。米国Metaがオープンソースで公開した「Llama 2」をはじめとする大規模言語モデル（LLM）などを企業の社内データで訓練し、データセンターはもちろん主要なパブリッククラウド、そしてエッジ環境に設置できる。

用途はチャットボット、アシスタント、検索、要約などの生成AIアプリケーションを想定している。Dell Technologies、Hewlett Packard Enterprise、Lenovoの製品が対応するという。

「VMware Private AI Reference Architecture for Open Source」も同時に発表した。こちらはオープンソースソフトウェア（OSS）でモデルを構築してVMware Cloud Foundation上で運用できるというものだ。

:::box

:::</description><pubDate>Fri, 25 Aug 2023 12:02:47 +0000</pubDate></item><item><title>Google 大規模言語モデルに「視覚」を与える メルカリと開発した商品画像検索AIも公開</title><link>https://ledge.ai/articles/google_vlm</link><description>「もし大規模言語モデルが画像の意味を理解する視覚を持っていたらどうだろうか？」。米国Googleは2023年8月22日、{target=“_blank”}で問いかけた。答え合わせをするように同社が開発した視覚言語モデル（Vision Language Model：VLM）と、それを生かしてメルカリと共同開発した商品画像検索AIも紹介している。

## 商品の画像を「見て」検索するAI
Googleとメルカリの米国版が共同開発した商品画像検索AIについてはの通りだが、このほど誰でも機能を体験できる{target=“_blank”}も登場した。

試したい場合はまず「MERCARI TEXT-TO-IMAGE」を選択し、例えば「handmade accessories with black and white beads（黒と白のビーズを使ったハンドメイドアクセサリー）」といった具合に、自然な文章で探しているものの情報を入力する。日本語も利用できるが、英語の方が精度が高い。

入力を終えると即座に検索結果があらわれ、関連した商品が画像付きでずらりと並ぶ。商品名や説明文、タグは一切使用せず、VLMが文章と画像の情報を照らし合わせているという。

!

!

企業がクラウドサービス上でAIの訓練や利用を行えるGoogle Cloudの機械学習基盤「Vertex AI」で8月初旬に一般公開が始まった新機能「Vertex AI Multimodal Embeddings」の先行導入事例だ。

この新機能はGoogle Researchが開発した「Contrastive Captioner（CoCa）」というVLMを組み込んでいて、複数の異なる種類の情報を処理する、いわゆる「マルチモーダル」AIを実現できるようになっている。

今回はメルカリの商品画像580万点をVertex AI Multimodal Embeddingsに渡して「埋め込み（ Embeddings）」つまりAIにとって処理しやすいベクトル情報を抽出し、検索する際の索引として利用できるようにしてある。デモで文章を入力するとVLMがベクトル情報を抽出し、先に画像から抽出したベクトル情報と照らし合わせる。

## VLMはどう社会を変えるか
深層学習技術では文章からも画像からもベクトル情報を抽出できるので、両者の関係を学習させれば、VLMは文章から画像（text-to-image）を、あるいは画像から文章（image-to-text）を自在に検索できる。

あらかじめ画像に対してタグやラベルをつけておかなくてもよく、従来の光学文字認識（OCR）も不要。色々な分野に応用のきく便利な仕組みだ。

例えばメルカリのようなアプリで、誰かが販売したい商品の画像を投稿したとする。するとVLMが同じカテゴリやブランド、類似した色やスタイルの既存の商品を検索し、見つけた情報に基づいて商品名、説明、販売価格を提案する。情報をいちいち手動で入力する手間が省ける。

また数千台の監視カメラを設置している施設を考えてみる。毎分何百万もの画像を記録していても、VLMさえあれば「ドアを開けようとしている人」「工場が浸水している」「機械が燃えている」などの自然な文章で条件にあった画像を探し出せる。

!
さらに自動運転技術の開発にも役に立つ。クルマを制御するAIは、運転中に遭遇する不測の事態にどう対処するかを学習せねばならない。事故などに関する写真や動画そのものはすでに大量に蓄積しているが、必ずしもタグやラベルをつけて整理しておらず、そのままでは使用しづらい。だがVLMがあれば「赤信号が点灯している交差点で歩行者が立っている」や「前方の高速道路の真ん中で停止している潰れた車」などの複雑な条件を自然な言語で指定して一致する画像を見つけられる。

LLMの使い道はもはや単なるチャットボットにとどまらず、「視覚」を与えればさまざまな事業で活かせるという示唆だ。

:::box

:::
:::box

:::</description><pubDate>Fri, 25 Aug 2023 16:09:59 +0000</pubDate></item><item><title>OpenAIが「GPT-3.5 Turbo」のファインチューニングに対応 「GPT-4」は今秋にも
</title><link>https://ledge.ai/articles/gpt_finetuning</link><description>:::small
画像出典：OpenAI
:::
米国OpenAIは2023年8月23日、対話型AI（チャットボット）「ChatGPT」などが採用する大規模言語モデル（LLM）「GPT-3.5 Turbo（gpt-3.5-turbo-0613）」が{target=“_blank”}に対応したと発表した。外部のアプリケーションからgpt-3.5-turbo-0613の機能を利用する際、従量課金で目的に合わせたカスタマイズができるようになる。最新版LLM「GPT-4」も同年秋に対応予定だ。

まずLLMの機能を外部から呼び出すアプリケーションプログラミングインターフェイス（API）を通じて学習データの準備とアップロードを行い、新たなモデルを訓練し、しかるのち利用を開始する、という流れ。

利点としては例えば次のようなものがある。ChatGPTは英語の文献を多く学習しているため、別の言語で質問をしても英語で回答する場合があるが、企業の社内チャットボットなどで微調整済みのgpt-3.5-turbo-0613を利用すれば、英語以外の言語で質問した際に同じ言語で回答させられる。

またChatGPTの回答は定まった形式がないが、微調整したgpt-3.5-turbo-0613を利用すれば同じ型を守らせられるようになる。企業ごとのブランドに合わせた言葉選びをさせることも可能だ。また文章による指示「プロンプト」をより簡略にし、処理する文中の語彙「トークン」の数を節約できるので、回答の速度を上げられる。OpenAIのサービスはトークンごとに料金が発生するため、コストを下げる効果も見込める。

なお微調整はプロンプトの書き方を工夫する「プロンプトエンジニアリング」、情報検索（IR）、関数呼び出しなどの手法と組み合わせられる。微調整と関数呼び出しの組み合わせは今秋後半から対応予定。

gpt-3.5-turbo-0613が1度に処理できる語彙は4,000トークンだが、より長い1万6,000トークンを処理できる「gpt-3.5-turbo-16k」の微調整も今秋後半からできるようになる見込み。

gpt-3.5-turbo-0613の微調整にかかる料金は1,000トークンあたり学習が0.008ドル、入力が0.012ドル、出力が0.016ドル。

ちなみに従来の「GPT-3」をもとにしたモデル「ada」「babbage」「curie」「davinci」は 2024年1月4日に終了するが、代替として今回新たに「babbage-002」と「davinci-002」も利用可能になった。微調整も行える。

babbage-002の料金は1,000トークンあたり通常の入力と出力がそれぞれ0.0004ドル。微調整は訓練が0.0004ドルで、入力と出力が0.016ドル。


davinci-002の料金は1,000トークンあたり通常の入力と出力が0.002ドル。微調整は訓練が0.006ドルで、入力と出力が0.012ドル。




:::box

:::
:::box

:::
</description><pubDate>Fri, 25 Aug 2023 06:36:51 +0000</pubDate></item></channel></rss>