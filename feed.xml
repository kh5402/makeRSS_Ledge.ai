<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Fri, 09 Aug 2024 12:12:07 +0000</lastBuildDate><item><title>OpenAIと提携のFigure、新型ヒューマノイドロボット「Figure 02」を発表—　BMWとの自動車製造の実用化に向けたテストにも成功</title><link>https://ledge.ai/articles/figure02</link><description>:::small
画像の出典：{target=“_blank”}
:::

カリフォルニアを拠点とするロボット開発企業 Figureは2024年8月6日、最新のヒューマノイドロボット「Figure 02」を{target=“_blank”}した。前モデル「Figure 01」と比較して大幅な技術的進化を遂げており、特にAI性能と自律作業能力が強化されているという。
## Figure 02の技術的進化と設計
Figure 02は、NVIDIAの最先端GPU技術を活用し、リアルタイムでのAI推論を可能にする3倍の計算能力を搭載している。これにより、製造業や物流などの現場で、複雑なタスクを完全自律的に実行できるようになった。ロボットには6台のRGBカメラと改良された人間型の手が搭載されており、16の自由度を持つ手は、最大25kgまでの重量物を精密に操作可能とのこと。

さらに、Figure 02にはOpenAIとの提携により、人間と自然な会話が可能な音声認識システムが組み込まれている。この機能は、労働力不足が深刻化する産業界で特に期待されており、Figureは今後、消費者向けバージョンの開発も視野に入れている。

@



## BMWとの実用化テスト
{target=“_blank”}は、サウスカロライナ州スパータンバーグの工場で、Figure 02を用いたテストを実施した。このテストでは、ロボットが車体の組み立て工程で金属パーツを正確に配置することに成功し、製造ラインでの実用性が確認できたという。

BMWの生産担当役員であるミラン・ネデリコビッチ氏は、「我々は早期テストを通じて、ヒューマノイドロボットの製造業への応用可能性を評価している」とコメントしており、今後の技術開発と産業化に向けた取り組みを強化していく方針を示した。


Figure 02は、単なる試作機を超えた商業利用可能なヒューマノイドロボットとして、製造業や物流業界など多岐にわたる分野での実用化が期待されている。Figure社は引き続き技術開発を進め、労働力不足の解消と産業の効率化に向けたソリューションを提供することを目指している。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 09 Aug 2024 08:09:08 +0000</pubDate></item><item><title>世界初 AI駆動の全自動ロボット歯科医による虫歯治療が成功ーーボストンのPerceptive社</title><link>https://ledge.ai/articles/perceptive_automated_robotic_dentist</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月30日、ボストンを拠点とするPerceptive社が開発したAI制御の自律型ロボットが、世界で初めて完全自動の歯科治療を人間に対して成功させたことを{target=“_blank”}した。

このロボット歯科医療システムは、光干渉断層撮影（OCT）技術を用いたハンドヘルド型スキャナーで患者の口腔内を3Dスキャンし、歯茎の下や歯の内部の構造を詳細に捉える。得られた3Dデータは、AIアルゴリズムによって分析され、治療計画が自動的に立案される。その後、ロボットアームが正確な操作を行い、例えばクラウンの装着といった治療を従来の2時間以上に及ぶ工程からわずか15分に短縮するという。

この技術は、X線を使用せずに90%以上の精度で虫歯を検出できることから、患者の安全性を高め、診断の精度を向上させる。また、患者の動きが多い状況でも安全に治療を行えるように設計されており、患者の快適性も向上させるという。

同社のCEOであるDr. Chris Ciriello氏は、この技術が「歯科治療の精度と効率を飛躍的に向上させ、より多くの患者に質の高いケアを提供する」と述べ、今後のさらなる発展に意欲を示している。現時点ではこのシステムはまだプロトタイプ段階であり、FDA（米国食品医薬品局）の承認を待っている状況とのこと。

:::box

:::
:::box

:::
</description><pubDate>Fri, 09 Aug 2024 07:22:41 +0000</pubDate></item><item><title>バイトダンス、「Jimeng AI」でAI分野に本格参入　テキストから画像と動画を両方生成できるアプリを公開</title><link>https://ledge.ai/articles/jimeng_ai_release</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年8月6日、字節跳動（バイトダンス）が短編動画アプリ「TikTok」に続き、新たなサービス「Jimeng AI」でAI分野へ本格参入するとロイターが{target=“_blank”}。

バイトダンス傘下のFaceu Technologyが開発した「Jimeng AI」は、ユーザーが簡単なテキストを入力するだけで、リアルで高品質な画像や動画を生成できる。このアプリは、現在中国のApp Storeで利用可能となっている。

「Jimeng AI」の大きな特徴の一つは、テキストから画像と動画の両方を生成できる点にある。これは、OpenAIの「DALL・E3」などの競合サービスと比較をしても差別化された機能だ。ダウンロードは無料だが、利用料金に関しては月額69元（約1400円）または、年額659元（約13400円）のサブスクリプションプランが提供されている。プランに加入することにより、毎月約2050枚の画像、もしくは168本の動画を生成することができるとのこと。

:::box

:::

:::box

:::

:::box

:::
</description><pubDate>Fri, 09 Aug 2024 12:12:07 +0000</pubDate></item><item><title>JAPAN AI　マーケティング特化型AI「JAPAN AI MARKETING(™)」の日本人画像生成機能を正式版にアップデート</title><link>https://ledge.ai/articles/japan_ai_marketing_official_ver_release</link><description>:::small
画像の出典：{target=“_blank”}
:::

JAPAN AI株式会社は2024年8月1日、自社が提供するマーケティング特化型AIサービス「JAPAN AI MARKETING(™)」において、日本人の特徴を忠実に捉えた人物画像を生成する機能の正式版をリリースしたことを{target=“_blank”}した。

近年、生成AI技術の進化が企業の広告クリエイティブや販促物制作の現場で注目を集めている。しかし、従来のAIモデルではプロンプトに「日本人」と指示をしても、期待通りの日本人の特徴を持つ画像を生成することが困難だった。この点が生成AI活用における課題となっていたという。これを受け、JAPAN AIは2024年6月に「JAPAN AI MARKETING(™)」の日本人画像生成機能の{target=“_blank”}し、今回、さらに自然で精度の高い日本人画像を生成できる正式版をリリースした。

JAPAN AIは、今後も独自のAIモデルを通じて日本市場に特化したマーケティングやコンテンツ制作におけるイノベーションを推進していき、今回のリリースを皮切りに、継続的な機能拡張と性能向上を目指していくとしている。

:::box

:::
:::box

:::

:::box

:::

</description><pubDate>Thu, 08 Aug 2024 09:48:22 +0000</pubDate></item><item><title>電通、コピーライターの思考プロセスを学習したAIツール「AICO2」とAI戦略「AI For Growth」を発表 – 人間とAIの協働</title><link>https://ledge.ai/articles/dentsu_japan_aico2_ai-for-growth</link><description>:::small
画像の出典：{target=“_blank”}
:::

電通は2024年8月5日、次世代AI広告コピー生成ツール「{target=“_blank”}」を発表するとともに、新たなAI戦略「{target=“_blank”}」を公開した。
## AI広告コピー生成ツール「AICO2」
「AICO2」は、電通が長年培ってきたコピーライターの思考プロセスをAIに学習させ、心に響く広告コピーを自動生成するツールだという。ツールには、GPT-3.5 Turboモデルを実装。過去の膨大なコピー実績を基にファインチューニングしているとのこと。ユーザーが「伝えたいこと」や「商品名」を入力すると、それに基づいた高品質なコピーを生成し、その過程や理由も明示されるという。

!
:::small
画像の出典：{target=“_blank”}
:::

「AICO2」には自動採点機能が搭載されており、質の高いコピーのみを出力することが可能だという。これにより、人間のコピーライターがより創造的な作業に集中できる環境が整う。同技術は特許出願中とのこと。

## AI戦略「AI For Growth」
!
:::small
画像の出典：{target=“_blank”}
:::

同日発表された「AI For Growth」は電通グループの新たなAI戦略で、AIと人間の知識を組み合わせることで、顧客企業や社会全体の成長を目指すビジョンを掲げている。この戦略は、3つの主要レイヤーと8つの領域にわたる取り組みを含んでいるという。

!
:::small
画像の出典：{target=“_blank”}
:::

**1. クライアントサービス：**  マーケティング支援やプロダクト開発をAIで強化し、広告コピー生成ツール「AICO2」や生成AI活用ソリューション「∞AIシリーズ」を提供

**2. AIアセット：**  データインフラの拡充、AI人材育成、技術研究を推進し、特に東京大学AIセンターとの共同研究が注目される

**3. コーポレート機能：**  AIガバナンスの整備や組織運営の最適化を進め、AIを安全かつ効果的に活用するためのガイドラインを整備


同戦略により、電通グループは単なるAIの効率化ツールとしてだけでなく、AIを人間の創造性を引き出すパートナーとして位置づけ、より高度なクリエイティビティと生産性の実現を目指すとのこと。


:::box

:::
:::box

:::
</description><pubDate>Thu, 08 Aug 2024 05:47:49 +0000</pubDate></item><item><title>ペライチ、参考にしたいURLを入力するだけでAIがホームページを自動生成する新機能を発表</title><link>https://ledge.ai/articles/peraichi_create_assistant</link><description>:::small
画像の出典：{target=“_blank”}
:::

株式会社ペライチは2024年8月5日、新たな機能「ペライチクリエイトアシスタント」を{target=“_blank”}した。この機能は、参考にしたいサイトのURLを入力するだけで、AIが最適なホームページを自動で生成するというもの。専門的なウェブデザインの知識がなくても、短時間でプロフェッショナルなウェブサイトを作成できるという。


!
:::small
画像の出典：{target=“_blank”}
:::

ホームページ制作の工数やリードタイムを大幅に削減し、特にSMB（中小企業）にとって大きな生産性向上の効果が期待されるという。例えば、大手ECモールのページを参考に自社のオンラインショップを作成したり、過去に作成した古いサイトを簡単に最適化してアップデートすることが可能になるとのこと。

この「ペライチクリエイトアシスタント」の開発には、Amazon Web Services（AWS）の技術支援が活用されており、同社の生成AI技術が導入されている。これにより、AIが自動的にデザインやコンテンツを生成し、制作にかかるコストと時間を大幅に削減可能となる。現在、無料モニターの募集も行っており、公式サイトから参加申し込みが可能だ。




:::box

:::
:::box

:::
</description><pubDate>Wed, 07 Aug 2024 08:02:09 +0000</pubDate></item><item><title>ニッポン放送　AI技術でパーソナリティの声をそのまま英語に変換　新ポッドキャストを2か国語で配信開始</title><link>https://ledge.ai/articles/nippon_broadcasting_starts_podcast_with_lingiine</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年8月1日、ニッポン放送はAI技術を用いて日本語音声を英語に変換し、ポッドキャスト番組を配信する新たな取り組みを{target=“_blank”}した。新番組『TOKYO MUSIC LAB ～今日から話せる音楽雑学～』において、同社が開発した多言語音声変換ツール「リングイイネ！」が活用されるという。

リングイイネ！は、日本語で話した内容を話者の声そのままに他言語へ翻訳できるAIツール。リスナーは同番組を日本語と英語のどちらかで楽しめるとのこと。初回は8月1日18時に配信開始。ニッポン放送 PODCAST STATIONほか、各種ポッドキャストアプリで配信される。

{target=“_blank”}によると、AIで日本語の音声を英語に翻訳した後いったん日本語に再翻訳し、文章を人の目で見比べて確認するという。翻訳システムは他社のものを使っているが、ニュアンスや主述、人名が違うことがあるため、再翻訳して比べた上で再び英語にしているとのこと。

ニッポン放送は、今後この修正作業の自動化を進めるとともに、リングイイネ！の商業化を検討しており、他のラジオ局への導入にも前向きに取り組むという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 07 Aug 2024 03:58:06 +0000</pubDate></item><item><title>Stable Diffusionの元開発者たちがAI企業「Black Forest Labs」を設立し、新たにオープンソースの画像生成AI「Flux」を発表</title><link>https://ledge.ai/articles/black_forest_labs_announces_flux</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年8月1日、画像生成AI「Stable Diffusion」の開発に携わった研究者チームが、新たなAI企業「{target=“_blank”}」を設立し、オープンソースの画像生成AIモデル「Flux」を{target=“_blank”}した。

Fluxは120億のパラメーターを持つ、現時点で最大規模のオープンソースの text-to-image モデルであり、これまでの業界標準を大きく超える性能を誇るという。

Black Forest Labsは、Stable Diffusionに続き、テキストから高品質な画像を生成する技術において新たなマイルストーンを打ち立てた。Fluxは、ユーザーの様々なニーズに応えるため、以下の3つのバリエーションが用意されている。

!
:::small
画像の出典：{target=“_blank”}
:::

**1.FLUX.1 [dev]：** 基本モデルで、非商用ライセンスのもとオープンソースとして提供される
**2. FLUX.1 [schnell]：** 基本モデルを10倍の速度で動作させる蒸留版。Apache 2ライセンスのもとで提供される
**3. FLUX.1 [pro]：** API経由でのみ利用可能なクローズドソース版

これらのモデルは、Hugging Faceやfal.aiといったプラットフォーム上で公開されており、ユーザーはこれらを自由に試すことができる。特にFLUX.1 [schnell]は、従来のモデルと比較して処理速度が2倍に向上しており、リアルタイムでの応用に適しているという。

Black Forest Labsの発表によると、Fluxは解像度の向上や人間の解剖学的精度の改善、プロンプトに対する高い忠実性など、多くの点で他のモデルを凌駕している。特に、同社が強調しているのは、MidjourneyやDALL-E 3などの他の主要な画像生成AIモデルを上回るパフォーマンスを実現したという点だ。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の発表は、Black Forest LabsがAndreessen Horowitzをはじめとする著名な投資家から総額3100万ドルの資金調達に成功した直後に行われたものであり、同社の技術的なリーダーシップと市場への影響力を示すものとなっている。



:::box

:::
:::box

:::
</description><pubDate>Wed, 07 Aug 2024 03:54:07 +0000</pubDate></item><item><title>米インターネット掲示板大手RedditのCEO「ブロックするのホントに面倒」と無断データ利用を批判　MicrosoftなどAI企業を名指し</title><link>https://ledge.ai/articles/reddit_huffman_it_has_been_a_real_pain_in_the_ass_to_block</link><description>:::small
画像の出典：{target=“_blank”}
:::

RedditのCEOであるスティーブ・ハフマン氏は2024年8月1日、Microsoftをはじめとする複数のAI企業による無断データ利用を批判し、その対策として同社が行ったウェブクローラーのブロックが  “a real pain in the ass to block these companies.（本当に面倒くさい作業）” であったと{target=“_blank”}で明らかにした。

同氏は特に、検索エンジンBingを運営するMicrosoftと、AI企業のAnthropic、Perplexityの3社を名指しで批判した。これらの企業がRedditのデータを無許可で利用し、AIモデルのトレーニングや検索結果の要約に用いていることを問題視した結果、Redditはやむを得ずこれらの企業によるデータ取得をブロックする措置を取ったという。

RedditはすでにGoogleやOpenAIといった企業とはデータ利用に関する合意を締結しており、これによりRedditは自身のデータの使用方法や表示内容を制御できるようになった。しかし、MicrosoftやAnthropic、Perplexityとの交渉は合意に至らず、最終的にRedditは7月初めにrobots.txtファイルを更新し、合意のないウェブクローラーをブロックする方針を打ち出した。

これにより、Redditの検索結果はGoogleの検索エンジンには表示されるが、Bingなど他の検索エンジンには表示されなくなっている。この措置について、Microsoft側は競争に悪影響を与えるとして異議を唱えているが、ハフマン氏はRedditのデータがAIモデルのトレーニングに無断で使用されている点を重視している。

Anthropicはすでに5月中旬からRedditをブロックリストに追加し、同サイトのURLをクロールしていないと表明しているが、MicrosoftやPerplexityからの公式なコメントは得られていない。ハフマン氏は今後も、Redditのデータ利用に対して公正なライセンス料を求める姿勢を示している。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Aug 2024 08:45:34 +0000</pubDate></item><item><title>＜生成AIでここまでできる＞月間10万6,000時間の余白を作り出した組織の企業風土とAI導入の仕掛けとは？GMOインターネットグループ株式会社が次フェーズで見据えるもの</title><link>https://ledge.ai/articles/expo2024-interview-gmo</link><description>※2024年6月に登録制のオンラインイベント「Ledge.ai EXPO 2024 Summer」に掲載した記事を全文公開

2024年5月、Open AI社が最新モデル『GPT-4o』を発表し、活用の幅がさらに広がった生成AI。昨年も企業での活用事例がメディアで多く取り上げられてきたが、現在もAI利活用や従業員のAI/ITスキル向上に関する取り組み事例が多く発信されている。企業におけるAI活用の重要性は日々増している。

そのような中、2024年4月9日にGMOインターネットグループ株式会社は生成AIを活用した業務効率化により、業務時間を月間10万6,000時間創出することに成功したと発表した。

同社がなぜ大幅な業務時間削減を達成できたのか？
今回は、企業の生成AI導入成功事例として、100社以上のグループ会社を持つGMOインターネットグループ株式会社のAI活用プロジェクトリーダーにインタビューを行った。巨大企業の生成AI活用術を是非見てほしい。

:::box
!
**GMOインターネットグループ株式会社**
**システム統括本部 アプリケーション開発本部**
**DX推進開発部**
**部長**
**李 奨培（リ ジャンベ）**
20年以上にわたり、ウェブベースの業務効率化ツールの開発に携わってきた経験を活かし、近年はノーコード・ローコードツールを活用したDX推進に注力しています。2023年4月からは、GMOインターネットグループを横断する生成AIを用いた業務活用プロジェクト「AI（愛）しあおうぜ！」のリーダーを務める。
:::

## 生成AI活用のためのバーチャルチーム
**──貴社が従業員向けの生成AI活用を始めた背景を教えてください。**

**ジャンベ氏**
弊社は10年以上前からデータサイエンティストなどを採用し、金融の分野などでAIの研究開発は進めておりましたが、Chat GPTがリリースされた2022年11月以降、弊社の会長兼社長執行役員・CEOである熊谷がグループでの生成AIの活用促進へいち早く着手し、2023年3月には生成AIを業務活用するためのコンテスト実施をX（旧Twitter）で発表しました。

もともと私はDX推進開発部に所属しており、社内パートナー（従業員）向けに時間とコストの削減に繋がる開発を行っています。そして生成AIの社内活用プロジェクトの担当を社内公募することを知り、実際に手を挙げてプロジェクトのリーダーになりました。このプロジェクトは、これまで私が行ってきた業務に「AI」が加わっただけなんです。つまり、ツール作成やノウハウ確立など通して、パートナーの業務効率化のサポートをすることに変わりはありません。ならば「私がやった方が良いな」と考えたんです。自動化の啓蒙プロジェクトなども進めていたので、その経験が活きるだろうなと思いました。

そして、プロジェクトメンバーを私が直接指名し、まず2023年4月にはChatGPT業務活用コンテストを開始しました。これをきっかけに、様々なAI活用推進施策を進めるプロジェクトとして「AI（愛）しあおうぜ！」が始まりました。
プロジェクトメンバーは、社内にAIを浸透させるために一時的に作られたバーチャルチームなのですが、グループ横断でメンバーを集めているので、同じ部署の部下などで構成されているわけではないんです。

!

:::small
GMOインターネットグループの生成AI活用プロジェクトロゴ
:::

**──AI活用プロジェクトのために作られたチームなのですね。そういったバーチャルチームは、貴社ではよく組まれるのですか。**

**ジャンベ氏**
弊社内ではよく作られています。弊社の熊谷がスピード重視であり、また、GMOインターネットグループ全体がスピード重視の文化を持っているので、やると決めた事柄に対して適した組織がない場合は、指名や立候補により、適性のある人が集まってチームが編成されます。そして開始したプロジェクトが安定して運用できるようになったら、会社の組織へ落とし込む、ということはよくあるんです。

**──よくある企業事例だと、AI導入を行う場合に「情報システム部だから」という理由で任せられたりするなどがあります。それと比較すると、前向きな人がバーチャルに組織を作って進めていくのは、一つの良い例ですね。**

**ジャンベ氏**
そうですね。弊社にはAI研究開発室もあるのですが、その部隊に任せるのではなく、今回は “生成AI” という文脈があったので、通常のAI研究とは別物として、バーチャルチームが組まれました。

今回のプロジェクトで集まったメンバーは、必ずしもAIの専門家でありません。AIを専門に扱う、いわゆるアカデミックな人材はAI研究開発室が担います。我々は「生成AIを道具として活用し、いかに生産性を上げるか」という点を重視していました。AI研究開発室が「作る人」、我々のチームが「使う人」の立場、というすみ分けをしています。


## 生成AI活用促進のカギは「リスキリング」と「社内SNS」
**──実際の利用者の話ですが、パートナーの皆さんは、ITやAIなどと親和性の高い方が多いのですか？**

**ジャンベ氏**
弊社はIT企業であり、人員構成の半数はエンジニアやクリエイター、もう半数はビジネスサイドのユーザーなので、一般の企業よりはAI活用との親和性はあるかと思います。
しかし、コンテストが開始される前の実態調査としてアンケートを行った際、国内パートナーは5,000人以上いるのですが、生成AIを業務に活用している人は全体の6％程度しかいませんでした。利用したことがない／知らないと答えた人は半数以上もいたんです。

そのため、まだ知識が不足しているパートナーに対して、フォローを行うことに注力しました。
昨年は、生成AIの業務利用促進に向けた働きかけをしていました。

そして、今年に入ってからは、非エンジニアを対象としたリスキリング施策である「虎の穴」と呼ばれる施策を開始しました。これは、3ヵ月間の短期AI人財育成プログラムで、講義中に課題を出し、それを毎週クリアしてもらう形式で、AIを活用した自動化や業務効率化スキルを身に着けてもらっています。2月から開始して、現在3ヵ月が経ちました。

この「虎の穴」は、業務効率化ツールを自身で作成することを最終ミッションにしており、ツールが作れるようになるだけではなく、プログラム参加者が伝道師となり、部やチーム内によりよい自動化の方法を広めてもらうことをゴールにしています。

**──プレスリリースでは、様々な有料ツールの活用状況が書かれていましたが、生成AIのツールは絞り込んで活用されないのですか。**
!

**ジャンベ氏**
同じ文章生成AIでも、それぞれの特徴があります。最も有名なChat GPTを “バランスをとれているもの” として中央に置くとしたら、Geminiは独創的で創造的な回答に長けており、Claudeはとても正確で、要約に慣れている人が作業したかのような正確なものが返ってくるツール、という特徴があります。弊社のSlackでは、Claude、Gemini、ChatGPTが利用できるようになっているので、3つ同時に同じ質問を投げることもできます。利用するパートナーは、同時に３つのAIの生成を比較しながら最適な解を目利きします。

また、前提として、弊社はグループ会社が100社以上あるのですが、我々が所属している本社は1,000名以上が所属しておりますが、規模がかなり小さい会社もあります。それぞれ業種も文化も異なるので、最適なAIツールは様々です。
ですので、自社・事業にあったツールをそれぞれ取り入れてもらっており、選択を最適化し、効率よく採用する為のサポートを、私達のプロジェクトでは行っているのです。

**──活用についてもう少し深堀りしてお伺いしたいのですが、独自データの活用などはされていますか。**

**ジャンベ氏**
RAGやファインチューニングなどの技術を用いた独自データ活用の取り組みも様々な場所で行われています。例えば、我々が提供している国内最大級のドメイン公式登録サービス「お名前.com byGMO」では、お客様向けのチャットボットの回答生成に、RAGの技術を使用しています。あらかじめ用意されているFAQのドキュメントをAIが検索・参照して、返答するような仕組みになっていますが、他にもグループ各社でこのような取り組みは実施されています。

個々の会社での取り組みを収集する仕組みも用意していて、AI活用総合ポータルの「GMO Genius」という社内SNSがあるのですが、そこで各社の取り組みや、AIに関する広めたいニュース・知識を共有しあっています。

こういうツールがあると当然、積極的に使う人とそうでない人が分かれてきますが、GMO Geniusの利用を促進するために、ポイ活ならぬAI活（あいかつ）の取り組みを行っています。GMO Geniusにトピックを投稿したり、閲覧したり、質問したりするとポイントが溜まっていき、四半期ごとに溜まったポイントで懸賞に応募できるんです。実際に1回目の抽選が終了して、景品も発送し終えました。国内パートナーが現在5,000名程度いるのですが、GMO Geniusは4,000名が利用していて、1日に2、3件は情報が投稿されています。現時点の投稿本数は、累計で600本を超えています。

結果的に、最新のオープンソースLLMやツールの実装報告や、高度なプロンプトテクニック、そして各種海外の最新情報の要約等々、AIの最新情報を効率的に入手出来るプラットフォームになっています。

**──生成AIの活用というと「ハルシネーション」の問題が挙げられますが、それについては対策などしていますか。**

**ジャンベ氏**
昨年は「生成AIってまだまだでしょ」という言い訳の一つとして、ハルシネーションというキーワードが頻出していましたが、最近は社内からも聞かないですね。おそらくですが、LLMそのものが進化している点と、ハルシネーションありきで活用するということが全社に伝わっている気がします。
また、弊社の熊谷がグループパートナー全員参加必須のミーティングの場で「ハルシネーションだから使えないと言っているようじゃダメだ」と伝えていることも大きいですね。新しい道具というのは何か欠点があるから、それを加味して「どうしたら使えるか」を考えるのが知恵である、ということを、代表から全体に伝えているため、パートナーがそのマインドを持っているのだと思います。

我々が実施しているセミナーでもハルシネーションをある程度回避する方法だったり、出てきてしまった場合の対処法などを伝えている点も、問題の解決に貢献していると思います。

全ての道具や素材は「使い方」、なにかネガティブな要素があるからと言って、使うことを辞める、様子を見るといった習慣は私達にはありません。どうやったら活用できるか、弱点を克服するだけではなく、それを活かす方法はないか？を常に私も考えています。

**──生成AIの活用で、663人月に相当する業務時間を創出したのは、当初思い描いていたよりも効果がありましたか。**

**ジャンベ氏**
プロジェクト当初はKPIをもって動いていたわけではないんです。昨年はとにかく生成AIをパートナーに知ってもらうきっかけを、我々が提供することだけに注力していました。
その取り組みの中で、コンテストをはじめ、AIのトレンドやツールの使い方などの基礎を教えるセミナーや、よりハイレベルなエンジニア向けのウェビナーを、月2回の頻度で定期的に実施しました。また、AIパスポートというAIに関連する問題集を作成して、問題を解いたら生成AIに関する基礎知識が身につくような仕組みを作りました。

その他の取り組みでは、社内にある図書館にAIの本の充実です。昨年の取り組みとしては「AI読むべき100冊」という取り組みでAI関連の書籍を選出してもらい、400から500冊程度の本を揃えました。現在も書架の拡充は続けており、学びたい人が本選びで迷うことのない環境を維持しています。
!
:::small
渋谷フクラス GMOインターネットグループオフィス内にある図書スペース「GMO Library」
:::

**──GPT-4oのようなマルチモーダルAIの技術がリリースされていますが、そのような技術により貴社の中でもさらにAI利用が加速するイメージはお持ちですか。**

**ジャンベ氏**
マルチモーダルの文脈では、画像の表をインプットしてExcelに変換したり、音声データからテキストを起こすなど様々ありますが、活用の幅が広がると感じています。GPT-4oが正式にリリースされ、弊社でも（マルチモーダル関連の）活用事例が出てくるのではと思っています。
最近のグループ内の近しい取り組みで行くと、動画作成の工程で、文章生成AIで出力したプロンプトで画像を生成し、さらにその画像を使って動画生成AIで動画を生成した、という事例があるのですが、マルチモーダルAIなどの技術で利用の幅が広がると、工程ごとに使うツールが分かれていたところを、一気通貫で作成できるのではないかと期待しています。

## 「AIで未来を創るNo.１企業グループへ」を目指す
**──生成AIの業務活用で、時間が短縮された以外の効果はありましたか。**

**ジャンベ氏**
プレスリリースには掲載しなかったのですが、2024年3月11日から15日に実施したグループ内の生成AI活用アンケートの設問で、「アウトプットの質が向上していると思うか」の質問に対し、95%以上の人が「向上していると感じている」と回答していたんです。生成AIを利用することで、自分一人で業務を行った場合と比較して、誤字脱字がなくなるなど、小さなことも含めて効果を感じているようです。

「AIを活用して生まれた時間で何か面白いことができているか？」については、正確に把握することは難しいと思います。ただ、ひとつ指標を挙げるとすると、私たちは今まで毎年15％の成長を目指して事業を行っており、成長に比例する形で人員を増やしているのですが、ここ1、2年は人数がほぼ増えていないんです。とすると、何らかの改善によって業務が効率化されたと考えられるのですが、その一番の立役者がAIではないかと勝手に見ています（笑）

**──今後のビジョンはありますか。**

**ジャンベ氏**
グループとしては現在、生成AI活用の方針として、①時間とコストの節約、②既存サービスの質向上、③AI産業への新サービス提供　を掲げていますが、①と②は、今の流れに任せれば、うまく進んでいくと感じています。そのため、③の “AI産業への新サービス提供” に今後は注力していくと考えています。グループのスローガンも「AI活用No.1企業グループへ」から「AIで未来を創るNo.１企業グループへ」に深化させています。

それにあわせて、「AI（愛）しあおうぜ！」プロジェクトでも①や②の方針に向けて、グループ内の良い事例を吸い上げて、③の “AI産業への新サービス提供” に横展開していくことに注力しようと考えています。
しかし、実をいうと②の既存サービスの質向上については、それぞれの場所で改善されていて、我々もプレスリリースが出てから知ることもあるんです（笑）


我々の昨年の活動はあくまで “きっかけ” と”活用環境”の提供です。それが良い方向に転がっていくかどうかというのは、経営者の強い意志がバックグラウンドにあるかどうかも鍵だと思います。
弊社の熊谷が最近よく話す「ダーウィンの進化論」の言葉を借りると、「最も強いものが生き残るのではない。最も変化に対応したものが生き残る」という点は、この生成AI時代の企業戦略にも言えることではないでしょうか。</description><pubDate>Mon, 05 Aug 2024 08:49:38 +0000</pubDate></item><item><title>Microsoft、AI生成ディープフェイク詐欺の防止を目指す包括的法規制を米議会に要求</title><link>https://ledge.ai/articles/microsoft_protecting_the_public_from_abusive_ai_generated_content</link><description>:::small
画像の出典：{target=“_blank”}
:::

Microsoftの副会長兼社長であるBrad Smith氏は、2024年7月30日に{target=“_blank”}した声明で、AI技術を悪用したディープフェイク詐欺に対する包括的な法律の制定を米議会に求めた。

AI技術の進展によりディープフェイクが簡単に作成可能となり、詐欺や操作、虐待に利用されるリスクが急速に増大していることが背景にあるという。

Smith氏は、「AIの生成するディープフェイクは非常にリアルで、誰でも容易に作成できる。この技術は特に子供や高齢者をターゲットにした詐欺や虐待に使われる危険性が高い」と述べ、これらのリスクに対して迅速な法的対応が必要不可欠であると強調した。また、「最大のリスクは、問題に対して十分な対応を行わないことだ」と警告し、法規制の必要性を訴えた。

さらに、ディープフェイク技術は選挙妨害などの政治的目的に利用されるケースが注目されているが、同氏はその他の犯罪や虐待におけるこの技術の広範な悪用にも注意を払うべきだと述べている。AI生成コンテンツの出所を明確にするラベル付け技術や、AIを用いた詐欺に対する独立した法的枠組みの導入が必要だと提案している。

Microsoftは、民間企業としてAIの悪用を防ぐための安全策を導入する責任があるとしつつ、政府が「責任あるAIの開発と利用を促進する」政策を策定することの重要性も強調している。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Aug 2024 06:48:56 +0000</pubDate></item><item><title>Google、パリ五輪に向け制作された Gemini AI のCM「Dear Sydney」のテレビ放映を停止　「AIの使い方として最悪の例」との批判も</title><link>https://ledge.ai/articles/google_withdraws_gemini_ads_from_paris_olympics_coverage</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年8月、パリ五輪中継中に放送されたGemini AIのCM{target=“_blank”}を、視聴者や専門家からの批判を受けてテレビ放映から撤回した。この広告は、陸上競技の米代表シドニー・マクラフリン＝レブローニ選手に憧れる娘のために、父親がGoogleのAIを利用してファンレターを作成するという内容だ。

この広告は、Googleが開発したGemini AIを使用し、父親が娘のアイドルであるマクローリン・レブローネに感謝の手紙を書く手助けをするという内容であった。広告では、父親がAIを使わなければ適切な手紙が書けないと述べ、AIが手紙を生成する過程が強調されていた。

@


広告が放送されると、視聴者や批評家から「人間の経験をAIが奪う」として反発が起こったという。この広告が「本来父親と娘が共有すべき感動的な瞬間を機械に任せることを助長している」という批判や、「人間らしさを欠いた冷たい表現」であり、「AIの使い方として最悪の例」との声もあがったとのこと。

Googleは当初、この広告を擁護し、「Team USAを祝う真実のストーリー」として宣伝したが、批判の高まりを受けて広告を撤回することを決定した。Googleは、「AIが人間の創造性を補完する優れたツールになり得るが、決してそれを置き換えるものではない」との声明を複数メディアに表明し、広告を五輪中継から外す措置を取った。

広告は現在もGoogleのYouTubeチャンネルで視聴可能だが、コメント機能は無効化されている


:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Aug 2024 06:46:27 +0000</pubDate></item><item><title>夏だ！レジャーの後は「学びの夏」もいかが？ー スタンフォード大学で提供中の無料講座をご紹介</title><link>https://ledge.ai/articles/learning_stanford_2024summer</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

猛暑の夏休み、「お盆休みは帰省やレジャーの予定でいっぱい」という方も、「何もせず涼しい自宅でのんびり」という方も、「学びを満喫する夏」という時間を過ごしてみるのはいかがだろうか？

この記事では、スタンフォード大学で開講されている無料オンライン講座をピックアップ。特に注目すべき6つの講座を紹介する。
## 1. Introduction to Machine Learning Specialization：機械学習入門専門コース
この{target=“_blank”}は、機械学習の基礎から応用までをカバーする専門コースで、スタンフォード大学の著名な教授であり、Courseraの共同創設者でもあるAndrew Ng氏によって提供されている。聴講のみで利用可能な範囲では、講義ビデオやリーディングマテリアルに無料でアクセスできるが、課題提出や修了証の取得には有料プランが必要だ。機械学習アルゴリズムやPythonプログラミングを実践的に学びたい方に最適だという。
## 2. Advanced Cybersecurity Program Preview：高度サイバーセキュリティ（プレビュー）
{target=“_blank”}の高度なトピックに関するイントロダクションで、聴講のみで全て無料で受講可能なコースだという。情報保護や脅威の検出に関する実践的な知識を得ることができ、サイバーセキュリティの基礎を固めたい方におすすめ。

## 3. Databases: Advanced Topics in SQL（データベース：SQLの高度なトピック）
この{target=“_blank”}では、SQLの高度なトピックを学べる。データベースの最適化やトランザクション処理を深く理解するための内容が含まれており、聴講のみで利用可能な部分が無料で提供されているが、修了証の取得には有料プランが必要。

## 4. R Programming Fundamentals（Rプログラミングの基礎）
Rプログラミングの基礎を学ぶ{target=“_blank”}は、聴講のみで全て無料で受講できる。Rは、世界中のデータアナリスト、統計学者、データサイエンティストに広く利用されており、インストールから基本的な統計関数までをカバーする。データセットの操作や統計モデルの作成、データ視覚化のスキルを習得することができ、データサイエンスに興味のある方に適しているという。
## 5. Game Theory（ゲーム理論）
映画『ビューティフル・マインド』などで有名になった{target=“_blank”}は、合理的（そして非合理的）なエージェント間の戦略的相互作用を数学的にモデル化する学問である。チェスやポーカー、サッカーなど、一般的に「ゲーム」と呼ばれるものに加え、国同士の紛争、政治キャンペーン、企業間の競争、ニューヨーク証券取引所（NYSE）などの市場における取引行動のモデル化も含まれるという。

このコースでは、ゲームと戦略の表現、拡張形式（コンピュータサイエンティストがゲームツリーと呼ぶもの）、ベイズゲーム（オークションなどのモデル化）、繰り返しゲームや確率ゲームなどの基本を学ぶ。クラシックなゲームやいくつかの応用例も紹介される予定とのこと。聴講のみで利用可能な部分は無料で学習可能だが、修了証の取得には有料プランが必要だ。

## 6. Designing Your Career（キャリア設計）
この{target=“_blank”}は、どの年代や学歴の人々にも役立つデザイン思考のアプローチを用いて、効果的なキャリアデザインを学ぶことができる。コースは、キャリアに特化した5つの主要な概念で構成されており、それぞれがビデオで解説され、個人的な振り返りや演習によって理解を深めることができる。スタンフォード大学のライフデザインラボによって作成されたこの講座では、参加者が自身の人生とキャリアをデザインするためのスキルを提供している。聴講のみで利用可能な部分が無料で受講できるが、修了証を取得するには有料プランが必要だ。


これらの講座は、聴講モードを利用することで主要なコンテンツを無料で学ぶことができるが、修了証や追加機能には有料登録が必要な場合がある。特に、財政援助のオプションも提供されており、条件を満たせばコース料金の一部または全額が免除されることもあるとのこと。


:::box

:::
:::box

:::
</description><pubDate>Fri, 09 Aug 2024 07:12:06 +0000</pubDate></item><item><title>「短期開発したAI VTuberに大きな反響」エンジニアから42 Tokyo発の起業家へ　42Tokyo特別インタビュー【第5回】第1期生　福山 裕介さん</title><link>https://ledge.ai/articles/42tokyo-5</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第5回。**
:::

※インタビューは2024年2月22日に行われた。

:::box
!

**42 Tokyo 第1期生**
**福山 裕介**
株式会社ツクルバ、株式会社メルカリでエンジニアインターンを務めた後、スタートアップ企業の技術担当を務め、42 Tokyo卒業後にKinkaku株式会社を設立。
:::

## 再び学びの場へ　42 Tokyoを選んだ理由
福山さんは長い間海外で過ごし、日本に帰国した後は文化の違いに戸惑いながらも、企業のエンジニアとして活躍していた。既にエンジニアとしての経験を積んでいた中、どのようなきっかけで42 Tokyoを知り入学を決意したのか。福山さんは以下のように振り返った。

:::box
**福山さん**
私は幼い頃から15年以上インドやフィリピンなど、海外に住んでいました。海外に住んでいた学生時代は、中学生からPCに触れる環境だったため、PC操作に馴染みはありましたが、プログラミングに関しては全く知りませんでした。

海外の高校卒業時期が5～6月だったため、日本の大学の入学時期まで結構期間が空くんです。その期間に、アメリカの大学へ進学した友人から、「プログラミングで有名な講師のオンライン講座が無料で受けられる」と勧められて始めたのが、プログラミングを知るきっかけでした。

大学入学のタイミングで帰国したのですが、日本の文化や教育に馴染めないと感じ、すぐに休学しました。その後、学んだプログラミングスキルを活かし、株式会社ツクルバやメルカリでエンジニアのインターンを経て、スタートアップの技術担当を務めました。年数でいうと、エンジニアの仕事を5年ほど続けました。
この経験からエンジニアとして知識や経験が身についたのは事実ですが、もう一度しっかり学び直したいという思いがありました。

情報収集する中で、Twitterで42 Tokyo開校の情報を見つけたのが42 Tokyoを知るきっかけでした。新しい教育システムに興味が湧き、実際に入学して自分自身で体感したいと思い、受験を決意しました。
:::

福山さんは勤めていた会社を退社し、第一期生として42 Tokyoに入学した。既にエンジニアとしての経験を積んでいた福山さんは、42 Tokyoに入学する前から起業する目標を持っていたという。42 Tokyoでどのような学生生活を送っていたのか、以下のように語ってくれた。

:::box
**福山さん**
とにかく入学試験の「Piscine(ピシン)」が凄く楽しかったんです。会社に勤めていた頃は、文化の違いに馴染めず本来の実力が発揮できなかった苦い経験がありました。しかし、42 Tokyoは文化の違いも関係なく、皆がプログラミングを学ぶという同じ目標に向かって進んでいくので、萎縮することなく話せました。誰かと無邪気に話したり、意見を言い合いながら自由に学ぶ場というのが新鮮で楽しかったという印象がとても強いです。

日本初の「42」開校なので、一般的には少し様子を見たり、一旦立ち止まって入学を考えますよね。私含めですが、新しいものに飛びついて受かった人は、結構特殊だと思うんです。第一期生は躊躇なく受験した人たちの集まりなので、やはり個性的な人が多く、バックグラウンドや年齢も様々でした。また、良い意味で他人の過去にはあまり興味を示さないので、何をやっていたとか年齢も気にせず、皆対等に接することができました。

「42」は、根本的に目的意識が強い学びたい人しか集まらないので、そういったところが大学とは違うと感じ、皆が学びへの姿勢も熱量もモチベーションも高いので、私の意識も一層高まりました。
:::

「周囲の人たちに刺激を受けながら学生生活を送っていた」と語った福山さんだが、全ての学生が今までの人生を苦難なく過ごしてきたかと言うと、必ずしもそうではないという。

:::box
**福山さん**
過去に学校や仕事を辞めた人、ずっと家で過ごしていた人、周りから過小評価されていた人もいました。しかし、共通して言えるのはコードを書く能力が高く、シンプルに課題解決能力や適応能力、学習速度が速い人が多かったですね。

エンジニアとしてステップアップしたいというのはもちろんですが、私自身も大学生活で躓いた経験があるので、リハビリも兼ねて社会や人と触れ直すきっかけがほしかったんです。共通の話題があることで自然と話せましたし、そういう部分でも42 Tokyoを選んで良かったと思います。
:::

## 42 Tokyoの魅力　実践的な学びの重要性と習得したスキル
!

大学との学び方の違いを体感し、改めて42 Tokyoのカリキュラムの良さを実感したという。モチベーションが下がることなく課題に取り組むことができた理由を、福山さんは以下のように話してくれた。

:::box
**福山さん**
6～7年前は、ソフトウェアエンジニアで情報系出身の人材がかなり少ない時代でした。学べる場といえば、仕事で任されるタスクに関連した内容がほとんどなので、どうしても知識の偏りが生じてしまうんです。

現在は環境が変わっていると思いますが、当時の大学は知識を詰め込む座学が多く、コードを書く物量が全然足りていなかった。そのまま大学に通っていても理論は学べるが、実践的なことはあまり身につかないと思いました。コードを書く機会が少ないと「こうやって書くんだ」だけで終わってしまうので、もったいないですよね。

42 Tokyoは100％プロジェクトベースの実践的カリキュラムなので、コードを書く物量でいうと数十倍はあると思います。例えば、ソフトウェアを制作するという課題があったとして、それを作るために理論を学びにいくので、目的ありきの学び方なんです。

また、現状の知識より少しチャレンジングな課題をあえて渡されるので、独学で勉強していたら学べないようなものが多いんです。簡単すぎない、少し背伸びをした課題を解くために、自身の持っている知識を活用したり、調査したり、時間を使って向き合えば絶対にクリアできるので、達成感や自信に繋がります。モチベーションも上がっていきますし、「勉強すればなんとかなる」というマインドセットが身につきました。次の課題への意欲も湧いてきますし、そこだけは陳腐化せずに自分のスキルとして身につくことを、課題を通して学べたと思います。
:::

## 42 Tokyoでの経験を経て起業の夢を実現
42 Tokyoを卒業した福山さんは、その後、ともに学んだ仲間とハッカソンに参加し、見事優勝した。その成功体験を経て、起業した当時を以下のように福山さんは語ってくれた。

:::box
**福山さん**
42 Tokyoに入る前から起業はひとつの目標でした。
42Tokyoに在籍しながら、大学院で画像生成の研究をしていた友人と、二人で共同創業者として会社を立ち上げました。当時はちょうどChatGPTがリリースされた時期で、「なんか化け物みたいなものが出てきた！」と、とても衝撃を受けました。この言語モデルを使って一番ワクワクするものを作り出したいという思いから「AI VTuber」の開発プロジェクトが始まりました。

その後、短期間で開発したAI VTuberをXに投稿したところ大きな反響があり、「これはいけるかもしれない」と二人で意気込み、さらにこの波に乗るために開発を進めました。

私たちはエンジニアなので絵を描くことができません。そのため、画像生成AIを活用してキャラクターを描いたりコンテンツを制作していたのですが、開発を進める中で、現状の生成AIは絵柄や顔の一貫性がなくなる課題が見えてきました。また、画像を生成するにあたって、テキストで自分の作りたい画像のイメージを伝えることの難しさを知り、それを簡単に解決できるサービスはないか？と考え、その課題に対応するサービスを開発しました。
そのサービスは、ビジュアルベースで作りたい画像のイメージを描いてAIに指示をすると、リアルタイムで画像が生成することができます。基盤モデルはStable Diffusionを使用しており、高速で生成する技術を用いながら独自で改良を重ね、0.1秒という高速生成を実現することができました。
:::

## 今後のビジョンと新たな目標
様々な生成AIに関連するサービスを開発してきた福山さんだが、さらに大きな目標を掲げて今後も開発を続けていくという。今後の具体的な展望も以下のように語ってくれた。


:::box
**福山さん**
私たちは、42 Tokyo卒業後初めて起業した実績があるので、今後は上場も視野に入れて、「コンテンツ周りの生成AIならKinkaku」と言われるくらい、日本を代表するような生成AI企業に成長したいと思っています。

先ほども話したように、画像生成における絵柄の一貫性がない問題も、その部分を解決すれば活用の幅はさらに広がるので、改良してビジネスで役立つものを生み出したいと考えています。最終的には、生成AIをアニメなどのコンテンツ制作の場で使用されるものを開発したいですね。

すべての作業をAIが行えば良いとは考えていません。例えば、漫画制作でストーリーや構成を人間が考えて、キャラクターの名前やセリフをまとめる部分をAIが担っていくというように、基本的に面白いコンテンツを作り出せるのは人間だと思います。そこは今もこれからも変わらないと思います。人とAIが協業する世界に向けて、アニメや漫画業界と基盤モデルの橋渡し役を私たちが担いたいです。
:::

:::box
特集：
:::</description><pubDate>Mon, 22 Jul 2024 01:51:14 +0000</pubDate></item><item><title>東大松尾研究室が監修・開発のLLM講座「大規模言語モデル 2024」の受講生募集を開始</title><link>https://ledge.ai/articles/large-language-model_matsuo_iwasawa_lab</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月9日、松尾・岩澤研究室が主催する講座「大規模言語モデル 2024」の受講生募集を{target=“_blank”}した。

本講座は、データサイエンティスト育成講座やDeep Learning講座を10年以上運営し、多くの人材を育成した実績を持つ東京大学松尾・岩澤研究室の松尾豊氏と岩澤有祐氏が監修・開発しており、生成AIの基盤モデルである大規模言語モデル（LLM）の基礎理論や既に公開されているLLMモデル、APIの活用方法を学び、幅広い知識やスキル習得を目的としている。全12回の講義と受講生同士で競うLLMに関するコンペティション型の最終課題を実施予定だ。

受講料無料の完全オンラインでの実施で、募集締切は2024/7/31(水)10:00までとのこと。
!

:::small
画像の出典：{target=“_blank”}
:::


2023年9～10月に東京大学サマースクールで開催されたLLM講座では、約2,000名の受講者が参加し、最終課題のGPUを使ったコンペディションでは約800名が熱戦を繰り広げたという。講義のスライドが{target=“_blank”}でダウンロード可能だ。


:::box

:::
:::box

:::
:::box
[関連記事：年末年始こそAIのリスキリング　2023-24年のおすすめ無料講座を一挙紹介！ー松尾研LLM講座・Google認定資格プログラム・プロンプトエンジニアリングなど](https://ledge.ai/articles/free_courses_in_winter2023-24
)
:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Jul 2024 06:56:44 +0000</pubDate></item><item><title>コンサルからエンジニアへ　東京・パリで学び、データ分析でグローバルな活躍を目指す　42 Tokyo特別インタビュー【第4回】小林 瑠理さん</title><link>https://ledge.ai/articles/42tokyo-4</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第4回。**
:::

※インタビューは2024年1月30日に行われた。

:::box
!
**42 Paris 在学生**
**小林 瑠理**
新卒で外資系コンサルティング企業に入社し、ビジネスアナリストを経験したのち、転職してIT企業に転身。その会社でエンジニア養成機関「42 Tokyo」を勧められ、2022年4月に入学。仕事と並行しながら基礎カリキュラムを修了し、現在は「42 Paris」に留学中。 現在は勉強と並行して、フリーランスエンジニアとして、アメリカの企業でwebオートメーション支援と日本のベンチャー企業でLLM活用支援をおこなっている。
:::

## 未経験からの挑戦　42 Tokyoで見つけた学びの道

:::box
**小林さん**
大学卒業後は、ITのシステムインテグレーターの会社に入社して、ビジネスコンサルとして仕事をしていましたが、そこでエンジニアリングに興味を持ち、未経験でITエンジニアとして転職しました。しかし、全く教育を受けていない状態で転職したため、自主学習も思うように進まずに悩んでいたんです。そんな中、社内の技術担当の方から「42 Tokyo」を教えていただき、入学試験「Piscine（ピシン）」を受験しようと決意しました。

42 Tokyoを教えてもらうまでは、オンライン講座を受講したり、本を読んだりしていましたが、自分でプログラムを最初から作るのが一番習得への近道だと思っていたので、42 Tokyoでは実践的にプログラムを作り、その過程を学べるのがとても魅力的でした。

一般的な学習方法である教師がいる環境もメリットはあると思うのですが、インターネットで情報が簡単に手に入る今の時代の中で、教師がいることで受け身になってしまう部分もあるように感じていました。42 Tokyoは、教師がいないからこそ主体的に動けるのではないかと思い、興味が湧いてきたんです。

年末の休みと有給休暇を利用してPiscineを受験して無事に合格し、入学しました。
:::

小林さんは、Piscineを受験した時はC言語にも触れたことがなく、ロジックの組み立て方も分からず、なかなか思うように進められずに焦る場面もあったという。周りがどんどん進んでいく中、「なんで自分はできないんだ」と落ち込むことも何度かあったというが、落ち込みながらも合格まで辿り着くことができた。その理由を小林さんは以下のように振り返った。

:::box
**小林さん**
当時は本当に簡単なコードの書き方も全然分からない状態だったので、進みが遅い自分に焦りを感じ、落ち込むことが多かったです。何度か心が折れたこともありました。最後まで乗り切れたのは、相談しあったり、励まし合ったりできる仲間がいたからだと思います。仲間がいなかったら合格まで辿り着けなかったかもしれません。その点でも、仲間の存在はとても大きかったですね。

入学試験を受けている仲間同士で学業以外のこと、人生相談など結構深い話もしていました。年齢層やバックグラウンドが皆様々で、18歳から60代歳まで幅広い年齢層の人が集まっているので、課題の合間に皆でコミュニケーションを取っていましたね。"意欲的に何かを成し遂げたい"と強い意志を持ってチャレンジしている方が多く、良い刺激を受けていました。友達というよりは、ともに試験合格を目指す“仲間”と呼べる存在でした。
明確な目的があって、自分のやりたいことを探求したい野心的な人は42 Tokyoで能力を発揮できると思います。実際に42 Tokyoでは、目的意識が高い人が多く、自分の目的を達成するために課題と向き合う強い意志が大切なので、そういった意志がある人にはピッタリな環境ですし、普通の大学や職場では得られないことが経験できる環境だと思います。
:::

## 42 Tokyoでの実践的な学びの風景　仲間とともに挑む課題と成長
!

:::small
42Tokyoの学習風景
:::

無事に入学試験をクリアして42 Tokyoに入学した小林さんだが、仕事を休職することなく、学業と両立していくことを選んだという。どのように両立していたのか、42 Tokyoでの学習環境を詳しく聞いてみた。

:::box
**小林さん**
課題を進めるにあたって、週に35〜40時間は必要なので、仕事と学業の両立がすごく大変でした。朝早く起きて仕事が始まる前に勉強して、仕事が終わってからも勉強して、土曜日は一日中校舎に行って課題を進める生活を1年半ほど続けていました。当時勤めていた会社は人を大切にする会社で、42 Tokyoに通うことを応援してくれたり、様々な場面で助けていただきました。学業と両立できたのは、会社の皆さんの協力あってのことだと思います。

42 Tokyoの課題をこなす時は、実際にプログラムを書いて仲間同士で教えあったり、時には突っ込まれたりもするんですが、そういった生徒同士で教え合いながら学ぶ学習方法が想像以上に濃い内容でした。課題を提出したあとに3回レビューをするのですが、相手が全くの知識0の人もいれば、すでにかなりの知識を備えた熟練者だったり、色々なレベルの人とランダムでマッチングする形式なので、相手に合わせた説明が求められるんです。

例えば、知識が0の人には基礎から分かりやすく説明して理解してもらう必要がありますし、逆に熟知している人からは、自分の説明に対して鋭い指摘を受けて、少しずつ直していく、ということの繰り返しでした。同じ課題でも、相手によって自分も視点を変えて学習した内容を分かりやすく説明する必要がある。そういったことから、今振り返るとコミュニケーション能力や説明能力も身についたと思います。
:::

課題のレビューは生徒同士で行う。相手によって説明内容や視点を変えることで、改めて課題への理解が深まったという。レビューをし合う中での発見や、印象に残っていることを小林さんは以下のように語った。

:::box
**小林さん**
レビューはポイント制になっていて、自分がレビューをすると1ポイント加算され、そのポイントを使用して課題を提出してレビューを依頼するシステムなので、必ず交互にランダムでマッチングする形式になっています。

最初は知識がない中でレビューをしなければならないので、相手の説明を正しく理解することを心がけていました。自分でも正誤が分からない状態なので、分からないことは理解できるまで教えてもらったり、自分でも調べながらレビューをしていました。一年ほど経ってくると自分の知識も広がっているので、「良いコードだな」と、自分で判断できるようになり、「ここのコードはこうやって書き直すとより見やすいんじゃないか」など、アドバイスができるようになりました。

とにかく実践的に課題に取り組むカリキュラムなので、本を読むよりも自分には合っていると思います。課題の進捗をチームごとに確認できるのですが、課題が進んでいる人を見ると、良い意味で競争心が掻き立てられて、「もっと頑張ろう」と意気込んでいました。
:::

課題をクリアするには、3回レビューを通さなければならないルールがある。1、2回目はクリアできても3回目で返されるとまた1回目から再度レビューになるため、3回目で返されるのが一番キツかったと話す小林さんだが、そのレビューがきっかけで自身の考え方が大きく変わったという。

:::box
**小林さん**
課題の説明をする上で、その結論に至るまでの “過程” の部分にこだわりを持つ人が多かったので、その相手の主張に対して、「私はこういう理由で実装した」と論理的に伝えることが難しく、苦労しました。意見が対立した時に、私は逃げてしまうタイプだったのですが、何故この考えに至ったのかを論理立てて主張することの重要さを学びました。

相手にも意見があって、別に精神的な攻撃をしたいわけではない、建設的な議論がしたいんだと思えるようになったので、メンタルにくることも少なくなりました。自分の意見をしっかり伝えることの大切さに気づけたことが私自身に大きなプラスとなりましたし、社会人としても成長できたと思います。
:::

## 42 Tokyo卒業後の挑戦　42 Paris本校への留学と新たな目標

小林さんは42 Tokyoの基礎カリキュラム（コモンコア）を1年半で修了した後、会社を退社し、42 Paris本校へ留学をした。インタビューの最後に、パリでの生活や42 Paris校の様子、そして今後の展望を語ってくれた。

:::box
**小林さん**
東京で働いていた時は主にアプリ開発をしており、その間に42 Tokyoのコモンコアで基礎であるC言語の勉強を行っていました。コモンコアを修了後は、別の国の42に移籍できるようになるので、データ分析を学ぶためにパリに移籍をしました。もちろん42 Tokyoでもデータ分析は学べますが、もともとグローバルに働いてみたいという思いがあり、パリを選択しました。

パリに来て言語の不安がありましたが、ほぼ全員が英語が流暢に話せるので、今は英語で勉強をしています。仕事と学業の両立をしていた日本での生活と比べると、今は自分の時間も確保できますし、勉強の時間もしっかり取れているので、充実した生活を送っています。データ分析の基礎を楽しみながら学んでいるので、今後はデータ分析に関連する仕事に就きたいと思っていますが、ロケーションを日本にするかヨーロッパにするかはまだ決めていません。
今はパリの生活を存分に楽しみたいと思います。おしゃれな街並みに囲まれて、すぐ近くには美術館があったり、ミーハーなだけかもしれないですが結構楽しんでいます（笑）

42 Parisは、東京校と比べると学校の雰囲気が違います。規模も大きいですし、人数も多いので両隣の人との距離が近くて教室での密集度がかなり高いです。東京校の方が自分の空間が取れてその点は東京校の方が過ごしやすくて好きでした。

42 ParisではRNCPという職能資格を習得できる制度があり、そのためにインターンシップ経験が必要なので、インターンでも様々な経験を積んでより知識を深めていきたいと思います。基本的に勉強が好きなので、身につけた技術を仕事に活かしつつ、新しい技術の勉強はずっと続けて、両輪で生きていく人生にしたいと思っています。
:::

:::box
特集：
:::</description><pubDate>Mon, 08 Jul 2024 07:44:09 +0000</pubDate></item><item><title>【無料LIVEウェビナー】RAGの活用方法や最新AIツールを紹介！生成AIを活用する時に知っておきたい重要トピックを解説</title><link>https://ledge.ai/articles/expo2024-live-webinar</link><description>:::box
Ledge.aiが6月に開催したオンラインイベント「{target=“_blank”}」のうち、終盤に実施したライブ配信による解説ウェビナーには多くの好評をいただいた。この反響を受け、イベントの追加コンテンツとして、7月31日までLIVEウェビナーの追加企画を実施している。また、それに伴って一部コンテンツは延長公開中だ。気になるコンテンツがあれば、是非チェックしていただきたい。
:::

## これからのビジネス環境で必須となる生成AI活用の重要トピックを解説
生成AI技術の企業での業務利用は、いまだ慎重論は一定数見られるものの、徐々にその風潮に変化が見られている。
ICT市場調査コンサルティング企業のMM総研が2024年3月に発表した調査結果によると、2025年度には69％の企業が生成AI技術の本格的な利用を検討すると回答している。

:::box
{target=“_blank”}
:::

今はまだ顕在化していないが、今後生成AI技術を効果的に活用できている企業とそうでない企業との間には、ビジネスでの競争力に大きな差を生み出していくことになるだろう。

今回Ledge.aiでは、先月開催したオンラインイベント「{target=“_blank”}」の追加企画として、昨今の生成AIトレンドの中で、押さえておくべきトピックについて解説するLIVEウェビナーを開催する。

:::button

:::

## 配信ラインナップ紹介
以下がこの先の配信予定だ。一度参加登録することで、すべての配信に視聴参加できるようになるので、合わせてご覧いただきたい。

**「RAGを使った独自データの活用の基本」
配信日時：7/9（火） 15:00-15:30**
大規模言語モデル（LLM）に不足している知識を補い、独自の情報を反映した回答を出力させることができる「RAG（Retrieval-Augmented Generation）」という手法について、その基本的な仕組みや活用方法について解説する。
なぜ独自の情報を参照させる必要があるのか？といった背景知識を押さえた上で、外部から与えた知識の処理プロセスや、精度向上の鍵となる技術要素など、RAG導入の基本となるポイントを押さえる。

**「今話題の生成AIツールを紹介」
配信日時：7/11（木） 15:00-15:30**
ChatGPTやGemini、Claudeといった会話型AIツールだけでなく、昨今生成AI技術を活用した様々なツールが登場している。本配信では、その中でも最近特に注目度の高いツールを2つ紹介する。
一つ目は、誰でも手軽にLLMアプリケーションが構築できるLLMアプリ開発プラットフォーム「Dify.AI」を紹介する。RAGを使ったエージェント形式のチャットボットや、複数のタスクを組み込んだワークフローなどが実際にどれくらい簡単に作れるのかをLIVEでデモ実演する。
２つ目は、テキストや画像から高品質な動画を生成することができるサービスとして話題になっている動画生成AI「Luma Dream Machine​」だ。活用ケースを想定しながら、実際にプロンプトを送り、どのような動画が生成されるのかをデモ実演する。

**「RAGの回答精度を上げるためにすべきこと」
配信日時：7/16（火） 15:00-15:30**
7/9配信のRAG解説に続く発展編として、RAGの性能を向上させるための手法・テクニックを解説する。「質問に関連するドキュメント群を探し出すこと」、「取得したドキュメント群から正しい回答を生成すること」という２つの要素に分解して、RAGの回答精度向上につながる重要なアプローチをいくつかピックアップして紹介する。
RAGに取り組んでみたけどうまくいかない、これから実装を検討する上で躓くポイントが知りたいという方は、是非参考にしていただきたい。

**「優秀なAI部下で管理業務を楽にする！上司が知りたい生成AIの活用術」
配信日時：7/18（木） 15:00-15:30**
2022年のChatGPTの登場から進化が止まらない生成AI。新しいモデルや新機能の発表で、なかなかアップデートが追いつかず、使いこなせていない読者も多いのではないだろうか。本ウェビナーでは、生成AIを優秀な部下として活用し、業務効率を上げるためのテクニックを解説します。ChatGPTなどの会話型AIツールを使ってはみたものの、途中で挫折してしまった方も、このウェビナーを通じて、仕事で使えるテクニックを学び、あなただけの優秀なAI部下を作り、育てていくきっかけとして活用いただきたい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button

:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。


## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
配信形式：zoomウェビナー（LIVE）
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Mon, 08 Jul 2024 10:25:57 +0000</pubDate></item><item><title>松尾研インターンから42へ　基礎カリキュラムを最速で終了した学生がAI開発企業の人事統括になるまで　42Tokyo特別インタビュー【第3回】松本悠秀さん</title><link>https://ledge.ai/articles/42tokyo-3</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第3回。**
:::

※インタビューは2024年4月23日に42Tokyoの校舎にて行われた。

:::box
!
**42 Tokyo卒業生**
**松本悠秀**
東京大学松尾研究室主催のGCIにて優秀賞を受賞し、現在は同講義の教材開発及び講師として関わる。株式会社松尾研究所の複数のプロジェクトにてエンジニア・マネージャーを経験。42 Tokyoのコモンコアを最速で突破。現職ではAIスタートアップにて、プロダクトマネージャー/人事統括を担当している。
:::

## データサイエンスとの出会い　松尾研から42 Tokyoへの挑戦
松本さんは大学4年生で転機を迎えた。それが、データサイエンスとの出会いだったという。普通の大学生からどのようにして「42 Tokyo」への入学を決意したのか、以下のように語ってくれた。

:::box
**松本さん**
僕の経歴は少し特殊で、大学4年生を2度経験しています。入学してから3年間は、サークルへの参加や家庭教師をするなど、普通の大学生活を送っていました。大学4年生に上がったタイミングで経済学部に転学し、教育に携わる仕事に就くために就職活動を進めていました。その後、教育関連企業への内定も決まったのですが、就職活動をしている中でデータサイエンスの重要さを知り、卒業後に良いスタートが切れるように、という思いから松尾研のGCIというデータサイエンスの講義を受講しました。


GCIは、東京大学松尾研究室の研究室が運営するデータサイエンスの講義で、東大以外の人も受講可能です。この講義を受講して、データサイエンスやプログラミングの面白さに気づきました。僕が本格的にプログラミングに触れたのは、この講義がきっかけでした。

この講義が一通り終わったあと、松尾研でのインターンを開始し、GCIの講義開発や講師を務めたり、共同研究において機械学習のエンジニア/プロジェクトマネージャーを経験しました。
:::
松本さんは、希望していた教育関連企業への就職が決まっていたが、子どもと関わりたいという気持ちがある中、自身の強みを活かせるキャリアプランをどのように作っていくか悩んでいたという。

:::box
**松本さん**
松尾研のインターンでは主に機械学習のモデリングを担当していました。その中で、実際に作ったモデルが実社会へ実装されることに興味を持ち、実装にはソフトウェアエンジニアリングが必要だということを知りました。その時、全く関係ない文脈で「教育に興味があるのであれば、42 Tokyoというところに入学してみたらどうか」とお話をいただいたんです。「革新的な教育プログラムらしい」ということを聞き、後から調べたところ、ソフトウェアエンジニアリングを学べることを知りました。まさに求めていたものだと思い、一切の迷いなく入学試験を受けることを決めました。


就職が決まっていた企業での業務は、僕が得意とすることとは少し乖離があったんです。就職について悩んでいたとき、松尾研の方から42 Tokyoの話を聞いて、内定を辞退して学ぶことを選びました。ソフトエンジニアリングの勉強をしたいというのが一番でしたが、独自の教育カリキュラムへの興味もありましたので、とても良いタイミングだったと思います。

試験に合格したあとは、松尾研のインターンをしながら42 Tokyoのコモンコア（基礎カリキュラム）の勉強を始めました。
:::

## 日本最速でコモンコアをクリアした松本さんが語る42Tokyoの学び方
!
通常の授業のように時間が決まっているのではなく、好きな時間に好きなだけ勉強ができるのが「42」の魅力のひとつだ。松本さんは42 Tokyoのコモンコアを開校以来最速でクリアしているが、どのようにして課題を進めていたのだろうか。

松本さんは、42 Tokyoのカリキュラムについて、「今までの学習方式を破壊したような斬新なカリキュラムだった」と語った。
:::box
**松本さん**
コモンコアの修了については急いで終わらせようと思ってやっていたわけではなく、結構黙々と一人で集中して課題に取り組む時間が多かったんです。もちろん周りの人と協力しながら進める場面もありましたが、一人でできるところは黙々と課題を解いていました。


これまで色々な人たちが学問というものを紡いできた歴史がありますよね。今までの一般的な学習方式は、論文や学術本などを発表して、それを授業や研究という形で紡いでいく考えだったのですが、「42」はこれを破壊しているんです。課題を渡されて、自分で考えたり周りに相談しながら答えを導き出して、自分の力で登っていかないといけない。


効率性の観点で考えると、決して効率的とは言えません。しかし、課題をクリアするために自分たちで情報を取得しながら進めなければならないので、「未知のものに対する対応力」という、育成するのが難しい能力を育てる上では、最適な構図だと思います。最初に教科書をもらった方が全部覚えられて学びやすいじゃないですか。
すべての人に刺さる学習方法ではないと思いますが、この方法で学ぶことで得られるものは多いと思います。
:::
松本さんは2度目の大学4年生になることを決意したときから「あと1年しかないのに、この時間を無駄にはできない」と、黙々と課題をこなしていたという。そして、最速でのコモンコアクリアを実現した。自主性を育む環境で、一人で自由に課題を進めることもできる。自分のペースでこなせるところも42Tokyoの魅力なのだ。
:::box
**松本さん**
「42」の学習方法についてですが、例えば、「ウェブページを自分でデザインして作れるようになりたい」という具体的な目標がある場合、42 Tokyoで学ぶことはエンジニアの基礎なので、他のスクールの方がその目的達成のゴール到達は早いかもしれません。
しかし、エンジニアという刻々と変化していく分野において、「基礎・土台となるような力を、時間をかけてでもいいので学びたい」など、幅広く応用の効くところまで学ぶ目的があるのであれば、力を養う学習方法として最も効率的なカリキュラムだと思います。
:::

## 42 Tokyoで得たスキルと知識
!
:::small
42 Tokyoの実際の学習風景
:::
42 Tokyoでの学びを通して、どのようなスキルが身についたのだろうか。特殊カリキュラムをこなす日々の中で身についた知識やスキルについて、松本さんに詳しく聞いた。
:::box
**松本さん**
42 Tokyoでのコモンコアが終了した時点では、正直、自分に身についた知識やスキルについてはあまり実感はなかったんです（笑）目に見えたスキルの習得がゴールになっていないので、実際に課題をこなしているときは「これ、役に立つときが来るのか？」と思っていました。恐らく、僕以外にも同じことを思いながら続けていた人は多いと思います。


しかし、役に立ったと思う日が来たんです。それは、松尾研在籍中、プロジェクトでエンジニアリングをしていた時期があり、定期的に業務の進捗報告をする機会があったんですが、「なぜこのような実装に至ったか」と聞かれたとき、「このような背景があり、こういった意図で実装しています」と、とてもスムーズに説明ができたんです。学生同士でフィードバックしあいながら課題を進める42 Tokyoの学習フローを、ここで活かすことができました。自分が行った作業の内容を、相手がしっかり理解できるように説明しないと課題をクリアできなかったので、そこで“説明力”が身についたのだと思います。


未知の領域に対しての対応力は確実に身につきましたし、自身の技術面の成長も感じました。コモンコアで学んだ内容とは違う技術領域に触れたときに、「これはあの課題で学んだ内容と裏にある理念は共通なのではないか」と気づき、さらに理解が深まった瞬間もありました。

そういった気づきがあるたびに、課題の意味を改めて理解できたと実感しました。
:::
松本さんはさらに、「42 Tokyoの特殊なカリキュラムは、偶発的な学びが起きやすい環境となるよう、意識的に設計されているんだろうと実感した。」と続けた。42 Tokyoを通して身についたスキルの存在に気づくたびに、点と点がつながっていく感覚があったのだという。
## 人事統括担当として描く組織像
42 Tokyoと松尾研の両軸で進んでいった1年間は、どのような将来像を描いて日々を過ごしていたのか。そして、42 Tokyoを卒業した現在は、どのようなビジョンを描いているのか、松本さんは以下のように語った。
:::box
**松本さん**
当時は明確なビジョンを意識していなかったんです。ただ、松尾研も42 Tokyoも同様に、自分の得意分野に気づけたというのは、人生を大きく変えたきっかけでもありますし、人生に与えたインパクトはとても大きいと思います。


42 Tokyoは去年の7月に卒業していて、現在はスタートアップで働いています。所属企業は、オーダーメイドでAIの受託開発を主に行っています。AIを学ぶ環境も展開しており、講義の設計なども行っています。その中で現在は、人事統括及びプロダクトマネージャーとして仕事をしています。人事統括としては、Missionの達成を第一としつつ、メンバーそれぞれの強みを活かしながら、事業を一番成長させられる文化の浸透・採用・アサインを日々模索しています。また、プロダクトマネージャーとしては、プロダクトの設計から、開発や機能検証のマネジメントを行っています。


42 Tokyoに在籍していた当初は明確なビジョンはなかったと話しましたが、現在の僕は、将来的には教育関連に携わることを目標としています。そのためにも、まずは自分の価値を最大限に発揮できる今の会社で、尊敬できる人たちと一緒に会社としての目標を達成していくことが大事だと思っています。
:::
松本さんの所属している企業のビジョンは “テクノロジーですべての「ひと」の力を解き放つ” であり、この「すべて」の部分は、外の人たちだけではなく、会社で働くメンバーも含まれるそうだ。社内外でこのビジョンを達成すべく、現在は業務にあたっているという。

:::box
特集：
:::</description><pubDate>Tue, 02 Jul 2024 02:23:09 +0000</pubDate></item><item><title>日本リスキリングコンソーシアム　最新の生成AI講座「 Google AI Essentials」を先着1万人に無料提供
</title><link>https://ledge.ai/articles/google_ai_essentials</link><description>:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::

2024年6月19日、日本リスキリングコンソーシアムは、 最新の生成AI講座「Google AI Essentials」を新規会員先着10,000人に無料で提供すると{target=“_blank”}した。

本講座は、初心者でも10時間程度でAIの基礎知識と活用方法を習得できる日本語対応のオンライン講座だ。通常8,000円相当の有料講座だが、今回は新規会員の先着10,000人が無料で受講できるという。GoogleのAIエキスパートが講師を務め、受講修了時には認定証が発行される。

### 主な学習内容は以下の通り
- 生成 AI ツールを使って、アイデアやコンテンツを開発し、より多くの情報に基づいた意思決定を行い、日々の作業をスピードアップする
- 明確で具体的なプロンプトを作成し、必要なアウトプットを得る。プロンプトのテクニックを応用して、要約やキャッチフレーズの作成などに役立てる
- AI にありうるバイアスを特定し、その弊害を回避することで、責任を持って AI を使用する
変化する AI の今後の展開の中で常に最新の情報を得るための戦略を立てる

AIに興味はあるが、何から学んだら良いのか迷っている方、日々の業務を効率化したい、AIスキルを習得してキャリアアップを目指す方に推奨の基礎講座で、さらに本講座を受講すると、以下2種の講座も無料で受講が可能だという。

### Google データアナリティクス プロフェッショナル認定証（2022 年提供開始）
データに基づいてビジネス上の意思決定を行うためのデータ収集、変換、整理スキルを学び、データアナリストとして即戦力となるためのスキルを身につけるコース

### Google サイバーセキュリティ プロフェッショナル認定証（2023 年提供開始）
一般的なリスク、脅威、脆弱性を特定する方法やそれらを軽減するテクニックなど、成長著しいサイバーセキュリティ分野で即戦力として活躍するためのスキルを身につけられるコース

!
:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::
学位や事前知識など受講条件はなく、誰でも申込みが可能とのこと。AIの基礎知識を身に着けたい方はぜひお見逃しなく。

:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:41:55 +0000</pubDate></item><item><title>【6/27 15:00開始】 最新モデル「Claude 3.5 Sonnet」の実力に迫るLIVE配信をレッジが開催！GPT-4oやGemini 1.5 Proとの違いなど徹底解説</title><link>https://ledge.ai/articles/expo2024_claude3-5_sonnet_live</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している特設サイト「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 突如発表された最新モデル「Claude 3.5 Sonnet」 その実力を検証するLIVE配信の開催が決定
2024年6月21日にAnthropicが突如として最新AIモデル「Claude 3.5 Sonnet」を発表した。

:::box
{target=“_blank”}
:::

Claude 3.5 Sonnetは、コードの生成やイメージの認識の性能が大幅に向上し、前バージョンの上位モデルであるClaude 3 OpusやGPT-4oなどの競合モデルを上回る性能を持っているという。

現在公開中の「{target=“_blank”}」では、LLM比較というテーマで、GPT-4o（OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった主要LLMの最上位モデルの比較結果のまとめ記事（{target=“_blank”}）を公開している。

今回の発表を受け、EXPO特設サイトでは、上記記事の追加企画として、Anthropicの最新LLM「Claude 3.5 Sonnet」について解説するLIVE配信を行う。

前バージョンのモデルであるClaude 3 Opusとの違いや、GPT-4oやGemini 1.5 Proといった他LLMとの違いを実際のデモを通じて比較しながら、リアルな使用感をお届けする。
主要LLMの最新情報をアップデートしたい読者は、是非視聴してみてほしい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button
{target=“_blank”}
:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。

## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
URL：{target=“_blank”}
配信形式：zoomウェビナー（LIVE）
配信日時：2024年06月27日（木） 15:00〜15:30
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Tue, 25 Jun 2024 13:36:46 +0000</pubDate></item><item><title>NLP（自然言語処理)これまでの80年とこれからの20年（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-msd-short</link><description>
:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

## ChatGPTなどに活用されるNLPの歴史を紐解く
生成AIの台頭により "NLP" が一般的にも広く認知されるようになったが、NLPが80年にわたって発展してきた技術であることはご存じだろうか。実は、NLPの起源を探ると、1940年代の機械翻訳までさかのぼる。

今回は、長年研究されてきた技術であるNLPについて、元女子高生AI「りんな」などで知られるrinna株式会社の元CEOであり、現在はマイクロソフト ディベロップメント株式会社のプリンシパル アプライド サイエンティストであるZhan (Cliff) Chen / 陳 湛 氏にお話を伺った。

:::box
!
**マイクロソフト ディベロップメント株式会社**
**Zhan (Cliff) Chen / 陳 湛 氏**
:::

:::button
{target=“_blank”}
:::

**Cliff 氏**
私は今年の４月にマイクロソフトに入社しましたが、実は入社は２回目です。2015年にマイクロソフトでAIチャットボットのrinnnaを作り、翌年以降もディープラーニングの技術を用いたチャットボットを開発していました。例えば、音声合成、歌、ダンスなど、現在生成AIで話題になっているコンテンツを2017年～2019年ごろに研究していて、2019年にはGPTがチャットボット開発に適していることも発見していました。
そもそもなぜチャットボットなのか？という点ですが、チャットボットは人間の知能に一番近いと考えていたからです。GPTには未来がありそうだと考えていました。2019年11月には、現在「RAG」として認知が広がっている技術も作って、発表も行っていました。

!

2020年にマイクロソフトからrinnaがスピンオフして、rinna株式会社を設立し、そこのCEOに就任しましたが、面白かったのは2021年4月ごろに日本語版のGPT-2のオープンソースで発表したことです。そこからGPTをアップデートし続け、Hugging Faceでオープンソースとしてリリースしていました。
凄く自慢できることがあるのですが、その当時の日本のNLP大会の中で、rinnaのGPT-2の技術を引用した論文が全体の3%から5%程あったことです。その当時はBERTが主流で、GPTはマイナーな技術だったのですが、日本語のGPTの論文の中にrinnaの技術が参照されていたのは印象深かったです。

**箕部（モデレーター）**
RAGの研究に関してもかなり早い段階から行われていたのですね。

**Cliff 氏**
我々もその時、KGC(※)は重要だということをたくさん話していましたが、そもそもGPTがマイナーだったのと、GPTは誤回答をすることから「全然ダメだ」と言われていましたね（笑）

OpenAIのChatGPTが出たことは、アカデミックから見るとそんなに革新的ではないのですが、インダストリーの観点から見ると一般ユーザーのマインドセットが変わった出来事でしたね。

:::box
（※）KGC（Knowledge Graph Construction）：知識グラフの構築のこと。知識グラフとは、知識を抽象化したデータ間の関係性を示すデータベース。知識情報が体系的に整理されることで、検索や情報抽出などのタスクにおいて必要な情報を提供することに役立つ。
:::

**箕部（モデレーター）**
AIを理解するうえで、”これまで” と “これから” を理解していくことが重要だと考えますが、クリフさんは専門だと思いますので、そのあたり詳しくお話を伺えればと思います。

**Cliff 氏**
「今までのNLPの80年」について、つまり、LLM（大規模言語モデル）はどこから来たのか？という話ですが…

※続きは特設サイトよりご覧ください 

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：
開催形式：オンライン（特設サイト）</description><pubDate>Fri, 21 Jun 2024 06:43:48 +0000</pubDate></item><item><title>【主要LLMの最上位モデルを比較】GPT-4o、Gemini Pro1.5、Claude 3 Opus 仕事で使えるLLMはどれか？まとめ記事公開中！</title><link>https://ledge.ai/articles/expo2024-llm-comparison</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

大規模言語モデル（LLM）は、チャットボットや文章生成、翻訳、要約、コード生成などの様々なタスクで活用されている。その一方で多くのLLMが存在しており、どれを選べばよいか頭を悩ませている読者も多いと思われる。

6月10日（月）より公開しているLedge.ai EXPO 2024 Summerでは、GPT-4o（ChatGPT / OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった最新モデルを比較したまとめ記事を公開している。いわゆるLLMのスペック比較ではなく、実際の出力結果を比較し、その使用感や出力の特徴を解説しているので、自社にとって最適なLLMを探す際の参考情報としてご覧いただきたい。

:::button
{target=“_blank”}
:::

## ビジネスシーンでの活用を想定した３つのタスクの実行結果を比較
今回の比較記事の中では、以下３つの主要LLMの最上位モデルを対象として比較を行っている。

- GPT-4o（ChatGPT / OpenAI）
- Gemini 1.5 Pro（Gemini / Google）
- Claude 3 Opus（Claude / Anthropic）

パラメータ数や学習データの範囲といったスペック比較は既に様々なところで行われているため、今回は仕事で実際に使えそうか？という観点で、企画、データ分析、ルーティンワークといった切り口で、LLMのアウトプットの比較を行った。
ビジネスシーンでの活用を想定した３つのタスクとその結果の一部を以下に紹介する。

## 企画：アイデアを創造する能力を比較
記事の中では、各LLMに「新しいテクノロジー製品のアイデアを提案してください。」というプロンプトを送り、それぞれの出力結果を比較している。
LLMは、学習した膨大な過去データから確率的な推論を行い、もっともらしい出力を行うものである。よくも悪くも私たち人間の一般的な価値観に合わせた平均的な回答の生成が得意なLLMが、新しいアイデアの発想において、現在どの程度のアウトプットを出すことができるのかをまとめている。

例えばOpenAIが開発した最新の大規模言語モデルGPT-4oでは、アイデアの中身については、真新しさや面白みには欠けるのは否めないというのが正直な評価であった。しかし出力に関する指示はなくとも、文章の項目構成を整理したアイデアが出力してくれる点には有用性も感じられた。アウトプットをそのまま使うレベルではないものの、着想のきっかけを得るための手段としては十分に使えるものではないだろうか。

!
:::small
GPT-4oが出力した企画案
:::

その他の２つのLLMの実行結果も記事の中で取り上げている。詳細は是非記事をご一読いただきたい。

## データ分析：データを理解し、可視化する能力を比較
２つ目のデータ分析の比較も興味深い示唆が得られる内容になっている。比較の内容としては、ChatGPTで生成したマーケティングデータのサンプルファイルを元に各LLMに分析結果を出力してもらった。上述した企画よりも、LLM毎の違いが見受けられた。

特にGeminiは、出力後もグラフをインタラクティブに操作でき、その場でデータの編集ができる。またGoogleスプレッドシートとの連携もスムーズにできる点などは、Google製品で業務を行っているビジネスマンにとっては、有力な選択肢となりそうだ。

!
:::small
Gemini 1.5 Proでのグラフ編集の動画も公開している
:::

## ルーティンワーク：記事を要約する能力を比較
最後に記事要約の実行結果をまとめている。シンプルなタスクであるがゆえに、LLMが有する言語処理能力がわかりやすく現れる内容といえるだろう。
今回は以下の記事の原稿ファイルを読み込ませ、要約を実行した。

:::box
{target=“_blank”}
:::

要約の内容については、どのLLMも違和感はなく、十数秒ほどで得られるクオリティとしては十分なものだった。しかし要約の仕方にはそれぞれ違いがあり、この部分は個人によって判断が分かれるように思われる。記事内の実行結果をその目で見て判断いただきたい。

!
:::small
Claude 3 Opusが出力した要約結果
:::

今回はプロンプト内で出力の形式などを特段指示していないため、プロンプトの作り込みで変わってくる部分もあるだろう。しかし同一の条件の元で、各LLM毎のアウトプットの違いを把握しておくことは、LLMを選ぶ際の重要な参考情報となりうる。記事をきっかけに是非お手元で試し、実際の使用感を体験いただきたい。
比較記事の全文は以下の特設サイトより閲覧できる。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 20 Jun 2024 06:38:09 +0000</pubDate></item><item><title>AWSが新AI認定試験を発表　2024年8月13日より開始、初の「ベータ試験」での日本語試験も提供</title><link>https://ledge.ai/articles/aws_crtified_ai_practitioner</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年6月14日、Amazon Web Services, Inc.（AWS）は、AI人材育成に関する説明会で、AIスキルを証明できる「AWS Certified AI Practitioner」と「AWS Certified Machine Learning Engineer（MLA）」の2種の新しい認定試験が2024年8月13日から開始することを{target=“_blank”}した。

**「AWS Certified AI Practitioner」**
AI、機械学習（ML）、および生成AIのコンセプトやツールに精通していることを証明する際に役立つ、AIに特化した資格だ。この資格は、AWS認定試験の4つのレベルの中でも基礎的な知識習得を目的とした「Foundational」のカテゴリに位置づけられる。

**「AWS Certified Machine Learning Engineer（MLA）」**
こちらは、AIやMLソリューションの構築、デプロイ、保守に必要なスキルを証明するものであり、モデルパフォーマンスの最適化、計算資源の管理、モデルのバージョンアップ、AIソリューションの保護などをスキル対象とする技術者向けの認定資格だ。AWS認定試験の「ASSOCIATE」のカテゴリに位置づけられる。

新たな2種の認定資格は、2024年8月13日から「ベータ試験」として登録を開始する。通常は英語での実施だが、このベータ試験は同社として初の試みである日本語試験も提供をする予定だという。
</description><pubDate>Thu, 20 Jun 2024 09:19:07 +0000</pubDate></item><item><title>その日から使えるデモも実演！「マルチモーダルAI」の概念を15分で丁寧に解説するウェビナーが公開中</title><link>https://ledge.ai/articles/expo2024-webinar-multimodalai</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 多種多様なデータを扱うことが生成AIをビジネスで活用する際の重要な鍵となる
生成AIは、ビジネスの多岐にわたる分野で急速に活用されている。生成AIは、テキスト、画像、音声、ビデオなどの多種多様なデータを扱う能力により、より高度な意思決定や業務効率化を実現するツールとして注目を集めている。特に、マルチモーダルAIの多様なデータソースを統合して分析・生成する能力は、ビジネスの競争力を高める鍵として注目を集めている。

とはいえマルチモーダルAIという言葉こそよく耳にする機会は増えてきたものの、実はまだその概念について良くわかっていない読者も多いのではないだろうか？

6月10日（月）より開催している「Ledge.ai EXPO 2024 summer」オンライン特設サイトでは、マルチモーダルAIについて15分で基本的な概念を解説するウェビナーを公開している。マルチモーダルAIの概要を短時間で学べるため、興味のある方は是非動画をご覧いただきたい。



:::button
{target=“_blank”}
:::

## マルチモーダルAIとは何か？
マルチモーダルAIとは一言で説明すると、複数種類の情報を組み合わせて高度な判断を行うAIのことである。モーダルとはデータの種類を指し、テキストや画像、音声、映像など様々なデータを扱うことが含まれている。
ビジネスの現場で扱うデータが多様化してきたことで、このマルチモーダルAIが今注目を集めている。

!

私たちがこれまでAIとして扱ってきたいわゆるシングルモーダルAIでは、単一のデータ形式に特化していた。マルチモーダルAIでは、異なるデータ形式間の関連性を学習し、それを基にした高度な予測や判断を行うことが可能になる。これにより単一のデータ形式だけでは得られない複雑な処理結果を引き出すことができる。

!

## 大規模言語モデルとの統合でマルチモーダルAIの能力は飛躍的に向上
大規模言語モデル（Large Language Models, LLM）は、テキストデータの処理に特化したAIモデルであり、膨大なテキストデータから学習することで、高度な言語理解能力を持っている。この言語処理能力が、異なるデータ形式間の関連性の理解においても非常に高い性能を発揮し、主要な大規模言語モデルにも、画像、テキスト、音声などのデータを統合して処理するマルチモーダル機能が強化される動きが加速した。

ウェビナーの中でも国内外の主要な大規模言語モデルを4つほどピックアップしているので、是非チェックしてみてほしい。

!

## マルチモーダルAIでどんなことができるかをデモ実演
ウェビナーの中では、OpenAIの最新モデル「GPT-4o」を使い、ビジネスシーンでの活用を想定したデモを実演している。すぐ試すことができるデモ内容になっているので、是非動画を参考に自身の業務の中でも活用してみてもらいたい。

今回は
- ホワイトボードの会議メモの整理
- 手書きのラフデザインからhtmlのソースコードを生成

の2種類のデモを行った。
ホワイトボードの会議メモを整理するデモについてその一部を簡単に紹介する。

会議でディスカッションした内容をホワイトボードに書き込んで記録することは、ビジネスの現場でよく見られる光景だ。
ホワイトボードの内容を構造化して整理しておきたい場合に、手打ちでテキストメモに書き起こしたりしていないだろうか？
こうした作業は、マルチモーダルAIを活用することで、作業を大幅に効率化できる。

!
!

デモの中では、ホワイトボードを撮影した画像と簡単な指示テキストを与えるだけで、情報が整理されたテキストメモが出力される過程を確認することができる。さらにそのメモからアイデアをブラッシュアップするといった追加指示を与えて、ただの文字起こしに＋αのタスクを実行させるところまで実演しているので、このあたりも注目してみてもらいたい。

ーーー

マルチモーダルAIは、大規模言語モデルと統合し、より自然で人間らしいインタラクションが実現可能になり、さまざまな分野での応用が期待されている。
この機会にぜひ動画をご覧いただき、ビジネスの現場でどのように活用できるかを学び、実際に導入するためのヒントとなれば幸いである。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）

</description><pubDate>Fri, 14 Jun 2024 04:03:02 +0000</pubDate></item><item><title>GitHubが開発者向けに「GitHub Models」を発表　最新のAIモデルを無料で試せる機会を提供</title><link>https://ledge.ai/articles/github_models</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年8月1日、「GitHub Models」を{target=“_blank”}した。この新たな取り組みは、1億人を超える開発者に、最新のAIモデルを無料で試せる機会を提供し、AIエンジニアリングの可能性を広げるという。

GitHubのCEOである Thomas Dohmke 氏は「このプラットフォームは、すべての開発者がAIの力を利用し、業界をリードするAIモデルで構築できるようにする」と述べている。
## GitHub Modelsの概要
GitHub Modelsは、「Llama 3.1」「GPT-4o」「GPT-4o mini」「Phi 3」「Mistral Large 2」といった最先端のAIモデルへのアクセスを提供する。このモデル群は、GitHub Marketplace内の無料プレイグラウンドで利用可能となり、開発者はさまざまなプロンプトやモデルパラメーターを試すことができる。プレイグラウンドで得られた結果に満足した場合、これらのモデルは「Codespaces」や「Visual Studio Code」などの開発環境にシームレスに統合できる移行パスも用意されている。

特に、Mistral Large 2やGPT-4oなどのモデルは、コード生成やマルチモーダルアプリケーションの構築に優れた性能を発揮する。これらのモデルは、従来のソフトウェア開発プロセスに革新をもたらし、AIを活用した新しいソリューションの創出を支援するという。

@



## AI技術の民主化と未来展望
GitHub Modelsの導入により、これまでAIに触れる機会が少なかった開発者でも、最先端のAI技術を手軽に試し、プロジェクトに取り入れることが可能になる。これにより、AI技術の普及がさらに加速し、さまざまな業界でのイノベーションが期待されるという。

GitHub Modelsの登場により、AIエンジニアリングがますます身近なものとなり、新たなイノベーションの波が広がることが期待される。これにより、世界中の開発者がAIを駆使して、より高度なソリューションを創出し、人類全体の進歩に寄与する未来が現実のものとなるとDohmke 氏は述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 04 Aug 2024 12:26:42 +0000</pubDate></item><item><title>AWSが、生成AI業務アプリを作成する「AWS App Studio」のプレビューを公開　開発スキルがなくても自然言語で利用できる</title><link>https://ledge.ai/articles/aws_app_studio_public_preview</link><description>:::small
画像の出典：{target=“_blank”}
:::

現地時間の2024年7月10日、米Amazon Web Services（AWS）は、ニューヨークで開催された「AWS Summit New York 2024」で、生成AIでアプリ作成ができる「AWS App Studio」のパブリックプレビューを{target=“_blank”}した。

「AWS App Studio」は、専門的なソフトウェア開発スキルがなくても、自然言語で作成したい業務アプリの説明を行うと、数分で業務アプリを作成することができる。

以下のように、左側に作成したい業務アプリの説明を入力をすると、入力されたプロンプトをもとに、生成AIがアプリのユースケース、操作の流れや主要機能を右側に書き出す。内容に問題がなければ生成を開始すると、わずか数分でアプリを作成することができる。さらに、生成されたアプリは公開前に実際のデータソースを使用して、プレビューで検証することもできるという。

!

:::small
画像の出典：{target=“_blank”}
:::

また、AWS App Studioの利用料金は無料で、開発されたアプリを使用した分だけ支払うシステムとのこと。例えば、企業で今後3ヶ月以内にAWS APP Studioを使用して2つのアプリを作成予定だった場合、2つのアプリを公開後1ヶ月のうちに10日間各アプリを使用した場合は、以下のような料金体系となる。

!

:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::

:::box

:::
</description><pubDate>Tue, 16 Jul 2024 13:58:52 +0000</pubDate></item><item><title>AGI実現への一歩となるコンテスト「ARC Prize 2024」開催中　賞金総額は約1億8000万円！</title><link>https://ledge.ai/articles/arc_prize_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月11日より、Zapier社の共同創設者マイク・クヌープ氏とGoogleの研究者フランソワ・ショレ氏が提案する「ARC」（Abstraction and Reasoning Corpus）を用いたコンテスト「ARC Prize 2024」が{target=“_blank”}されている。

ARCは、AGI（汎用人工知能）に向けた進歩を測定するAIベンチマークであり、人工知能と人間の知能を比較することを目的として作られた。これまでの競争では、人間の平均84％の正解率に対して、AIの最高スコアは34％程度となっている。これらの根本となる知識は、人間が子供の頃から自然と身につけている感覚のため、人間にとっては簡単だがAIには難解なテストだという。

現代のAI研究は大規模言語モデル（LLM）に重点を置いているが、これらのモデルは基本的な新しい発明や単純な問題への適応ができないため、真の知能とは言えない。この問題に対処するため、ARCというベンチマークテストが注目を集めている。

「ARC Prize 2024」は、LLMを超えた新しいアイデアを研究者が探求し、その進歩をオープンソース化することを目的としている。コンテスト提出締切は11月10日で、12月3日に賞の発表を予定しているとのこと。

テスト内容は以下のとおり、カラフルなグリッド図形から規則性を見つけ、右側のテスト用のアウトプットにその規則性に基づいた図形を表現する簡単なテストだ。
!
:::small
画像の出典：{target=“_blank”}
:::

【ARC Prize 2024の概要】
**グランプリ**
・1位：25万ドル（約3,500万円）
・2位：10万ドル（約1,400万円）
・3～5位：5万ドル（約700万円）
・追加グランプリ：50万ドル（約8,081万円）
※人間の正解率が平均84％のため、85％以上の精度スコアを達成した上位5チームに追加のグランプリ50万ドルを分配。
**2024進歩賞**
・1位: 2.5万ドル（約404万円）
・位: 1万ドル（約161万円）
・3〜5位: 各5,000ドル（約80万円）
※2024年の競争期間中に最高スコアを記録した上位5チームに授与
**論文賞**
・優勝: 4.5万ドル（約727万円）
・次点: 5,000ドル（約80万円）
※ARC-AGIでの性能を実現する方法についての理解を最も進展させた論文に授与
**参加条件**
・提出物のコードと手法はパブリックドメインのオープンソースライセンスの下で公開する必要がある
・第三者のコードや手法もオープンソースライセンスの下で利用可能でなければならない

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Jul 2024 07:18:15 +0000</pubDate></item><item><title>OpenAI が開発者向けQ&amp;AコミュニティサイトStack Overflowと新たなAPIパートナーシップを発表</title><link>https://ledge.ai/articles/openai_stackoverflow_api_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、OpenAIとStack Overflowは、開発者向けに最適化された技術情報とAI開発ツールを提供する新しいAPIパートナーシップを{target=“_blank”}した。

このパートナーシップにより、OpenAIのユーザーや顧客は、Stack Overflowが提供する正確で検証済みのデータを基に迅速な問題解決を図り、重要なタスクに集中できるよう支援されるという。

この協業の一環として、OpenAIはStack Overflowの「OverflowAPI」を利用し、ユーザーにStack Overflowの検証済み技術知識を直接提供する。これにより、ChatGPTはStack Overflowの豊富な技術データベースと連携し、利用者に対してより精度の高い支援を提供できるようになる。また、Stack Overflowは、OpenAIのAIモデルを利用して「OverflowAI」の開発を行い、内部テストから得た洞察を活かしてAIモデルの性能向上を図る。

このパートナーシップは、技術者が直面する課題への対応速度を向上させ、開発者コミュニティ全体の生産性とエンゲージメントの向上を目指している。両社は、開発者が必要とする情報や解決策を、より迅速かつ正確に提供できる環境を整備することで、技術開発の新たなスタンダードを築くことを目指している。

Stack Overflowは2月29日にGoogle Cloudとの協業を発表しており、「Gemini for Google Cloud」との統合を進めている。この連携ではGoogle Cloudのプラットフォーム上でStack Overflowの情報を活用し、開発者が容易に重要なナレッジベース情報やコーディング支援を利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 12:52:43 +0000</pubDate></item><item><title>AWSが「Amazon Q」の一般提供を開始　企業内データを活用したAIアプリケーション開発の加速を目指す</title><link>https://ledge.ai/articles/amazon_aws_q</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）は2024年4月30日、生成AIアシスタント「Amazon Q」の一般提供を開始したと{target=“_blank”}した。

このサービスは、開発者が自社のデータを活用してAIアプリケーションを構築できるよう支援することを目的としており、特にソフトウェア開発の加速と企業データの活用が可能になるという。

Amazon Qは、コード生成、テスト、デバッグ、計画立案、推論機能を備え、開発者はコードの自動変換やアップグレード（Javaバージョンアップグレードなど）、新しいコードの実装が可能となる。この生成AIアシスタントは、エンタープライズデータリポジトリへの接続もサポートしており、企業のポリシー、製品情報、業績、コードベース、人材に関する質問への回答や、データの論理的な要約、トレンド解析、データ関連の対話が行えるとのこと。

また、社内データから生成AIアプリの構築を可能にする新機能「Amazon Q Apps」も同時に発表された。従業員は自然言語でアプリについて記述するだけで、必要とされる業務を遂行するアプリを生成できるという。この機能により、日常業務の簡素化と自動化が促進される。

さらに、Amazon Qは40以上の一般的なビジネスツールと簡単に接続でき、企業は自社のデータを効率的に集約し、アクセスできるようになる。この広範なデータ統合能力により、企業はよりデータ駆動型で効率的な運営が可能になる​とのことだ。


:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 11:42:47 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>「RAG」と「ロングコンテキストLLM」の徹底比較：LLMの長文理解における新たなハイブリッドアプローチ　Google DeepMindとミシガン大学の研究</title><link>https://ledge.ai/articles/google_deepmind_lc-vs-rag</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月、Google DeepMindとミシガン大学の研究者たちは、LLM（大規模言語モデル）の長文理解における2つの主要なアプローチ「Retrieval Augmented Generation（RAG）」と「ロングコンテキストLLM（LC）」の性能を包括的に比較した論文を{target=“_blank”}した。

この研究は、LLMの長文処理能力に関する重要な知見を提供するとともに、コスト効率を最大限に引き出す新たなハイブリッド手法「SELF-ROUTE」を提案している。
## 研究の背景と目的
従来、RAGは長文処理の際に、外部データベースから関連情報を検索し、それを元に回答を生成する手法として注目されていた。この方法は、必要な情報のみを抽出するため、計算コストが抑えられるという利点がある。一方で、Googleの「Gemini-1.5-Pro」やOpenAIの「GPT-4O」といった最新のLLMは、膨大なトークン数にわたる文脈を直接処理し、高い性能を発揮することが可能になっている。

同研究の目的は、これら2つのアプローチを直接比較し、それぞれの利点と欠点を明らかにすること、そして、両者の長所を組み合わせた新たな手法「SELF-ROUTE」を提案することだという。研究では、長文理解における効率性と性能の両立を目指すとした。
## 主要な発見
### パフォーマンスの比較
LLMを用いた複数の公開データセットにおいて、RAGとLCを徹底的に比較した結果、リソースが十分に確保されている場合、LCがRAGを全体的に上回る性能を示したという。ただし、RAGは特に入力テキストがモデルのコンテキストウィンドウサイズを大幅に超える場合において、依然として有効であることが確認された。

下図は、3つの最新のLLMを用いてRAGとLCの性能を比較したもので、LCがRAGに比べて優れたパフォーマンスを示すことを視覚的に表している。

!
:::small
画像の出典：{target=“_blank”}
:::
### コスト効率
LCは高い性能を発揮するものの、その計算コストはトークン数に比例して急激に増加する。一方、RAGは必要な情報のみを取得するため、コスト効率が非常に高い。このため、タスクによっては、RAGがLCに匹敵する性能を、はるかに低コストで達成できることが示された。
### ハイブリッド手法「SELF-ROUTE」
研究者たちは、RAGとLCの長所を組み合わせることで、コストを削減しながらもLCに匹敵する性能を実現するハイブリッド手法「SELF-ROUTE」を提案した。この手法は、最初にRAGを用いてクエリに回答可能かどうかを判断し、必要に応じてLCを適用するという2段階のプロセスを採用している。この結果、全体の計算コストを最大65%削減しつつ、LCに近い性能を維持できることが明らかになった。

下図は、RAGとLCが生成する予測がどれほど一致するかを示しており、SELF-ROUTEがいかにして効率的にRAGとLCを組み合わせるかを視覚的に説明したもの
!
:::small
画像の出典：{target=“_blank”}
:::

研究者たちは、同研究がロングコンテキスト LLM の実用化に貴重な洞察をもたらし、RAG 技術の最適化に関する将来の研究への道を開くものと考えていると期待を述べた。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 08 Aug 2024 05:52:34 +0000</pubDate></item><item><title>Google DeepMindが国際数学オリンピックで銀メダルレベルのスコアを達成するAI「AlphaProof」「AlphaGeometry 2」を発表</title><link>https://ledge.ai/articles/google_deepmind_alpha-geometry2_alpha-proof</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは、形式的な数学推論と幾何学問題を解決するための新たなAIシステム「AlphaProof」と「AlphaGeometry 2」を開発し、国際数学オリンピック（IMO）で銀メダルレベルのスコアを達成したことを{target=“_blank”}した。この成果は、AIによる数学的推論能力の進化を示すものであり、今後の研究や応用に大きな可能性を開くものとなる。

## AlphaProofとAlphaGeometry 2の概要
「AlphaProof」は、数学の命題を形式言語「Lean」を用いて証明するシステムで、これまでAlphaZeroが囲碁や将棋、チェスで達成した成功を基に開発された。AlphaProofは数百万の数学問題を解決することで自己学習を進め、今回のIMOでは、特に難易度の高い代数、数論の問題を解くことで28点を獲得。このスコアは、IMOでの銀メダル基準に相当し、金メダルの境界までわずか1点差であったという。

!
:::small
画像の出典：{target=“_blank”}
:::

一方、「AlphaGeometry 2」は幾何学問題に特化したニューロ・シンボリックハイブリッドシステムである。過去のIMO問題に対する成功率を83%まで引き上げ、今回のIMOでも複雑な幾何学の問題を迅速に解決することに成功した。特に、AlphaGeometry 2は新たな知識共有メカニズムを利用し、複数の検索ツリーを組み合わせて問題を解くという。


2024年の国際数学オリンピックでは、AlphaGeometry 2は下図「{target=“_blank”}」を受け取ってからわずか19秒で解答を導き出したとのこと。


!
:::small
画像の出典：{target=“_blank”}
:::

## AIが数学分野にもたらす影響
今回の成果は、AIが人間の領域である高度な数学的推論をも補完できる可能性を示しており、数学教育や研究、さらには他の科学技術分野への応用が期待されているという。DeepMindの研究チームは、これらの技術がさらに発展することで、AIがより複雑な数学的問題や新しい理論の発見に貢献できることを目指していると述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 02 Aug 2024 08:34:13 +0000</pubDate></item><item><title>AIモデルの「モデル崩壊」に対する脆弱性が判明　他のAIモデルが生成したデータを学習することのリスク</title><link>https://ledge.ai/articles/ai_models_collapse_when_trained_on_recursively_generated_data</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月25日、オックスフォード大学のイリア・シュマイロフ氏率いる研究チームが、AIモデルが「モデル崩壊」と呼ばれる現象に対して根本的に脆弱であることを示す論文を学術誌『Nature』に{target=“_blank”}した。

この現象は、他のAIモデルによって生成されたデータを学習することで発生し、AIモデルが時間とともに基礎となるデータ分布を忘れてしまうという退化プロセスを指すという。

論文では、モデル崩壊の現象を視覚的に示すために、言語モデルを用いて実験を行った。下図は、モデルの世代が進むにつれてデータの品質がどのように劣化するかを示している。

図a：モデル崩壊のフィードバックメカニズムの高レベルの説明。初期データは人間によってキュレーションされたものであり、時間とともにモデル生成データがデータセットに加わる。
!
:::small
画像の出典：{target=“_blank”}
:::


図b, c：異なる世代のモデルが生成するデータの複雑度（perplexity）のヒストグラム。初期モデルが生成したデータは高品質だが、世代が進むにつれてデータの品質が低下し、エラーが蓄積される

!
!


:::small
画像の出典：{target=“_blank”}
:::

研究によると、「モデル崩壊」を防ぐためには、人間が生成したデータに依存することが重要だという。AI生成データと人間生成データを区別し、適切にフィルタリングする必要がある。例えば、AI生成データにウォーターマークを付ける方法が提案されているが、これには大規模な調整と協力が必要とされる。さらに、元のデータ分布にアクセスし続けることが不可欠であると強調した。

この研究は、将来的なAIモデルの開発において、人間の監視とデータの管理の重要性を示しているという。AIの生成するデータの品質と信頼性を確保するため、AIモデルのトレーニングデータの出所を明確にし、人間の生成するデータを活用することが不可欠だと述べられている。


:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jul 2024 08:46:28 +0000</pubDate></item><item><title>ディープフェイク画像の新たな見抜き方「眼の中の星を観て検出」ー英国王立天文学会で発表される</title><link>https://ledge.ai/articles/want_spot_deepfake_look_stars_their_eyes</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月14〜19日にイギリスで開催された{target=“_blank”}で、イングランド・ハル大学の研究チームは、銀河の測定に使用される天文学的手法を応用して、ディープフェイクを見分ける新たな技術を{target=“_blank”}した。この手法は、人間の目の反射に基づいて画像の真偽を判断するものだという。

同大学の大学院生アデジュモケ・オウォラビが中心となった研究チームは、ディープフェイク画像の目の反射に不一致が見られることに着目した。通常、現実の人間の目では左右の目の反射が一致するが、AI生成画像ではこの反射が物理的に一致しないことが多いという。

研究チームは、天文学で使用される手法を応用して反射を定量化し、左右の眼球の反射の一致性をチェックした。まず、光の分布を測定し、眼球の反射の形態学的特徴を分析するためにCAS（集中度、非対称性、平滑性）指標を使用したが、これは偽の目の予測には成功しなかった。一方、Gini係数を用いることで、反射の不一致を検出することができたという。Gini係数は、銀河の画像の光がピクセル間でどのように分布しているかを測定するためのものであり、この手法が眼球の反射の分析に有効であることが示された。

下の画像は、それぞれの目に一貫性のない反射を示すディープフェイクの目を並べたもの


!
:::small
画像の出典：{target=“_blank”}
:::

こちらは、両目にほぼ一貫した反射を示す本物の目を写したもの

!
:::small
画像の出典：{target=“_blank”}
:::


この新しい方法により、ディープフェイクの検出精度が向上することが期待されるが、万能な解決策ではないと研究者たちは強調している。ハル大学のケビン・ピンブルト教授は、「この方法はすべての偽画像を検出できるわけではなく、誤検出や見逃しが存在する。しかし、ディープフェイクとの戦いにおいて重要な基盤を提供する」と述べた。



:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jul 2024 08:39:52 +0000</pubDate></item><item><title>Stability AI、新たなマルチアングル映像生成モデル「Stable Video 4D」を発表</title><link>https://ledge.ai/articles/stability_ai_svd-4d</link><description>:::small
画像の出典：{target=“_blank”}
:::

Stability AIは2024年7月24日、1本の動画から8つの異なるアングルやビューの動画を生成するAIモデル「Stable Video 4D」を{target=“_blank”}した。このモデルは、ユーザーが動画をアップロードするだけで、複数の視点からの映像を簡単に生成できるという。

Stable Video 4Dは、Stability AI初のVideo to Video生成モデルで、Stable Video DiffusionとStable Video 3Dを基に開発されたという。ユーザーは希望する3Dカメラの視点を指定することで、入力動画に映るオブジェクトの新規ビュー動画（4D画像マトリックス）を生成し、8つの異なるアングルの動画を出力できる。

@

このモデルは、5フレームの動画を約40秒で生成し、全体の4D最適化には約20～25分かかるという。

Stability AIは、この技術がゲーム開発、動画編集、VRコンテンツ生成などの分野で大きな応用可能性を持つと説明している。複数の視点からオブジェクトを視覚化する能力により、製品のリアリティと没入感を高めることができると期待されているとのこと。

Stable Video 4Dのトレーニングデータセットには、Open Data Commons Attribution Licenseが配布するObjaverseが利用されたという。

現在、Stable Video 4Dは研究段階にあり、{target=“_blank”}で利用可能とのこと。Stability AIのチームは、合成データセットに加えて、実世界のビデオにも対応できるようモデルを最適化している。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jul 2024 08:55:27 +0000</pubDate></item><item><title>枯渇するAIトレーニングデータ：データ収集の新たな課題とその影響　MIT主導の調査団体が発表</title><link>https://ledge.ai/articles/dpi_consent_in_crisis_paper</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

AIモデルのトレーニングに必要となる大量のテキスト、画像、動画データは、主にインターネットから収集されるが、近年、多くのWebサイトがロボット排除プロトコル（robots.txt）を使用して自動収集をブロックしている。また、利用規約を変更してデータの使用を制限するサイトも増えているという。

2024年7月19日の{target=“_blank”}の記事によると、AI企業が使用可能なデータの総量は1年で約5％減少し、高品質なデータは約25％が利用できなくなっているという。これらの制約は、特にニュースサイトやソーシャルメディアプラットフォームからのデータ収集において顕著であるとのこと。

MIT主導のData Provenance Initiative（DPI）によるこの調査は、問題の深刻さを浮き彫りにしている。DPIは、AIトレーニング用データセット「C4」「RefinedWeb」「Dolma」に含まれる1万4,000件のWebドメインを分析し、クローリングで得られるデータとその使用に関する同意状況の変化を追跡した。その結果、これらのデータセットにおけるトークンの約45％が、利用規約の変更により使用制限がかけられていることが判明したという。

DPIは、MITメディアラボのプロジェクトとして開始され、AIトレーニングデータセットのライセンスおよび帰属に関する大規模な監査を行う団体だ。法律および機械学習の専門家が協力し、データセットの出所や使用に関する透明性を向上させることを目的としているという。
## データ制限の現状とその傾向
調査によると、2023年から2024年の間にC4データセットの5％以上、最も重要なソースの28％以上がrobots.txtによって制限されている。また、利用規約による制限は全体の45％に及ぶ。

下図は、2016年から2024年までの期間における、主要なWebドメインにおけるrobots.txtと利用規約の制限の変化を示している。この図は、AI組織のクローラーに対する制限の増加を視覚的に示すもので、特に2023年以降、AIクローラーに対するrobots.txtの制限が急増していることが明らかにされている。

!
:::small
画像の出典：{target=“_blank”}
:::

## 主要なデータ制限の例
- **RedditとStackOverflow：**  各サイトは、AI企業に対してデータアクセスを有料化している
- **The New York Times：** NYTは、OpenAIやMicrosoftを著作権侵害で訴えており、これらの企業がニュース記事を許可なく使用してAIモデルをトレーニングしたことが原因と考えている

高品質なデータの減少は、AIモデルの性能低下や、公開データセットに依存する小規模なAI開発者に対して影響を及ぼすという。

OpenAIは、クローリングによるデータ収集が{target=“_blank”}しているが、出版社やコンテンツ提供者向けにオプトアウト機能を提供するなど、倫理的なデータ利用を推進している。同社は、クローリングによるデータ収集が法的に認められている地域であっても、コンテンツ提供者の意向を尊重する姿勢を示しているという。

DPIは、Web上のデータ収集に関する同意の取り扱いが不十分で、多くのサイトがAI開発に対してデータ利用を制限していると指摘。この傾向は、今後も続くと予測され、AI技術の発展において重大な影響を及ぼす可能性があると述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Jul 2024 22:32:48 +0000</pubDate></item><item><title>AIエージェントに「心の理論」を実装すると、他のエージェントの状態を推測して行動するーースタンフォード大学の研究</title><link>https://ledge.ai/articles/hypothetical_minds</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

スタンフォード大学の研究チームは2024年7月9日、認知科学に基づく設計で、他のエージェントの状態を推測して行動するエージェント「Hypothetical Minds」の成果を{target=“_blank”}した。このモデルは、競争、協力、混合動機のマルチエージェント環境で他のエージェントの戦略や目標を推測し、適応的な行動を取ることができるという。

Hypothetical Mindsは、LLMを中核に据えた認知的なアーキテクチャを特徴とし、認識、記憶、階層的な計画のためのモジュールを統合している。特に、心の理論モジュール（ToMモジュール）を搭載しており、他のエージェントの戦略や目標に関する仮説を自然言語で生成、評価、改良する機能を持つという。

このToMモジュールは他のエージェントの行動を観察し、仮説を生成してからその仮説を評価、改良する一連のステップを経る。このプロセスにより、Hypothetical Mindsは他のエージェントの行動を効果的に推測し、適応的な戦略を実行することが可能となる。

下図は、Hypothetical Mindsがどのようにして他のエージェントの行動を予測し、仮説を評価・改良するかを示している。エージェントは観察データをもとに、他のエージェントの戦略に関する仮説を生成し、それを繰り返し評価することで、より正確な仮説に近づいていく。

!
:::small
画像の出典：{target=“_blank”}
:::


## 実験結果と評価
研究チームは、マルチエージェント環境「Melting Pot」ベンチマークにおいて、Hypothetical Mindsの性能を評価した。このベンチマークには、競争的、協力的、および混合動機のドメインが含まれており、30の異なる評価シナリオが存在する。

**競争環境（Running With Scissors）：** ゼロサムゲーム環境で、エージェントは他のプレイヤーの動きを予測し、対抗する戦略を選択する。Hypothetical Mindsは、固定的な戦略を採用するシナリオでも、適応的な戦略を用いるシナリオでも、常に高い報酬を得ることができた。

**協力環境（Collaborative Cooking Asymmetric）：** 非対称のキッチンでトマトスープを効率的に調理するために、エージェントが協力する。このシナリオでは、Hypothetical Mindsはパートナーのスキルや役割に適応し、高い協力成果を上げた。

**混合動機環境（Prisoner’s Dilemma）：** エージェントは協力または裏切りの選択を行うが、長期的な利益を最大化するためには協力が必要である。Hypothetical Mindsは、動的なパートナーとの相互作用で最も高いスコアを達成した。


Hypothetical Mindsは、LLMを活用して他のエージェントの意図を推測し、適応的に行動するエージェントとして、競争的、協力的、および混合動機のマルチエージェント環境で高い性能を発揮した。特に、心の理論モジュールの導入により、他のエージェントの戦略を効果的に推測し、それに基づいて行動を選択する能力が向上したことが確認されたという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 04:11:05 +0000</pubDate></item><item><title>ディズニーの研究チームが二足歩行ロボット『BD_X』を発表ーー「強化学習」で表現力豊かな動きを実現</title><link>https://ledge.ai/articles/disney_research_bdx</link><description>:::small
画像の出典：{target=“_blank”}
:::

ディズニーリサーチとウォルト・ディズニー・イマジニアリングの研究チームは2024年7月15日、エンターテインメント分野向けに特化した新しい二足歩行ロボット「BD_X」の設計と制御技術を{target=“_blank”}した。このロボットは、観客に対する魅力的なパフォーマンスを実現するために、芸術的な動きと動的な安定性を両立しているという。

@

このロボットは、ディズニーキャラクターのような表現力豊かな動きを実現することを目的としている。ロボットが芸術的な動きをしながらも、バランスを保って安定して動くことができるように設計されている。

「BD_X」は、両足に5つの関節、首と頭に4つの関節を持つ。このため、複雑で多彩な動きを可能にしている。さらに、強化学習によりロボットが芸術的な動きを学習し、実行するという。

下図は、キャラクターデザインと制御の全体的な流れを示している。アニメーションとロボットの設計が互いに影響し合いながら進められ、最終的にはリアルタイムでの操作が可能になる。

!
:::small
画像の出典：{target=“_blank”}
:::

強化学習とは、ロボットが試行錯誤を通じて最適な動きを学ぶ方法である。この技術を使って、ロボットはさまざまな動きや歩行を習得する。ディズニーの研究チームは、ロボットが立ったり歩いたり、特定の動作を繰り返したりするための複数の動きを学習させた。

実際の運用では、リモコンを使ってロボットを操作する。操縦者は、直感的な操作でロボットにさまざまな動きをさせることができる。この技術は、エンターテインメントだけでなく、教育や医療、サービス業などのさまざまな分野での応用が期待できるとのこと。

下図は、操縦者がロボットを操作し、人間と対話する様子を示している。上部の画像では、ロボットが紙巻きを見つけて、それをベンチの下に蹴り飛ばすシーンを演じている。下部の画像では、ロボットが人間に近づき、頭をなでられる様子を示している。このようにして、ロボットはさまざまな感情表現やインタラクションを実現する。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 04:07:03 +0000</pubDate></item><item><title>Microsoftがスプレッドシートなどの表計算ソフトを理解できる大規模言語モデル「SpreadsheetLLM」を発表　複雑なスプレッドシートの処理を削減</title><link>https://ledge.ai/articles/spreadsheet_llm_microsoft</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月12日、Microsoftの研究チームは、大規模言語モデルを活用してスプレッドシートの処理を効率的に行う技術「SpreadsheetLLM」を{target=“_blank”}した。

スプレッドシートは、ビジネスで広く使用されるデータ管理ツールだ。しかし、その複雑なレイアウトや多様なフォーマットで大量のデータを効率的に処理することは従来の手法では困難だったという。この課題改善のために、スプレッドシートの理解および、効率的に処理することを目的として「SpreadsheetLLM」が開発された。

SpreadsheetLLMの中心となるのは、「SheetCompressor」という手法で、表計算シート内で重要な構造を特定し、その情報を保持しながらデータ量を大幅に削減する。SheetCompressorは、表計算データを平均して25倍に圧縮することに成功しており、LLMが一度に処理できるデータ量が増加する。これにより、複雑な表計算ファイルの分析が可能となり、データ処理にかかる計算コストも96％削減されたという。

実験結果において、SpreadsheetLLMは表計算検索タスクで従来のモデルを12.3％上回る性能を達成したと発表している。
!

:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Jul 2024 14:44:17 +0000</pubDate></item><item><title>OpenAI　開発コードは「Q*」から「Strawberry」に。推論能力を向上し、数学などの高正答率を目指す新たなAI技術の開発が進んでいる</title><link>https://ledge.ai/articles/openai_strawberry</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月12日、ChatGPTを開発したOpenAIが「Strawberry」というコードネームの新しいAI技術に取り組んでいることが、内部文書と関係者の証言により明らかになった。{target=“_blank”}によれば、プロジェクトはMicrosoftが支援するOpenAIがAIモデルの推論能力を向上させるために進めているという。

OpenAIの内部文書によると、Strawberryは単に質問に答えるだけでなく、インターネットを自律的かつ信頼性を持ってナビゲートし、「深い研究」を行う能力を持つことを目指している。推論能力の向上により、AIモデルが複雑なタスクを計画し実行する能力を持つことが期待されているとのこと。

Strawberryプロジェクトは以前「Q*」として知られており、すでに社内で画期的なものと見なされていた。内部文書には、Strawberryモデルが複雑な科学や数学の質問に答えるデモを行うことができ、90%以上の正答率を記録していると記されている。

OpenAIは、この技術を使用してAIモデルの推論能力を大幅に向上させると期待を寄せており、特に、自動化された深い研究やソフトウェア・機械学習エンジニアの業務を行う能力を持たせることが目標だという。これにより、AIモデルが自主的にウェブを閲覧し、研究を行うための「CUA」（コンピュータ利用エージェント）を使用することが可能になる。

AIの推論能力が向上すれば、科学的発見の促進や新しいソフトウェアアプリケーションの計画・構築が可能となり、人間または超人間レベルの知能を実現する鍵となる。OpenAIのCEOであるサム・アルトマン氏も、AIにおける最も重要な進歩は推論能力の向上であると述べているという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 07:34:17 +0000</pubDate></item><item><title>Google DeepMind　Gemini1.5を使ってオフィス道順案内などのタスクを自然言語で実行させる</title><link>https://ledge.ai/articles/google_deepmind_mobility_vla</link><description>
:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年7月10日、同社のAIモデル「Gemini 1.5」の最大100万トークンという長大なコンテキストウィンドウを活用することで、オフィス内でのタスクを自然言語で解決させたと{target=“_blank”}した。この様子をデモ動画に納め、AIがオフィス内での道案内やタスク実行を行う様子を紹介している。例えば、「どこで絵を描けるか教えて」といった指示に対して、AIがユーザーをホワイトボードに案内する様子が示された。

!
:::small
画像の出典：{target=“_blank”}
:::

Gemini 1.5の特徴に「Mixture-of-Experts（MoE）」アーキテクチャが挙げられる。この技術により、AIモデルは入力に応じて関連する部分のみを活性化することができ、効率的に動作する。これにより、長文のQAや長時間の動画の理解など、従来のモデルでは困難だったタスクも高い精度で実行できるという。

Mobility VLAと呼ばれるナビゲーションポリシーは、長大なコンテキストウィンドウを持つ視覚と言語を組み合わせたAI（VLM）と、地図のような役割を果たすトポロジーグラフを使って、ロボットがどこに行くべきかを決定する仕組みを組み合わせている。このAIは、デモンストレーションツアービデオとユーザーからの指示をもとに、最適なルートを導き出す。

下図は、Mobility VLAのアーキテクチャを示している。デモンストレーションツアービデオとマルチモーダルユーザー指示を使用して、目標フレームを特定し、オフラインで構築されたトポロジーグラフを使用してロボットのアクションを生成する仕組みが描かれている。

!
:::small
画像の出典：{target=“_blank”}
:::

論文では、AIが自然言語での指示に基づいて、オフィス内の特定の場所にユーザーを案内する様子が紹介された。例えば「これを戻すべき場所は？」といった質問や、「スマートフォンを充電する場所は？」という指示に対して、AIが正確に応答することが示された。

研究チームは、Gemini 1.5が現実世界の大規模な環境での複雑な推論やマルチモーダルなユーザー指示において、最大90％の成功率を達成したと発表している。このモデルは、データセンターからモバイルデバイスまで幅広いプラットフォームで効率的に動作し、今後のAIの可能性に期待すると述べた。



:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Jul 2024 05:32:50 +0000</pubDate></item><item><title>スマホ上でも高速動作可能　NICTが21言語対応のニューラル音声合成技術を開発</title><link>https://ledge.ai/articles/nict_mobile_presen_tra</link><description>:::small
画像の出典：{target=“_blank”}
:::

国立研究開発法人情報通信研究機構（NICT）は2024年6月25日、ユニバーサルコミュニケーション研究所において、21言語に対応した高品質なニューラル音声合成技術開発に成功したことを{target=“_blank”}した。

この技術により、CPUコア一つで1秒の音声をわずか0.1秒で高速合成することが可能となり、従来モデルの約8倍の速さを実現した。また、ネットワークに接続されていないミドルレンジスマートフォン上でも、テキスト入力からわずか0.5秒で音声を生成できるという。

@


この新技術は、NICTが運用するスマートフォン用多言語音声翻訳アプリ「{target=“_blank”}」のサーバに搭載され、既に一般公開されている。今後は、商用ライセンスを通じて多言語音声翻訳やカーナビなど、様々な音声アプリケーションへの導入が期待される。

## 開発の背景
NICTのユニバーサルコミュニケーション研究所では、言語の壁を超えた音声コミュニケーションを実現するため、多言語音声翻訳技術の研究開発を{target=“_blank”}。特にテキスト音声合成技術は、音声認識や機械翻訳と同様に、多言語音声翻訳の実現に不可欠な技術である。従来の音声合成技術では、ネットワークに接続されていないスマートフォン上での合成が困難だったが、今回の開発によりその課題が解決されたとのこと。

## 技術の詳細
この技術は、入力テキストを中間特徴量へ変換する「音響モデル」と、中間特徴量を音声波形へ変換する「波形生成モデル」から成り立っている。「音響モデル」には、高速・高性能なConvNeXt型エンコーダとデコーダが使用されており、従来のTransformer型モデルに比べて3倍の高速化を実現。また、「波形生成モデル」には改良型のMS-FC-HiFi-GANが導入され、合成速度を4倍に引き上げているという。


!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::

</description><pubDate>Mon, 15 Jul 2024 14:08:36 +0000</pubDate></item><item><title>アルゼンチン　リアル『マイノリティ・リポート』！　AIによる未来の犯罪を予測するユニットが設立される</title><link>https://ledge.ai/articles/argentina_plans_unit_to_predict_crime_with_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

アルゼンチンのハビエル・ミレイ大統領は2024年7月29日、新たに「治安対策に応用された人工知能ユニット（UIAAS）」を設立する計画を{target=“_blank”}した。このユニットは、国内のサイバー犯罪・サイバー問題局の傘下に設置され、AIを活用して犯罪を予測し、未然に防ぐことが目的だという。

UIAASの主な機能は、過去の犯罪データを機械学習アルゴリズムで解析し、将来の犯罪を予測すること。さらに、リアルタイムで防犯カメラの映像を分析し、不審者や指名手配犯を検出するほか、ソーシャルメディアの監視、ドローンによる空中監視、サイバー攻撃への対応など、様々な先端技術を用いる​とのこと。

同ユニットの設立に対しては、プライバシーの侵害や表現の自由への影響などの懸念の声が上がっているという。特に監視技術の濫用が自己検閲を促し、市民の自由な発言を抑制する可能性が指摘されている。また、ブエノスアイレス市で過去に導入された{target=“_blank”}が誤認逮捕やデータの違法収集を引き起こしたことから、同様のリスクがあると批判する声もあるとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 09 Aug 2024 07:16:32 +0000</pubDate></item><item><title>文化庁が「AI著作権チェックリスト＆ガイダンス」を公開—AI時代の著作権リスク対策を強化</title><link>https://ledge.ai/articles/bunkacho_ai_copyright_checklist_and_guidance</link><description>:::small
画像の出典：{target=“_blank”}
:::

文化庁は2024年7月31日、2回目となる文化審議会著作権分科会政策小委員会を開催し、AI技術の普及に伴い著作権リスクを低減し、著作権者の権利を保護するための指針をまとめた「AI著作権チェックリスト＆ガイダンス」をウェブサイト上で{target=“_blank”}した。この資料は、AI開発者や提供者、利用者、さらに著作権者を対象とした実務的なアドバイスを提供しており、関連する公的資料からの抜粋や要点が盛り込まれている。

## 資料の構成と目的
この「AI著作権チェックリスト＆ガイダンス」は、全44ページにわたる資料で、2部構成となっている。

第1部は「AI開発・提供・利用のチェックリスト」（全24ページ）として、AI技術を利用する企業や個人が著作権に関わるリスクを回避するために必要な項目をリスト化している。具体的には、著作物の適正な使用方法や、データセット管理の重要性について詳細に説明されている。

!
:::small
画像の出典：{target=“_blank”}
:::


第2部は「権利者のためのガイダンス」（全15ページ）で、著作権者が自らの権利を守るために必要な情報や対応策が紹介されている。ここでは、AIが生成するコンテンツに対する権利の主張方法や、管理方法についての具体的な手引きが示されている。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の資料作成には、文化庁が2024年3月に発表した「AIと著作権に関する考え方について」、内閣府が同年5月に発表した「AI時代の知的財産権検討会　中間とりまとめ」、そして総務省と経済産業省が4月に発表した「AI事業者ガイドライン（第1.0版）」が参考として使用されている。

なお文化庁は、8月9日に著作権セミナー「AIと著作権II」をYouTube Liveで無料配信する予定。






:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 05 Aug 2024 03:09:58 +0000</pubDate></item><item><title>規約により「AIゆういちろう」一時休止へ。OpenAI「政治キャンペーンには使わないで」玉木雄一郎氏「Geminiで検討中」</title><link>https://ledge.ai/articles/ai_yuichiro_is_temporarily_suspended</link><description>:::small
画像の出典：{target=“_blank”}
:::

国民民主党代表の玉木雄一郎氏は2024年8月1日、同氏の運営するAIサービス「AIゆういちろう」を一時休止することを同氏のX（旧Twitter）アカウントで{target=“_blank”}した。

このサービスは、OpenAIのChatGPTを基盤にしており、ユーザーが玉木氏の政策に関する質問をすると、AIが自動で応答するものであった。しかし、OpenAIから「政治キャンペーンに利用することは規約違反である」との指摘を受け、急遽運用停止に至った​とのこと。

「AIゆういちろう」は、7月8日に公開され、わずか8日間で12万件以上の利用があり、API利用料が急増するなど、予想以上の反響を呼んだ。一連の出来事に対して、玉木氏はGoogleの生成AI「Gemini」への移行を検討しているとのことを明かした。

政治キャンペーンにAIを使用することを禁じている企業には、Meta や Microsoft が挙げられる。これらの企業は、AIを利用した選挙広告や誤情報の防止に重点を置き、選挙の透明性と信頼性を守るための規則を設けている。一方、安野たかひろ氏が東京都知事選で使用した「AIあんの」は、オープンソース技術を採用し、特定の企業規約に縛られないため、選挙活動には問題なく活用された。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 03 Aug 2024 14:07:21 +0000</pubDate></item><item><title>失われた声をAIで取り戻すーー米連邦会議で、闘病中の下院議員がAIを使った「自分の声」で演説</title><link>https://ledge.ai/articles/speech_in_her_own_voice_with_ai-voice</link><description>:::small
画像の出典：{target=“_blank”}
:::

民主党下院議員のジェニファー・ウェクストン氏は2024年7月25日、米連邦議会で、AIを利用して再現された「自分の声」で{target=“_blank”}した。

ウェクストン氏は進行性核上性麻痺（PSP）という神経疾患を患っている。PSPは、脳の特定の領域に影響を与えるまれな神経変性疾患で、運動機能やバランス、眼球運動に関する困難を引き起こす。同氏のケースでは、特に発話機能が深刻に損なわれ、通常の会話や即興の演説が困難になっているという。また、歩行困難や転倒のリスクも高まり、最終的には車椅子が必要となることが多いとのこと。

同氏は11日にX（旧Twitter）で「私の声が再び聞こえるのはAIのおかげ。これが健康やアクセシビリティの課題に直面する人々に力を与え、私たちの能力が私たちを定義しないことを示す助けになることを願っている」と{target=“_blank”}。また、「AIは悪意を持った人々によって誤用されると危険な新しいフロンティアになる可能性があるが、障害を持つアメリカ人にとって新しく、想像もつかないほどの人生を変える機会を提供することもできる」とも述べている。

25日は、毎年7月に祝われる障害者プライド月間を記念するために行われた特別な演説で、ウェクストン議員は自身のキャリアを通じて障害者の権利とアクセシビリティの問題に取り組んできたこと、そしてPSPの診断以来、それがどれほど個人的な戦いとなったかを語った。

「私がこの仕事を愛し続け、できる限り最善を尽くして生きている姿を見たとき、多くの異なる能力を持つアメリカ人が日々示す勇気、レジリエンス、そして精神を理解し、評価してもらいたい。AIの声であっても、障害を持つアメリカ人の声となれることを望んでいる。なぜなら、私たちはその障害だけで見られるべきではないからだ」とウェクストン議員は述べた。

ウェクストン議員を支えるAI音声モデルは、AIスタートアップのElevenLabsが開発したもの。同氏の演説データを基に数日間で作成されたとのこと。この技術は、従来のロボット音声とは異なり、自然で感情豊かな発声を可能にしているという。同氏が初めてこのAI音声を聞いたとき「最も美しい音だった」と涙を流したと語った。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 02 Aug 2024 08:18:11 +0000</pubDate></item><item><title>IPA「情報セキュリティ白書2024」を発行　アンケート回答でPDF版は無料配布 </title><link>https://ledge.ai/articles/ipa_wp-security_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

独立行政法人情報処理推進機構（IPA）は2024年7月30日、「情報セキュリティ白書2024」を{target=“_blank”}した。同白書は、国内外における情報セキュリティの最新動向やインシデント事例を詳述し、情報セキュリティの全体像を把握するための貴重な資料だという。

PDF版はアンケートに回答することで無料でダウンロード可能だ。印刷書籍は2,200円で、Amazonおよび全国官報販売共同組合が取り扱っているとのこと。IPAは2008年から毎年この白書を発行しており、情報セキュリティ分野の包括的な情報提供を行っているという。

白書では、2023年度の情報セキュリティ状況として、国家支援が疑われる攻撃者グループによるゼロデイ脆弱性を悪用した攻撃や、ファイル転送ソフトウェアを狙ったゼロデイ攻撃による情報漏えいとランサムウェア被害が報告された。また、名古屋港のコンテナターミナルがランサムウェア攻撃により停止するなど、日本国内でも深刻なサイバー攻撃が続いているという。

さらに、政府機関のサイバーセキュリティ対策基準の全面改訂や、福島第一原発処理水放出に関連する偽情報の拡散といったトピックも取り上げられており、現代のサイバー空間における多様な脅威に対する警鐘が鳴らされている。

「情報セキュリティ白書2024」は、情報セキュリティ分野の現状分析と将来展望を包括的にまとめており、その網羅性と参照性の高さが特徴となる。IPAによれば、同白書はセキュリティ対策を検討する企業や組織にとって、全体像を把握するための重要なリソースとなっているという。 

:::box

:::
:::box

:::
</description><pubDate>Thu, 01 Aug 2024 08:04:37 +0000</pubDate></item><item><title>複数のドローンを同時に無力化する高出力マイクロ波システム　日米共同研究で実用化へ</title><link>https://ledge.ai/articles/japan-us_joint_research_neutralizes_multiple_drones_simultaneously</link><description>:::small
画像の出典：{target=“_blank”}
:::


防衛省と米国防省は2024年7月16日、「高出力マイクロ波システムに係る日米共同研究」に関する事業取決めに署名を行ったと{target=“_blank”}した。

この共同研究は、将来の「ゲーム・チェンジャー」とされる高出力マイクロ波システム（HPM）の実用化に向け、日米で共同研究を実施するものだという。

HPMシステムは、無人航空機（UAV）などの脅威に対処するための技術で、強力な電波を照射して電子機器の誤作動や破壊を引き起こす。この技術は、複数のドローンを同時に無力化する能力を持ち、ドローン対策として注目されている。

今回の共同研究では、以下の具体的な内容が含まれている：

**米国内試験場での日米共同試験：** 防衛省の次世代装備研究所と米国防省の海軍研究局が主体となり、米国内の試験場で屋外試験を実施する。この試験により得られたデータを日米間で共有し、HPMの実用化に向けた課題を明らかにする

**高出力マイクロ波の効果評価：** 日米双方のHPMシステムを用いて、電子機器への高出力マイクロ波の効果を評価する。これにより、実用化に向けた教訓事項を得て改善点を明確にする

この共同研究は、防衛装備の技術と能力を向上させるための戦略的パートナーシップに基づいて行われる。HPMシステムは、現在の防衛技術の中でも特に注目される分野であり、日米両国の協力により、その実用化が期待されるという。

:::box

:::
:::box

:::
</description><pubDate>Mon, 29 Jul 2024 03:30:24 +0000</pubDate></item><item><title>DNPが、メタバースを活用した自治体サービス「メタバース役所」の提供を開始</title><link>https://ledge.ai/articles/dnp_metaverse_government_office</link><description>:::small
画像の出典：{target=“_blank”}
:::

大日本印刷株式会社（DNP）は2024年7月24日、インターネット上の仮想空間「メタバース」を活用した自治体サービス「メタバース役所」を提供開始すると{target=“_blank”}した。
## 「メタバース役所」の概要と共同利用モデルの特徴
メタバース役所は、複数の自治体が共同で運用し、サービス利用料を抑える共同利用モデルを採用している。

国内の各地域では、少子高齢化や大都市圏への人口集中による労働力不足が深刻な問題となっている。このような背景から、DNPは2021年より「XRコミュニケーション®」事業を展開し、自治体のデジタル化と地域活性化を支援しており、2024年2月に三重県桑名市との共同で行った実証実験で、電子申請手続きや市民相談、交流の場を提供するなどの経験を重ねて今回のサービス提供に至ったという。

複数の自治体が「メタバース役所」を共有することで、子育てや介護、不登校といった課題に対して連携して取り組み、住民サービスの質を向上させることができ、さらに、緊急時には複数の自治体が互いに支援し合う強固なBCP（事業継続計画）を構築できる。物理的な役所機能が滞った際にも連携先の「メタバース役所」で対応が可能になるそうだ。

DNPは、2028年度に10億円の売上を目指し、「メタバース役所」の運用と関連サービスの提供を継続的に強化していく方針。利用者のニーズに対応しながら、自治体のDX推進を一層支援していき、「メタバース役所」を通じて、誰一人取り残されない、人に優しいデジタル化を実現し、住民の生活の質向上に貢献していくとしている。

:::box

:::

:::box

:::

:::box

:::

:::box

:::
</description><pubDate>Sat, 27 Jul 2024 07:36:41 +0000</pubDate></item><item><title>米の映画俳優組合（SAG-AFTRA）、ストライキ開始を表明　ゲーム業界のAI利用問題で対立</title><link>https://ledge.ai/articles/sag-aftra_strike</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月25日、全米の俳優ら16万人が加入する映画俳優組合（SAG-AFTRA）は、ゲーム部門で働く全ての組合員がストライキを開始することを{target=“_blank”}した。
このストライキは、ゲーム業界における俳優の同意なしにAIを利用する問題に対する抗議として行われる。

SAG-AFTRAは、2022年10月からTake 2 Productions、Electronic Arts、Activision Blizzard、Warner Bros. Gamesなどの大手ゲームスタジオと交渉を続けてきた。この交渉の目的は、AIを用いて俳優の声や容姿を再現する際の事前同意や、AIが俳優を模倣する場合の適切な報酬の支払いがなされていないことにあった。しかし、約18ヶ月にわたる交渉の結果、ゲームスタジオとの交渉は決裂。これにより、SAG-AFTRAは組織のインタラクティブ・メディア契約に基づき、ゲーム部門で働く組合員によるストライキを承認した。

ゲームスタジオには、SAG-AFTRAと契約した俳優を声優、モーションキャプチャーのパフォーマンス、ゲーム内に登場させるなどの条件で採用する場合、SAG-AFTRAが提示する「Tiered-Budget Independent Interactive Media Agreement」および「Interim Interactive Media Agreement」に署名する必要がある。これらの契約には「組合員のための適切なAI保護」が含まれており、2500人以上のナレーションパフォーマー、モーションキャプチャーパフォーマー、スタントマン、スタントコーディネーター、歌手、ダンサー、人形遣い、バックグラウンドパフォーマーが対象となっている。

インタラクティブ・メディア契約交渉委員会のサラ・エルマレ委員長は、「彼らが私たち組合員全員に最適な条件を提示する準備ができた場合、再度交渉を開始する予定です」と述べ、また、SAG-AFTRAの最高契約責任者であるレイ・ロドリゲス氏は「ストライキは最後の手段です。私たちは責任を持ってできる限りの時間を使い交渉に臨んできました。しかし、交渉が成立する可能性が失われてしまったため、ストライキを実行します」と述べている。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 27 Jul 2024 07:29:23 +0000</pubDate></item><item><title>つくば市　NECとLLMおよび画像分析技術を活用した防災実証実験を実施</title><link>https://ledge.ai/articles/nec_tsukuba_supercity</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::


NECは2024年7月12日、茨城県つくば市において、大規模言語モデル（LLM）と画像分析技術を活用し、災害に強いまちづくりを目指す実証実験を行うと{target=“_blank”}した。この実証実験は、2024年11月から2025年1月まで行われ、住民が投稿した画像から街の状況をリアルタイムに可視化し、災害時の迅速な状況把握と対応を支援することを目的とする。

!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みは、2024年度の内閣府「先端的サービスの開発・構築及び規制・制度改革に関する調査事業（スーパーシティ・デジタル田園健康特区対象）」に採択されたことを受けて行われる。つくば市は2022年にスーパーシティに指定されて以降、「つくばスーパーサイエンスシティ構想」を掲げており、NECはその一環として本実証実験を実施するとのこと。

## 実証実験の概要
つくば市内の一部エリアで行われるこの実験は、住民が投稿した画像を収集し、LLMと画像分析によりダッシュボード上に可視化する。つくば市公式アプリ「つくスマ」を通じて、違法駐車や混雑する場所などの平時の状況を可視化し、災害時にはこれらのデータを活用して迅速な初動対応を可能にするという。

また実験では、災害時に投稿される画像に含まれる個人情報の取り扱いについても検証を行う。防災分野におけるデータ活用の可能性を広げ、より安全で安心な防災・減災対策の実現を目指すとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

NECは、この実証実験を通じて得られた結果をもとに、データ連携基盤の活用によるさらなるサービスの高度化を検討する予定だ。また、将来的にはデジタルツインの実装も視野に入れており、取得した情報を基に平時・災害時を通じた多様なサービスの開発を進めていく計画だという。



:::box

:::
:::box

:::

</description><pubDate>Wed, 24 Jul 2024 03:54:20 +0000</pubDate></item><item><title>AWS、政府のAI支援プロジェクト「GENIAC」における計算リソース提供者に選定</title><link>https://ledge.ai/articles/aws_selected_as_geniac_computational_resource_provider</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）2024年7月19日、経済産業省とNEDOが推進する国産生成AI開発力強化プロジェクト「GENIAC」（Generative AI Accelerator Challenge）において、同社が計算リソース提供者として選定されたと{target=“_blank”}した。このプロジェクトは、生成AI基盤モデルの開発を通じて日本国内の技術力を底上げし、企業のイノベーションを促進することを目的としている。
## プロジェクト概要
2024年2月に{target=“_blank”}したGENIACは、国内の生成AI開発力を強化することを目指している。このプロジェクトは、生成AIの基盤モデル開発に必要な高性能な計算資源を提供するだけでなく、開発者同士の連携や国際的な発信活動を支援することで、広範な技術革新を促進する。

## 助成内容
GENIACでは、スタートアップ企業や中小企業、学術機関に対して計算リソース利用料の2/3を助成し、その他の企業や団体には1/2を助成する。総助成額は最大245億円に達する予定。

プロジェクトでは、計算リソースの確保方法として二つの選択肢が設けられている：
1. 提案者が計算リソース提供事業者と個別に調整し、直接確保する方法
2. 経済産業省が計算リソース提供事業者から一括で確保し、提案者に提供する方法

AWSは後者の一括確保方法における計算リソース提供事業者として選定された。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 03:50:50 +0000</pubDate></item><item><title>内閣府　AI戦略会議で「AI制度研究会」のメンバーを発表、座長には東大松尾教授　AIに関する法規制のあり方を議論</title><link>https://ledge.ai/articles/cabinet_office_announces_members_of_ai_system_study_group</link><description>:::small
画像の出典：{target=“_blank”}
:::

内閣府は2024年7月19日、AIに関する法規制のあり方を議論するための「AI制度研究会」のメンバーを{target=“_blank”}した。研究会の目的は、AI技術の進展とそれに伴う社会的影響を考慮し、適切な法規制の枠組みを検討することである。

研究会の座長は、東京大学大学院の松尾豊教授が務める。その他のメンバーには以下の専門家が選ばれた（敬称略）

- 江間有沙（東京大学国際高等研究所東京カレッジ准教授）
- 岡田淳 （森・濱田松本法律事務所弁護士）
- 川原圭博 （東京大学大学院工学系研究科教授）
- 北野宏明 （株式会社ソニーリサーチ代表取締役プレジデント）
- 佐渡島庸平 （株式会社コルク代表取締役社長）
- 田中邦裕 （さくらインターネット株式会社代表取締役社長）
- 山口真一 （国際大学グローバル・コミュニケーション・センター准教授）

この発表は、同日に持ち回りで開催された第10回AI戦略会議において行われ、「AI制度研究会」の設置案が原案の通り決定された。同研究会は、AI技術の健全な発展とその利活用を促進するための法的課題や倫理的問題について、多角的な議論を進めることを目指すという。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 07:53:28 +0000</pubDate></item><item><title>気候変動による猛暑とAIで世界の電力需要急増、17年ぶりの増加率に　IEA報告</title><link>https://ledge.ai/articles/iea_reports_global_electricity_demand_to_surge_with_extreme_heat_and_aiiea_reports_global_electricity_demand_to_surge_with_extreme_heat_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

国際エネルギー機関（IEA）は2024年7月17日、2024年と2025年の電力需要は過去17年で最高の増加率を示す見込みだと最新のレポートを{target=“_blank”}した。特に気候変動による気温上昇、AI技術の普及が主な要因となっており、太陽光発電がその増加の半分を賄うとされている。
## AIとデータセンターの影響
AIの普及に伴いデータセンターの電力需要が急増しており、より信頼性の高いデータと精度の高い評価が求められている。IEAは、エネルギー部門とデジタル化の関係を研究する最前線に立っており、新たなイニシアティブ「エネルギーのためのAIとAIのためのエネルギー」を開始した。この一環として、IEAは政府、産業界、研究者、民間専門家と協議を行う予定である。2024年12月5日にパリで開催される「エネルギーとAIに関する国際会議」が重要なマイルストーンとなるとのこと。
## 需要の急増と再生可能エネルギーの拡大
IEAの「電力半期更新」報告によると、2024年の世界の電力需要は約4％増加し、これは2007年以来の最高年次成長率となる（金融危機やCOVID-19パンデミック後の特異な反発を除く）。この強い増加は2025年にも続き、同様に約4％の増加が見込まれている。

再生可能エネルギーの電力供給も急速に拡大し、2023年の30％から2025年には35％に増加すると予測される。2025年には、再生可能エネルギーによる発電量が石炭を上回る見通しで、特に太陽光発電が2024年と2025年の電力需要増加の約半分を賄う見込みである。太陽光と風力を合わせると、需要増加の約3/4を占めるとされる。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 07:48:24 +0000</pubDate></item><item><title>SunoとUdio、RIAAからの著作権訴訟に反論：「音楽の未来はフェアユースの中にある」</title><link>https://ledge.ai/articles/suno_and_udio_respond_to_copyright_lawsuit</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年8月1日、AI音楽生成企業の Suno と Udio が、6月に提起された著作権侵害訴訟に対し正式に反論を展開したと{target=“_blank”}が報じた。両社は、AIが生成する音楽がフェアユースに該当し、訴訟は音楽業界が新技術を抑制しようとする動きであると主張している。

ソニー・ミュージックエンタテインメント、ワーナー・レコード、ユニバーサルミュージックグループの3大レコード会社が6月、アメリカレコード協会（RIAA）を介して、AI音楽生成企業のSunoとUdioを著作権侵害で{target=“_blank”}。この訴訟は、SunoとUdioが著作権で保護された楽曲を無断でコピーし、それをAIモデルのトレーニングに使用していると主張している。
## 訴訟の背景と主張
訴状によれば、SunoとUdioはAI技術を用いて生成された音楽が、オリジナルの楽曲と直接競合し、その価値を下げると非難されている。RIAAの最高法務責任者であるケン・ドロショウ氏は、このケースを「著作権侵害の典型例」と位置付け、AI企業が法律を守らずに利益を得ようとしていると批判している。

これに対し、SunoとUdioは、両社のAI技術が生成する音楽はフェアユースの範囲内であり、著作権侵害には当たらないと主張している。特に、彼らはAIが既存の楽曲を使用して新しい作品を創り出すプロセスが「人間の創造性を促進する」ものであり、著作権法の下で許容されるべきだと強調した。

Sunoはさらに、レコード会社がAI技術に対して誤解を抱いているとし、同社の技術は既存の音楽スタイルやパターンを学習し、それを基に新しい楽曲を創作するプロセスであると説明した。これを、人間が音楽を学び、作曲する方法と比較し、AIも同様に創造的であり、単なる模倣ではないと主張している。また、彼らの技術はオープンインターネット上で公開されている楽曲から学習しており、他のAI技術と同様の手法であると付け加えている。

さらに、Sunoはこの訴訟を「事実と法律の両方で根本的に欠陥がある」とし、音楽業界が過去に新技術に対して取ってきた制限的なアプローチの一環であると非難している。同社は、音楽業界が競争を阻害するのではなく、共に新たなビジネス機会を模索するべきだと強調した。

## 音楽の未来
Sunoは8月1日にブログ記事「{target=“_blank”}」を公開し、同社の技術が音楽の創造を民主化し、より多くの人々に音楽創作の機会を提供することを目指していると説明した。Sunoは、すでに1200万人以上がこの技術を利用し、新しい形で音楽を楽しんでいると強調している。

Udioもまた、AIによる音楽生成が合法であると主張し、既存の音源を分析して新しい創作を行うことはフェアユースの典型であると訴えている。

両社は、レコード会社が市場シェアを守るために新技術を抑制しようとしているとし、この訴訟が競争を阻害するものであると反論している。

## RIAAのさらなる反論
しかし、RIAAは8月2日にX（旧Twitter）に投稿した声明で、SunoとUdioの反論に対してさらに強く反撃した。RIAAは、SunoとUdioがアーティストの楽曲を無断で大規模にコピーし、その価値を搾取していると批判し、これを「フェアユース」として正当化することはできないと強調している。また、Sunoの共同創設者がプラットフォームのデモで「Hendrix」というプロンプトを使用していたことを例に挙げ、Sunoの主張する「独自性の奨励」に対する疑念を示している 。

!
:::small
画像：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 08 Aug 2024 06:35:11 +0000</pubDate></item><item><title>パリ五輪2024、カナダ女子サッカー代表がドローンによるスパイ行為で波紋</title><link>https://ledge.ai/articles/coc-statement_on_canada_soccer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月27日、パリ五輪2024の開幕が華々しく行われたが、その陰でカナダ女子サッカー代表チームが{target=“_blank”}に見舞われた。カナダ代表は、ニュージーランド女子サッカーチームの練習をドローンでスパイしていたことが発覚し、監督とスタッフが追放される事態となった。

7月22日、ニュージーランド代表が練習をしているときにドローンが飛行していることに気づき、国際オリンピック委員会（IOC）のインテグリティ部門に通報。その結果カナダ代表チームの非公認の分析官であるジョセフ・ロンバルディ氏がドローンを操作していたことが判明し、フランス当局に逮捕され、執行猶予付きの判決を受け入れたという。

カナダのサッカーチームの監督であるビバリー・プリーストマン氏は、責任を取る形でパリ五輪から追放され、自ら初戦の指揮を辞退したという。カナダオリンピック委員会（COC）はニュージーランドのサッカー協会およびオリンピック委員会に謝罪を表明し、「フェアプレーを重視し、このような行為にショックを受け失望している」との声明を{target=“_blank”}した。

また、カナダのアシスタントコーチ、ジャスミン・マンダー氏もチームから外されることとなった。NZOCは、事件に対して深い失望を{target=“_blank”}し、選手とチームの支援に努めるとしている。

:::box

:::
:::box

:::</description><pubDate>Tue, 30 Jul 2024 03:37:57 +0000</pubDate></item><item><title>Sakana AIが新たな浮世絵生成モデルを開発　日本の伝統美をAIで再現</title><link>https://ledge.ai/articles/sakana_ai_evo-ukiyoe_evo-nishikie</link><description>:::small
画像の出典：{target=“_blank”}
:::

Sakana AIが2024年7月21日、浮世絵風画像生成モデル「Evo-Ukiyoe」と、浮世絵をカラー化できるモデル「Evo-Nishikie」を{target=“_blank”}した。これらのモデルは、同社が2024年4月に発表した、画像生成モデル{target=“_blank”}を基盤として開発された。
## Evo-Ukiyoe-浮世絵風画像生成モデル-

!

:::small
画像の出典：{target=“_blank”}
:::

Evo-Ukiyoeは、日本語のプロンプトから浮世絵風の画像を生成するモデルだ。風景や着物姿の人など、浮世絵によく取り上げられる題材について、高品質な画像を生成することができる。このモデルは、立命館大学アート・リサーチセンター（ARC）所蔵の24,038枚の浮世絵デジタル画像を学習データセットとして利用し、浮世絵の特徴を詳細に学習している。

桜や富士山、着物を着た人物など、Evo-Ukiyoeが認識しやすいプロンプトを入力することにより、浮世絵に近い画像を生成することができる。しかし、利用する上で「人物」の画像を生成する際の課題も挙がっているそうだ。「男性」と入力しても、女性の着物や髪型を生成してしまうことがあるため、この場合は男女を明確にする必要がある。プロンプトに「男性」、ネガティブプロンプトに「女性」と加えることで、よりイメージに近い画像を生成できるとのこと。
## Evo-Nishikie-浮世絵カラー化モデル-
!

:::small
画像の出典：{target=“_blank”}
:::

一方でEvo-Nishikieは、墨一色で摺られた浮世絵を、多色摺の浮世絵風にカラー化するモデルだ。江戸時代の本の挿絵をカラー化して、現代の絵本のように楽しむことができる。

これらのモデルは、本物の浮世絵と生成した浮世絵を比較することで、浮世絵の特徴を学ぶ材料となり、歴史や文化を学ぶための新たなコンテンツ作成のツールとしても利用できる。浮世絵や日本文化に興味を持つきっかけになることを期待しているそうだ。

Sakana AIは、公式サイトでEvo-UkiyoeとEvo-Nishikieのデモを公開している。ただし、各モデルは研究開発目的で商用利用などは想定しない。「本モデルの使用に伴うリスクを十分に理解し、自己の判断で使用する必要がある」とのこと。

:::box

:::

:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 09:04:15 +0000</pubDate></item><item><title>ディズニー内部Slackデータ1.1TiB流出「生成AIからアーティストの権利を擁護するハッカー集団」Nullbulgeの攻撃</title><link>https://ledge.ai/articles/disney_slack_leak</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月、ハッカー集団「Nullbulge」がウォルト・ディズニー・カンパニーの内部Slackチャンネルから約1.1テビバイト（TiB）のデータを流出させたと{target=“_blank”}した。

!
:::small
画像の出典：{target=“_blank”}
:::

上記のメッセージは、ハッカー集団Nullbulgeがディズニーの内部Slackデータを流出させ、その中には未公開のプロジェクト、ログイン情報、内部APIのリンクなどが含まれていることを伝えるもの。また、内部協力者が途中で撤退したことについて言及し、将来の警告として個人情報を公開するとしている。

Nullbulgeは、約10,000のSlackチャンネルから収集したメッセージやファイル、未公開プロジェクトの詳細、ログイン情報、内部APIやウェブページのリンクなどを含む1.1TiBのデータを公開したと主張している。このデータは、ハッキングフォーラムやソーシャルメディアで広く共有されているという。

同集団は、ディズニーがアーティストとの契約を不適切に扱い、AI技術の導入に対するアプローチが問題であり、さらに消費者を無視していると主張し、このハッキングを行った理由を説明している。特に、ディズニーが「スター・ウォーズ」や「エイリアン」シリーズの作者に対するロイヤリティの支払いを停止したことが批判の中心となっている。

現在、ディズニーはこの事態を調査中であり、公式なコメントはまだ出されていない。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 08:59:41 +0000</pubDate></item><item><title>安達寛高（乙一）ら原作・監督　全編生成AI制作の映画「generAIdoscope：ジェネレイドスコープ」2024年公開予定</title><link>https://ledge.ai/articles/the_film_generaidoscope_produced_entirely_with_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

映画や映像の企画・立案などを行うリアルコーヒーエンタテインメントは2024年7月10日、同社による企画で全編生成AIで制作されるオムニバス形式の映画「generAIdoscope：ジェネレイドスコープ」の製作を{target=“_blank”}した。2024年内の劇場公開を予定しているとのこと。


!
:::small
画像の出典：{target=“_blank”}
:::

「generAIdoscope：ジェネレイドスコープ」は、その全編が生成AIによって制作されるという点が最大の特徴だ。映像、音声、音楽すべてがAI技術を駆使して生成されることで、従来の映画制作とは一線を画す新しい試みとなっているという。映画の原作・監督には、各ジャンルで活躍する映像作家が名を連ねている。安達寛高（乙一）、曽根剛、山口ヒロキの3人がそれぞれ独自の物語を手がける。

### 安達寛高（乙一）氏「モンキーズ・オデッセイ」
大航海時代を舞台に、船乗りが猿たちの住む無人島に漂着する物語「モンキーズ・オデッセイ」を描く。

### 曽根剛氏「AZUSA」
空想癖のある風変わりな女の子が夢を叶えるために二つの世界を行き来する「AZUSA」。この作品では、ファンタジーとリアリティの融合が見どころとなる。

### 山口ヒロキ氏「グランマレビト」
遠い未来の世界を舞台に、元魔術師の老婆が架空の国家を旅する「グランマレビト」を監督。壮大な未来世界のビジョンと共に、人間ドラマが展開される。


@


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 10:07:20 +0000</pubDate></item><item><title>優勝はモロッコのAI美女　世界初のAIビューティーコンテスト「Miss AI 2024」の受賞者発表</title><link>https://ledge.ai/articles/fanvue_miss_ai_winners</link><description>
:::small
画像の出典：参加者たちのインスタグラムより
:::

World AI Creator Awards（WAICA：世界AIクリエーター賞）が2024年7月、「Miss AI 2024」の受賞者を{target=“_blank”}した。このコンテストは、AIによって生成されたモデルが参加する世界初のビューティーコンテストとして、Fanvueとの共同開催で実現したという。

## 受賞者一覧
### 第1位：Kenza Layli（ケンザ・ライリ）氏　モロッコ出身
!
:::small
画像：{target=“_blank”}
:::

1位の栄冠に輝いたモロッコ出身のケンザ・ライリ氏は5,000ドルの賞金に加え、3,000ドル相当のAIメンターシッププログラム、および5,000ドル以上のPR支援を受ける。同氏は、モロッコの文化に根ざした魅力的なコンテンツで19万人以上のフォロワーを獲得し、審査員たちから高い評価を受けたとのこと。

### 第2位：Lalina（ラリーナ）氏　フランス出身

!
:::small
画像：{target=“_blank”}
:::

2位のラリーナ氏には2,000ドル相当のプロモーションパッケージと2,500ドル以上のPR支援が提供された。フランスからの参加で、特に技術力とプロモーション力が評価された。同氏の作品は、その精巧なデザインと高い技術力で注目を集めた。 

### 第3位：Olivia C（オリビア・C）氏　ポルトガル出身
!
:::small
画像：{target=“_blank”}
:::

3位のオリビア・C氏には、2,000ドル相当のプロモーションパッケージとコンサルティングコールを受け取った。ユニークなアプローチと創造性が高く評価された。同氏の作品は、多くのファンから支持を受け、コンテストでも高い評価を得たという。

## コンテストの概要
「Miss AI」は、AIによって生成されたモデルが美しさ、技術力、そしてソーシャルメディアでの影響力を競う新しい形式のビューティーコンテストだ。参加者は、見た目の美しさやポーズ、そしてAIツールを使用した技術力に加え、ソーシャルメディアでのフォロワー数やエンゲージメント率なども評価対象となる。

今回のコンテストには、トルコ、バングラデシュ、ブラジルなど世界中から多くのAIモデルが参加した。参加者たちはそれぞれ独自のAIモデルを作成し、その創造性と技術力を{target=“_blank”}した。


:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 09:45:31 +0000</pubDate></item><item><title>生成される画像の価値とは何なのか？　ライゾマティクスが「AIと生成芸術」がテーマの個展を開催中</title><link>https://ledge.ai/articles/rhizomatiks_beyond_perception</link><description>:::small
画像の出典：{target=“_blank”}
:::

クリエーター集団のライゾマティクスが、AI技術を活用した新しいアートの形を提案している。KOTARO NUKAGA（天王洲）の拡張移転に伴い、2024年6月29日から9月28日までの3ヶ月間にわたり、「AIと生成芸術」をテーマに個展「Rhizomatiks Beyond Perception」を{target=“_blank”}する。

展覧会では、ライゾマティクスが独自に作成した画像のみを学習したAIモデルを新たに開発し、その成果を展示する。現代において誰もがAIを使って画像を生成できる中、ライゾマティクスは「生成される画像の価値とは何なのか？」という問いを観客に投げかける。

展示作品の一環として、初めて販売されるのは “AIモデルデータ” である。購入者はこのAIモデルを使って入力を変えることにより、無限に画像を生成する体験が可能となる。このAIモデルデータは、ライゾマティクス自身の作品108本の映像を静止画に変換した約17万枚の画像を学習データとして使用し、既存の基盤モデルを一切使用せずにゼロから開発されたものだという。

### 展覧会概要
**会期:** 2024年6月29日（土） – 9月28日（土）
**開廊時間:** 11:00 – 18:00（火曜日から土曜日、日月祝休廊）
**会場:** KOTARO NUKAGA（天王洲）
**住所:** 東京都品川区東品川1-32-8 TERRADA Art Complex II 1F
**アクセス:** 東京臨海高速鉄道りんかい線「天王洲アイル駅」から徒歩約8分、東京モノレール羽田空港線「天王洲アイル駅」から徒歩約10分、京急本線「新馬場駅」から徒歩約8分



:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Jul 2024 07:35:19 +0000</pubDate></item><item><title>ハリウッド撮影クルー、AI使用も雇用維持で合意</title><link>https://ledge.ai/articles/hollywood_iatse_amptp_agreement</link><description>:::small
画像の出典：{target=“_blank”}
:::
全米のエンターテインメント産業の撮影現場で働く労働者の組合「IATSE」と主要スタジオを代表する「AMPTP」は2024年6月27日、AIの使用を認めながらも雇用を維持することで合意に達したと{target=“_blank”}した。
この合意は、「ハリウッド基本合意」と「ビデオテープ合意」の枠組みで成立し、IATSEの約50,000人のメンバーに影響を与えるものだという。
## 合意の詳細
今回の合意には、AIの使用に関する新たな保護措置が含まれている。具体的には、AIが労働者の職を奪うことがないようにするための条項が盛り込まれ、労働者がAIプロンプトを提供する場合でも、それが雇用喪失につながらないようにする対策が取られている​。また、賃金の引き上げも合意され、契約期間中3年間で7%、4%、3.5%のスケール賃金率の引き上げを予定しているとのこと。

## 交渉の背景
IATSEは衣装デザイナーやヘアスタイリスト、照明技術者、カメラオペレーターなど、多岐にわたる職種の労働者を代表している。今回の合意は、生成AIの台頭により雇用の危機感が高まる中で、労働条件の是正を求め{target=“_blank”}したものだ。特にコロナ禍のパンデミック以降、ハリウッドの労働者たちは自身の権利と雇用条件についてより積極的に声を上げている。

この合意はまだIATSEのメンバーによる批准が必要だが、正式に承認されれば、ハリウッドの労働環境におけるAIの影響を適切に管理しながら、労働者の権利と雇用を保護する新たな枠組みが確立されることになる見通し。また、同様の合意が他の労働組合との間でも期待されており、エンターテインメント産業全体での労働環境の改善が見込まれているという。

全米の映画俳優組合（SAG-AFTRA）によるストもAMPTPとの暫定合意に達し、2023年11月に終結している。


:::box

:::
:::box

:::

</description><pubDate>Fri, 05 Jul 2024 07:31:03 +0000</pubDate></item><item><title>大阪・関西万博に実物大ガンダム登場へ　バンダイナムコHDが展示計画を発表
</title><link>https://ledge.ai/articles/bandainamco_gundam</link><description>:::small
画像の出典：{target=“_blank”}
:::

バンダイナムコホールディングスは2024年6月26日、2025年に開催される大阪・関西万博で「機動戦士ガンダム」の実物大模型を展示すると{target=“_blank”}した。このガンダム像は、かつて横浜で展示されていた動く実物大ガンダムの部材を再利用しており、関西での展示は初めてとのこと。

展示されるガンダム像は高さ約17メートルで、片膝を立て片腕を上げたポーズを取っている。2020年から2024年3月末まで横浜市の「GUNDAM FACTORY YOKOHAMA」で展示されていた動く実物大ガンダム像の装甲部分を、頭部から足までほぼ再活用しているが、今回の展示では動くことはないという。

このガンダム像は、大阪・関西万博のパビリオン「GUNDAM NEXT FUTURE PAVILION」の近くに展示される予定。パビリオン自体は内装を除き2024年7月の完成を予定しているという。

@

バンダイナムコホールディングスでガンダムシリーズの知的財産戦略を担当する榊原博社長は、「ファンの方と一緒につながりたい」と述べ、ファン参加型の企画を計画していると明らかにした。2024年は「ガンダム」のテレビアニメ放映45周年にあたり、全国で関連イベントが開催される予定だ。SNS上でファンからのメッセージを募集し、その一部はパビリオン内で投影される。


:::box

:::
:::box

:::
</description><pubDate>Mon, 01 Jul 2024 13:23:40 +0000</pubDate></item><item><title>Mantraが7.8億円調達を実施　画像認識とLLM（大規模言語モデル）を併用したマンガ特化の翻訳ツール開発　</title><link>https://ledge.ai/articles/mantra_engine_ai_manga</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月26日、マンガAI翻訳技術の開発を行うMantra株式会社は、集英社、小学館、KADOKAWA、スクウェア・エニックス・ホールディングスなどから、総額7億8000万円の資金調達を行ったことを{target=“_blank”}した。

Mantraが開発した「Mantra Engine」は、AIを活用したマンガ/縦スクロールコミックの翻訳を効率化するクラウドツールだ。画像認識とLLM（大規模言語モデル）を併用し、キャラクターやストーリーを考慮しながら、ブラウザ上で翻訳に関わるすべての作業を完結させる。現在は、国内外の出版社や翻訳会社、配信事業者を中心に利用されており、集英社の人気マンガ『ONE PIECE』『SPY×FAMILY』のベトナム語版などの制作にも用いられている。

今回の資金を活用し、向こう5年を目処に「エンドユーザーが楽しんで読める」を目指し、マンガAI翻訳の精度向上に取り組むと同時に、小説やゲーム、動画への翻訳技術転用を本格化させる研究開発も進めていくという。

Mantraの代表取締役である石渡 祥之佑氏は、「エンタメから言語の壁をなくしたい」という明確な目的意識を創業前から持っており、昨今の急速に進むLLMや画像生成AIの進化を見て、「言語の壁がなくなる未来が少しずつ現実のものとして想像できるようになった」と述べている。

:::box

:::

:::box

:::

:::box

:::

</description><pubDate>Sun, 30 Jun 2024 21:14:19 +0000</pubDate></item><item><title>KRAFTON JAPAN　GPT-4o搭載の推理アドベンチャーゲーム『Uncover the Smoking Gun』を正式リリース</title><link>https://ledge.ai/articles/uncover_the_smoking_gun</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月25日、KRAFTON JAPAN株式会社は、AI技術を搭載した推理アドベンチャーゲーム『Uncover the Smoking Gun』をリリースしたと{target=“_blank”}した。

『Uncover the Smoking Gun』は、KRAFTON JAPAN傘下のクリエイティブスタジオ「ReLU Games」が制作した、ロボットと人間が共存する近未来を舞台にした没入型推理アドベンチャーゲームだ。プレイヤーがAI専門の探偵となり、事件の手がかりを追いながら、容疑者であるロボットに対してチャットで尋問していく。

OpenAIがリリースした「GPT-4o」を搭載しており、容疑者のロボットは単純に質問に回答するだけではなく、プレイヤーの性格に合わせた口調で、まるで実際に人とチャットで会話しているような感覚で楽しめるという。ロボットの曖昧な証言を見極め、真実にたどり着くために鋭い質問を投げかけながら、事件解決を目指す没入型の推理ゲーム。

『Uncover the Smoking Gun』は、現在Steamでダウンロード可能。日本語、韓国語、英語、中国語など全8言語に対応しており、詳細はSteamページおよびReLU Games公式サイトで確認できる。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:57:02 +0000</pubDate></item><item><title>Google DeepMindが動画に合うBGMや効果音を生成するAI「Video to Audio」を発表</title><link>https://ledge.ai/articles/google_deepmind_v2a</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年6月17日、新たな技術「Vide to Audio（V2A）」を{target=“_blank”}した。Generative Mediaチームの発表したこの技術は、動画の映像情報とテキストのプロンプトを用いて、映像にぴったりと合ったサウンドトラックを生成する能力を持つ。

現在、映像生成モデルは急速に進化しているが、多くの現行システムは無音の出力しか生成できない。V2Aは、この課題を解決し、生成された映像にリアルな音響を付与するための重要なステップとなる。

V2Aは、映像ピクセルと自然言語テキストプロンプトを組み合わせて、画面上のアクションに対してリッチな音響効果を生成する。例えば、ドラマチックなスコア、リアリスティックな音響効果、またはビデオのキャラクターやトーンに合ったダイアログを生成することが可能だ。

{target=“_blank”}（音声プロンプト： 映画、スリラー、ホラー映画、音楽、緊張感、雰囲気、コンクリートの上の足音）

!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}（音声プロンプト: 月に向かって吠えるオオカミ)

!
:::small
画像の出典：{target=“_blank”}
:::

## V2Aの技術的詳細
V2Aシステムは、ビデオ入力を圧縮された表現にエンコードし、拡散モデルがランダムなノイズから音声を逐次的に洗練させる。このプロセスは視覚的入力と自然言語プロンプトによってガイドされ、プロンプトに密接に一致する現実的な音声を生成する。最終的に音声出力がデコードされ、音声波形に変換され、ビデオデータと組み合わせられる。

また、高品質な音声を生成するために、詳細な音の説明や音声トランスクリプトを含むAI生成のアノテーションを追加情報としてトレーニングプロセスに加えた。これにより、特定の音声イベントを様々な視覚シーンと関連付けることが可能となり、アノテーションやトランスクリプトで提供された情報に基づいて音声を生成できるという。

!
:::small
画像の出典：{target=“_blank”}
:::


## 創造的なコントロールと今後の展望
V2Aは、任意のビデオ入力に対して無限のサウンドトラックを生成する能力を持つ。ユーザーは「ポジティブプロンプト」を定義して望ましい音にガイドするか、「ネガティブプロンプト」を使用して望ましくない音を排除することができる。この柔軟性により、V2Aの音声出力を迅速に実験し、最適なマッチを選択することが可能だという。


以下は、同じ動画に対して複数のサウンドを生成した例
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）
{target=“_blank”}(音声プロンプト: 優美なチェロの雰囲気）
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）

!
:::small
画像の出典：{target=“_blank”}
:::


Google DeepMindは、責任あるAI技術の開発を重視し、クリエイティブコミュニティからの多様な視点や洞察を収集し、研究と開発に反映させているとのこと。また、AI生成コンテンツに透かしを入れるためのSynthIDツールキットも導入し、この技術の誤用を防ぐための対策を講じている。V2A技術は公開前に厳格な安全評価とテストを経る予定だという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 28 Jun 2024 12:32:10 +0000</pubDate></item></channel></rss>