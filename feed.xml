<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Thu, 02 May 2024 05:06:12 +0000</lastBuildDate><item><title>トヨタ・日産が、中国テック企業とAIで提携　北京モーターショー2024で戦略的パートナーシップを発表
</title><link>https://ledge.ai/articles/toyota_nissan_autochina2024</link><description>:::small
画像：{target=“_blank”}
:::

2024年4月25日、北京モーターショー2024で、トヨタ自動車と日産自動車がそれぞれ中国のテクノロジー企業との新たな提携を発表したことを各メディアが報じている。トヨタはテンセントと、日産は百度（Baidu）との間で、AIを中心とした提携を進めるとした。

トヨタは、テンセントの強みであるビッグデータ処理、AI、クラウドコンピューティングを活用し、2024年内に中国で製造される新型乗用車に技術を組み込む計画であると発表。一方、日産と百度は、AIやいわゆる「スマートカー」技術の研究を共同で進める覚書を締結し、将来の技術開発の可能性を探るとしている。
!
:::small
画像：{target=“_blank”}
:::

この{target=“_blank”}では、新エネルギー車が大きく注目を集め、過去最多の117車種が世界初公開されたという。展示された車両数は約1000台に上り、新エネルギーモデルは前回比70%増の278台が展示され、新エネルギー車のブランドが20以上初出展したとのこと。会期は5月4日まで。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 02 May 2024 05:06:12 +0000</pubDate></item><item><title>OpenAI　ChatGPTの「Memory」機能をすべての有料ユーザーに向けて提供開始</title><link>https://ledge.ai/articles/openai_chatgpt_memory_for_all_plus_users</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年4月29日、ChatGPTの新機能「Memory」の提供をChatGPT Plusユーザー全員に対して開始したと{target=“_blank”}した。

この機能は、ユーザーの過去のチャットを記憶し、個別の情報を繰り返し入力する手間を省く。2月よりこの機能がテストされていたが、このアップデートにより、有料会員のプラスユーザーなら全員使用できるようになったという。

Memory機能は、ユーザーとの対話を通じて情報を記憶し、次回以降の対話においてその情報を反映させるというもの。対話中にMemoryが更新されると「Memory updated」と表示され、記録された内容を確認できるようになっている。

たとえば「私のペットは、ゴールデンレトリバーのエリーと、メインクーンのテディ―です」と入力し、その情報を記憶させる。その後「私のペットたちがサーフボードに乗っている絵を作って」と依頼すると、ChatGPTが前述のレトリバーとメインクーンがサーフボードを乗りこなす画像を生成する。
!
:::small
画像：{target=“_blank”}
:::

Memory機能は、初期設定で「オン」に設定されており、ユーザーは設定画面からON・OFFの切り替えが可能。また、Memoryの管理（Manage）より、特定の記憶されたデータを選んで削除できる。ChatGPTとの対話で、何を記憶しているか確認し、それを忘れるように指示しデータを削除することも可能。チャット自体を削除しても記憶されたデータは消去されない。

!
:::small
画像の出典：{target=“_blank”}
:::

なお、この機能は企業向けプラン（Enterprise）およびチーム向けプラン（Teams）、そしてGPTsでの利用が予定されている。



:::box

:::
:::box

:::
</description><pubDate>Thu, 02 May 2024 05:02:19 +0000</pubDate></item><item><title>ニッセンが画像生成AIを活用し着用パターンを自動生成する実証実験を実施　生成された着用イメージで洋服を試着体験！</title><link>https://ledge.ai/articles/nissen_apparel_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月22日、株式会社ニッセン、BIPROGY株式会社、株式会社メタクロシスの３社は生成AIを活用した衣服着用パターンを自動生成する実証実験を実施したと{target=“_blank”}した。

ECサイトの進化により実店舗へ足を運ばなくても好きな時間に手軽に買い物を楽しむことができる時代。アパレル業界でもECサイトの活用が進んでいるが、商品を実際に試着したイメージが掴みにくいという視点から、店舗スタッフやモデルの着用画像を掲載していることが多い。しかし、着用画像掲載にはコストもかかるため掲載の幅が限られている現状。このような課題を解決するため実証実験を実施した。

実証実験についてはメタクロシスのアパレルDXアプリ「FIGUR（フィギュア）」の画像試着機能を活用し、ニッセンの保有データをもとに着用パターンや着用イメージを自動生成する。この機能を活用することで、ECサイトで販売している商品を実店舗に足を運ぶことなくECサイト上でイメージに近い洋服を探したり購入することができる。課題であるコスト削減や業務効率化にも期待できるという。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 30 Apr 2024 08:15:35 +0000</pubDate></item><item><title>Financial TimesとOpenAIが戦略的パートナーシップを締結</title><link>https://ledge.ai/articles/openai_content_partnership_with_ft</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月29日、Financial Times（FT）は、OpenAIとの戦略的パートナーシップ及びライセンス契約を{target=“_blank”}した。ChatGPTのモデルがFTのジャーナリズムを取り入れた内容で強化され、新しいAI製品やFT読者向けの機能開発に協力するという。

この契約のもと、ChatGPTユーザーは関連する問い合わせに応じて、FTのジャーナリズムからの選ばれた要約、引用、リンクを閲覧できるようになる。さらに、FTは今年初めにChatGPT Enterpriseを導入し、すべてのFT従業員がこの技術を活用できるようになった。これにより、創造性と生産性の向上が図られるとのこと。

FTグループのCEO、ジョン・リディング氏は「この合意は多くの点で重要である」と述べている。AIを通じてコンテンツがどのように提示されるかについての早期の洞察を得ることができ、また、FTのジャーナリズムの価値を認識しているとした。同氏はさらに、この契約がFTの作業範囲を広げ、読者の要求や関心の深い理解を促進すると付け加えた。

一方、OpenAIのCOOブラッド・ライトキャップ氏は「FTとのパートナーシップ及び継続的な対話は、ニュース組織とジャーナリストをAIで強化し、世界中の何百万もの人々にリアルタイムで高品質なジャーナリズムを提供するChatGPTの体験を豊かにするための創造的かつ生産的な方法を見つけることについてだ」とコメントしている。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 01 May 2024 12:18:48 +0000</pubDate></item><item><title>チューリングがプレシリーズAで30億円の資金調達、完全自動運転の開発加速
</title><link>https://ledge.ai/articles/turing_raised_3b_yen_in_funding</link><description>:::small
画像の出典：{target=“_blank”}
:::

チューリングは2024年4月23日、独立系ベンチャーキャピタルANRIをリードとする複数のベンチャーキャピタル、事業会社、個人投資家からの出資を受け、プレシリーズAラウンドの前半で30億円の資金調達を行ったと{target=“_blank”}した。

同社はカメラから取得したデータを用いて、運転に必要な判断をAIが自動で行うEnd-to-End（E2E）方式の自動運転技術に特化している。自社開発したマルチモーダル生成AI「Heron」を活用することで、従来の走行データでは対応困難な未知の状況にも倫理的に適応可能なシステムの構築を目指し、完全自動運転のレベル5達成に向けた開発を進めているという。

調達した資金は、Heronの運用に必要な大規模GPUクラスタ「Gaggle Cluster」の構築、2025年までに人間の介入なしで都内を30分間自動運転する「Tokyo30」プロジェクトの実施、および必要なMLエンジニアの採用に充てられる。これにより、同社は国内トップクラスの計算資源をエンジニアに提供することが可能となる。


「完全自動運転に向けたマルチモーダル基盤モデルの開発」を目指すチューリングは、2月に経済産業省の「ポスト5G情報通信システム基盤強化研究開発事業」の事業者として採択された。生成AI基盤の開発事業者として、Googleクラウドの計算資源を無償で利用できるよう支援を受けている。



:::box

:::
:::box

:::
</description><pubDate>Wed, 01 May 2024 12:16:09 +0000</pubDate></item><item><title>Apple　オープンソースの言語モデル「OpenELM」を発表　iPhone上での効率的なAI処理が可能</title><link>https://ledge.ai/articles/apple_open-elm</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

Appleは2024年4月24日、オープンソースの新しいAI言語モデル「OpenELM」を{target=“_blank”}した。（ELM：Efficient Language Model）

このモデルは、効率的なパラメータ割り当てを実現するためにレイヤーごとのスケーリング戦略を採用しており、特定の層により多くの計算資源を割り当てることで全体の性能を向上させているという。

OpenELMは、2億7000万、4億5000万、11億、30億の4つの異なるパラメータ数を持つモデルバリエーションで提供される。
下図は、OpenELMの約11億パラメータモデルでそのパフォーマンスを評価した結果を表す。OLMo（Open Language Model）という言語モデルと比較して、事前トレーニングに必要なトークン数を半分に削減しつつ、パフォーマンスでは約2.36%の向上を達成しており、モデルの効率性と効果性を示しているという。
!
:::small
画像の出典：{target=“_blank”}
:::

これまでの一般的な慣行とは異なり、OpenELMのリリースには、モデルの重みや推論コードだけでなく、公開データセット上でのトレーニングと評価のための完全なフレームワーク（トレーニングログ、複数のチェックポイント、事前トレーニングの設定などを含む）が含まれる。

さらに、Appleデバイス上での推論とファインチューニング用に、モデルをMLXライブラリに変換するコードも公開されているという。これによりAppleデバイス上での効率的なAI処理が可能となる。{target=“_blank”}した「MLX」とは、Appleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​フレームワークだ。

OpenELMのソースコード、事前トレーニングされたモデルの重み、およびトレーニングのレシピはオンラインで公開されており、Hugging Faceプラットフォーム上でもモデルは利用可能。

この包括的なリリースは、研究の透明性を高め、データやモデルのバイアス、潜在的なリスクについての調査を容易にすることで、信頼性のある結果を保証することを目的としているという。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 01 May 2024 12:13:06 +0000</pubDate></item><item><title>Microsoftが新たな小規模言語モデル「Phi-3」を発表 ― 「Tiny but Mighty」―オフラインでも動作するモデルがアプリケーション開発を強力に支援</title><link>https://ledge.ai/articles/microsoft_slm_phi-3</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Microsoftは2024年4月23日、新しいAIモデルシリーズ「Phi-3」のリリースを{target=“_blank”}した。

このシリーズは、小規模でありながら高い性能を実現し、特に最小モデルである3.8Bパラメータの「Phi-3-mini」は、オープンモデルとしてMicrosoftのAzure AIモデルカタログ、Hugging Face、Ollamaで無料で商用利用が可能だ。

Phi-3-miniは128Kトークンというクラス最長のコンテキストウィンドウをサポートし、インストラクションチューニングが施されているため、箱から出してすぐに使用可能だという。このモデルは、同サイズの他のモデルと比べて倍以上のパフォーマンスを実現していると同社は述べる。


 Phi-3の品質を表す図。Massive Multitask Language Understanding (MMLU) ベンチマークでパフォーマンスを計測し、同様のサイズの他社モデルと比較している。
!
:::small
画像の出典：{target=“_blank”}
:::

主要なベンチマークにおいて、同じサイズおよびより大きなサイズの言語モデルよりも大幅に優れたパフォーマンスを示す。
注：Phi-3はモデル サイズが小さくなると事実を保持する容量が少なくなるため、事実知識ベンチマーク (TriviaQA など) ではそれほどパフォーマンスが高くない。
!
:::small
画像の出典：{target=“_blank”}
:::

「Phi-3-mini」は、ONNX Runtimeを活用して最適化され、Windows DirectMLや様々なGPU、CPU、そしてモバイルハードウェアを含むクロスプラットフォームで利用可能となる。これにより、開発者は異なるデバイス上でモデルを効率的に運用でき、特にオフライン環境や低レイテンシが求められるシナリオでの利用が想定されるという。

例えば、モバイルデバイスやPCなど、クラウドに接続しない環境での利用が可能となり、レイテンシを大幅に削減し、プライバシーを保護できる。この特性は、交通システム、工場のスマートセンサー、リモートカメラなど、様々な用途に適用可能となる。

この新シリーズには、今後「Phi-3-small」（7B）、及び「Phi-3-medium」（14B）も追加され、より多様なニーズに応えるための選択肢が拡充予定とのことだ。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 30 Apr 2024 01:49:32 +0000</pubDate></item><item><title>日本経済新聞が「NIKKEI Language Model」の開発を発表　40年分の記事情報で磨かれた経済情報特化型大規模言語モデル</title><link>https://ledge.ai/articles/nikkei_language_model</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月24日、日本経済新聞は経済情報に特化した大規模言語モデル「NIKKEI Language Model」（略称　NiLM　にるむ）を開発したと{target=“_blank”}した。

日本経済新聞社の研究開発部署である日経イノベーション・ラボは、開発にあたり約40年分もの自社グループの雑誌や新聞などの各媒体記事を学習させ、日本経済新聞にしか作れない高品質な経済情報特化型の言語モデル開発を実現した。

開発したモデルはパラメータ数が130億と700億の2種類がある。パラメータ数が最大130億のモデルは既存モデルをベースとせず独自に構築しているが、パラメータ数が700億のモデルはmetaが開発した「Llama（ラマ）2」をベースにファインチューニングを行い開発。最新ニュースの幅広い知識を持ち、記事の要約などで活用できるという。また、現在はパラメータ数80億のモデルについても着手しており、こちらはmetaが4月に公開した「Llama（ラマ）3」をベースに作られている。

今回開発したモデルは、日経イノベーション・ラボが推進するAIプロダクトの研究開発などで利用を検討しており、大規模言語モデルの研究開発は今後も継続し、性能改善や課題に対する検証をすすめていくという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 30 Apr 2024 03:07:58 +0000</pubDate></item><item><title>イーロン・マスク氏「テスラは今年1.5兆円を自動運転のためのAI開発へ投資する」と発言　</title><link>https://ledge.ai/articles/tesla_invests_10b_in_self-driving-ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

テスラは2024年に主に自動運転プログラム向けAIの開発へ100億ドル以上を投資する計画だ。同社CEOのイーロン・マスク氏が2024年4月28日にこのことを明らかにしたと共同通信などが報じている。

この日マスク氏は自身のX（旧Twitter）アカウントにて、約100億ドル（約1.5兆円）をAIのトレーニングと推論に投資し、その主な用途は自動車内のAIであると明言。さらに、このレベルの投資を効率的に行わない企業は競争に太刀打ちできないと警告した。

!
:::small
画像：{target=“_blank”}
:::


また、テスラは2024年8月に自動運転タクシー「ロボタクシー」を公開する予定だという。

**Tesla アプリによる自動運転配車のプレビュー**
!
:::small
画像：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 30 Apr 2024 01:43:02 +0000</pubDate></item><item><title>大日本印刷が音声をリアルタイムで文字に変換する「DNP対話支援システム」提供開始　気持ちや情報のポイントをフォントや色・大きさに反映</title><link>https://ledge.ai/articles/dnp_dialogue_support_system</link><description>:::small
画像の出典：{target=“_blank”}
:::

大日本印刷は2024年4月23日、音声をリアルタイムで文字に変換し、フォントで強調して透明スクリーンに表示する「DNP対話支援システム」を提供開始したと{target=“_blank”}した。

感情や話題に応じたフォント変更が可能な「DNP感情表現フォントシステム」とアイシンの音声認識システム「YYSystem」を統合して開発されたシステムだ。主に、聴覚障がい者や高齢者、訪日外国人とのコミュニケーション支援が目的だという。

@



同社の「DNP感情表現フォントシステム」は、発言を素早く正確に文字化し、感情やイメージを表す単語を12種類のフォントから自動選択して表示する。さらに、透明スクリーンや指向性マイクの活用により、対面接客時にも自然なコミュニケーションが可能となるという。

同システムは、自治体、調剤薬局、金融機関、保険会社の窓口業務や観光業界での使用が想定されている。現在はJR九州の小倉駅に試験的に導入されており、JR東日本の一ノ関駅にも同様の導入が予定されているとのこと。



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Sun, 28 Apr 2024 13:31:42 +0000</pubDate></item><item><title>リコーがLLM開発に続きドイツの新興企業「ナティフAI」の買収を発表　更なるオフィス業務効率向上を目指す
</title><link>https://ledge.ai/articles/ricoh_natif_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月22日、株式会社リコーはドイツの新興企業であるナティフAIを買収したと{target=“_blank”}した。

ナティフAIは、2019年に設立されたインテリジェントキャプチャーと呼ばれるAIを活用した画像認識やOCR（Optical Character Recognition）など、文書データ情報を抽出する技術に強みを持つ企業。リコーは自社の複合機でスキャンした紙文書や手書き文書から情報抽出する機能をより強化し、自動化・高度化を実現するという。読み取りが難しいとされる手書き文書にも対応しており、この先進的な技術を取り入れ更なるオフィス業務効率化の向上を目指す。

!

:::small
画像の出典：{target=“_blank”}
:::

リコーは2019年にドイツの「ドキュウェア社」を買収している。ドキュウェア社とナティフAIの持つ技術を掛け合わせることでより高度な技術と幅広い業務領域への対応が可能になると期待できるという。

:::box

:::
:::box

:::</description><pubDate>Fri, 26 Apr 2024 01:39:57 +0000</pubDate></item><item><title>NEC、高速・高性能な大規模言語モデル「cotomi Pro」と「cotomi Light」を開発</title><link>https://ledge.ai/articles/nec_llm_cotomi-pro_cotomi-light</link><description>:::small
画像の出典：{target=“_blank”}
:::

NECは2024年4月24日、新たな大規模言語モデル（LLM）「cotomi Pro」と「cotomi Light」の開発を{target=“_blank”}した。これらのモデルは、グローバルトップレベルの性能を数倍から十数倍の速度で提供することが特徴だ。

生成AIの急速な進展により、多くの企業や公共機関がLLMの導入を進めている中で、NECはレスポンスタイムの短縮と高いセキュリティを保ちながら、高性能なモデル提供を目指している。同社は、学習データとアーキテクチャの全面的な見直しを行い、「cotomi Pro」と「cotomi Light」を開発。これにより、大規模モデルでありながら実用的なレスポンスタイムを実現しているという。

「cotomi Pro」は、GPT-4やClaude 2といったモデルに匹敵する性能を持ちつつ、GPU2枚の設定で約1/8のレスポンスタイムを達成。一方、「cotomi Light」は、GPT-3.5-Turbo相当の性能を持ちながら、さらに高速に大量のリクエストを処理可能で、実際の業務で十分な処理能力を発揮する。

NECはこれまで、約4万人の社員が生成AIを活用した社内サービスで約1年間実際の業務にこれらのモデルを利用し、その結果をフィードバックして性能向上を図ってきた。この実績に基づき、新しいモデルは現実的なユースケースでの性能も大幅に向上している。

!
:::small
画像の出典：{target=“_blank”}
:::

「cotomi Pro」は文書検索システムでの使用例があり、ファインチューニングを施さない状態でGPT-3.5を上回る正答率を、ファインチューニング後はGPT-4を超える正答率を、およそ1/15のレスポンスタイムで達成しているという。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Sun, 28 Apr 2024 08:53:57 +0000</pubDate></item><item><title>AIエージェントとは｜マニアックなプロンプトエンジニアリングはいらない 注目の生成AI活用トレンド</title><link>https://ledge.ai/articles/about_ai-agent</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

:::box
**目次**
- 導入
- AIエージェントの仕組み
- AIエージェントの実装例
:::

## 導入
### AIエージェントという概念　～AIのエージェントアプローチ＋LLM～
AIエージェントという仕組みは、昨今の生成AI活用ブームの中で注目を集めているが、エージェントという概念自体は、コンピューターサイエンスやロボット工学の分野で研究が進められてきたものである。特に1980年代にロボット研究者であるロドニー・ブルックスらの研究は、自律型ロボットやエージェントシステムに大きな影響を与え、2000年に発売された自動掃除機ルンバといった製品として実用化もされている。その後、機械学習の手法を組み合わせた研究が進み、近年の大規模言語モデル（LLM）の普及によって、より複雑な問題を自律的に解決できる仕組みであるAIエージェントという概念として語られるようになった。

### プロンプトエンジニアリングの限界
2022年11月30日にOpenAIが発表したChatGPTは、その利用の手軽さや生成物のクオリティから、生成AIという技術がビジネスを大きく変えていく未来を想像させた。
チャット型のユーザーインターフェースは、プログラミング言語などの特殊な言語を扱うことなく、人間と対話するときと同じような感覚で送ったテキスト情報に対して意味の通る文章を生成、回答してくれる。
生成される回答は、プロンプトと呼ばれる命令の出し方一つで異なってくる。生成AIから質の高い回答を得るためには、効果的なプロンプトを作ることが重要であり、プロンプトを使いこなす手法や技術を指す分野としてプロンプトエンジニアリングという言葉も誕生した。
ChatGPTの発表以後も、様々な活用方法が生み出され、プロンプトエンジニアリングに関するセミナーや書籍なども数多く目にするようになった。

生成AIは、プロンプトを使いこなせるようになると便利なツールである。ただし実際の業務に最適化させていくほど、プロンプトは長く複雑なものになっていく。実行してもらいたいタスクの詳細情報や実行の条件、参照すべき情報など、業界や業種、業務の用途に合わせてプロンプトに書き込んでいかなければならないからである。
さらに、ベースの学習済みの言語モデル自体も、日々アップデートされている。アップデートによって、以前使用していたプロンプトの出力内容も変わってしまう可能性がある。
生成AIはうまく活用できれば業務の効率化に役立てられるが、それを実感できるレベルにまでたどり着ける人は少ないのかもしれない。
このような背景を踏まえると、プロンプトエンジニアリングで業務効率化を実現していくアプローチには限界があるといえる。

そこで注目を集めているのが、細かな指示がなくとも自律的に目的に向かってタスクをこなしてくれる「AIエージェント」の仕組みである。現在はまだ先進的な企業で技術検証が進んでいる段階ではあるが、今後の生成AI活用における大きなトレンドになると期待されている。本記事で「AIエージェント」の基本的な概念や仕組みについて理解を深め、生成AI活用のヒントとしてもらいたい。

### AIエージェントの概要
AIエージェントとは、一言でいうとある目標を達成するために自律的に行動するソフトウェアプログラムやシステムのことである。 
例えば、オフィスでの会議室の予約をしたい状況で、AIエージェントの活用イメージとして以下のようなシナリオを描くことができる。

!

まず最初にユーザーがAIエージェントに対して、来客用の会議を予約するという目的を与える。AIエージェントは、会議室予約のデータベース参照し空き状況を確認するというタスクを実行する。もし会議室の空きがなかった場合には、会議の重要性を判断し、他の会議室予約者との交渉を行い、会議室の確保を自律的に遂行してくれる。

AIエージェントは、現在もなお研究・開発が進行している分野である。研究や社会実装の分野での様々なプロジェクトの中で、AIエージェントの技術的な可能性が示され、現在に至っている。以下にAIエージェントの発展の中で注目を集めたマイルストーンプロジェクトを紹介する。

**社会シミュレーション「Generative Agent」：**
複数のAIエージェントによる社会シミュレーションを行ったスタンフォード大学とGoogleとの共同研究のプロジェクト。
25人のエージェントと仮想的なゲーム環境による人工的な村社会を構築し、AIエージェント同士が創発的に協同しあうかを実験した内容が論文として発表された。

**ソフトウェア開発会社「ChatDev」：**
AIエージェントが経営するソフトウェア開発会社を仮想的に再現し、エージェント同士の協働によって、実際のソフトウェアを開発するツール。
現実世界のソフトウェア会社のように、プログラマー・テストエンジニア・アートデザイナーなどのAIエージェントにそれぞれ役割を与え、エージェント同士でコミュニケーションを取りながらソフトウェア開発のステップ（設計、コーディング、テスト等）を進めていくことができる。

**完全自律型AIエンジニア「Devin」：**
米国のAIスタートアップCognition社が発表したソフトウェア開発のAIエージェント。与えられた要件からソフトウェア開発の一連のプロセスを自動で実行し、エラー発生時にも自律的に問題解決するなど、高度なエンジニアリングスキルを持っている。Devinの発表は、そう遠くない未来にソフトウェア開発のあり方が大きく変わる可能性を示した。

:::box
関連記事：
:::

## AIエージェントの仕組み
AIエージェントは、概念的には個性／記憶／計画／行動の4つの機能で構成されており、互いに作用し合うことで、複雑な問題の解決を実現する。AIエージェントはまだ研究途上の段階にある仕組みではあるが、これらの要素のポイントを押さえて設計していくことがAIエージェント構築の肝になる。

!

### 個性（Profile）
個性（Profile）は、年齢、性別、職業等といった基本情報や性格・社内的な立場といった情報で、AIエージェントの振る舞いに影響を与える。
現実世界では、営業や人事、開発、法務など様々な職域があり、複数の職種の人たちによる相互の営みを通じて事業は構成されている。それぞれに与えられた役割があり、向いている性格や思考や行動の特性があり、適切な人材を配置し、組織を設計することで生産性を向上させることができる。AIエージェントも同様に、異なる性格や価値観、役割を定義することで、AIエージェントの思考・行動の決定プロセスに影響を与えることができる。

### 記憶（Memory）
タスクを適切に実行していくためには、「記憶」の仕組みを考える必要がある。その理由の一つには、LLMが一度に扱えるデータ量には制限がある。もう一つは、会話の文脈や過去の経緯を踏まえて適切に判断を下すためには、短期的な記憶と長期的な記憶を区別して情報を処理する必要がある。
さらにAIエージェント自身の体験の記憶だけでなく、外部に蓄積されているデータベースを参照し、大量の業務データを記憶として扱える点は、人間の記憶とは大きく異なる。
扱えるデータ形式としては、リレーショナルデータベースとベクトルデータベースの大きく2種類存在する。

**リレーショナルデータベース：**
業務システムで一般的に利用されるデータベースであり、データをテーブル形式の構造化された状態で保存する。データの検索・抽出といった操作には、SQLというデータベースクエリ言語を使う。大規模言語モデルを用いて、SQLクエリの生成を行うことができ、記憶の呼び出しができる。

**ベクトルデータベース：**
文書や画像など、構造化された形式のデータに変換ができない形式のデータを扱うデータベース。データをベクトル空間という空間内の特定の座標にマッピングすることで、データ同士の意味的な関係性を、2点間の座標の方向や大きさという数値情報によって扱うことができる。

海外では、Airtableというクラウドデータベースサービスに様々なデータを格納し、それらをAPI経由で、AIエージェントがアクセスできるようにしておき、ファイルやデータの参照から書き込みまで各種タスクの実行を行えるようにする活用事例なども出てきているという。

### 計画（Planning）
計画は、AIエージェントが目的を達成する上で非常に重要なプロセスである。このプロセスでは、必要なタスクを思考し、それらを分解をすることで、目的達成のための最適な手順とアクションを明確にする。
AIエージェントにおける計画で押さえておくべきアプローチとして、”タスク分解”がある。
タスク分解は、文字通り目的の達成のために必要なタスクを分解することである。AIエージェントでは、ユーザーから提示された目的に対して、そのタスク分解のためのプロンプトを生成し、タスク分解を行うように設計していくことが重要になる。
オープンソースのAIエージェント「BabyFoxAGI」では、タスク分解のプロンプトを生成する仕組みがプログラムされており、汎用的なタスク実行に対応できるようになっている。

さらにReActというプロンプティングの手法を取り入れることで、分解したタスクに対してLLMに正しい推論と意思決定を行わせ、計画の解像度を高めていくことができる。
ReActは、理由（Reason）と行動（Action）を中心に思考しながらタスクを進めていくアプローチであり、その英単語の頭文字を取って名付けられている。
与えられたタスクを達成するために、行動を思考し、行動の結果を観察、そこから得た学びを思考に反映し、行動を最適化していく、というのがReActの基本的な流れである。
例えば、先程あげた会議室予約を例に、AIエージェントでのタスク分解のイメージを下記に示す。

:::box
**会議室の予約で想定されるタスク分解例**
- ユーザーのその日のスケジュールを確認し、会議可能な時間を把握
- 同席者の有無を確認し、同席がいる場合に同席者のスケジュールを踏まえた会議時間を設定
- 会議室予約のデータベースを参照し、設定時間での会議室の空き状況を確認
- 会議室の空きがなかった場合は、ユーザーに会議室確保の重要度に関するフィードバックをもらう
- 重要度が高い会議の場合、先に会議室を予約している担当者を確認
- 会議室を空けてもらうための依頼文章を生成し、メッセージを送信
- 担当者から承諾をもらえた場合、カレンダー予約システムに対して、会議室予約の変更手続きを実行
- ユーザーに完了報告
:::

### 行動（Action）
AIエージェントに具体的なタスクの実行を定義するのが、「行動」である。
LLM単体では、学習データにない最新情報に基づいたアウトプットができなかったり、言語モデルの特性上、数値計算なども得意ではない。AIエージェントは概念的には、外部機能にアクセスできる権限や実行プログラムを定義することができるものについては何でも実行できる。
一般的に取り上げられる行動の例としては、ブラウザ検索を行い最新の情報を収集や、外部システムと連携しデータベースからデータの抽出や保存、pythonプログラムによる数値解析処理など、実装次第で様々な行動を起こさせることができる。定義した各種行動の中からどれを実行するかは、AIエージェント自身が思考プロセスの中で判断する。

**AIエージェントのユースケース**
AIエージェントが各種システムやデータにアクセスし、様々な操作・処理が行えることが前提にはなるが、AIエージェントが実現しうる世界観として考えられるユースケースを以下に示す。

:::box
**旅行予約**
- 旅行に行きたいエリアを提示すると、AIエージェントがそのエリアまでの交通手段の調査や、チケットの空き状況を確認
- 現地のホテル情報やグルメ・観光情報を収集し、ユーザーの過去の傾向から好みを踏まえて旅行プランを作成
- 予算や観たいところなど、ユーザーからのフィードバックを受けて、再度旅行プランの再作成
- チケット・予約手配を代行
- 旅行中の各種案内や予定変更などのサポート
:::

:::box
**営業管理**
- お問い合わせを受け付けた際に、インターネット上の公開情報を検索し、問い合わせ企業の情報を調査
- 過去の問い合わせ履歴から同じ業界や会社規模での類似の問い合わせがなかったを自社データベースから調査
- 問い合わせに関連する社外ニュースなどの参考情報も収集
- 調査結果を次回以降も再利用できるようにデータベースに保存
:::

## AIエージェントの実装例
実験的なものも含めてプロダクトとしてインターネット上に公開されているものや、独自のAIエージェント開発を支援する開発フレームワークなどが出てきている。まずは既存のAIエージェントツールに触れ、AIエージェントの動きを体感してみるのもいいだろう。その上で実際の業務シーンでの活用に向けては、開発フレームワークを用いて設計・カスタマイズしていく必要がある。
ここでは代表的なものをいくつか紹介する。

### AIエージェントアプリケーション
**AutoGPT：**
AutoGPTは、2023年3月に登場した実験的なプログラムで、AIエージェントブームの火付け役と言われている。目的を与えると、AIが自律的に達成に必要な道筋を考え、情報を収集し、それらをまとめた内容をファイルに出力するといったことができる。この仕組みがAIコミュニティの中で注目され、AutoGPTの活用事例（AutoGPTがウェブサイトを構築するデモetc）が活発に公開されるようになったことで、AIエージェントブームが巻き起こった。

**BadyAGI：**
AIエージェントブームの中で注目を集めたもう一つ代表的なAIエージェントが「BabyAGI」である。AutoGPTとほぼ同時期の2023年の4月に、ヨウヘイ・ナカジマ氏によって開発されたAIエージェントである。タスクを自動で実行していくという点はAutoGPTとにていますが、AutoGPTが個別のタスク毎にユーザーによるフィードバックと承認が必要な事に対し、BabyAGIは最終目標に向かって自動的にタスクの実行と調整を繰り返していくことが特徴である。

:::box
**BabyAGIの実行フロー**
1. 「タスク作成エージェント」がゴール達成に必要なタスクリストを生成
2. 「タスク優先度付けエージェント」が実行の優先順位付け
3. 最初のタスクを「タスク実行エージェント」に渡し、タスクを実行
4. 実行結果を「タスク作成エージェント」に渡し、新たなタスクを生成
5. 全てのタスクが終了するため2〜4をループ
:::

!

**Scalable Instructable Multiworld Agent（SIMA）：**
SIMAは、Google DeepMindは2023年3月13日発表した新たなAIエージェント。様々なビデオゲームで自然言語の指示に従ってタスクを実行する能力を持つ。トレーニングには、「No Man's Sky」「Teardown」「Valheim」「Goat Simulator 3」「Satisfactory」「Hydroneer」「Space Engineer」「Wobbly Life」「Eco」といったバラエティに富むゲームを使用した。「左折」「はしごを登る」「地図を開く」 などの約600の基本スキルを持ち、さまざまな状況に適応する訓練が施されており、研究チームの報告によると、初めてプレイするゲームでも、そのゲームに特化してトレーニングを受けたエージェントと平均してほぼ同じパフォーマンスを示したとのこと。今後、日常生活のタスク、より複雑な指示への対応、効率的な学習方法の開発に向けて進められる。

:::box
関連記事：
:::

### 開発フレームワーク
**Langchain：**
LangChainは大規模言語モデルを活用してアプリケーションを構築するためのフレームワークであり、開発者がAIを利用した言語理解の能力を簡単に組み込むことができるように設計されている。LangChainが提供する多様な統合機能を活用して、複雑なタスクや問題解決に取り組むAIエージェントを構築することができる。

**AutoGen：**
Microsoft Researchから発表されたAIアプリケーション開発フレームワーク。「複数のAIエージェント」が相互に会話しながらタスクを解決するのが特徴。AutoGenを使うことで、複数のAIエージェントを組み合わせることができたり、役割に応じてタスクをAIエージェントに割り振ることができるようになる。

2024年は、各企業での生成AI活用に向けた取り組みがより一層加速していくとみられる。

:::box
関連記事：
:::

そうした動きの中で「AIエージェント」は確実に今後の重要トレンドとなってくると言える。
LLMを始めとするAI技術の発展・普及とともに、AIと人との関わり方は変わっていくだろう。目的達成のための手段やその計画は、AIエージェントが行ってくれる。AIエージェントの仕組みが実用化された世界で私達人間が求められる役割は、正しい目的を与え、成果物に対して適切なフィードバックを返すことである。

ーーー

レッジでは生成AIの導入支援サービスを提供しています。
その中ではAIエージェントを企業の生成AI活用の重要テーマとして包括的な支援が可能です。
ご興味ある方は、下記ページよりお問い合わせください。

:::box
関連ページ：
:::</description><pubDate>Tue, 30 Apr 2024 06:14:30 +0000</pubDate></item><item><title>Google の無料教材公開「Beyond the Prompt」「Prompting guide 101」生成AIの効果的な活用法やヒントを紹介</title><link>https://ledge.ai/articles/google_prompt_guide</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年4月19日、Google Workspaceユーザーを対象にした新しいブログシリーズ「{target=“_blank”}」を開始した。

このシリーズは、生成AIを効果的に活用するためのヒントやコツ、提案を定期的に提供することを目的としている。Google Workspaceは元々、リアルタイムおよび非同期でのコラボレーションを核として構築されており、この新技術を取り入れることで、ユーザーの生産性、創造性、および作業の質をさらに高めることが期待されているという。

このブログシリーズでは、特に効果的なプロンプトの作成方法にスポットライトが当てられている。プロンプトは、AI搭載アシスタントとの対話を始めるためのトリガーとして機能し、ペルソナ（Persona）、タスク（Task）、コンテキスト（Context）、フォーマット（Format）の4つの主要な要素を含めることが推奨されている。これらの要素を組み合わせることで、より具体的かつ効果的な応答を引き出すことが可能だ。

具体例としては、Google Slidesで旅行ブログの記事に添える画像を生成するプロセスが紹介されている。ユーザーは「Create image with Gemini」というプロンプトを用いて、希望するシーンの画像を生成し、選んだ画像を直接スライドに挿入することができる。

!
:::small
画像の出典：{target=“_blank”}
:::

「Beyond the Prompt」は、Google Workspaceを使用している全ユーザーがGeminiの機能を最大限に活用し、より効果的に作業を進めるための支援を提供していくという。

またGoogleは「{target=“_blank”}」という電子ブックも公開しており、プロンプトの基本から応用まで、多岐にわたる情報を45ページにわたって提供している。このガイドは、GeminiをはじめとするAIチャットボットの活用を促進し、具体的な業務に応用するための例文も含まれているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Apr 2024 06:10:44 +0000</pubDate></item><item><title>GWに徹底理解！GPTの仕組みをめちゃくちゃ分かりやすく解説する無料動画公開</title><link>https://ledge.ai/articles/3blue1brown_transformer_attention</link><description>:::small
画像の出典：{target=“_blank”}
:::

連休を自己研鑽に充てようと考える方へ朗報だ。

数学と科学をビジュアルで解説する教育サイト「3Blue1Brown」が2024年4月、GPTの仕組みを分かりやすく解説する動画を公開している。ディープラーニング・第5章「But what is a GPT? - Visual intro to Transformers」というタイトルだ。この動画は、GPT（Generative Pretrained Transformer）の基本的な構造とその動作原理を詳しく説明している。


## ディープラーニング　第5章「しかし、GPTとは何なのか」

@


GPTは、大量のデータから事前学習を行い、特定のタスクに対してさらに微調整を加えることで、テキスト生成などの機能を実現するAIモデルだ。トランスフォーマーとは、このようなAIブームの中核となる特定のニューラルネットワークの一種であり、2017年にGoogleによって導入されたもので、もともとはテキストの翻訳が主な用途であった。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の動画では、GPTのモデルがどのようにテキストを生成するか、その過程を一から丁寧に解説している。特に、入力されたテキストから次に来る言葉を予測する機能は、単純ながらもテキストを生成する上で重要な役割を果たしている。GPT-2とGPT-3の違いについても触れられており、より大きなモデルであるGPT-3では、より一貫性と感覚的なストーリー生成が可能であることが示されている。

!
:::small
画像の出典：{target=“_blank”}
:::

3Blue1Brownの動画は、数学を直感的かつ視覚的に理解できるようにデザインされており、複雑な数学的概念や定理をアニメーションを用いて説明する。運営資金調達には、クラウドファンディングのプラットフォーム「Patreon」を採用しており、広告に頼らず視聴者の直接的な支援によって高品質のコンテンツを提供している。


## ディープラーニング　第６章「アテンション、トランスフォーマーの心臓を視覚化」
@



4月26日に公開されたAIの核心技術の一つである 第6章「Attentionメカニズム」についての解説動画もおススメしたい。このメカニズムは、Transformer構造の中心部品として、AIによる言語理解の精度を飛躍的に向上させるものだ。

「Transformer」という言葉はAIの技術者の間ではよく知られているが、その詳細な機能まで理解している人は少ないという。Transformerは、特にLLMが文章を「読む」際の基盤技術として活用されており、文章中の「トークン」と呼ばれる単位ごとに情報処理を行う。

!
:::small
画像の出典：{target=“_blank”}
:::

動画では、「トークン」として処理される各単語がどのようにAttentionメカニズムによって重要視されるかをビジュアル化しており、教育的な視点からも高い評価を受けているとのことだ。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:55:32 +0000</pubDate></item><item><title>NVIDIA、生成AI分野の技術者向けにプロフェッショナル認定制度を新設</title><link>https://ledge.ai/articles/nvidia_genai_professional_certification</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAは2024年3月14日、生成AIに関するプロフェッショナル認定制度を新たに提供開始することを{target=“_blank”}した。

この認定制度は、生成AI技術の開発者がその技術的な信頼性を確立できるように設計されている。NVIDIAによれば、この新しい認定制度は、同社が初めて提供するプロフェッショナル向けのものであり、大規模言語モデル（LLM）とマルチモーダルワークフロースキルの習熟度を測ることを目的としている。

この制度には、2種類のアソシエイトレベルの認定が用意されており、GTC 2024イベント以降に利用可能になる予定だ。GTC 2024は、3月18日から21日まで開催されるNVIDIAのイベントで、現地参加者は認定試験に備えるための推奨トレーニングにアクセスできるとのこと。

NVIDIAのデベロッパープログラム担当バイスプレジデント、グレッグ・エステス氏は、「NVIDIAの目標は、皆さまのスキルアップを支援し、資格を持つプロフェッショナルの能力を磨き、個人がその熟練度を証明できるようにすることにより、雇用市場で競争優位を得られるようにすること」とコメントしている。

この認定制度の開始は、生成AI技術の発展と普及に伴い、この分野で活動する技術者が自身の技術力を証明し、業界での地位を確立するための重要な機会を提供するものだという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 17 Mar 2024 05:03:19 +0000</pubDate></item><item><title>Anthropic、チャットAI「Claude 3」向け公式プロンプト集を公開</title><link>https://ledge.ai/articles/anthropic_claude3_prompt_library</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月11日、AIスタートアップのAnthropicは、同社が開発したチャットAI「Claude 3」向けの公式プロンプト集を{target=“_blank”}した。

現在64種類の使用例が集められているこのプロンプト集は、「プロンプトライブラリ」でアクセス可能だ。公開されたプロンプト集は、英語と日本語の両方に対応しており、ユーザーはこれを利用してClaude 3の応用範囲を広げることができる。

プロンプトライブラリには、クリエイティブな執筆、データ分析、キャラクターロールプレイといった様々な用途に合わせたプロンプトが含まれている。Anthropicは、このライブラリを通じて、Claude 3を最大限に活用するためのガイドラインを提供し、ユーザーが特定のタスクを効果的に達成できるよう支援している。

また、Anthropicは「{target=“_blank”}」も公開しており、プロンプトの作成とテストのプロセスを通じて、Claude 3のパフォーマンスをさらに向上させる方法について説明している。これにより、ユーザーはより具体的なユースケースに対してClaude 3の応答を微調整することが可能となる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:21:11 +0000</pubDate></item><item><title>パーソルホールディングス、生成AI研修で社員スキルアップを加速</title><link>https://ledge.ai/articles/persol_group_upreskilling</link><description>:::small
画像の出典：{target=“_blank”}
:::

パーソルホールディングスは2024年02月16日、グループ社員の生成AIに関する知識と活用スキルの向上を目指し、専門家による研修や社内勉強会の開催などの積極的な取り組みについて{target=“_blank”}した。

この取り組みは、社員個人のスキルレベルを「理解」「業務導入」「業務活用と伝播」の3段階に区分し、全社員が生成AIを業務に活用する環境を整備することにあるという。

外部の専門家を招いた研修や勉強会をはじめ、1,500名以上の社員が受講した入門編から実践編、さらには経営幹部向けの勉強会まで、参加者のレベルや属性に応じた内容で開催されている。また、社内専用GPT「PERSOL Chat Assistant」の基礎知識についての動画講義には3,800名の社員が参加し、IT系職種に限らず多岐にわたる職種の社員が生成AIの教育を受けているとのこと。

さらに、生成AIパスポートの資格取得に向けた取り組みも進められており、2024年第1回試験にはグループ各社から200名以上の社員が受験予定。受験費用は会社が支給しているという。この資格は、生成AIを活用したコンテンツ生成の方法や企業のコンプライアンスに関する知識を学ぶもの。

これらの教育プログラムを通じて、社員はメール文章作成や議事録の要約、英文作成、アイデア出し、営業アポイントのテーマ検討、トークスクリプト作成、ソースコードの分析・修正など、多岐にわたる業務で生成AIを活用するスキルを習得し、業務効率化とパフォーマンスの向上、リスク回避につなげているという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 29 Feb 2024 03:36:19 +0000</pubDate></item><item><title>JDLAが「生成AIの利用ガイドライン（画像編）」を公開</title><link>https://ledge.ai/articles/jdla_guideline_for_image_generating_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本ディープラーニング協会（JDLA）は2024年2月13日、「生成AIの利用ガイドライン（画像編）」を{target=“_blank”}した。

このガイドラインは、2023年5月に公開された「{target=“_blank”}」の続編として作成されており、主に画像生成AIに特化した内容となる。

ガイドラインの目的は、画像生成AIを事業において利用する企業等に向け、ルール策定時に検討が必要な法的論点を解説することにある。具体的には、画像生成AIの利用に際して、社内体制の整備、プロンプトの入力ルール、AI生成物の利用規則など、遵守すべきポイントが詳述されている。

JDLAは、ディープラーニング技術を日本の産業競争力向上の核とし、その普及と適用を目指して活動している組織だ。今回のガイドライン公開も、その一環として行われたもので、画像生成AIの健全な利用と発展の促進を期待してのことだとされる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 28 Feb 2024 05:54:19 +0000</pubDate></item><item><title>日本最大級のDX推進コンテスト『日本DX大賞2024』応募開始</title><link>https://ledge.ai/articles/dx_taisho_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

一般社団法人日本デジタルトランスフォーメーション推進協会は2024年2月6日、民間企業や自治体のDX取り組みを表彰する「日本DX大賞 2024」の応募受付を開始したと{target=“_blank”}した。

コンテストは、DXの成功事例を発掘し共有することで、日本全体のDX推進を加速させることを目的としている。昨年行われた「日本DX大賞2023」への応募数は111件。今年はサステナビリティトランスフォーメーションやビジネスモデルの変革、顧客体験の向上など、多様なカテゴリーでのDX取り組みが対象となる​。

**募集期間**： 2024年2月6日から4月26日まで
**応募対象**：「DX推進」に取り組んでいる民間企業、公的機関、自治体等の変革を実現した事例や成果をあげた事例。または、ユーザー企業・団体が取り組んだ事例


日本DX大賞サイト：{target=“_blank”}



:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Feb 2024 10:45:28 +0000</pubDate></item><item><title> LoRA(ローラ)とは｜今年注目の画像生成AI (Stable Diffusion) のファインチューニングを試してみた
</title><link>https://ledge.ai/articles/LoRA</link><description>LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。従来はLLM（大規模言語モデル）や画像生成AIのファインチューニングに膨大な計算量が必要だったが、LoRAによって少ないリソースで行うことができるようになった。LoRAはLLMや画像生成AIに応用できる、計算量を減らしてファインチューニングを行う技術である。

2023年末にはChatGPTの新機能である、ユーザーがChatGPTを自由にカスタマイズ（ファインチューニングも）できる「GPTs」がリリースされた。誰もが簡単に学習済みモデルをファインチューニングできるようになりつつある。自社や個人が持つアセットを最大限に活用した生成AIの効果的な使用が、一層重要なフェーズに突入している。

今回は、ファインチューニングの理解に必須の技術「LoRA」について解説する。

:::small
※「LoRA」という用語は元々、計算効率を向上させる技術を指す。しかし、この技術を基にして「Stable Diffusion」というAIモデルをファインチューニングした際に生まれる特定のモデルも、同様に「LoRA」と称されている。「LoRA」が二重の意味を持つことに注意が必要。
:::

:::box
関連記事 : 
:::

:::box
**目次**
- LoRAとは
- LoRAのビジネスへの活用
- LoRAを使って「Stable Diffusion」をファインチューニングしてみた
:::

## LoRAとは

LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。2021年にMicrosoftに所属していたEdward Huらによって論文で発表された技術だ。

LoRAは、元のモデルのパラメータを直接変更する代わりに、低ランクの行列を導入して、パラメータの変更を行うことができる。少ない計算量で元のモデルに修正を加えることが可能になった。

LoRAは、事前学習されたモデルの重みを固定し、変換器アーキテクチャの各層に低ランクの分解行列を注入することで、下流のタスク用の訓練可能なパラメータの数を大幅に削減する。例えば、GPT-3 175Bモデルにおいて、LoRAは訓練可能なパラメータを10,000倍減らし、GPUメモリ要件を3倍削減することを実現している。
論文中では以下の図でモデルの概要が説明されている。
!


LoRA（Low-Rank Adaptation）の計算例を示す。通常、変換器モデルでは、重み行列W ( m×n)があり、入力x に対してWx の形で適用される。LoRAでは、この重み行列W を直接変更するのではなく、低ランクの行列A (m×k)とB (k×n)を用いて、W ( m×n)+AB ( m×n) の形で変換を行う。ここで、A とB は小さな行列であり、元の重み行列W に比べてはるかに少ないパラメータを持つ。この方法により、全体のパラメータ数が減少し、計算の効率が向上する。
A=正規分布、B=0で初期化されている。

具体的な計算を以下に示す。重み行列Wのパラメータ数は合計24、行列AとBは合計8となり調整するパラメータ数が3倍削減されている。
!
実際の計算規模は上記の計算例よりはるかに大きく、学習済みモデルのパラメータ数はGPT-3で175億、Stable Diffusionで10億程度と言われている。LoRAによってこれらのモデルのファインチューニングが少ないリソースで行なえることを理解できた。

##  LoRA・ファインチューニングのビジネスへの活用

次にビジネスへの活用例を示す。

**カスタマイズされたチャットボット:**
企業はLoRAを使用して、自社のリソースを学習させ大規模なLLMから自社専用のチャットボットを作成することができる。社内独自のQ＆Aを行えるチャットボットが使用されている。

**AI写真集:**
LoRAを使用して、基盤モデルとなるStable Diffusionをファインチューニングすることで、「アジア人女性」などの特定の画像を生成できる。
Amazon.co.jpの電子書籍読み放題サービス「Kindle Unlimited」をAI生成画像の「写真集」が席巻している。SNSで話題になり、ニュースサイトも相次いで報じるなど、社会現象といってよい状態だ。生成AIの技術が進化し、実際に存在しないがリアルに見えるモデルの画像が生み出され、グラビア界に新たな波をもたらしている。
!

:::box
関連記事：
:::


**AIモデル:**
自社ブランドのファッションアイテムを学習させ、AIモデルに着用させることができる。
AI model株式会社は、2022年6月14日にサービス「AI model モデル撮影サービス
」を提供開始した。撮影場所・費用の確保、起用タレント・モデルの不祥事など「人ならでは」のリスクを回避しつつ、ECの顧客に合わせたブランド専属モデルを生み出せる。
!

:::box
関連記事： 
:::


## LoRAを使って「Stable Diffusion」をファインチューニングしてみた

Stable Diffusion LoRAは、人物の顔、服装、ポーズなど画像の一部を学習し、その特徴をもった新たな画像を生成することができる。

今回はStable Diffusion LoRAを使い、人物の顔を学習させ、その人そっくりのAIモデルを生成する。肖像権の関係で弊社執行役員・箕部 和也の宣材写真を使いStable Diffusionをファインチューニングして、箕部そっくりの人物画像を作ることを試みた。

**Stable Diffusion LoRAの特徴**

- 20枚程度の画像からLoRAの追加学習ファイルを作成できる。
- 服装、ポーズ、顔、イラストの画風を学習させることができる。
- 100〜200MB程度のファイル。
- 学習時間が短い (今回の方法で1時間程度)。
- Stable Diffusionのチェックポイントをベースに作成可能。

今回はGPUを所有してない場合もオンラインで実行できる方法を紹介する。
のを使用する。Loraを使った学習が、簡単に行えるように必要なコードがまとめられている。

基本的なStable Diffusionの使い方はこちらで確認できる。

:::box
関連記事:
:::


### STEP0 実行環境と学習用画像を準備する

**実行環境**
をクリックすると以下のようなノートブックが開く。Google ColaboratoryはPythonの実行環境であり、GPUを無料で使うことができる。ただし画像生成AIを行う場合はColab Pro (1 か月あたり ￥1,179) が推奨されている。今回はColab ProでLoraファイルの作成を行う。ノートブックをマイドライブにコピーしておく。
!

**学習用画像**
今回は画像を15枚用意した。画像サイズは512×512や1024×1024の正方形が望ましい。
画像サイズは512×512にトリミングした。顔を学習させたい場合は、髪型や服装が違う画像があれば顔のみを学習しやすい。数パターンの髪型、表情、ポーズ、服装の画像を用意できることが理想的だ。
!

### STEP1  LoRAファイルを作成する。
変更できるパラメータは多量にあるが、最低限の実行に必須な部分のみを解説していく。

**I. Install Kohya Trainer**
!
:::box
1.1. Install Dependencies
 mount_drive:◻︎にチェックを入れて実行。colabからgoole driveにアクセス可能になる。
:::


**II. Pretrained Model Selection**
!
:::box
2.1. Download Available Model
 学習の基盤となるStable Diffusionのモデルを選択できる。
Stable-Diffusion-v1-5を選択して実行する。
:::

**III. Data Acquisition**
!
:::box
3.1. Locating Train Data Directory
 デフォルトで実行する。学習用画像の保存場所が作成される。
:::

!

 :::box
3.2. Unzip Dataset
Gooole Driveに学習させたい画像のzipファイルをアップロードする。
保存したディレクトリのパスをコピーして、zipfile_urlに貼り付けて実行する。
実行後 /content/LoRA/train_dataに自動的に保存される。
:::

**IV. Data Preprocessing**
!
:::box
4.1. Data Cleaning
convertにチェックを入れて実行する。
学習のための形式に対応していない画像は自動で削除される。
:::

:::box
4.2. Data Annotation
画像を認識し自動でキャプションを作成するためのブロック

4.2.1. BLIP Captioning
自動でキャプションをつける際のパラメータを変更できる。デフォルトで実行。

4.2.2. Waifu Diffusion 1.4 Tagger V2
下部のgeneral_thresholdを0.85程度に設定する。大きくするとタグの数が少なくなる。
特定の人物を学習させたい場合は数値を大きくすることが一般的。
traindataのファイルにキャプションが入ったテキストファイルが追加される。
以下の画像には”a man in a black suit and black shirt”と自動的にキャプションが追加された。
!
:::





**V. Training Model**
!
:::box
5.1. Model Config
上記の画像通りに入力して実行する。
:::


:::box
5.2. Dataset Config
dataset_repeats を１に変更する。同じ画像を学習させる回数を調整できる。
flip_augにチェックを入れると左右反転させた画像を学習させられる。
その他はそのままで実行。
:::

:::box
5.3.~ 5.5までをデフォルトのまま実行する。画像の枚数にもよるが1時間〜2時間程度で学習が完了する。完成したLoRAファイルはマイドライブのLora/outputに自動で保存される。
拡張子.safetensorsがLoRAのファイルだ。一番上に保存されている番号が振られていないファイルが最終的な出力になっている。
!
:::


### STEP2  作成したLoRAを使って画像を生成する。
STEP1で作成したLoRAファイルを使って早速、画像を生成する。
15枚の画像で学習を行った結果、右の画像が生成できた。髪型やヒゲ、黒いスーツが強く学習されていることが確認できる。写実的で、AIで作成された画像とは気が付かない可能性があるクオリティだが、似ているが本人ではないことが一目で分かる程度だ。また顔や髪型の特徴と同時に黒のスーツも学習してしまっている。これは学習用画像がすべて同じ服装であるためである。
!
**各種パラメータ**
*** 
モデル  
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt;,professional, masterpiece, 8k, hyperrealistic portrait,  Japanese man, 30yo, dark eyes, detailed face, detailed skin, photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


&lt; lora:minobe_model:0.9 &gt;はLoraファイルの適用の強さを示すもので数値を変更して調整できる。Loraファイルを複数使用したときを考慮して0.8程度で狙った特徴が出るようにすることが一般的。


### STEP3 パラメータを変更して画像をさらに生成する。
次により本人に似た、理想に近い画像を生成するために学習のパラメータやプロンプトを変更していく。特に学習の精度に影響を与えるとされるmin_snr_gammaの値を-1から1に変えて新たなバージョンのLoraファイルを作成した。min_snr_gammaは学習の低step化に貢献するオプションであり、学習過程を大きく変化させるパラメータである。推奨値は5とされている。
!
*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, Standing in the Desert,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


!

*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, ride a horse,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 

今回はStable Diffusion LoRAを使用して、Stable Diffusionをファインチィーニングし画像を生成した。画像を15枚を準備して数時間でコードを一切書くことなく簡単に、驚くほど精巧な画像を生成できた。Stable Diffusion LoRAには多くのパラメータがあり、それらの適正値を見つけることでさらに精度が向上すると予想される。パラメータの適正値は「アニメ風の画像を生成したい」や「同じポーズの画像を生成したい」「綺麗なアジア人女性を生成したい」など目的によって変化するため、各々が生成された結果を見ながら、理想の生成画像に向かって微調整を加えていく必要がある。

</description><pubDate>Tue, 06 Feb 2024 07:47:09 +0000</pubDate></item><item><title>Webアプリケーションの巡回ツールを開発せよ｜MBSD Cybersecurity Challenges 2023</title><link>https://ledge.ai/articles/mbsd-security-contest2023</link><description>三井物産セキュアディレクション株式会社が主催する、専門学校・高等専門学校を対象としたセキュリティコンテスト『{target=“_blank”}』の最終審査会が、2023年12月15日（金）に東京都大手町で行われた。

## セキュリティ業務の一端を疑似体験
本コンテストは、これからの時代を担う学生に向けて、より実践的で現実味のある課題を用意し、セキュリティ業務の一端を疑似体験しながら、課題を解決するためのアイデアや技術を競うものだ。入賞者には副賞が設定されており、最優秀賞には外付けSSD(4TB)とMeta Quest 3、2位には外付けSSD(2TB)と高級キーボード、3位には外付けSSD(1TB)とRaspberry Pi4 スターターキットを、受賞者ー１人ひとりに贈るという、かなり豪華な内容となっている。

第8回目を迎えた今回は、全国より18校 55チームのエントリーがあり、最終審査会へは上位10チームが参加した。
!
:::small
最終審査会参加チーム：{target=“_blank”}より
:::

本コンテストの課題は『Webサイトに実際にアクセスし、診断対象となる箇所を抽出、診断対象の規模を把握するための自動巡回ツールを開発し、提出すること』。学生は、Webサイト運営会社のWebアプリ診断を行うチームメンバーとして、ツールの開発から説明資料の作成、最終選考ではプレゼンテーションを行った。

本コンテストの開催フローは以下の通り。エントリーは2023年7月より開始したため、12月の最終審査まで5ヵ月の期間をかけてコンテストは実施された。

- エントリー受付
- 課題配布
- 説明資料・巡回ツール提出
- 一次審査結果発表
- 性能審査
- 最終審査会（オフライン開催）


## 最優秀賞は新潟コンピュータ専門学校『復活の電子遊戯部』
!
:::small
最優秀賞に輝いた『復活の電子遊戯部』チーム
:::
最終審査に残ったチームの中で、最優秀賞に輝いたのは、新潟コンピュータ専門学校『復活の電子遊戯部』だ。プレゼンテーションでは、開発した巡回ツールをオーディエンスがその場で触れられる試みもあり、随所に工夫が見られた。

!
:::small
開発した巡回ツールをその場で試せる実演用のQRコードを使ったプレゼンテーション
:::
受賞コメントでは、「全て穴だらけでグダグダだと思っていたけれど最優秀賞をいただけて感無量。本当にありがとうございました。」とコンテストの感想を述べた。
:::box
『復活の電子遊戯部』審査員の評価
- インストールがシンプルで、遷移図やスクリーンショットの機能も非常に良い機能だったと思います。
- ロードマップが準備されているのも良かったです。
- 発表も全体的にまとまっており、今までにない、その場でツールに触れるようにする試みも良かったと思います。
:::

第2位は、YIC情報ビジネス専門学校『塞翁が馬』。同チームは、内部での性能テストのためにテストサイトを自作するなど、他チームにはないプロセスでツールを開発した点が大きく評価された。
:::box
『塞翁が馬』審査員の評価
- 再検索機能が良く、テストサイトを自作しているところに意気込みややる気を感じました。ステータスによる色分けなどインターフェースが分かりやすく、動作状況がリアルタイムに表示されるのが良かったです。
- リーフレットなどで分かりやすくアピールしているのも良かったと思います。
- フラグの検出率がもう少し上がると良かったと思います。
:::
第3位は、審査員から「出来ないと思っていた画像内のフラグに対応してきたのが面白かった」と評価された、情報科学専門学校『Bananacat』が輝いた。
:::box
『Bananacat』審査員の評価
- プロキシ機能が特徴的で、ドキュメントがマークダウンのみで玄人向けという感じでした。
- 機能の優位性を分かりやすく説明していて、ツールの特徴が良く理解できました。
- できないと思っていた画像内のフラグに対して、対応してきたのが素晴らしい。
:::

## セキュリティ業界で第一人者を目指してほしい
!
:::small
三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャー 洲崎氏
:::

表彰式終了後、全体講評として三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャーの洲崎氏は「非常に嬉しく思ったのは、コンテストの卒業生がセキュリティ業界の一員として活躍していること。ぜひ皆さんもセキュリティ業界に来ていただき、またどこかでお会い出来たらと思う」と語った。また、同社 PS事業部 レッドチームの国分氏も「これから新たなセキュリティ技術が出てくると思うが、いち早くチャレンジして、ぜひ第一人者を目指してほしい」と、若い力への期待を露わにした。</description><pubDate>Tue, 23 Jan 2024 08:23:53 +0000</pubDate></item><item><title>大学入試の記述式対策もAI活用　駿台、AI学習教材「スルメ」で特許を取得</title><link>https://ledge.ai/articles/sundai_patented_surume</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年12月26日、学校法人駿河台学園（駿台）は、エスエイティーティー（SATT）との共同開発により、記述式問題対策のAI学習教材「スルメ」で特許を取得したことを{target=“_blank”}した。

この教材は、難関国公私立大入試の記述式問題対策として開発され、学習者の理解度に応じた最適な「ヒント」をAIが自動で提示する仕組みが特徴とされる。

**ヒント画面（解答に行き詰った際、段階的に与えられるヒントを確認する）**

!
:::small
画像の出典：{target=“_blank”}
:::



**解答画面（タブレット上で解く。解答は手書きで、自動採点される。メモやノートを取ることも可能）**

!
:::small
画像の出典：{target=“_blank”}
:::



「スルメ」を特許取得に導いたのは、個別の学習状況及び科目特性に応じた最適な予測正答率を分析し、それに基づいて難易度調整を行うシステムの新規性と、それを裏付けるデータによるものだという。特に、電気通信大学植野真臣教授の研究を基にした予測正答率の最適化がこの特許の核心とされている。

今後、駿台は「スルメ」を使用する学習者のデータに基づいて得られた分析結果を活用し、学習効果を最大化する予定だという。現在は「物理」「化学」に加えて「数学」の記述式問題に対してもこのシステムを適用し、さらに「英語」のリスニングや文法問題への適用も検討しているとのことだ。

:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Jan 2024 02:44:39 +0000</pubDate></item><item><title>GPT Store(GPTストア)とは｜GPTを公開して収益化する方法</title><link>https://ledge.ai/articles/GPT-Store</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2023年12月の公開が予定されていたが、延期が発表されていたGPT Storeが2024年1月10日(現地時間)についに公開された。GPT Storeは、GPTsで構築されたオリジナルのGPTをユーザー全体と共有できる新しい機能だ。さらにGPT Storeは収益化が可能であり、新たなマーケットとして期待が高まっている。

:::box
**目次**
- GPT Storeとは
- GPT Storeの利用方法と料金
- GPT Storeで自作のGPTを公開する方法
- GPT StoreでGPTを公開して収益化する方法
- GPT Storeの注意点
:::

## GPT Storeとは

GPT Storeは、GPTsで構築されたGPTを全ユーザーが公開・共有・検索できるプラットフォームである。この機能により、ユーザーは特定のタスクに特化したGPTを容易に見つけることができる。例えば、Open AI公式のGPTとして、文章の添削やライティングスキルの向上に特化した「Creative Writing Coach」や冷蔵庫の中身の写真から料理を提案する「Sous Chef」が公開されている。

:::box

:::

## GPT Storeの利用方法と料金

GPT Storeは月額20ドルの「GPT Plus」に入会することで利用できる。
さらに2024年1月10日(現地時間)に**新料金プラン**「**Team**」が追加された。

新プラン「Team」の特徴は以下の通り

料金は一人当たり年払いで月額25ドル (メンバー2人以上から利用可能)
GPT-4使用時に制限があった送信できるメッセージ数の上限増加
チーム内でのGPTsのワークスペース
使用者のデータを学習しないこと

画面左のサイドバーにある「Explore GPTs」をクリックすると以下のような画面が表示され、すぐに利用できる。有料プランに加入していなくても検索のみは可能。
!
左上の地球アイコンをクリックすると、Global ViewのOn・Offが切り替えられる。
Onでは世界のランキング、Offでは日本のランキングが表示される。

## GPT Storeで自作のGPTを公開する方法

GPTsでオリジナルのGPTを構築後、保存する際に3つの選択肢から保存できる。

- Only me (自分しかアクセスできない)
- Anyone with a link (発行できるリンクを知っている人なら誰でも)
- Everyone (全ての人に向けてGPT Storeで公開)

Everyone に設定しGPT Storeで公開する場合、Buider ProfileのNameを有効にして、ユーザー名を公開する必要がある。また必ずを守ったGPTでなければならない。

## GPT StoreでGPTを公開して収益化する方法

現在GPT Storeの収益化についてOpen AIで以下のように発表されている。
:::box
**Builders can earn based on GPT usage**
In Q1 we will launch a GPT builder revenue program. As a first step, US builders will be paid based on user engagement with their GPTs. We'll provide details on the criteria for payments as we get closer.

第1四半期(1月~ 3月)には、GPTビルダー収益プログラムを開始します。第一段階として、米国のビルダーには、GPTへのユーザーのエンゲージメントに基づいて報酬が支払われます。支払い基準の詳細については、追ってお知らせします。
:::

第一段階は米国のビルダーと明記されているため、**日本のビルダーの収益化はまだ先**になりそうだ。またユーザーによるエンゲージメント数によって、収益が発生することが判明した。
エンゲージメント数とはユーザーが「反応して行動した回数」である。

## GPT Storeの注意点

公式のガイドラインはとから確認できる。


### 作成が禁止されているGPT(一部抜粋)
- 違法行為のコンテンツ
- 児童性的虐待 児童を搾取したり危害を加えたりする素材またはコンテンツ
- 嫌がらせ、嫌がらせ、または暴力的なコンテンツの生成
- マルウェアの生成
- 兵器開発・軍事と戦争
- エネルギー、交通、水の重要インフラの管理または運営
- 自殺、切断、摂食障害などの自傷行為を促進、奨励、または描写するコンテンツ
- ギャンブル
- 詐欺
- 盗作
- 学術不正
- アダルト コンテンツ、アダルト産業、出会い系アプリ

以上のようなコンテンツが禁止されており、「競馬の予想ができるGPT」などの作成はガイドラインの禁止事項に該当する恐れがある。

### GPTの名称に関して

GPT の名称を「GPT」で終わらせることは推奨されていない。作成したアプリやサービスの内容に適した名称を与える必要がある。ただし、禁止されているわけではないため個人用に「〇〇GPT」という名称を与えることは問題ない。

:::box

:::



</description><pubDate>Thu, 11 Jan 2024 05:41:21 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>生成AIプロジェクトの開発者コミュニティ、アメリカ・インドに次いで日本が先導ーGit Hub 2023年の動向レポート</title><link>https://ledge.ai/articles/github_the_state_of_open_source_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2023年11月8日、「オープンソースとAIの現状」に関する報告を{target=“_blank”}した。

報告によると、開発者たちは大量の生成AIプロジェクトに取り組んでいる。特にOpenAIなどの基礎モデルを用いた開発が目立ち、生成AIプロジェクトは2023年のオープンソースプロジェクトのトップ10にランクインしたという。これらのプロジェクトには、全開発者の92%が使用または実験中であると報告されており、GitHub上での次世代AIイノベーションを牽引すると期待されている。

また、2023年はオープンソースへの初参加者が最も多く、これまで商業的に支援されたプロジェクトが初参加者の大部分を占めていたが、今年は生成AIプロジェクトも初参加者向けのトップ10プロジェクトに登場した。GitHub上のプライベートプロジェクトの数は前年比38%増加し、全活動の80%以上を占めている。

全世界で、GitHubを使用してソフトウェアを構築し、共同作業を行う開発者が増加している。アメリカは依然として最大の開発者コミュニティを持つが、他の地域も成長を見せている。

次の5年間で最も成長が見込まれる開発者コミュニティに関する予測では、インドが2027年までにGitHub上で最大の開発者コミュニティになると予想されている。日本の開発者数は約280万人で、世界8位にランクされており、今後の成長が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::

さらに、生成AIは個々のコントリビューターの数において148%の年間成長率を達成し、生成AIプロジェクトの総数も248%増加している。この分野において、アメリカ、インド、そして日本が先導しており、他の地域も追随している。

!
:::small
画像の出典：{target=“_blank”}
:::



報告は、2022年10月1日から2023年9月30日までに、GitHub から取得した匿名化されたユーザーおよび製品データに基づいて作成された。

:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:49:07 +0000</pubDate></item><item><title>AIの遅れ取り返せるか　Appleが開発者向けフレームワーク「MXL」Geminiの裏でひっそりと公開</title><link>https://ledge.ai/articles/apple_released_mlx</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2023年12月、AI分野での新たな取り組みとして、開発者向けのオープンソース機械学習フレームワーク「MLX」を{target=“_blank”}した。GoogleのAIモデル「Gemini」の発表と同時であったと各メディアで報じている。

MLXはAppleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​。

Appleの機械学習研究者であるAwni Hannun 氏は、自身のX（旧Twitter）アカウントで、
「ちょうどホリデーシーズンに間に合うよう、本日、Apple 機械学習研究からいくつかの新しいソフトウェアをリリースします。
MLX は、Apple シリコン (つまり、ラップトップ) 向けに特別に設計された効率的な機械学習フレームワークです」
と{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

{target=“_blank”}は10月に、Appleの経営陣は業界の突然のAIブームに驚かされ、昨年末から急いで対応を図っていたと報じており、MLXの発表は、AI分野での急速な進展に対応しようとするAppleの努力の一環との見方もある。



:::box

:::
:::box

:::</description><pubDate>Fri, 15 Dec 2023 05:44:48 +0000</pubDate></item><item><title>古いコードを最新のJavaに生成AIが自動変換「Amazon Q Code Transformation」</title><link>https://ledge.ai/articles/aws_amazonq_code_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月28日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて「Amazon Q Code Transformation」を{target=“_blank”}した。

この機能はAmazon Qを使用して、古いJavaおよび.NETのコードを最新のJavaにAIが自動変換するツールで、アプリケーションの保守と最新化を簡素化することを目的としている。現在Javaアプリケーションのバージョン8および11から17へのアップグレードが可能で、近い将来にはWindowsベースの.NET Frameworkアプリケーションをクロスプラットフォームの.NETに変換できるようになる予定だという。

かつて開発者は、各アプリケーションのアップグレードに 2~ 3日かかっていたが、同社内部テストでは、手動アップグレードに通常は数日または数週間かかるのに対し、新機能を使用すると数分でアプリケーションをアップグレードでき、別の要件へ集中する時間に充当できたという。

このツールは、既存のコードを自動的に分析し、変換計画を生成して、計画に基づいた変換タスクを完了する。パッケージ依存関係の特定と更新、時代遅れかつ非効率的なコードコンポーネントのリファクタリングを行い、新しい言語フレームワークへの切り替えとセキュリティのベストプラクティスの組み込みを行う。変換が完了すると、ビルドとテストの結果を含む変換されたコードをレビューし、変更を承認することができる。

Amazon Q Code Transformationのプレビューは、 AWS Toolkit for IntelliJ IDEAおよびAWS Toolkit for Visual Studio Code のAmazon CodeWhisperer プロフェッショナル ティアの顧客が利用可能。組織が使用するプロファイルへのアクセスを許可する必要がある。プレビュー中の使用には追加料金不要。


:::box

:::
:::box

:::
</description><pubDate>Fri, 08 Dec 2023 15:20:21 +0000</pubDate></item><item><title>GTP-4を利用した「GitHub Copilot Chat」一般提供12月より「GitHub Universe 2023」で発表</title><link>https://ledge.ai/articles/github_universe2023</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国GitHubは2023年11月8日、サンフランシスコで年次イベント「GitHub Universe 2023」を開催した。1日目の{target=“_blank”}で、CEOのThomas Dohmke氏は「GitHubがGitという仕組みの上に構築されたように、今日私たちはCopilotの上に ”Re-founded”（=再構築）された」と述べた。また、GitHubの掲げるビジョン「Copilot X」は、ソフトウェア開発のライフサイクル全般を支援することを目指すという。

生成AIを活用した「GitHub Copilot」シリーズの進展、特に「GitHub Copilot Chat」の一般提供の発表に注目が集まった。この新機能は、自然言語での指示を通じて、コーディングを支援するもので、すでにベータ版は全個人向けユーザーに9月より無償で提供している。既存のサブスクリプションサービス、GitHub Copilotプランの一部として、organizationおよび個人ユーザーに対して12月より一般提供される予定だ。

Copilot ChatはGPT-4を使用しており、より正確なコードの提案と説明を実現しているという。コードに関する質問や議論を可能にし、さまざまなスラッシュコマンドを通じて、コーディングタスクを簡素化する機能も備えている。このサービスは、GitHubのウェブサイトやモバイルアプリにも統合されており、開発者はいつでもどこでもこの機能を利用できるようになる​​とのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

講演の最後には新機能として、自社のコードをもとにGitHub CopilotのAIモデルをカスタマイズする「GitHub Copilot Enterprise」が紹介された。これにより、組織は自社特有のコードベースに合わせたAIのサポートを受けられるようになる。


:::box

:::</description><pubDate>Wed, 15 Nov 2023 05:08:10 +0000</pubDate></item><item><title>オルツが数兆パラメータ規模の大規模言語モデル構築に着手</title><link>https://ledge.ai/articles/alts_begins_building_llm_with_trillions_of_parameters</link><description>:::small
画像の出典：[オルツ](https://alt.ai/news/news-2710/{target=“_blank”}
:::

オルツは2024年4月26日、数兆パラメータ超規模の大規模言語モデル（LLM）の開発に着手したことを{target=“_blank”}した。同社の約10年間にわたる自然言語処理を含むAI技術の研究開発の集大成であり、ビジネスシーンや日常生活における実用的な応用を目指しているという。

オルツは、高いパフォーマンスを実現しつつも、スピードとコストの効率を重視したモデル開発を進めている。開発される言語モデルは、エンドユーザーが直面する具体的な問題解決を念頭に置いた設計が施されており、実運用時の計算効率とコストパフォーマンスに優れていることが求められる。

オルツの新LLMは、特に日本語処理の精度向上に特化しており、既存のモデルを超える使いやすさとカスタマイズ性の実現を目標にしているという。これには、高品質な学習データの確保と効率的なデータ管理が重要となり、エネルギー消費の観点からも、データセンターの地理的分散化やエッジコンピューティングの利用が進められている。

### 技術革新に向けた多角的アプローチ
オルツは、LLM開発を通じて以下のような技術革新を推進しているという
- 学習データの大規模構築
- インストラクションデータの構築と自動化
- プロンプトエンジニアリングの自動化
- 既存モデルの改良を可能にする生涯学習の研究加速
- 軽量モデルによる大規模モデル同様の出力再現の研究加速
- LLM特化チップ（TPU, LPU, NPU）の研究開発

この取り組みを通じ、国内外のパートナーとの連携を積極的に推進し、グローバル市場での競争力を高めるとともに、日本発の技術革新を世界に示していく意向だという。



:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Apr 2024 12:36:32 +0000</pubDate></item><item><title>Microsoftのトーキングヘッド生成AI「VASA-1」　1枚の静止画と音声データで、その人物があたかも喋っているような動画を生成</title><link>https://ledge.ai/articles/microsoft_vasa-1</link><description>:::small
画像の出典：{target=“_blank”}
:::

Microsoft Research Asia は2024年4月16日、AIモデル「VASA-1」が、1枚の静止画と音声データから、その人が話しているかのような動画をリアルタイムで生成する技術を{target=“_blank”}した。

VASA-1は、単一の画像と音声クリップを用いて、話している人物のリップシンクや表情、頭の動きを含むリアルなビデオを作成可能だ。

このAIは、特にリアルタイムアプリケーションにおいてその能力を発揮する。オンラインモードでは、512x512の解像度で最大40fpsのフレームレートを達成し、170ミリ秒の極めて低い遅延で動作する。また、オフラインバッチ処理モードではさらに高速で45fpsを実現するという。

VASA-1は、表情の細かいニュアンスや自然な頭の動きを捉えることができ、話者の感情や意図をよりリアルに伝えるという。さらに、このモデルは外見、3D頭部ポーズ、顔の動きを分離して扱え、高度なカスタマイズを可能にする。

### Controllability of generation
視線の方向、頭の距離、感情オフセットなどのオプションの信号を条件入力した例

!
:::small
画像の出典：{target=“_blank”}
:::

### Out-of-distribution generalization
学習分布から外れた写真や音声入力を扱う能力を示す例（芸術的な写真、歌声、英語以外の音声）データはトレーニングセットには存在しないという
!
:::small
画像の出典：{target=“_blank”}
:::

Microsoftは、この技術が誤用されることを防ぐため、製品化やAPIのリリースは行わず、研究デモンストレーションに留める方針だ。この技術の責任ある使用を確実にするため、適切な規制が整うまでオンラインデモや関連する実装の詳細を公開しないと明示している。


:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:45:53 +0000</pubDate></item><item><title>Googleの研究チーム開発の新技術「Infini-attention」無限のテキスト処理を実現ーー長大な文脈を踏まえた濃い内容の応答を可能に</title><link>https://ledge.ai/articles/google_infini_attention</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月、Googleの研究チームはトランスフォーマーベースの大規模言語モデル（LLM）を用いて、理論上無限のテキスト長を処理できる新技術「Infini-attention」を{target=“_blank”}した。

論文のタイトルは「Leave No Context Behind（コンテキストを置き去りにしない）」

Infini-attentionは、有限のメモリと計算リソースを使いつつ、入力の長さに制約を設けずに処理を可能にする。この技術の鍵は「圧縮メモリ」の導入にあり、これにより不要になったデータを完全に削除するのではなく、有用な情報を効率的に保存し、再利用することができる。具体的には、マスクされたローカルアテンションと長期リニアアテンションを一つのトランスフォーマーブロック内で統合しているという。


**無限に長いコンテキストを処理するためのアーキテクチャ**
!
:::small
画像の出典：{target=“_blank”}
:::

この技術の主な特徴は、過去のキーとバリューの状態を圧縮メモリに保存し、新たな情報を処理する際にこれらを活用することで、以前のコンテキストを用いて高精度なテキスト生成を実現する点にある。このアプローチにより、LLMは新しい情報を迅速に処理し、より正確なテキストを生成する。

具体例としては、長編小説の要約や長時間にわたる会議の議事録作成など、情報の連続性を重視するシーンで、その価値が発揮されると考えられる。
たとえば、「戦争と平和」のような長編小説を要約する際には、初期の章で登場した重要なキャラクターや出来事を圧縮メモリに保存し、それを数百ページ後の章で参照することで、物語全体の文脈を保持しながら要約を行う。また、数時間にわたる国際会議の議事を記録する際にも、会議の開始から終了までの情報を追跡し、重要な議論や決定事項を適切に記録することが可能になるなど。


**Infini-Transformer(上)はコンテキストの全履歴を持つのに対し、Transformer-XL(下)は最後のセグメントのみのKV状態をキャッシュするため、古いコンテキストを破棄する**
!
:::small
画像の出典：{target=“_blank”}
:::

Infini-attentionの導入は、LLMが扱う情報量を大幅に増やすことができ、これによりより複雑で内容の濃いテキスト応答を生成可能にする。この技術は、特に長大なテキストデータを処理する必要がある分野での応用が期待されており、学術研究や法律文書の解析、長編の文学作品の要約など、さまざまなシナリオで利用されることが考えられる。

論文の実験結果によると、1Mトークンを超えるシーケンス長での言語モデリングベンチマークにおいて、従来のモデルと比較してInfini-attentionが顕著に優れた性能を示しており、特に1Bおよび8Bのモデルを使用した1Mシーケンス長のパスキー文脈ブロック取得や500K長の書籍要約タスクでのこのアプローチの有効性を実証したという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 25 Apr 2024 12:29:45 +0000</pubDate></item><item><title>国内初、AIが執刀中の外科医の視覚をリアルタイム支援するプログラム医療機器「Eureka α」の薬事承認を取得</title><link>https://ledge.ai/articles/anaut-surg_eureka-alpha</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月12日、AI手術支援スタートアップのアナウト株式会社は、同社の開発した外科手術視覚支援プログラム「Eureka α（ユーリカアルファ）」が、厚生労働大臣から製造販売承認を取得したことを{target=“_blank”}した。


このシステムは、手術中に疎性結合組織の位置や領域をリアルタイムで推定し、強調表示することで外科医の視覚を支援する。

**「Eureka α」の製品イメージ**
!
:::small
画像の出典：{target=“_blank”}
:::

Eureka αは手術用の内視鏡システムや手術支援ロボットからの映像信号を解析し、サブモニター上で疎性結合組織を強調表示する。この技術は特に胃、大腸、鼠径ヘルニア領域の手術で利用され、外科医の手術操作を視覚的に支援する。

国内でこの種のプログラム医療機器が承認されるのはこれが初めて。手術用画像認識支援プログラムという新たな医療機器カテゴリーが厚生労働省により2024年1月に設立された後のことだ。


これまでに同社は、20以上の医療機関と共同研究を行い、外科医とエンジニアが共同で開発に取り組んできたという。また、同社はすでに「Surgical Vision Eureka」として知られる教育及び研究用ソフトウェアを提供しており、今後は消化器外科領域から婦人科・泌尿器科領域への適用範囲を拡大する計画であるとのこと。

この技術の導入により、外科医の疲労軽減や手術の安全性向上が期待され、さらには手術技術の継承と発展に寄与すると見られている。




:::box

:::
:::box

:::

</description><pubDate>Thu, 25 Apr 2024 12:21:42 +0000</pubDate></item><item><title>スマートグラスを超低電力で動かせるようになる「AIソナー技術」をコーネル大研究チームが開発　反響する音声を拾いAIが表情や視線を推測する</title><link>https://ledge.ai/articles/cornel_uni_ai-powered_sonar</link><description>:::small
画像の出典：{target=“_blank”}
:::

コーネル大学の研究者は、ソナーのようなセンシングを通じて人の視線と顔の表情を追跡する2つの技術を{target=“_blank”}した。

これらは商用スマートグラスやVR、ARヘッドセットに装着可能で、従来のカメラベースのシステムと比較して著しく低い電力で動作する。

「GazeTrak」と「EyeEcho」という新たな２つの技術は、眼鏡のフレームに取り付けられたスピーカーとマイクロフォンを用い、顔や眼の動きによって生じる音波の反射を捉えるという。

## GazeTrak：音響信号を利用して視線を追跡する
@


スピーカー１つとマイク４つをメガネの左右のフレームの内側に配置し、眼球と目の周囲からの音波を反射させ拾う。結果として得られる音声信号は、AIが視線の方向を継続的に推測するようカスタマイズした深層学習パイプラインに供給されるという。

このシステムは、カメラに依存する最先端の視線追跡技術ほどにはまだ機能しないが、新しいデバイスは音声信号も有効であるという概念を実証する。最適化を進めることで、同じ精度を達成し、必要なスピーカーとマイクの数を減らすことができるとのこと。

**GazeTrakより：視線をスクリーンの異なる領域に移動させたときの異なるマイクのエコープロファイル**

!
:::small
画像の出典：{target=“_blank”}
:::

## EyeEcho：顔の表情をリアルタイムで検出し、アバターを通じて再現
@


EyeEchoのシステムは、スピーカー1つとマイク1つをメガネのヒンジの隣に配置する。表情の変化に応じて、顔の皮膚の動きを捉えるために下向きに配置する。反射された信号は AIが解釈するという。 

この技術を使用することで、騒がしいカフェや路上でも、ユーザーはアバターを介してハンズフリーのビデオ通話が可能だ。一部のスマートグラスには顔を認識したり、いくつかの特定の表情を区別したりする機能があるが、現時点では EyeEcho のように継続的に表情を追跡するものはないとのこと。


**EyeEchoより：デザインされた表情と対応する差分エコープロファイル**

!
:::small
画像の出典：{target=“_blank”}
:::

これらのデバイスは、スマートグラスのバッテリーで数時間、VRヘッドセットでは一日以上持続する性能を持つという。
デバイスを開発した Smart Computer Interfaces for Future Interactions (SciFi) Labを率いるコーネル大学情報科学助教授である Cheng Zhang 氏は、「小型で、低価格、超低電力なので、毎日スマートグラスに装着してもバッテリーがすぐには減らない」と語る。

2つの研究を主導する博士課程の学生 Ke Li 氏は、ビデオの代わりに音声信号を利用することで、プライバシー保護にも貢献すると強調する。また「VR環境では、他のユーザーとのインタラクションを向上させるために、詳細な顔の表情と視線の動きを再現したい」と述べた。

これらの技術は、VR体験の向上だけでなく、視力が低い人々のためのスクリーンリーダーのサポートや、アルツハイマー病やパーキンソン病などの神経変性疾患の進行監視にも応用可能だという。



:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Apr 2024 07:40:15 +0000</pubDate></item><item><title>ボストン・ダイナミクスのヒト型ロボ「Atlas」油圧式が引退サヨナラ動画発表　翌日「新型Atlas」の動画公開</title><link>https://ledge.ai/articles/boston_dynamiccs_farewell_to_hd_and_hello_new_atlas</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月18日、ボストン・ダイナミクスは、長年にわたり開発を進めてきた人型ロボット「Atlas」の油圧式モデルの引退を発表する動画を{target=“_blank”}し、ロボティクス業界における一時代の終わりを告げた。この動画は、Atlasが技術的障壁を越え、さまざまな挑戦に取り組む様子をフィーチャーしている。

@



引退動画の公開翌日、同社は全く新しい「新型Atlas」の動画を{target=“_blank”}した。

完全電動式となった新型Atlasは、油圧式の前モデルに比べ、より強力で広範囲な動きを実現し、さまざまな操作ニーズに応えるための複数のグリッパーをテスト中だという。このロボットは、Hyundaiとの提携を通じ、自動車製造における新たな可能性が期待されるほか、初期段階からの顧客との連携を重視し、実用化に向けた具体的なテストと改良が進められているとのことだ。


@



同社はこの新型ロボットを通じて、ロボットが日常生活においてより積極的な役割を果たす未来を構築することを目指している​​という。この一連の動きは、ロボティクス業界における新たなマイルストーンとされ、同社の未来に向けたビジョンの一端を示す。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Apr 2024 08:12:48 +0000</pubDate></item><item><title>AppleがスマートフォンのUI画面を認識できるマルチモーダルLLM「Ferret-UI」に関する論文を発表</title><link>https://ledge.ai/articles/apple_ferretui_mllm</link><description>:::small
画像の出典：{target=“_blank”}
:::

Appleは2024年4月8日、スマートフォンのUI画面を認識するために設計したマルチモーダル大規模言語モデル（MLLM）「Ferret-UI」を開発したと{target=“_blank”}した。

最近注目されているマルチモーダル大規模言語モデル（MLLM）だが、スマートフォンのUI画面を認識するにはパフォーマンスが不足していると言われている。スマートフォンのUI画面は縦長に対してトレーニングで使用される画像のほとんどが横長でアスペクト比が異なることが理由のひとつとされている。

今回発表された「Ferret-UI」は、スマートフォンのUI画面に含まれるアイコンやテキストなどの小さな対象物に対応するため、画像の細部を拡大し強化された視覚的特徴を活用する「any resolution」という技術を組み込み画面の解像度に関係なくUIの詳細をより正確に認識することができるようだ。

アイコン認識、テキストの検索、ウィジェットのリスト化など幅広い基本的なUIタスクをトレーニングサンプルとして収集しており、領域ごとにアノテーションが付けられている。これらのサンプルは言語と画像の基礎付けや参照が容易になり、多くのサンプルを学習することでUIをより正確に理解できるようになっている。

{target=“_blank”}によると「Ferret-UI」はGPT-4Vなど既存のUI対応MLLMを上回る優れた性能を示しているようだ。iPhoneに搭載しているSiriと連携し、より高度なタスクを自動化できるようになればさらに様々な場面で役立つツールになりアクセシビリティ向上が期待できるという。

:::box

:::
:::box

:::</description><pubDate>Wed, 17 Apr 2024 08:19:40 +0000</pubDate></item><item><title>イーロンマスク率いるニューラリンクのライバル会社「シンクロン」が脳インプラント臨床試験の患者募集を始める</title><link>https://ledge.ai/articles/synchrone_launches_patient_registry</link><description>:::small
画像の出典：{target=“_blank”}
:::

脳波を用いたデジタルデバイス操作技術を開発する米国企業シンクロンは2024年4月8日、運動障害を持つ患者の機能回復を目指す脳インプラント「Stentrode」の臨床試験に向けた患者登録の開始を{target=“_blank”}した。

患者、ケアギバー、臨床医が一堂に会し、Brain-Computer Interface（BCI）がどのように人々の移動能力を向上させるかを学ぶためのコミュニティ中心の取り組みだという。

シンクロンの技術は、脳の神経コードを解読し、デジタルデバイスを操作するための運動意図を復元する新しいアプローチである。同社のCEOであるトム・オックスリー氏は「BCI技術により運動障害を持つ個人が独立性を回復できるようになり、日常のタスクをより簡単かつ効率的に行えるようになることは、この技術の革命的な前進である」と述べた。

同社の技術は、脳の自然な「ハイウェイ」である血管を利用し、侵襲的な脳手術を避けながら装置を脳に埋め込むことが可能だという。Stentrode装置は、頚静脈を通じて最小侵襲で脳の運動皮質に挿入される。

この装置は脳の運動意図を検出し、無線で外部デバイスへ信号を送信することで、患者はデジタルデバイスを自由自在に操作可能とのこと。ニューラリンクと異なり、シンクロンは開頭手術を必要としない治療法を提供している点が特徴となる。

脳マシンインターフェース市場において、シンクロンはニューラリンクとの競争を通じて、より多くの患者に新たな希望を提供する可能性を探求している。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 07:31:56 +0000</pubDate></item><item><title>「光る君へ」をAIで紐解く　大阪工業大学が『源氏物語』をAIで学習するシステム「おしゃべり源氏物語」を開発</title><link>https://ledge.ai/articles/oit_ai_genji_monogatari</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月5日、大阪工業大学の情報科学部ネットワークデザイン学科、矢野浩二朗教授が主導する研究チームは、複数のAI技術を組み合わせた『源氏物語』学習支援システム「おしゃべり源氏物語 －生成AIで学ぶ『源氏物語』－」を開発したことを{target=“_blank”}した。

このシステムは、音声入力やチャットを介して『源氏物語』に関するユーザーの質問に対し、AIが回答するもの。プロジェクトには、AmiVoiceやOpenAIのChat APIを含む6種類のAI技術が利用されており、和歌のリズム認識や発音タイミングの調整など、具体的な技術的工夫が行われた。また、『源氏物語』専用のデータベースを用いることで、高い精度の回答生成を実現している​という。

同システムは２月下旬から４週間、東京富士美術館で開催された展覧会に出展され、約3000人の来場者が体験した。このときのフィードバックを受け、矢野教授とそのチームは性能の改良を重ね、今後も更なる改善を続けるとのこと。

矢野教授は、「AIを用いることで、千年以上前の文学作品を現代の技術でどのように再解釈し、活用するかの一例を示すことができた」とコメントしている​​。このAIシステムを更に発展させ、パブリックなデータを用いた「Open 光源氏 AI」として他の施設でも展示を行う方針だという。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Apr 2024 13:21:02 +0000</pubDate></item><item><title>Anthropicの研究論文：LLMが訓練された安全策を回避する「脱獄」技術の発表　「今のうちに取り組むべき課題」</title><link>https://ledge.ai/articles/anthropic_many_shot_jailbreaking</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

「Claude3」の開発企業 Anthropicは2024年4月3日、大規模言語モデル（LLM）の安全対策を回避する「脱獄」技術「Many-shot Jailbreaking」に関する研究論文を{target=“_blank”}した。

この技術は、LLMが処理する情報量の増加、特にコンテキストウィンドウの拡大を利用するものだという。2023年初頭には長いエッセイ程度（約4,000トークン）であったコンテキストウィンドウは、現在では数百倍に拡大し、複数の長編小説相当（1,000,000トークン以上）サイズに及ぶ。

Many-shot Jailbreaking とは、偽の対話を含む大量のテキストをプロンプトとして使用し、モデルが訓練された安全機構を回避して危険または不適切な反応を引き出す技術だ。この技術が特に効果的なのは、コンテキストウィンドウの大幅な拡張により、プロンプト内で提供される情報の量が増えることで、モデルがコンテキスト内学習の過程で新たな行動パターンを採用するためだという。

研究では、偽の対話が含まれていると、モデルが安全に訓練されているにもかかわらず、最終的な危険なリクエストに対して回答を提供することが示された。

!
:::small
画像の出典：{target=“_blank”}
:::

この脆弱性は、特にLLMで効果的であり、その成功率は攻撃の長さに比例して増加する。Anthropicによれば、この技術は、同社のモデルだけでなく、他のAI企業のモデルにも有効であることが示された。技術の詳細は事前に他のAI開発者に説明され、システムに対する対策が実施されている。

Anthropicは、この研究を公開することが、問題の早期解決に寄与し、他のAI研究者との協力を促進し、長期的なコンテキストウィンドウを利用した潜在的な攻撃からモデルを守るための戦略を加速することにつながると考えていると述べている。この研究は、今後のモデルにおいて深刻な害を引き起こす可能性のある脱獄を防ぐために、今のうちに取り組むべき時であるとも強調している。

公式な論文は{target=“_blank”}から



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Apr 2024 12:02:42 +0000</pubDate></item><item><title>Apple　次世代Siriか？音声アシスタントが画面上のコンテキストを「見て」理解できるAI「ReALM」を発表</title><link>https://ledge.ai/articles/apple_realm</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2024年4月3日、ユーザーのスクリーン上に表示される情報を理解し、より自然なインタラクションを実現する新たなAIシステム「ReALM（Reference Resolution As Language Modeling）」を{target=“_blank”}した。この技術は、音声アシスタントがユーザーからの指示に基づき特定のアクションを実行するための、画面上の物体や文脈を「視覚的に理解する」能力を持つ。

ReALMは、ユーザーのスクリーン上に表示されるエンティティ、会話中に参照されるエンティティ、および背景で実行されるプロセスからのエンティティといった、さまざまなタイプのエンティティに対して参照解決を行うタスクを中心に設計されている。

たとえば、画面のコンテキストを「見て」理解し、ユーザーが「この取引先に電話する」と言った場合、ページ上に表示される取引相手の電話番号を認識し、追加の指示なしにその番号に自動で電話をかける機能を実現するという。

!
:::small
画像の出典：{target=“_blank”}
:::

ReALMの開発には、合成データやアノテーションを利用したデータセットが使用され、各データポイントにはユーザークエリとエンティティのリストが含まれる。これらのデータを用いて、画面上のコンテキストをテキストとして解析し、適切なエンティティを識別する。特に、ReALMはGPT-3.5およびGPT-4と比較してベンチマークされ、小規模モデルでGPT-4と同等の性能を達成し、大規模モデルではそれを大きく上回る結果を示したという。

!
:::small
画像の出典：{target=“_blank”}
:::


Appleは2024年のうちにAI関連で新たな発表をするとCEOのティム・クック氏が発言をしている。その発表が開発者会議「WWDC」となるのではと見られている。ReALMは果たして次なるのSiriとなるのだろうか。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Apr 2024 07:11:44 +0000</pubDate></item><item><title>中国が世界のAIトップ研究者の半数を輩出していることが明らかに　米シンクタンクのグローバルAIタレントトラッカー2.0の最新調査</title><link>https://ledge.ai/articles/macropolo_the_global_ai_talent_tracker2023</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月6日、シカゴ - ポールソン研究所のシンクタンクであるMacroPoloは、グローバルAIタレントトラッカー2.0の最新版を{target=“_blank”}し、AI分野でトップレベルの研究者たちの動きや集中地域に関する洞察を提供した。

「トップレベル」の判断には、Neural Information Processing Systems カンファレンス (NeurIPS) で承認された論文著者のデータ サンプルが用いられている。NeurIPSは、AIカンファレンスの中でも特に高い評価を受けており、ニューラルネットワークとディープラーニングの理論的進歩に特に焦点を当てた研究が多く発表されている。その選択性と人気はAI分野の進歩を示す重要な指標となっており、2019年以降、投稿論文数は2倍に増加しているものの、論文採択率は2019年は21.6％、2022年は約25％と低く、難易度の高い学会とされている。

2023年の最新調査によると、AI研究で世界の上位20％に位置するトップ研究者のほぼ半数が中国出身であることが明らかになった。中国は、AI分野でのトップ研究者の育成とその活躍の場への貢献で、アメリカや他の西洋諸国に匹敵、あるいはそれを上回る速度で成長しているという。

### トップレベルの AI 研究者の出身国 (学位に基づく上位20%)
!
:::small
画像の出典：{target=“_blank”}
:::

グローバルAIタレントトラッカー2.0のアップデートによると、2019年の調査と比較して、米国は依然としてトップレベルのAI人材の主要な就職先であり、米国と中国出身の研究者がトップレベルのAI人材の75%を占めている。

### 米国の機関で働くトップレベルAI 研究者の主要出身国
!
:::small
画像の出典：{target=“_blank”}
:::

中国は、成長する自国のAI産業の需要に応えるために国内のAI人材プールを拡大しており、より多くの中国人人材が国内産業で働くようになっている。そして、インドもまた、一流のAI研究者の重要な輸出国であると同時に、人材を国内に留める能力が高まっているという。

2022年には、インドのAI研究者の5分の1がインド内で働くことを選択しており、トップレベルのAI研究者の全体的な機動性が低下している傾向が見られるとのこと。これは、より多くのトップレベルの人材が母国に留まることを選んでいることを示しており、グローバルなAI人材の流れに変化の兆しが表れている。

### トップレベルのAI研究者が出身国で働く割合の変化
!
:::small
画像の出典：{target=“_blank”}
:::

### トップレベルの AI 研究者 (上位 ~20%) が勤務する主要国
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Apr 2024 13:41:28 +0000</pubDate></item><item><title>生成AIの児童安全安全対策強化へのコミットメント：主要AIテック企業が連携「子供の安全を優先すると確約」</title><link>https://ledge.ai/articles/thorn_generative_ai_principle</link><description>:::small
画像の出典：[THORN](https://www.thorn.org/blog/generative-ai-principles/{target=“_blank”}
:::

ThornとAll Tech Is Humanは、Amazon、Anthropic、Civitai、Google、Meta、Metaphysic、Microsoft、Mistral AI、OpenAI、Stability AIといった世界の主要なAI企業と協力し、児童の安全を保護するための「Safety by Design」原則に公式にコミットしたと{target=“_blank”}した。AI企業が、AI技術の開発、展開、および維持の各段階で子供の安全を優先することの確約である。

これらの原則は、AIによって生成される児童性的虐待素材（AIG-CSAM）およびその他の性的被害を防ぐことを目的としている。

公開された「生成AIによる安全設計：児童性的虐待の防止」の新しい報告書には、これらの原則が詳述されており、AI開発者、プロバイダー、データホスティングプラットフォーム、ソーシャルプラットフォーム、検索エンジンがこれらの原則を実施するための具体的な対策と戦略が定義されている。同報告書は、Thorn、All Tech Is Human、および参加企業の一部が共同で執筆した。

各社は、これらの原則に基づいて進行状況を透明に公表し共有することにも合意している。ジェネレーティブAI技術および製品に「Safety by Design」原則を統合することにより、これらの企業は子供たちを保護するだけでなく、倫理的なAI革新をリードしている。

生成AIの誤用は、すでに児童性的虐待の増加を加速している。技術の進展により、加害者は以前にも増して簡単に大量の内容を生成する能力を持ち、新たな虐待素材を創出したり、無害な子供の画像を性的な内容に変えたり、完全にAIで生成されたCSAMを作成することが可能となる。


**AIを使用して画像を歪める例**
!
:::small
画像の出典：[THORN](https://www.thorn.org/blog/generative-ai-principles/{target=“_blank”}
:::


開発からデプロイメント、メンテナンスに至るまで、これらの企業はジェネレーティブAIモデルが児童の安全リスクに積極的に対処するよう努めるとともに、トレーニングデータセットの適切な管理、フィードバックループと反復的なストレステスト戦略の導入、コンテンツの出典確認を重視することで、CSAMとCSEMの生成を防ぐための対策を実施するとした。


:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:12:36 +0000</pubDate></item><item><title>経済産業省 &amp; 総務省、AI事業者向けガイドラインを公表 ― 安全性、透明性、公平性ほか10の指針</title><link>https://ledge.ai/articles/government_released_guidelines_for_ai_providers</link><description>:::small
画像の出典：{target=“_blank”}
:::
2024年4月19日、政府はAI事業者向けの新たな指針「AI事業者ガイドライン（第1.0版）」を{target=“_blank”}した。

この指針は2023年5月、東京大学の松尾豊教授が座長を務めるAI戦略会議で取りまとめられた「AIに関する暫定的な論点整理」において示された、既存のガイドラインに関して必要な改訂などを検討する必要性を受けてのことだという。

このガイドラインは、AIに関わる企業のためのもので、AIの安全性、透明性、公平性をはじめとする10項目を強調しており、AI技術の適切な利用と社会的な課題への対応を目的とし、国内外のAI技術の進展とそれに伴うリスク管理を背景に公開された。

具体的には、「AI開発者」「提供者」「利用者」を対象に、リスクベースのアプローチによる自主的な取り組みが求められる。政府は、これらの指針を通じて、AI技術の健全な発展と産業競争力の強化を図ることを期待している。

### 「AI事業者ガイドライン」で明らかにされた10の指針
| 指針                   | 内容 |
|----------------------|-----------------------------------------------------------|
| 1. 人間中心のアプローチ | AIは人権を尊重し、人間の尊厳と自律を守るよう設計・運用される |
| 2. 安全性             | 人の生命や健康を損なわないよう、安全に設計されたAIの利用 |
| 3. 公平性             | 不公平な偏見や差別を含まないよう努力する |
| 4. プライバシー保護   | 個人情報は保護され、プライバシーを尊重する形でAIが利用される |
| 5. セキュリティの確保 | AIシステムは不正アクセスやデータ漏洩から守られる |
| 6. 透明性             | AIの判断プロセスが透明であり、誰にでも理解可能 |
| 7. アカウンタビリティ | AIの操作とその結果に責任を持ち、説明責任を果たす |
| 8. 教育とリテラシー   | AIの適切な理解と使用に必要な知識やスキルの提供 |
| 9. 公正な競争の促進   | AIを利用したビジネスが公正な環境で行われる |
| 10. イノベーションの推進 | 社会全体のイノベーションをAIを通じて促進する |


ガイドライン内容には、AIシステムのライフサイクル全体にわたるガバナンス強化が含まれており、実践のための指南も提供されている。たとえば、AI開発者には倫理的なモデル設計が、AI提供者には透明性と利用者の支援が、AI利用者にはデータの入力とシステムの適切な活用が求められる。

また、別添資料では、AIによる便益やリスクの具体例、AIガバナンスの構築、各種AIシステムサービスの詳細で分かりやすい解説が掲載されている。


**ガイドラインの構成**
!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みは、法的拘束力は持たないが、業界に対する自主規制としての役割を果たすことが期待されている。政府は、技術の進化や国際的な動向に応じて、ガイドラインの内容を更新していく方針を明らかにしている。

ガイドラインの全文は、経済産業省のウェブサイトで{target=“_blank”}されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Apr 2024 12:47:54 +0000</pubDate></item><item><title>文化庁「AIと著作権に関する考え方について」個人から寄せられた1000ページ超のパブコメ公開</title><link>https://ledge.ai/articles/bunka_cho_released_public_comments_on_ai_and_copyright</link><description>:::small
画像の出典：{target=“_blank”}
:::

文化庁は、2024年4月16日までに、生成AIと著作権に関する考え方をまとめた資料「AIと著作権に関する考え方（素案）」に対するパブリックコメント（パブコメ）の結果を部分的に{target=“_blank”}した。

このパブコメは、2024年1月23日から2月12日にかけて{target=“_blank”}しており、応募総数は2万4938件に達した。今回公開されたのは個人から寄せられた意見の一部で、1089ページにわたる内容（前回は1129ページ）となった。公開された意見には必要なマスキング処理が施されており、法人・団体からの意見については既に別途公開済み。

「AI と著作権に関する考え方について（素案）」のパブリックコメントの結果について（個人）
・{target=“_blank”}
・{target=“_blank”}

これらの意見を受け同庁は、有識者の意見を含めた最終版の資料「{target=“_blank”}」を3月15日に公開。概要が4月15日に{target=“_blank”}されている。

この資料では、AIが生成するコンテンツの著作物性、非享受目的の利用の具体的な例外、著作権侵害が発生した際の対応策などが詳細に定められており、AI技術の進展に伴う著作権法の適用がより明確化されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 21 Apr 2024 06:33:59 +0000</pubDate></item><item><title>自民党「キャッチコピーはAIが提案」新ポスター発表記者会見で「自民党AI」を披露　複数モデルを選択でき、API連携で利用</title><link>https://ledge.ai/articles/jiminto_ai_made_cach-copies</link><description>:::small
画像の出典：{target=“_blank”}
:::

自民党は2024年4月15日、新たな政治活動用ポスターを{target=“_blank”}した。

ポスターのキャッチコピー「経済再生 実感をあなたに。」の発案・選定や、デザイン制作に「自民党AI」が用いられたという。このAIは、過去3年間の党政策パンフレットや岸田文雄首相の演説データを基に、500案以上のフレーズを生成し候補を絞り込んだ。最終的には、岸田首相含む人間たちの目で評価し、コピーが確定したという。AIを活用することで「より多くの国民に政策の成果を実感してもらえるよう工夫した」とのこと。

さらに、このポスターのビジュアルには、AIが生成した複数のデザイン要素が採用されており、従来の政治広報とは一線を画する新しい試みだという。

!
:::small
画像の出典：{target=“_blank”}
:::

この日、党の広報本部長である平井卓也氏は、スピーチ作成や政策立案への活用などに用いられるとして1月に各メディアが{target=“_blank”}自民党AIを、記者会見の場で公開した。最も特徴的なのは、AIモデルを１つに限定することなく、ユーザーが異なるモデルから最適なものを選択し、APIと連携して利用できるインターフェースであると述べた。

!
:::small
画像の出典：{target=“_blank”}
:::

記者からの「ポスターのキャッチコピー作成時のプロンプトはどのようなものか？」という質問に平井氏は、もともと自民党AIには「キャッチコピー案作成」というアシスト機能が付与されており、ポスターに限らずプロジェクトに最適なコピーを生成すると回答した。このたびの「経済再生」というテーマをポスター作成の主軸に置こうと判断したのはあくまで「人間」であると強調。

平井氏はまた、生成AIはプロンプトの良し悪しでその生成結果が大きく左右されることも多い。そのAIの機能を最大限引き出せるようなプロンプトを誰でも簡単に出せるようなアシスト機能を目指すとした。

今のところ、党の広報だけが、限定的に自民党AIを取り扱うことができるという。学習についての権限も同様とのこと。今後、広報の立場を越えて使う場合のAIガバナンスについては、引き続き検討しながら、開発を続けていきたいと述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Apr 2024 03:34:03 +0000</pubDate></item><item><title>Microsoft「米国大統領選が標的に」最新の脅威報告で、中国のAI操作による選挙介入を警告　韓国、インドの選挙にも同様の警告</title><link>https://ledge.ai/articles/microsoft_threat_intelligence_warned_chinese_ai_io</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月4日、Microsoftの脅威分析センターは、中国がAIを利用したサイバー攻撃および情報操作を強化していると{target=“_blank”}した。同社は、特に中国がAIを活用してアメリカ、韓国、インドの選挙に影響を与えようとするだろうと指摘している。

このレポートでは、2024年1月に行われた台湾の総統選挙で、中国がAI生成のオーディオやビデオを用いた介入がすでに行われていたことが示唆されている。

台湾での選挙介入では、AIが生成したコンテンツが政治的なメッセージを強化し、特定の候補者を支持するかのような偽の情報が流された。この活動は、Microsoftの{target="_blank"}で初めて明らかにされ、以降その手法はさらに洗練されているという。

**台湾選挙におけるAIの影響**
!
:::small
画像の出典：{target=“_blank”}
:::

上図で紹介されている「Storm-1376」の活動は、前回の脅威レポート以降に活発化しているという。Storm-1376は、中国共産党（CCP）に関連する情報操作グループで、特に台湾の政治家や中国の反体制派を標的に、AIを活用した情報操作を行っているとのこと。このグループはAI生成のニュースアンカーやミームを用いて、視聴者を欺くキャンペーンを展開しており、台湾だけでなく、アメリカや韓国など他の国々でも同様の活動が行われていることが報告されている。

これらのキャンペーンはいくつかの重要な進化を遂げている。視聴者を欺くためにAIが生成した写真を取り入れたり、陰謀論的なコンテンツ（特に米国政府に対するもの）を煽ったり、ローカライズされたコンテンツで韓国などの新たな人口をターゲットにしたりしているとのことだ。


中国はさらに、南太平洋諸島や南シナ海地域、米国防産業基地に対するサイバー攻撃を行っており、これらの攻撃は政治的および経済的な利益を追求するものだという。

同社は、AIを活用した情報操作が、選挙期間以外にも国際的な緊張を引き起こす潜在的なリスクを持つと報告している。


:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Apr 2024 06:32:36 +0000</pubDate></item><item><title>東京都、AIを活用した建物被害判定支援ツールを開発　災害時の罹災証明を迅速化</title><link>https://ledge.ai/articles/metro_tokyo_ai-based_building_damage_assessment_support_tool</link><description>:::small
画像の出典：{target=“_blank”}
:::

東京都知事小池百合子氏は、2024年3月29日の知事記者会見を通じ、AI技術を活用した建物の被害状況を判定する支援ツールの開発を{target=“_blank”}した。

このツールは、特に災害時の建物損傷を評価するために設計されており、住家被害認定の精度向上とプロセスの効率化を目指す。

会見内容によると、このAI支援ツールは、住家の外壁を撮影し、損傷箇所を自動で検出する機能を持ち、得られた画像データはAIによって解析され、損傷の程度を示すことで調査員が被害認定の参考にすることができるという。

被害判定の基準は非常に複雑であり、現行の方法では認定作業に多大な時間と専門知識が求められる。この新しいツールにより、判定のばらつきを抑え、迅速かつ公平な認定が可能になると知事は述べた。

さらに、東京都は国に対しても住家被害判定方法の簡略化やAI技術の積極的な活用を促している。知事は、「いつ起こるかもしれない首都直下地震への備えとして、このAIツールの開発は極めて重要」と強調。技術の進化と共に、精度を高めるためのデータ蓄積も進める方針を示した。

このツールの具体的な使用例として、記者会見中には、破損した建物の画像がスライドで示され、AIがどのように損傷を検出し学習していくかが説明された。今後、このツールは東京都内外の災害対応の現場で広く利用される予定とのことだ。

会見後の担当者からの説明によると、このAI支援ツールは、木造モルタル住宅の壁面を撮影する際に特に有効で、画像一枚あたり数秒で損傷程度を判定できる速度が特徴だという。しかし、AIの誤認識も報告されており、垂れ下がった電線を壁のひび割れと誤認するケースもあるため、技術の更なる精練が求められている。東京都はAI技術の進展とともに、これらの課題を克服し、より信頼性の高いツールを提供する目標を掲げている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 17 Apr 2024 06:39:03 +0000</pubDate></item><item><title>イスラエル国防軍、AI標的システム「ラベンダー」を使用してガザのターゲットを特定</title><link>https://ledge.ai/articles/lavender_ai_israeli_army_gaza</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

イスラエル国防軍（IDF）が「Lavender（ラベンダー）」と呼ばれるAI標的システムを利用して、ガザ地区の攻撃ターゲットを特定している事実が2024年4月3日の{target=“_blank”}をはじめ、複数の報道により明らかにされた。

このシステムは、ガザ地区に居住する約230万人のデータを分析し、ハマスまたはパレスチナ・イスラム聖戦（PIJ）の活動家である可能性を数値で評価し、特定の個人を自動的に暗殺対象としてリストアップしているという。

ラベンダーは、ハマス関連の活動家やその関連地点を特定するために開発され、37,000人以上の個人を「キルリスト」に含めるほどの大規模な監視と分析を行っている。このシステムによるリストは、個々の詳細な検証を経ずに作成され、実際の攻撃命令として採用されている。報告によると、このリストに基づく攻撃では、低ランクのハマス活動家であっても、その居住する家族を含む民間人の死亡を多数許容しているとのこと。

IDFはこれらの報道に対して、ラベンダーが単なる情報集約と分析のツールであり、最終的な攻撃決定には人間が介入して個々の事案を評価していると反論しているが、実際の操作においてはほとんどが自動化されているとの証言が相次いでいるという。

AI技術を利用して、ターゲットの選定や攻撃の実行など特定の軍事的決定を人間の関与なしに自律的に行うことができ、致死性を有する「完全自律型兵器」に関して、{target=“_blank”}は2023年12月に、自律型致死兵器システム（LAWS）自律型兵器システムに関する国際的な合意に基づく規則と制限への支持を表明。新たな決議案を日本や米国など152カ国の賛成で採択している。中国や北朝鮮はじめ、イスラエルなど11か国が棄権した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 01:27:37 +0000</pubDate></item><item><title>米ワシントン州、銃撃事件の裁判「AIで強化した動画は証拠として認めない」高等裁判所の裁定</title><link>https://ledge.ai/articles/judge_blocks_ai_enhanced_video</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

ワシントン州の裁判所が「AI技術を使用して強化されたビデオを法廷での証拠として使用することを禁じる」という初めての裁定を下した。2024年4月3日に現地の各メディアが報じたこの判決は、キング郡高等裁判所の裁判官、リロイ・マッカロー判事によって出された。事件は、2021年にシアトル近郊のバーの外で起きた銃撃事件に関連しており、被告のジョシュア・プロカは3人の命を奪い、2人を負傷させたとされている。

プロカ被告の弁護団は、携帯電話の映像をAIで強化して明確化し、裁判での証拠として提出しようと試みた。しかし、この強化されたビデオは元の映像にないデータを加えたり、削除したりしており、実際の出来事を正確に反映していると証明する方法がないため、問題が発生した。さらに、AIの使用によって映像が「視覚的には魅力的に見えるが、実際のシーンを正確に表していない」という懸念が専門家から提起された​という。

マッカロー判事は、AI技術が「AIが示すべきだと考える」内容を不透明な方法で表現するため、その証拠を採用することは陪審員を混乱させ、証言の信頼性を損なう恐れがあると述べた。この決定は、AIの法廷での扱いについての重要な前例となり、今後の類似の裁判において参考とされる可能性が高い。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Apr 2024 13:15:16 +0000</pubDate></item><item><title>佐川急便など、レベル3.5飛行による東京都が推進するドローン宅配便配送プロジェクトを実施</title><link>https://ledge.ai/articles/sagawa_drone_parcel_delivery_project_by_tokyo</link><description>:::small
画像の出典：{target=“_blank”}
:::

佐川急便は2024年3月29日、イームズロボティクス、日本気象協会、サンドラッグと共に、山間地域の利便性向上に向けたドローンレベル3.5飛行による宅配便配送の実証実験を東京都青梅市において実施したことを{target=“_blank”}した。

四者は東京都が推進する「ドローン物流サービス社会実装促進事業」の支援対象として2022年7月28日に選定され、以降共同でプロジェクトを進めている。ドローンによる配送サービスの社会実装を目指し、山間地域での生活利便性の向上と持続可能な配送システムの構築が目的だという。

プロジェクトでは、国土交通省により2023年12月に制度化されたドローンレベル3.5飛行を利用し、宅配便配送の実証実験を行った。青梅市の山間地域で、ドローンから受取人が直接荷物を受け取る運用や、災害時の救援物資輸送を想定した配送実験が実施された。

!
:::small
画像の出典：{target=“_blank”}
:::

実証実験は2024年2月26日から3月8日にかけて平日10日間の予定で行われ、天候の影響を受けたものの、5日間は実施可能であった。期間中、イームズロボティクス社製のLAB6150を使用し、1日最大3往復6フライトを実施した。このドローンは、最大ペイロードが10kgであり、大きな荷物の輸送も可能である。

東京都内で初めて実施されたこのレベルのドローン飛行による宅配便配送実験では、地域住民からの高い関心と支持を得た。実際にドローンから荷物を受け取った住民を対象にしたアンケートでは、96％の人が今後もドローン配送を利用したいと回答しており、その有効性が示されたという。


:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Apr 2024 10:04:47 +0000</pubDate></item><item><title>大阪市、全庁で生成AIの業務活用を開始 — 効率化と品質向上を目指す</title><link>https://ledge.ai/articles/osaka_city_begins_using_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

大阪市は2024年4月1日、生成AIの全庁業務活用を{target=“_blank”}した。

大阪市はこれまで、民間事業者との共同検証や試行利用を通じ、生成AIの本格利用に向けた検討と取り組みを進めてきた。このたび、ガイドラインの策定と安全な利用環境の整備を経て、生成AIを業務に活用することで業務の効率化と品質の向上を図るという。

生成AIの利用は、大阪市全職員（水道局及び学校園を除く）を対象に、4月1日より開始する。利用内容には、文章の要約・作成・添削、企画案のたたき台作成、翻訳などを含む。ただし、市民や事業者への直接的な行政サービス提供には使用しない。

議事録や膨大な資料の内容把握、文章の練り直しや誤字脱字の確認に要していた時間の短縮、ゼロからの企画案作成の労力軽減、外国人へのより伝わりやすい翻訳の提供といった業務効率化と品質向上が期待されるという。

利用環境は、Microsoft社の「Azure OpenAI Service」を基にした本市独自の環境で、利用者の入力データは保存されず、生成AIの学習データとしても再利用されない。また、様々なリスクへの対応として「大阪市生成AI利用ガイドライン」に則り利用されるとのこと。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Apr 2024 09:51:03 +0000</pubDate></item><item><title>米バイデン政権　連邦政府機関のAI利用の包括的指針を発表　AI利用のリスクから国民を保護する措置を義務付け</title><link>https://ledge.ai/articles/omb_policy_in_federal_agencies_use_of_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

米国行政管理予算局（OMB）は2024年3月28日、連邦政府機関がAIを利用する際に、リスクを緩和し、その利益を最大化することを目的とした指針を示す文書を[発表](https://www.whitehouse.gov/briefing-room/statements-releases/2024/03/28/fact-sheet-vice-president-harris-announces-omb-policy-to-advance-governance-innovation-and-risk-management-in-federal-agencies-use-of-artificial-intelligence/
){target=“_blank”}した。この指標は、2023年10月にバイデン大統領が署名した、安全で信頼性あるAI開発管理方針示す{target=“_blank”}に基づくものだ。

この指針文書では、特にリスク管理、透明性の向上、イノベーションの推進、人材拡充、ガバナンス強化の五つの主要な領域に焦点を当てている。

### ■リスク管理
連邦政府機関が米国民の権利や安全に影響を与える可能性のあるAIを使用する場合、2024年12月1日までに、アルゴリズムによる差別を防ぐなどの具体的なセーフガード措置を講じることを義務付けた。これには、空港の顔認証システムや連邦政府系病院の診断システムが含まれる。これらの保護措置を適用できない場合、AIシステムの使用を原則中止するとのこと。

具体的なケースとしては、
・空港で旅行者は、TSAの顔認識の使用からオプトアウトでき、列での位置を失うことなく遅延なく続行できる。
・連邦ヘルスケアシステムでAIが重要な診断決定を支援するために使用される場合、ツールの結果を検証し、医療アクセスの不平等を避けるために人間がプロセスを監視している。
などを挙げた。

### ■透明性の向上
連邦政府機関がAIの使用に関して一層の透明性を確保することが要求されている。公衆の権利や安全に影響を与える使用ケースを特定し、関連するリスクにどのように対処しているかを一覧に含め年次報告する。

### ■イノベーションの推進
気候変動対策、自然災害対応、公衆衛生の向上、公共交通機関の安全性向上など、AIを責任ある形で活用することが奨励されている。

### ■人材拡充
AI専門人材を連邦政府機関全体で新たに100人雇用する計画が立てられており、これには2024年4月のキャリアフェアの開催も含まれる。

### ■ガバナンス強化
各連邦政府機関がAIの使用に関する説明責任、リーダーシップ、監督を担保するために最高AI責任者を配置し、AIの使用を調整・管理するためのAIガバナンス委員会の設置が求められている。


ハリス副大統領は、これらの施策が世界的な行動のモデルになることを目指しており、AIの責任ある開発と利用に向けた国際基準の策定において、米国がリードすることを強調した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 04 Apr 2024 01:00:24 +0000</pubDate></item><item><title>フランスの競争委員会がGoogleに2億5,000万ユーロの罰金を科す　Geminiの学習データめぐり</title><link>https://ledge.ai/articles/related_rights_autorite_fines_google_eu250_million</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月20日、フランスの競争規制機関であるAutorité de la Concurrenceは、著作隣接権に関するライセンス契約の交渉過程における違反を理由に、Googleに対して2億5000万ユーロの罰金を科したことを{target=“_blank”}した。

この措置は、2019年4月17日のEUの著作権及び著作隣接権に関する指令を法令化する2019年7月24日のフランス法に基づき、報道機関、出版社、デジタルプラットフォーム間のバランスの取れた交渉条件を確立することを目的とした約束事項の一部を遵守していなかったためとされる。

Googleは、同社開発のマルチモーダルAI「Gemini（当時は ”Bard”）」に、報道機関や出版社から提供されたコンテンツを基盤モデルの学習に使用していたが、これらの利害関係者や競争委員会に事前通知を行っていなかったという。さらに、Geminiが使用するコンテンツを、他のGoogleサービスで保護されたコンテンツの表示に影響を与えずに、報道機関や出版社がその使用からオプトアウトできる技術的解決策を提案していなかったため、報道機関や出版社が関連権に基づく報酬を交渉する能力が妨げられていたと当局は主張した。

Autorité de la Concurrenceは、透明性、客観性、非差別の基準に基づく誠実な交渉、著作隣接権に対する報酬の透明な評価のための情報提供、およびGoogleと報道機関や出版社との他の経済的関係に影響を与えない交渉の保証を含む、約束事項の4つを遵守していないと判断したという。

これに対してGoogleは、欧州著作権指令に基づき、280のフランスのニュース出版社と450以上の出版物をカバーするライセンス契約を締結し、年間数千万ユーロを支払うという成果を上げているにも関わらず、この制裁を受けたと{target=“_blank”}で述べている。

同社はこの長期間にわたる問題を解決し、出版社との建設的な協力に焦点を当てたい意向だが、競争委員会が提起した問題に対する罰金額は、違反に対して不釣り合いに高額であると主張。また、複雑な規制環境と継続する法的行動が交渉を困難にし、将来のフランスにおける情報分野への投資を不確実にしていると指摘した。

この問題に対応するため、Googleは間接収入の計算方法の見直しを含む一連の改善策を約束しており、ニュースコンテンツの実際の経済価値に関するさらなる分析を進める予定だという。

フランス競争委員会との和解により、Googleは交渉過程での手続き上の問題に対処する措置を講じ、特定の出版社および出版物に関する批判に対応しているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 25 Mar 2024 15:56:53 +0000</pubDate></item><item><title>AI Picasso　商用利用可能なAIアート生成ツール「Emi 2」を無償公開　クリエイター尊重するAI開発　追加学習に無断転載画像用いず</title><link>https://ledge.ai/articles/ai_picasso_emi-2</link><description>:::small
画像の出典：{target=“_blank”}
:::

AI Picassoは2024年4月26日、AIアートに特化した高品質画像生成ツール「Emi 2」を{target=“_blank”}した。

Emi 2 は商用利用が可能で、追加学習において無断転載画像を用いていない。{target=“_blank”}より無償利用が可能だ。

同モデルは、初代「{target=“_blank”}」と同様、特にイラストやアニメ、マンガ生成に特化して開発され、NVIDIA H100を用いた最先端の開発機材によって支えられている。追加学習に無断転載画像を用いず、Stable Diffusion XL 1.0と同様のライセンスで、ユーザーは安心して商用利用が可能だという。


以下は、2023年10月に公開された第1弾のEmiとの比較画像。Emi 2は全身を描画する際に安定する傾向にあるとのこと。
（左: Emi / 右: Emi 2）
!
:::small
画像の出典：{target=“_blank”}
:::


同社は、クリエイターとの協力を重視しており、データの提供に対して適切な報酬を設定し、利益分配の仕組みを導入している。特に、「AIいらすとや」のプロジェクトは、内閣府の報告会においてクリエイターへの還元事例として紹介された。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、Emi 2がEmiと同様、クリエイターたちの声を聞きながら作られたと語る。Emiだけではなく、同社はXやDiscord上などで、他のモデルを含めたモデルのあり方について、クリエイターたちと対話を続けながら、信頼関係を築いていくと述べた。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 30 Apr 2024 01:46:37 +0000</pubDate></item><item><title>AI翻訳で世界中のマンガファンと語り合える！集英社が1か月期間限定でマンガコミュニティサイト「MANGA Plus Universe by SHUEISHA」を公開中</title><link>https://ledge.ai/articles/mangaplusuniverse_byshueisha</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月12日、株式会社集英社は株式会社アルと共同でマンガコミュニティサイト「MANGA Plus Universe by SHUEISHA」の提供を{target=“_blank”}した。

「MANGA Plus Universe by SHUEISHA」は、集英社が運営するマンガアプリ「少年ジャンプ＋」で配信している人気タイトル15作品について語り合えるコミュニティサイト。日本語だけではなく英語、スペイン語、タイ語、フランス語など9言語に対応しており、翻訳機能とマイクロソフトの生成AIを活用しより自然な会話を楽しむことができる。

!

:::small
画像の出典：{target=“_blank”}
:::

最新話が配信されると様々な国のユーザーの書き込みで賑わい、国内外問わずリアルタイムで世界中のマンガファンと言語の壁を越えて自由に語り合える魅力的なサイトだ。2024年5月13日までの期間限定公開で期間中は無料で利用することができる。

:::box

:::
:::box

:::</description><pubDate>Wed, 24 Apr 2024 08:18:13 +0000</pubDate></item><item><title>40年後のTEDはどんな感じ？OpenAI「Sora」で制作されたTED40周年記念ビデオ
</title><link>https://ledge.ai/articles/ted2024_sora</link><description>:::small
画像の出典：{target=“_blank”}
:::

“What will TED look like in 40 years? “ 「TED は 40 年後にはどのようになっているでしょうか? 」

2024年4月20日、TEDのX（旧Twitter）アカウントを通じ、動画生成AI「Sora」が描く40年後のTEDの姿を描いたビデオが{target=“_blank”}され、このプロジェクトが注目を集めている。

このビデオプロジェクトは、TEDの40周年を記念する「TED2024」に寄せて制作され、未来への期待とクリエイティビティを称える内容が盛り込まれている。TED2024は「The Brave and the Brilliant」というテーマで開催されたカンファレンスで、2024年4月15日から19日までカナダのバンクーバーで開催された。

このビデオは、アーティスト・作家・映画監督として多方面で活躍するPaul Trillo氏とOpenAIが協力し、話題の動画生成モデル「Sora」を用いて、40年後のTEDの姿を描いたビデオを制作。TEDのロゴを除く全てがAIによって生成され、未来の可能性を映像化しているという。

Paul Trillo氏は、未公開のAI「Sora」への初期アクセスを許されたアーティストで、これを用いた作品「{target=“_blank”}」は、3月にOpenAIのブログでも紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


40年後のTEDを描くSoraのビデオは、近日中に{target=“_blank”}で公開されるとのことだ。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Apr 2024 07:06:45 +0000</pubDate></item><item><title>自動作曲ができる音楽生成AI「Udio」パブリックベータ版公開　誰でも無料で月1200曲まで高品質な楽曲を生成できる</title><link>https://ledge.ai/articles/udio_publicbeta</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月10日、元 Google DeepMindの研究者チームが設立したAIベンチャーUdioが、誰でも高品質な音楽を自動作曲できる音楽生成AI「Udio」のパブリックベータ版を{target=“_blank”}した。

Udioはテキストプロンプトを使用し希望するジャンルや曲のテイスト、歌詞を指定することで音楽を生成することができる。合成音声によるボーカルパート挿入にも対応しており、本格的な曲作りを体験することができるという。

!
:::small
画像の出典：{target=“_blank”}
:::

UdioのX（旧Twitter）公式アカウントでは実際にUdioで生成したバラードやアップテンポで賑やかなサウンドなど様々なジャンルのサンプル楽曲が多く掲載されている。現時点ではベータ版ということもあり無料で利用できるのも魅力のひとつ。１ヶ月に最大1200曲生成できるため納得いくまで音楽生成を楽しむことができる。

:::box

:::
:::box

:::</description><pubDate>Fri, 19 Apr 2024 06:55:44 +0000</pubDate></item><item><title>賞金総額は20万ドル以上　クリエータープラットフォームFanvueがAI美人コンテスト「Miss AI」開催</title><link>https://ledge.ai/articles/fanvue_miss_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::


2024年4月15日、ソーシャルメディアプラットフォームFanvueは、AIが生成した女性モデルを対象とした美女コンテスト「Miss AI」の開催を{target=“_blank”}した。

Fanvueは、AI生成コンテンツの分野における革新を表彰し、その業績を称えることを目的としている。参加者の美しさだけでなく、テクノロジーの使用と社会的影響力を評価の軸に置くとのこと。

賞金総額は20万ドル以上で、上位 3 人のミス AI 出場者には、優勝者への 5,000 ドルの現金を含む総額 20,000 ドルを超える賞品が授与される。また、優勝者にはメンターシッププログラムやPRサポートなどが提供される​​。

審査員には、AIインフルエンサーのエミリー・ペレグリーニとアイタナ・ロペスが名を連ねている。これらのAIモデルは、インスタグラムで数十万人のフォロワーを持ち、自身が築いたソーシャルメディアでの成功をもとに、コンテストの参加者を審査するという。


**審査員の2人（AI生成のインフルエンサー）左：エミリー・ペレグリーニ／右：アイタナ・ロペス**
!
:::small
画像の出典：{target=“_blank”}
:::

審査は美しさ、技術の使用、社会的影響力の3つの主要カテゴリーで行われ、参加者はそれぞれのカテゴリーで独自性と革新性をどのように発揮しているかを競うという。

!
:::small
画像の出典：{target=“_blank”}
:::

応募資格は18歳以上のAIモデルクリエイターで、使用するAIツールに制限は付けないが、作品は100% AI生成でなければならない。エントリーは無料で、クリエイターは複数のAI生成モデルを持ち込むことが許されている。

このイベントは「World AI Creator Awards (WAICAs)」の一部として開催され、「AIクリエイター経済のオスカー」となることを目指すとのことだ。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Apr 2024 08:19:29 +0000</pubDate></item><item><title>200名を超えるアーティストが署名「AIで音楽の価値を下げるな」ビリー・アイリッシュ、ノラ・ジョーンズ、ボン・ジョヴィなど参加の団体が権利保護を呼びかける声明</title><link>https://ledge.ai/articles/200_artists_urge_tech_platforms_stop_devaluing_music</link><description>:::small
画像の出典：{target=“_blank”}
:::

Artist Rights Alliance（ARA）は2024年4月2日、200人以上のアーティストの支持を受けて、AI開発者、テクノロジー企業、プラットフォーム、デジタル音楽サービスに対し、人間のアーティストの権利を侵害し価値を減じるAIの使用を停止するよう呼びかける公開書簡を{target=“_blank”}した。

ビリー・アイリッシュ、ノラ・ジョーンズ、ジョン・ボン・ジョヴィ、ケイティ・ペリー、スティービー・ワンダーなどを含む200名以上の著名アーティストがこの書簡に署名している。書簡では、AIがアーティストの芸術に「現実的な脅威」をもたらすと指摘し、音楽業界におけるAIの非倫理的な使用を非難している。

AIに関連する脅威は、ディープフェイクやボイスクローニングなどが注目を集めているが、この書簡では、AIが人間の音楽作品を無断で利用してAI「コピーキャット」を訓練・製作する行為や、AI「サウンド」を使って印税の負担を薄める行為といった、深刻で無責任な使用例が指摘されている。

ARAのエグゼクティブディレクター、ジェン・ジェイコブセン氏は、音楽ストリーミングサービスの普及によりアーティストが生計を立てることが難しくなっている現状を説明。「AIが生成する『ノイズの洪水』と戦うことは、アーティストとファンの両方にとって、音楽エコシステム全体の価値を下げる」と述べ、AI技術の責任ある使用をテクノロジー企業に呼びかけている。

公開書簡の一部には以下のように記されている。

「誤解なきように言うが、我々は、責任を持って使用された場合、AIが人間の創造性を前進させ、音楽ファンにとって新しく興奮する体験の発展と成長を可能にする莫大な潜在力を持っていると信じている。残念ながら、一部のプラットフォームや開発者が、創造性を破壊し、アーティスト、ソングライター、ミュージシャン、権利保持者を脅かすためにAIを使用している。」

「我々は、プロのアーティストの声や肖像を盗むAIの捕食的な使用、創作者の権利を侵害する行為、音楽エコシステムを破壊する行為に対して保護を求める。すべてのデジタル音楽プラットフォームや音楽サービスに対して、アーティストとソングライターの人間芸術を損なうか置き換えるAI音楽生成技術、コンテンツ、ツールの開発や展開を行わないよう誓約することを求める」と訴えている。

この公開書簡は、音楽におけるAIの責任ある使用について世界中で活発な議論が行われている中で発表された。すでにテネシー州は「公開の権利」を強化するいわゆるELVIS法を制定しており、同法は正式に「Likeness Voice and Image Security Act」と呼ばれている。類似の立法が米国議会および複数の米国州で議論されている。


## 署名したアーティストのリスト
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Apr 2024 11:40:17 +0000</pubDate></item><item><title>Stability AI　音楽生成AI「Stable Audio 2.0」にバージョンアップ　最大3分間の高品質なフルトラックを生成　Audio-to-Audio機能も</title><link>https://ledge.ai/articles/stable_audio_2-0</link><description>:::small
画像の出典：{target=“_blank”}
:::

Stability AIは2024年4月3日、オーディオ生成AI「Stable Audio 2.0」を{target=“_blank”}した。新しいモデルは、44.1KHzステレオで最大3分間の高品質なフルトラックを生成可能。ユーザーは自然言語のプロンプトを使用してオーディオサンプルをアップロードし、これを様々なサウンドに変換できる。

@



{target=“_blank”}との大きな違いは、特にオーディオからオーディオへの生成機能を導入した点にある。これにより、アーティストやミュージシャンは自らのオーディオサンプルをアップロードし、自然言語によるプロンプトを通じて変換することが可能となった。さらに、このモデルはイントロ、展開、アウトロを含む構造化されたコンポジションを含む楽曲を生成できるという。Stable Audio では45秒だった曲の長さも、2.0になり最長で3分間まで生成できる。

現在、{target=“_blank”}で無料で利用でき、将来的にはStable Audio APIでも利用可能となる。

### Audio-to-Audio Feature Demo
@


1.0モデルと同様、2.0は音楽、効果音、シングルインストゥルメントステムを含む800,000以上のオーディオファイルからなるAudioSparxのデータでトレーニングされている。オプトアウトのリクエストに対応し、クリエイターへの公正な報酬を保証することにも重点を置く。

オーディオアップロードに際しては、著作権侵害を防ぐためにAudible Magicと提携し、そのコンテンツ認識（ACR）技術を利用しているとのこと。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 09 Apr 2024 14:46:35 +0000</pubDate></item><item><title>OpenAI「Sora」をハリウッドに売り込み中か</title><link>https://ledge.ai/articles/openaii_pitches_sora_to_hollywood</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

OpenAIはロサンゼルスの映画スタジオ、メディア幹部、タレントエージェンシーと会合を持ち、エンターテインメント業界でパートナーシップを築こうとしている。関係者によると、映画制作者に同社の動画生成AI「Sora」を作品に組み込むよう奨励していると2024年3月22日に{target=“_blank”}が報じている。

2月下旬にOpenAIは最高執行責任者（COO）のブラッド・ライトキャップ氏を中心に、ハリウッドでの紹介対話を予定しており、同氏は数人の同僚とともに、ユーザーからのテキストプロンプトに基づき、長さ約1分までのリアルな動画を生成できる未発表の新サービス「Sora」の機能を実演したとのこと。その数日後、同社CEOのサム・アルトマン氏が、アカデミー賞の週末にロサンゼルスで開かれたパーティーに出席。OpenAIは、すでにいくつかの有名な俳優や監督にSoraへのアクセスを許可しているという。

既に映画製作者やスタジオではAIが活用されており、新しいツールの有望性の認識も得ている一方で、AIが人々の生活に与える影響に対し懸念を表明する声も存在する。ハリウッドでは2023年、脚本家と俳優がAIの使用に関する保護を求めてストライキに突入し、両組合はAIの使用方法についていくつかのセーフガードを確保した。メディア企業もまた、OpenAIのトレーニングデータに制作物が使用されることを警戒する動きが見られる。

2024年2月に発表されたSoraはまだ研究プレビューの段階で、価格は未定。テキストから動画を生成するサービスは、AIスタートアップのRunwayが先行しているという。業界ではすでに数百万人に利用されており、映画編集者も動画を作成し、視覚効果を作るために利用しているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 06 Apr 2024 12:29:42 +0000</pubDate></item><item><title>自分の楽曲をAIユニットに歌わせちゃおう！AI歌声ライブラリ「LAUGH DiAMOND」シリーズ　コナミより発売</title><link>https://ledge.ai/articles/konami_laugh_diamond</link><description>:::small
画像の出典：{target=“_blank”}
:::

コナミデジタルエンタテインメントは2024年4月1日、AI歌唱エンジンを用いた音声合成ソフト「VoiSona」向けのAI歌声ライブラリ「LAUGH DiAMOND」シリーズを{target=“_blank”}した。

同シリーズは、実在のシンガーの歌声をディープラーニング技術で学習したもので、音声合成ソフト「VoiSona」に歌詞と音符を入力することで楽曲制作が可能だ。

「LAUGH DiAMOND」シリーズの特徴は、声のモデルとなったシンガーの歌声や表現の特徴を忠実に再現し、人間らしい温かみのある歌声を表現できること、また、複数のシンガーとの組み合わせでユニット曲を容易に作成できることにある。これにより、声が混ざり合うことなく、ユニゾンでも美しいハーモニーを奏でることが可能となるという。

ライブで輝くことを夢見るシンガーグループ「LAUGH DiAMOND」の4キャラクター、「山田花音」「風祭朝陽」「篁響季」「小紫桃果」をイメージしており、声のモデルには声優の木戸衣吹さん、熊沢世莉奈さん、鈴木杏奈さん、白河みずなさんが起用されている。これら4名のコメントも公式サイトで公開されている。

発売を記念し、4月27日から28日にかけて千葉・幕張メッセで開催される「ニコニコ超会議2024」に参加予定であり、公式Xアカウントを通じて続報が待たれている。「LAUGH DiAMOND」シリーズの今後の展開にも注目が集まる。

キービジュアルでは、大きな舞台でのライブを夢見て路上ライブをする無名の「LAUGH DiAMOND」が描かれており、持ち歌がない彼女たちが楽曲に飢えている様子が伝えられている。クリエイターには、彼女たちに曲を提供し、夢の舞台に一歩近づけるよう呼びかけている。



:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Apr 2024 13:44:26 +0000</pubDate></item><item><title>OpenAI　動画生成AI「Sora」を使ったアーティストたちの映像作品を公開　AIは創造的プロセスに革新をもたらすのか</title><link>https://ledge.ai/articles/openai_sora_first_impressions</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年3月25日、動画生成AI「Sora」を使ったアーティストたちによる映像作品と、彼らが初めてSoraを使用した所感やフィードバックを{target=“_blank”}した。

Soraは、テキストからリアルで想像力豊かなシーンを生成できるAIモデルとして{target=“_blank”}され、世界を揺るがせた。モデルは現在のところ一般公開には至らず、ビジュアルアーティスト、デザイナー、クリエイティブディレクター、映画制作者などに対して、アクセスを提供している。同社は、こうした制作者たちのフィードバックを受けながら、創造プロセスをどのように支援できるかを学びつつ、モデルの改善を続けているという。ㅤ
ㅤㅤ
## shy kids – “Air Head”
@
トロントを拠点とするshy kidsはマルチメディア制作会社で、風船男のショートフィルムにSoraを活用した。

監督の Walter Woodman氏は「Soraは現実に見えるものを作り出す能力に優れているが、私たちを興奮させるのは、完全に超現実的なものを作り出す能力。抽象表現主義の新時代だ」と語る。

より広い業界に向けて言えば「胸からはちきれそうな物語を持つ世界中の人々が、ついにその中身を世界に見せる機会を得た」と述べる。  ㅤ
ㅤㅤ
## Paul Trillo, Director – “Abstract”
@
「Abstract」を制作したPaul Trillo氏は、アーティスト、作家、映画監督として多方面で活躍する。

同氏は「Soraが最もパワフルなのは、古いものを複製するのではなく、そうしなければ見る機会がなかったであろう新しく不可能なアイデアに命を吹き込むときだ」とコメントしている。

そして、Soraを使った制作は「映画監督として鎖に縛られていないと感じた初めての経験。時間やお金、他人の許可に縛られることなく、大胆でエキサイティングな方法でアイデアを出し、実験できる」と述べた。ㅤ
ㅤㅤ
### 「奇妙さ」こそSoraの強み
デジタルAR/XRアーティストの Don Allen Stevenson III氏は、Soraの「奇妙さ」を最大の強みとして挙げ、これが彼の創造性を純粋に集中させ、即時のビジュアライゼーションと迅速なプロトタイピングの世界を解き放つと述べている。Soraによって、従来の物理法則や思考の慣習に縛られない作品を制作することが可能になり、クリエイターたちは技術的な障壁よりも創造性に焦点を当てることができるようになった。これにより、これまでにないストーリーテリングやアート作品が生まれる土壌が整えられている。

彼の作品や、その他のアーティストの映像作品は、{target=“_blank”}で紹介されている。ㅤ
ㅤㅤ
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 30 Mar 2024 12:11:22 +0000</pubDate></item><item><title>Google DeepMind とリバプールFCが共同開発した「TacticAI」を発表ーーサッカー戦術をAIがアシストする</title><link>https://ledge.ai/articles/google-deepmaind_tactic-ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMind は2024年3月19日、リバプールFCとの間で数年にわたる共同研究の一環として、コーナーキックに関する戦術アドバイスを提供できるAIシステム「TacticAI」が開発されたことを、学術誌 Nature Communications に{target=“_blank”}した。

このシステムは、特にコーナーキックに焦点を当て、予測および生成AIを通じて専門家に戦術的洞察を提供する。TacticAIは、コーナーキックに関する限られたゴールドスタンダードデータを使用しながらも、幾何学的ディープラーニングアプローチを用いて、より一般化されたモデルの作成を支援し、最先端の結果を達成したという。

TacticAIは、プレミアリーグで行われた7,176回のコーナーキックのデータを分析し、選手をノードとして扱うグラフベースのアプローチを用いて、各選手間の複雑な相互作用と異なるコーナーキック設定の潜在的な結果をモデリングした。この方法により、どの選手がボールを受ける可能性が最も高いか、あるいはシュートを試みる可能性が高いかなど、様々なシナリオを予測し、チームパフォーマンスの向上に役立つ戦術的な推奨を提供する。

!
図(A) コーナーキックの状況をグラフ表示に変換する方法
図(B) TacticAI が与えられたコーナーキックをどのように処理するか
:::small
画像の出典：{target=“_blank”}
:::

リバプールFCのサッカー専門家からは、TacticAIの提案が実際のゲームプレイシナリオと区別がつかないほどであり、専門家たちは既存の戦術よりもTacticAIの戦略を90%の高い割合で好むという非常に肯定的な評価がなされた​​。また、このAIモデルは従来の技術よりもリバプールのコーチによって2倍有用と評価され、攻撃者の特定や守備時の注意散漫な選手の指摘に特に効果的であるとされている​​。




:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 29 Mar 2024 05:49:14 +0000</pubDate></item><item><title>YouTube、生成AIなどによる改変・合成コンテンツのラベル表示機能を順次導入</title><link>https://ledge.ai/articles/youtube_disclosing_ai_generated_content</link><description>:::small
画像の出典：{target=“_blank”}
:::

YouTubeは2024年3月19日、クリエイターが作成したコンテンツが改変または合成によって作成された場合、その事実を視聴者に開示するための新しいツールをYouTube Creator Studioに導入したと{target=“_blank”}した。

生成AIがストーリーボードのアイデア出しや創作工程のサポートツールとして活用される中、コンテンツが改変や合成によって作られたものかどうかについて、視聴者が求める透明性を確保するためのものだ。

### ラベル付けが必要とされるコンテンツ
- 実在する人物のように見せている： デジタル改変により、ある人物の顔を実在する別の人物の顔に置き換えたり、合成した人物の声を動画のナレーションに使用したりしているコンテンツ
- 実際の出来事や場所の映像を改変している： 実在する建物で火事が発生しているように見せたり、実在する都市景観を実際とは違って見えるよう改変したりしているコンテンツ
- 現実的な風景を生成している： 実在する都市に向かって移動している竜巻など、架空の大きな事件をリアルに描写したコンテンツ

視聴者が実際の人物、場所、出来事と勘違いしやすいようなリアルに見えるコンテンツに対して、クリエイターが改変または合成されたメディア（生成AIを使用したものを含む）で作成したことを開示する必要がある。ただし、明らかに非現実的であるコンテンツ、アニメーション、特殊効果が含まれるコンテンツ、または制作作業をサポートする目的で生成AIを使用したコンテンツについては、開示の必要はない。

この取り組みは、昨年11月に発表された{target=“_blank”}のアプローチの一環として、情報開示要件やラベル表示、プライバシー侵害の申し立てが更新されるなど、YouTubeのAI製品および機能に責任をもって組み込まれるよう徹底されている。

### ラベル付けが不要なケース
開示が求められる主なケースは、実在する人物のように見せかけたデジタル改変コンテンツ、実際の出来事や場所を改変したコンテンツ、現実的な風景を生成したコンテンツなどが該当する。しかし、生産性を高めるために生成 AI を使用している場合や、以下のような合成したメディアが非現実的な場合や、改変の重要度が低い場合は開示不要。

- アニメーションや、ファンタジーの世界でユニコーンに乗っている人間など、明らかに非現実的なコンテンツ
- 色の調整や照明
- フィルタ背景ぼかしやビンテージ調などの特殊効果
- 美肌加工フィルターやその他の視覚効果


このラベル表示機能は、今後段階的に導入予定だという。最初はスマートフォンの YouTube アプリ、続いてパソコンとテレビで視聴する YouTube 上でも順次展開していく予定。

将来的には、この情報を開示しないクリエイターに対する措置も検討予定で、改変または合成されたコンテンツが混乱や誤解を生む可能性がある場合は、クリエイターが情報を開示していなくても YouTube がラベルを追加するなどのケースも想定しているという。


:::box

:::
:::box

:::
</description><pubDate>Sun, 24 Mar 2024 11:41:00 +0000</pubDate></item></channel></rss>