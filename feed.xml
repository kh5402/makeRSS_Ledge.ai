<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Fri, 26 Jul 2024 07:08:50 +0000</lastBuildDate><item><title>OpenAI、リアルタイム検索エンジン「SearchGPT」プロトタイプを発表</title><link>https://ledge.ai/articles/openai_searchgpt_prottype</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年7月25日、新たにAI搭載の検索エンジン「SearchGPT」を{target=“_blank”}した。

この検索エンジンは、インターネット上の情報にリアルタイムでアクセスし、ユーザーの質問に迅速かつ直接的に回答することを目的としている。プロトタイプ版は一部のユーザーとパブリッシャーに限定して公開されており、広範な公開は今後予定されている。

SearchGPTは、テキストボックスに質問を入力すると、AIがネット上の情報を集約して回答を提示する。回答には、情報源のURLも併記されており、ユーザーは情報の出所を確認することができる。この機能は、Googleの提供していた「AI Overview」やPerplexityの「Perplexity AI」と類似しているが、より詳細かつ明確な引用元を提供する点で差別化されているとのこと。

OpenAIの説明によると、SearchGPTは「Webからの最新情報に基づいて質問に迅速かつ直接的に回答し、関連するソースへの明確なリンクを提供する」ことを目指している。また、検索結果に表示される情報の透明性を高めるために、パブリッシャーと協力し、記事の流用方法を管理するツールもリリースする計画だ。これにより、コンテンツの作成者が自身の情報がどのように使用されるかをコントロールできるようになる。

SearchGPTの利用を希望する場合、ウェイティングリストに登録する必要がある。現時点では、The AtlanticやNews Corpといった一部のメディアがテストに参加しているとのこと。SearchGPTは検索機能に特化しており、OpenAIのAIトレーニングとは独立しているが、将来的にはChatGPTにもこの機能が統合されるという。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Fri, 26 Jul 2024 05:50:09 +0000</pubDate></item><item><title>Google Gemini、「1.5 Flash」にアップグレード：無料版で高速応答と32Kトークンの長文対応が可能に</title><link>https://ledge.ai/articles/google_gemini5_flash</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年7月25日、Geminiの大規模なアップグレードを{target=“_blank”}した。今回のアップグレードでは、無料版のGeminiにも新たに1.5 Flashが導入された。日本を含む230カ国以上の無料版Geminiで利用可能だという。
## 1.5 Flashの導入と機能強化
Geminiの無償版に1.5 Flashが導入され、応答速度が速くなるとともに、推論や画像理解能力が大幅に向上した。さらに、コンテキストウィンドウが従来の4倍となる32Kトークン（英語で約2万4000語）に拡大され、より長く複雑な会話が可能となった。これにより、ユーザーは長文の資料や複雑な質問にも対応できるという。

!
:::small
画像の出典：{target=“_blank”}
:::

また、近日中にGoogleドライブやデバイスからのファイルアップロードが可能になるという。これにより、ユーザーは例えば経済学の参考書をアップロードして練習問題を作成したり、データを分析してグラフや図表を作成したりできるようになる。

英語圏の特定地域限定では、生成された文章に関連する情報へのリンクを表示する機能も新たに追加された。例えば、Gmail拡張機能を使用して入力されたメールへのリンクを添付するなどが可能になる。
## 関連コンテンツの表示機能
新たに導入された関連コンテンツの表示機能により、英語のプロンプトに対して関連するウェブサイトへのリンクが表示され、調査や学習が容易になった。これにより、ユーザーはGeminiの応答を基にさらなる情報を得ることができる。また、Gmail拡張機能を使用して情報が参照される場合、関連するメールへのインラインリンクも表示される。

この機能は、ハルシネーション（幻覚：AIの誤情報）を減少させる取り組みの一環であり、Geminiのダブルチェック機能と併用することで、情報の正確性を確認できる。

## ティーンエイジャー向けGeminiの拡大
ティーンエイジャー向けのGeminiが拡充され、40以上の言語で利用可能となった。最低年齢要件を満たすティーンエイジャーは、学校の科目の理解を深めたり、大学の準備をしたり、創造的なプロジェクトに取り組んだりする際にGeminiを活用できるようになる。

安全性を確保するため、追加ポリシーやティーンエイジャー専用のオンボーディングプロセスを導入。AIリテラシーガイドの提供により安心してGeminiを利用できるとのこと。また、子供の安全と発展に関する専門家の協力を得て、適切な支援を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Jul 2024 07:08:50 +0000</pubDate></item><item><title>AWSジャパンが「生成AI実用化推進プログラム」を開始　ビジネスイノベーション創出を目的に総額1,000万ドルの支援も</title><link>https://ledge.ai/articles/aws_japan_program_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月22日AWSジャパンは、新たに「AWSジャパン生成AI実用化推進プログラム」を開始すると{target=“_blank”}した。このプログラムは、生成AIを活用したビジネスイノベーションを支援することを目的としており、「モデル開発者」向けと「モデル利用者」向けの2種類に分かれている。


「モデル開発者」向けプログラムでは、利用者独自のデータを活用し、ビジネス目的に応じたファインチューニングや新規モデル構築を通じて、基盤モデルのカスタマイズを支援する。また、生成AIの実用化に向けて、分析環境の構築支援として総額1,000万ドル規模のAWSクレジットが提供され、想定コストの半額を上限としてAWSサービス利用料の負担を軽減するそうだ。
!

:::small
画像の出典：{target=“_blank”}
:::

一方、「モデル利用者」向けプログラムでは、公開されている基盤モデルを活用し、様々な手法でモデルの応答をカスタマイズすることで、ビジネス課題の解決を支援する。
!

:::small
画像の出典：{target=“_blank”}
:::

支援対象は、日本国内に法人または拠点を持ち、生成AIのビジネス適用を検討している企業・団体である。参加希望者は、AWSジャパンとのディスカッションを通じて課題やプランをヒアリングし、具体的な支援内容を決定するとのこと。プログラムへの応募受付は2024年10月31日、実施期間は2025年3月末まで。



:::box

:::
:::box

:::

:::box

:::
</description><pubDate>Wed, 24 Jul 2024 09:25:51 +0000</pubDate></item><item><title>xAI のイーロン・マスクが「世界最強のAIを訓練する」メンフィスに建設中のギガファクトリー「Gigafactory of Compute」稼働開始</title><link>https://ledge.ai/articles/gigafactory_of_compute</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

xAIのCEOイーロン・マスク氏は2024年7月22日、テネシー州メンフィスで「Gigafactory of Compute」が稼働を開始したと{target=“_blank”}した。このスーパーコンピュータは「世界最強のAIトレーニングクラスタ」を目指しており、約10万台のNVIDIA H100 GPUを使用しているという。

!
:::small
画像：{target=“_blank”}
:::

メンフィスの商工会議所は6月5日、イーロン・マスク氏のAI企業xAIがメンフィスに「Gigafactory of Compute」を建設すると{target=“_blank”}している。商工会議所の会長であるテッド・タウンゼント氏は、このプロジェクトがメンフィスに数十億ドル規模の資本投資をもたらすと述べており、メンフィス市における最大規模の新規企業投資となる。

!
:::small
画像：{target=“_blank”}
:::

設置場所は以前米Electrolux社が運営していた工場を再利用する予定。xAIは5月26日に60億ドル（約9400億円）の資金調達を発表し、この資金が「xAIの最初の製品を市場に投入し、高度なインフラを構築し、将来の技術研究開発を加速するために」使用されると説明している。

:::box

:::
:::box

:::
</description><pubDate>Thu, 25 Jul 2024 07:12:23 +0000</pubDate></item><item><title>Anthropic　次世代AIスタートアップに投資を開始　Menlo Venturesと共同で1億ドル規模の「Anthology Fund」を設立</title><link>https://ledge.ai/articles/anthology_fund_anthropic-menloventures</link><description>:::small
画像の出典：{target=“_blank”}
:::

Menlo VenturesとAnthropicは2024年7月18日、次世代AIスタートアップ支援のための1億ドル規模の「Anthology Fund」を設立すると{target=“_blank”}した。

このファンドはMenloが資金提供する1億ドルのイニシアチブで、Anthropicの技術を活用して幅広い分野で革新を図るスタートアップを支援することを目的としている。

Anthropicの共同創設者兼社長であるダニエラ・アモデイ氏は、「Menlo VenturesとのパートナーシップとAnthology Fundを通じて、画期的なAIアプリケーションの開発を加速させたいと考えている。特に、医療、法務、教育、エネルギー、インフラ、科学研究といった分野でAIを活用して人間の能力と生産性を向上させるベンチャーに関心がある」と述べている。

Anthology Fundは、AIインフラストラクチャ、新規AI応用分野（医療、教育、科学研究など）、消費者向けAIソリューション、信頼と安全ツール、および社会的利益を最大化するAIアプリケーションと技術の5つの主要分野で革新を進める起業家を支援する予定だという。

このファンドによって支援されるスタートアップは、Anthropicの製品と研究へのアクセス、最先端モデルの利用に対する25,000ドル相当の無料クレジット、Menloからの最高水準のベンチャーサポートなど、さまざまな利益とリソースを受けられる。

Menlo Venturesのパートナーであるマット・マーフィー氏は、「Anthropicと力を合わせてAnthology Fundを立ち上げることを非常に嬉しく思う。Menloの企業構築経験とAnthropicの最先端AI技術と人材を組み合わせることで、AIの未来を形作る最も有望な起業家を特定し、協力する独自の立場にある」と述べた。


:::box

:::
:::box

:::

</description><pubDate>Wed, 24 Jul 2024 04:02:45 +0000</pubDate></item><item><title>JR西日本、世界初の人型重機ロボットを鉄道設備メンテナンスに導入</title><link>https://ledge.ai/articles/jrw_introduced_humanoid_heavy_machinery_robots</link><description>:::small
画像の出典：{target=“_blank”}
:::

JR西日本は2024年7月より、鉄道設備のメンテナンスにおいて「多機能鉄道重機」を導入することを{target=“_blank”}した。株式会社人機一体のロボット工学技術を搭載した世界初の製品であり、高所での重作業の効率化と安全性の向上を目的としているという。

導入する「多機能鉄道重機」は、JR西日本、日本信号株式会社、および人機一体が共同研究開発した高所重作業ロボット「零式人機 ver.2.0」をベースにしている。この重機は、人機一体の特許技術を活用し、日本信号が製品化した。


!
:::small
画像の出典：{target=“_blank”}
:::

## 直感的な遠隔操作
人機一体独自の技術により、操作者はVRゴーグルを通じてロボット目線での作業が可能となり、直感的に遠隔操作できるという。
また、多様なツールの装備が可能で、遠隔操作で重量物（最大40kg）の把持、 高所作業（最大12m）が可能とのこと。 

!
:::small
画像の出典：{target=“_blank”}
:::

## 技術継承と労働力確保の課題
国土交通省の2021年の報告によれば、建設業の就業者数は減少傾向にあり、高齢化が進んでいる。このような状況で、若手技能者の確保と技術継承が喫緊の課題となっている。JR西日本は、この課題解決に向け、新技術の導入に積極的に取り組んでいる。

## 高所重作業の解消
JR西日本は「システムのメンテナンスチェンジ」を掲げ、多機能鉄道重機の導入を通じて高所重作業の解消を目指している。これにより、インフラメンテナンスの効率化と安全性の向上を図ることができる。

多機能鉄道重機は、鉄道設備メンテナンスに限らず、電力や土木分野など他の高所重作業の機械化にも応用される予定だという。現在、土木分野では株式会社竹中土木、電力分野では東北電力ネットワーク株式会社との共同研究開発が進行中とのこと。


:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 03:57:59 +0000</pubDate></item><item><title>セールスフォース、自律型AIエージェント「Einstein Service Agent」を発表</title><link>https://ledge.ai/articles/salesforce_einstein_service_agent</link><description>:::small
画像の出典：{target=“_blank”}
:::

Salesforce2024年7月17日、は完全自律型AIエージェント「Einstein Service Agent」を{target=“_blank”}した。

現在パイロット段階にあるEinstein Service Agentは、2024年後半に一般提供が予定されている。事前にプログラムされたシナリオなしでサービスの問題を理解し、自律的にアクションを実行する機能を持つAIエージェントであるとのこと。

Einstein Service Agentは、Salesforceの「Einstein 1 Platform」に構築されており、顧客のメッセージの文脈を分析し、大規模言語モデル（LLM）と連携して最適なアクションを決定する。従来のチャットボットとは異なり、このシステムはコンテキストやニュアンスも理解し、顧客との対話をより自然に行うとのこと。

この新しいAIエージェントは、顧客のサービス履歴や内部データにアクセスし、適切なアクションを取ることが可能だという。例えば返品や交換手続きを自動で処理することが可能で、必要に応じて人間のエージェントにスムーズに引き継ぐことができるとのこと。

現在、Einstein Service Agentはカスタマーサービスシナリオに焦点を当てているが、将来的には他のSalesforceクラウドにも展開される予定だという。同社は、この技術を通じて企業が24時間365日顧客対応を強化できることを期待していると述べた。


:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 04:00:24 +0000</pubDate></item><item><title>Meta、オープンソースの大規模言語モデル「Llama 3.1」をリリース</title><link>https://ledge.ai/articles/meta_llama-3-1</link><description>:::small
画像の出典：{target=“_blank”}
:::

Metaが2024年7月23日、新たな大規模言語モデル「Llama 3.1」を{target=“_blank”}した。Llama 3.1は、8B、70B、405Bの3種類のパラメータモデルが提供されており、オープンソースで公開されている。

Metaは、このモデルがGPT-4やAnthropicのClaude 3.5、GoogleのGemini 1.5など、現在の最先端クローズドソースAIモデルに匹敵する性能を持つと述べている。


!
:::small
画像の出典：{target=“_blank”}
:::

Llama 3.1は、15兆トークンを使用し、16,000台のNvidia H100 GPUでトレーニングされた。特に405Bモデルは、一般知識、数学、ツール使用、多言語翻訳において優れた性能を発揮するとのこと。また、プロンプトの長さを128Kトークンまでサポートしており、ユーザーは追加の文脈情報やドキュメントを提供でき、より高度なAIアプリケーションの開発が可能となるという。

MetaのCEOマーク・ザッカーバーグ氏は、オープンソースであるLlama 3.1のリリースがAI技術へのアクセスを民主化する重要なステップであると述べた。同氏は、オープンソースの取り組みが長期的に見て効率的かつ経済的であり、個々のユーザーが自分の運命をコントロールできるようにすると強調している。

また、AWS、Google Cloud、Azureなどの主要クラウドサービス上でLlama 3.1を利用可能とし、一般ユーザーがMeta AIアプリを通じて試すことができるようにしている。このアプリでは、現時点ではプレビュー版として利用でき、一定数のクエリに対して高品質なモデルを提供するとのこと。


:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 03:40:37 +0000</pubDate></item><item><title>メタ「今後のマルチモーダルAIモデルをEUでは提供しない」当局の規制指針が明確ではないと判断</title><link>https://ledge.ai/articles/meta_will_not_offer_future_multimodal_ai_in_eu</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Metaは今後のマルチモーダルAIモデルおよび将来のモデルを欧州連合（EU）の顧客に提供しない方針を明らかにした。この決定は、同社がEUの規制当局からの明確な指針が欠如していると判断したためであると、2024年7月17日に{target=“_blank”}が報じた

メタは、新しいマルチモーダルモデルをスマートフォンやMeta Ray-Banスマートグラスなど、多岐にわたる製品に組み込む計画を立てている。このモデルは、ビデオ、オーディオ、画像、テキストを横断的に処理できる能力を持つ。

メタの決定により、欧州企業は新しいマルチモーダルモデルをオープンライセンスで提供されるにもかかわらず利用できないことになる。これにより、EU外の企業が欧州でこれらのモデルを使用する製品やサービスを提供することも難しくなる可能性がある。近日中に、より大規模なテキスト専用のLlama 3モデルがリリースされ、こちらはEUの顧客や企業にも提供される予定だという。

メタは5月に、将来のモデルを訓練するためにFacebookやInstagramの公開投稿を使用する計画を{target=“_blank”}。メタはEU内のユーザーに対して、オプトアウトの手段を提供する通知を20億件以上送信し、訓練は6月に開始される予定だった。しかし、メタが計画を公に発表した後、EUの規制当局から訓練の中止を命じられたとのこと。

Appleも6月に発表したApple Intelligence機能を、規制上の懸念からEUでの提供延期を決めている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 09:41:13 +0000</pubDate></item><item><title>Mistral AI、コード生成特化型AI「Codestral Mamba」をオープンソースでリリース　Transformerと異なるMambaアーキテクチャを採用</title><link>https://ledge.ai/articles/mistral_ai_codestral_mamba</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月17日、Mistral AIは新しいコード生成特化型AIモデル「Codestral Mamba」をリリースしたと{target=“_blank”}した。このモデルは、従来のTransformerモデルとは異なるMambaアーキテクチャを採用しており、高速な推論時間と長い文脈処理能力を実現しているという。

Codestral Mambaは7億パラメータを持ち、コード補完、エラーディテクション、ドキュメント生成、コード最適化やリファクタリングなど、開発者向けの広範な支援機能を提供する。特にHumanEvalベンチマークでは他のオープンソースモデルを上回る性能を示し、256,000トークンまでの長い文脈を処理できる能力がある。

## 高性能を示すベンチマーク結果
HumanEvalベンチマークテストでは、Codestral Mambaは他のオープンソースモデルであるCodeLlama 7BやCodeGemma-1.17Bを上回る性能を示した。この性能は、開発者が日常的に使用するコード補完や自動生成のタスクにおいて、より正確で効率的な支援を提供することを意味すると同社は述べる。


!
:::small
画像の出典：{target=“_blank”}
:::

## 多様なデプロイメントオプション
Codestral Mambaは、mistral-inference SDKやNVIDIAのTensorRT-LLMを使用して展開可能だ。また、{target=“_blank”}から生データをダウンロードでき、ローカル環境での推論にはllama.cppのサポートも予定されているとのこと。これにより、開発者は自分のニーズに合わせて柔軟にモデルを統合し、利用できるという。

同社は、Codestral Mambaの継続的な改良と新機能の追加を計画している。これは、開発者が最新の技術を活用し、効率的に作業を進めるための支援を強化するためのもので、今後も新たなモデルや量子化バージョンのリリースが予定されており、開発者コミュニティを支援するとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Jul 2024 04:40:33 +0000</pubDate></item><item><title>AIビッグテック間で争いか　AppleやAnthropicがYouTube字幕データを無断使用、AIトレーニングに利用　Appleは「製品には使っていない」と主張</title><link>https://ledge.ai/articles/bigtechs_used_swiped_youtube_videos_to_train_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

米メディアの{target=“_blank”}は2024年7月16日、AppleやAnthropic、NVIDIAなどがYouTube動画の字幕データを無断で使用してAIをトレーニングしていたと報じた。Wiredとの共同調査により明らかになったという。このデータセット「YouTube Subtitles」は、EleutherAIが作成し、48,000以上のチャンネルから173,536本の動画の字幕を含んでいるとのこと。

このデータセットは、YouTubeの利用規約に違反しており、多くのクリエイターが自分たちのコンテンツが無断で使用されたことに対して不満を表明している。YouTubeの利用規約では、動画を「自動化された手段」で取得することを禁じているため、このデータの使用は規約違反とされている。

Appleはこれに対し、「研究用の言語モデルには使用したが、製品版AIのApple Intelligenceには使用していない」と反論していると7月17日に{target=“_blank”}が報じた。


:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Jul 2024 04:03:36 +0000</pubDate></item><item><title>富士通とCohere　日本語強化版LLM「Takane（高嶺）」を共同開発　企業向けAIサービス提供のため戦略的パートナーシップを発表</title><link>https://ledge.ai/articles/fujitsu_cohere_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

富士通とCohereは2024年7月16日、企業向けAIサービスの開発と提供に関する戦略的パートナーシップを{target=“_blank”}した。この協力により、両社は企業ニーズに応える大規模言語モデル（LLM）を共同開発し、富士通がグローバル市場向けに独占的に提供することで合意した。さらに、富士通はCohereに出資を行った。

両社は、CohereのLLMを基にした日本語強化版「Takane」（仮称）を共同開発し、2024年9月から富士通のAIサービス「Fujitsu Kozuchi」から提供を開始する予定だ。このモデルは、セキュリティを重視したプライベート環境での利用を想定しており、富士通の「Fujitsu Data Intelligence PaaS」や「Fujitsu Uvance」を通じて広く提供される。

「Takane」（仮称）は、ハルシネーションを軽減するRAGの性能を引き出すことを特徴とし、多言語対応でCohereの最新LLM「Command R+」を基にしているという。富士通の日本語特化技術とCohereの企業向け技術を組み合わせ、安全性と透明性に優れたLLMを実現するとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 21 Jul 2024 12:22:42 +0000</pubDate></item><item><title>「短期開発したAI VTuberに大きな反響」エンジニアから42 Tokyo発の起業家へ　42Tokyo特別インタビュー【第5回】第1期生　福山 裕介さん</title><link>https://ledge.ai/articles/42tokyo-5</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第5回。**
:::

※インタビューは2024年2月22日に行われた。

:::box
!

**42 Tokyo 第1期生**
**福山 裕介**
株式会社ツクルバ、株式会社メルカリでエンジニアインターンを務めた後、スタートアップ企業の技術担当を務め、42 Tokyo卒業後にKinkaku株式会社を設立。
:::

## 再び学びの場へ　42 Tokyoを選んだ理由
福山さんは長い間海外で過ごし、日本に帰国した後は文化の違いに戸惑いながらも、企業のエンジニアとして活躍していた。既にエンジニアとしての経験を積んでいた中、どのようなきっかけで42 Tokyoを知り入学を決意したのか。福山さんは以下のように振り返った。

:::box
**福山さん**
私は幼い頃から15年以上インドやフィリピンなど、海外に住んでいました。海外に住んでいた学生時代は、中学生からPCに触れる環境だったため、PC操作に馴染みはありましたが、プログラミングに関しては全く知りませんでした。

海外の高校卒業時期が5～6月だったため、日本の大学の入学時期まで結構期間が空くんです。その期間に、アメリカの大学へ進学した友人から、「プログラミングで有名な講師のオンライン講座が無料で受けられる」と勧められて始めたのが、プログラミングを知るきっかけでした。

大学入学のタイミングで帰国したのですが、日本の文化や教育に馴染めないと感じ、すぐに休学しました。その後、学んだプログラミングスキルを活かし、株式会社ツクルバやメルカリでエンジニアのインターンを経て、スタートアップの技術担当を務めました。年数でいうと、エンジニアの仕事を5年ほど続けました。
この経験からエンジニアとして知識や経験が身についたのは事実ですが、もう一度しっかり学び直したいという思いがありました。

情報収集する中で、Twitterで42 Tokyo開校の情報を見つけたのが42 Tokyoを知るきっかけでした。新しい教育システムに興味が湧き、実際に入学して自分自身で体感したいと思い、受験を決意しました。
:::

福山さんは勤めていた会社を退社し、第一期生として42 Tokyoに入学した。既にエンジニアとしての経験を積んでいた福山さんは、42 Tokyoに入学する前から起業する目標を持っていたという。42 Tokyoでどのような学生生活を送っていたのか、以下のように語ってくれた。

:::box
**福山さん**
とにかく入学試験の「Piscine(ピシン)」が凄く楽しかったんです。会社に勤めていた頃は、文化の違いに馴染めず本来の実力が発揮できなかった苦い経験がありました。しかし、42 Tokyoは文化の違いも関係なく、皆がプログラミングを学ぶという同じ目標に向かって進んでいくので、萎縮することなく話せました。誰かと無邪気に話したり、意見を言い合いながら自由に学ぶ場というのが新鮮で楽しかったという印象がとても強いです。

日本初の「42」開校なので、一般的には少し様子を見たり、一旦立ち止まって入学を考えますよね。私含めですが、新しいものに飛びついて受かった人は、結構特殊だと思うんです。第一期生は躊躇なく受験した人たちの集まりなので、やはり個性的な人が多く、バックグラウンドや年齢も様々でした。また、良い意味で他人の過去にはあまり興味を示さないので、何をやっていたとか年齢も気にせず、皆対等に接することができました。

「42」は、根本的に目的意識が強い学びたい人しか集まらないので、そういったところが大学とは違うと感じ、皆が学びへの姿勢も熱量もモチベーションも高いので、私の意識も一層高まりました。
:::

「周囲の人たちに刺激を受けながら学生生活を送っていた」と語った福山さんだが、全ての学生が今までの人生を苦難なく過ごしてきたかと言うと、必ずしもそうではないという。

:::box
**福山さん**
過去に学校や仕事を辞めた人、ずっと家で過ごしていた人、周りから過小評価されていた人もいました。しかし、共通して言えるのはコードを書く能力が高く、シンプルに課題解決能力や適応能力、学習速度が速い人が多かったですね。

エンジニアとしてステップアップしたいというのはもちろんですが、私自身も大学生活で躓いた経験があるので、リハビリも兼ねて社会や人と触れ直すきっかけがほしかったんです。共通の話題があることで自然と話せましたし、そういう部分でも42 Tokyoを選んで良かったと思います。
:::

## 42 Tokyoの魅力　実践的な学びの重要性と習得したスキル
!

大学との学び方の違いを体感し、改めて42 Tokyoのカリキュラムの良さを実感したという。モチベーションが下がることなく課題に取り組むことができた理由を、福山さんは以下のように話してくれた。

:::box
**福山さん**
6～7年前は、ソフトウェアエンジニアで情報系出身の人材がかなり少ない時代でした。学べる場といえば、仕事で任されるタスクに関連した内容がほとんどなので、どうしても知識の偏りが生じてしまうんです。

現在は環境が変わっていると思いますが、当時の大学は知識を詰め込む座学が多く、コードを書く物量が全然足りていなかった。そのまま大学に通っていても理論は学べるが、実践的なことはあまり身につかないと思いました。コードを書く機会が少ないと「こうやって書くんだ」だけで終わってしまうので、もったいないですよね。

42 Tokyoは100％プロジェクトベースの実践的カリキュラムなので、コードを書く物量でいうと数十倍はあると思います。例えば、ソフトウェアを制作するという課題があったとして、それを作るために理論を学びにいくので、目的ありきの学び方なんです。

また、現状の知識より少しチャレンジングな課題をあえて渡されるので、独学で勉強していたら学べないようなものが多いんです。簡単すぎない、少し背伸びをした課題を解くために、自身の持っている知識を活用したり、調査したり、時間を使って向き合えば絶対にクリアできるので、達成感や自信に繋がります。モチベーションも上がっていきますし、「勉強すればなんとかなる」というマインドセットが身につきました。次の課題への意欲も湧いてきますし、そこだけは陳腐化せずに自分のスキルとして身につくことを、課題を通して学べたと思います。
:::

## 42 Tokyoでの経験を経て起業の夢を実現
42 Tokyoを卒業した福山さんは、その後、ともに学んだ仲間とハッカソンに参加し、見事優勝した。その成功体験を経て、起業した当時を以下のように福山さんは語ってくれた。

:::box
**福山さん**
42 Tokyoに入る前から起業はひとつの目標でした。
42Tokyoに在籍しながら、大学院で画像生成の研究をしていた友人と、二人で共同創業者として会社を立ち上げました。当時はちょうどChatGPTがリリースされた時期で、「なんか化け物みたいなものが出てきた！」と、とても衝撃を受けました。この言語モデルを使って一番ワクワクするものを作り出したいという思いから「AI VTuber」の開発プロジェクトが始まりました。

その後、短期間で開発したAI VTuberをXに投稿したところ大きな反響があり、「これはいけるかもしれない」と二人で意気込み、さらにこの波に乗るために開発を進めました。

私たちはエンジニアなので絵を描くことができません。そのため、画像生成AIを活用してキャラクターを描いたりコンテンツを制作していたのですが、開発を進める中で、現状の生成AIは絵柄や顔の一貫性がなくなる課題が見えてきました。また、画像を生成するにあたって、テキストで自分の作りたい画像のイメージを伝えることの難しさを知り、それを簡単に解決できるサービスはないか？と考え、その課題に対応するサービスを開発しました。
そのサービスは、ビジュアルベースで作りたい画像のイメージを描いてAIに指示をすると、リアルタイムで画像が生成することができます。基盤モデルはStable Diffusionを使用しており、高速で生成する技術を用いながら独自で改良を重ね、0.1秒という高速生成を実現することができました。
:::

## 今後のビジョンと新たな目標
様々な生成AIに関連するサービスを開発してきた福山さんだが、さらに大きな目標を掲げて今後も開発を続けていくという。今後の具体的な展望も以下のように語ってくれた。


:::box
**福山さん**
私たちは、42 Tokyo卒業後初めて起業した実績があるので、今後は上場も視野に入れて、「コンテンツ周りの生成AIならKinkaku」と言われるくらい、日本を代表するような生成AI企業に成長したいと思っています。

先ほども話したように、画像生成における絵柄の一貫性がない問題も、その部分を解決すれば活用の幅はさらに広がるので、改良してビジネスで役立つものを生み出したいと考えています。最終的には、生成AIをアニメなどのコンテンツ制作の場で使用されるものを開発したいですね。

すべての作業をAIが行えば良いとは考えていません。例えば、漫画制作でストーリーや構成を人間が考えて、キャラクターの名前やセリフをまとめる部分をAIが担っていくというように、基本的に面白いコンテンツを作り出せるのは人間だと思います。そこは今もこれからも変わらないと思います。人とAIが協業する世界に向けて、アニメや漫画業界と基盤モデルの橋渡し役を私たちが担いたいです。
:::

:::box
特集：
:::</description><pubDate>Mon, 22 Jul 2024 01:51:14 +0000</pubDate></item><item><title>東大松尾研究室が監修・開発のLLM講座「大規模言語モデル 2024」の受講生募集を開始</title><link>https://ledge.ai/articles/large-language-model_matsuo_iwasawa_lab</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月9日、松尾・岩澤研究室が主催する講座「大規模言語モデル 2024」の受講生募集を{target=“_blank”}した。

本講座は、データサイエンティスト育成講座やDeep Learning講座を10年以上運営し、多くの人材を育成した実績を持つ東京大学松尾・岩澤研究室の松尾豊氏と岩澤有祐氏が監修・開発しており、生成AIの基盤モデルである大規模言語モデル（LLM）の基礎理論や既に公開されているLLMモデル、APIの活用方法を学び、幅広い知識やスキル習得を目的としている。全12回の講義と受講生同士で競うLLMに関するコンペティション型の最終課題を実施予定だ。

受講料無料の完全オンラインでの実施で、募集締切は2024/7/31(水)10:00までとのこと。
!

:::small
画像の出典：{target=“_blank”}
:::


2023年9～10月に東京大学サマースクールで開催されたLLM講座では、約2,000名の受講者が参加し、最終課題のGPUを使ったコンペディションでは約800名が熱戦を繰り広げたという。講義のスライドが{target=“_blank”}でダウンロード可能だ。


:::box

:::
:::box

:::
:::box
[関連記事：年末年始こそAIのリスキリング　2023-24年のおすすめ無料講座を一挙紹介！ー松尾研LLM講座・Google認定資格プログラム・プロンプトエンジニアリングなど](https://ledge.ai/articles/free_courses_in_winter2023-24
)
:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Jul 2024 06:56:44 +0000</pubDate></item><item><title>コンサルからエンジニアへ　東京・パリで学び、データ分析でグローバルな活躍を目指す　42 Tokyo特別インタビュー【第4回】小林 瑠理さん</title><link>https://ledge.ai/articles/42tokyo-4</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第4回。**
:::

※インタビューは2024年1月30日に行われた。

:::box
!
**42 Paris 在学生**
**小林 瑠理**
新卒で外資系コンサルティング企業に入社し、ビジネスアナリストを経験したのち、転職してIT企業に転身。その会社でエンジニア養成機関「42 Tokyo」を勧められ、2022年4月に入学。仕事と並行しながら基礎カリキュラムを修了し、現在は「42 Paris」に留学中。 現在は勉強と並行して、フリーランスエンジニアとして、アメリカの企業でwebオートメーション支援と日本のベンチャー企業でLLM活用支援をおこなっている。
:::

## 未経験からの挑戦　42 Tokyoで見つけた学びの道

:::box
**小林さん**
大学卒業後は、ITのシステムインテグレーターの会社に入社して、ビジネスコンサルとして仕事をしていましたが、そこでエンジニアリングに興味を持ち、未経験でITエンジニアとして転職しました。しかし、全く教育を受けていない状態で転職したため、自主学習も思うように進まずに悩んでいたんです。そんな中、社内の技術担当の方から「42 Tokyo」を教えていただき、入学試験「Piscine（ピシン）」を受験しようと決意しました。

42 Tokyoを教えてもらうまでは、オンライン講座を受講したり、本を読んだりしていましたが、自分でプログラムを最初から作るのが一番習得への近道だと思っていたので、42 Tokyoでは実践的にプログラムを作り、その過程を学べるのがとても魅力的でした。

一般的な学習方法である教師がいる環境もメリットはあると思うのですが、インターネットで情報が簡単に手に入る今の時代の中で、教師がいることで受け身になってしまう部分もあるように感じていました。42 Tokyoは、教師がいないからこそ主体的に動けるのではないかと思い、興味が湧いてきたんです。

年末の休みと有給休暇を利用してPiscineを受験して無事に合格し、入学しました。
:::

小林さんは、Piscineを受験した時はC言語にも触れたことがなく、ロジックの組み立て方も分からず、なかなか思うように進められずに焦る場面もあったという。周りがどんどん進んでいく中、「なんで自分はできないんだ」と落ち込むことも何度かあったというが、落ち込みながらも合格まで辿り着くことができた。その理由を小林さんは以下のように振り返った。

:::box
**小林さん**
当時は本当に簡単なコードの書き方も全然分からない状態だったので、進みが遅い自分に焦りを感じ、落ち込むことが多かったです。何度か心が折れたこともありました。最後まで乗り切れたのは、相談しあったり、励まし合ったりできる仲間がいたからだと思います。仲間がいなかったら合格まで辿り着けなかったかもしれません。その点でも、仲間の存在はとても大きかったですね。

入学試験を受けている仲間同士で学業以外のこと、人生相談など結構深い話もしていました。年齢層やバックグラウンドが皆様々で、18歳から60代歳まで幅広い年齢層の人が集まっているので、課題の合間に皆でコミュニケーションを取っていましたね。"意欲的に何かを成し遂げたい"と強い意志を持ってチャレンジしている方が多く、良い刺激を受けていました。友達というよりは、ともに試験合格を目指す“仲間”と呼べる存在でした。
明確な目的があって、自分のやりたいことを探求したい野心的な人は42 Tokyoで能力を発揮できると思います。実際に42 Tokyoでは、目的意識が高い人が多く、自分の目的を達成するために課題と向き合う強い意志が大切なので、そういった意志がある人にはピッタリな環境ですし、普通の大学や職場では得られないことが経験できる環境だと思います。
:::

## 42 Tokyoでの実践的な学びの風景　仲間とともに挑む課題と成長
!

:::small
42Tokyoの学習風景
:::

無事に入学試験をクリアして42 Tokyoに入学した小林さんだが、仕事を休職することなく、学業と両立していくことを選んだという。どのように両立していたのか、42 Tokyoでの学習環境を詳しく聞いてみた。

:::box
**小林さん**
課題を進めるにあたって、週に35〜40時間は必要なので、仕事と学業の両立がすごく大変でした。朝早く起きて仕事が始まる前に勉強して、仕事が終わってからも勉強して、土曜日は一日中校舎に行って課題を進める生活を1年半ほど続けていました。当時勤めていた会社は人を大切にする会社で、42 Tokyoに通うことを応援してくれたり、様々な場面で助けていただきました。学業と両立できたのは、会社の皆さんの協力あってのことだと思います。

42 Tokyoの課題をこなす時は、実際にプログラムを書いて仲間同士で教えあったり、時には突っ込まれたりもするんですが、そういった生徒同士で教え合いながら学ぶ学習方法が想像以上に濃い内容でした。課題を提出したあとに3回レビューをするのですが、相手が全くの知識0の人もいれば、すでにかなりの知識を備えた熟練者だったり、色々なレベルの人とランダムでマッチングする形式なので、相手に合わせた説明が求められるんです。

例えば、知識が0の人には基礎から分かりやすく説明して理解してもらう必要がありますし、逆に熟知している人からは、自分の説明に対して鋭い指摘を受けて、少しずつ直していく、ということの繰り返しでした。同じ課題でも、相手によって自分も視点を変えて学習した内容を分かりやすく説明する必要がある。そういったことから、今振り返るとコミュニケーション能力や説明能力も身についたと思います。
:::

課題のレビューは生徒同士で行う。相手によって説明内容や視点を変えることで、改めて課題への理解が深まったという。レビューをし合う中での発見や、印象に残っていることを小林さんは以下のように語った。

:::box
**小林さん**
レビューはポイント制になっていて、自分がレビューをすると1ポイント加算され、そのポイントを使用して課題を提出してレビューを依頼するシステムなので、必ず交互にランダムでマッチングする形式になっています。

最初は知識がない中でレビューをしなければならないので、相手の説明を正しく理解することを心がけていました。自分でも正誤が分からない状態なので、分からないことは理解できるまで教えてもらったり、自分でも調べながらレビューをしていました。一年ほど経ってくると自分の知識も広がっているので、「良いコードだな」と、自分で判断できるようになり、「ここのコードはこうやって書き直すとより見やすいんじゃないか」など、アドバイスができるようになりました。

とにかく実践的に課題に取り組むカリキュラムなので、本を読むよりも自分には合っていると思います。課題の進捗をチームごとに確認できるのですが、課題が進んでいる人を見ると、良い意味で競争心が掻き立てられて、「もっと頑張ろう」と意気込んでいました。
:::

課題をクリアするには、3回レビューを通さなければならないルールがある。1、2回目はクリアできても3回目で返されるとまた1回目から再度レビューになるため、3回目で返されるのが一番キツかったと話す小林さんだが、そのレビューがきっかけで自身の考え方が大きく変わったという。

:::box
**小林さん**
課題の説明をする上で、その結論に至るまでの “過程” の部分にこだわりを持つ人が多かったので、その相手の主張に対して、「私はこういう理由で実装した」と論理的に伝えることが難しく、苦労しました。意見が対立した時に、私は逃げてしまうタイプだったのですが、何故この考えに至ったのかを論理立てて主張することの重要さを学びました。

相手にも意見があって、別に精神的な攻撃をしたいわけではない、建設的な議論がしたいんだと思えるようになったので、メンタルにくることも少なくなりました。自分の意見をしっかり伝えることの大切さに気づけたことが私自身に大きなプラスとなりましたし、社会人としても成長できたと思います。
:::

## 42 Tokyo卒業後の挑戦　42 Paris本校への留学と新たな目標

小林さんは42 Tokyoの基礎カリキュラム（コモンコア）を1年半で修了した後、会社を退社し、42 Paris本校へ留学をした。インタビューの最後に、パリでの生活や42 Paris校の様子、そして今後の展望を語ってくれた。

:::box
**小林さん**
東京で働いていた時は主にアプリ開発をしており、その間に42 Tokyoのコモンコアで基礎であるC言語の勉強を行っていました。コモンコアを修了後は、別の国の42に移籍できるようになるので、データ分析を学ぶためにパリに移籍をしました。もちろん42 Tokyoでもデータ分析は学べますが、もともとグローバルに働いてみたいという思いがあり、パリを選択しました。

パリに来て言語の不安がありましたが、ほぼ全員が英語が流暢に話せるので、今は英語で勉強をしています。仕事と学業の両立をしていた日本での生活と比べると、今は自分の時間も確保できますし、勉強の時間もしっかり取れているので、充実した生活を送っています。データ分析の基礎を楽しみながら学んでいるので、今後はデータ分析に関連する仕事に就きたいと思っていますが、ロケーションを日本にするかヨーロッパにするかはまだ決めていません。
今はパリの生活を存分に楽しみたいと思います。おしゃれな街並みに囲まれて、すぐ近くには美術館があったり、ミーハーなだけかもしれないですが結構楽しんでいます（笑）

42 Parisは、東京校と比べると学校の雰囲気が違います。規模も大きいですし、人数も多いので両隣の人との距離が近くて教室での密集度がかなり高いです。東京校の方が自分の空間が取れてその点は東京校の方が過ごしやすくて好きでした。

42 ParisではRNCPという職能資格を習得できる制度があり、そのためにインターンシップ経験が必要なので、インターンでも様々な経験を積んでより知識を深めていきたいと思います。基本的に勉強が好きなので、身につけた技術を仕事に活かしつつ、新しい技術の勉強はずっと続けて、両輪で生きていく人生にしたいと思っています。
:::

:::box
特集：
:::</description><pubDate>Mon, 08 Jul 2024 07:44:09 +0000</pubDate></item><item><title>【無料LIVEウェビナー】RAGの活用方法や最新AIツールを紹介！生成AIを活用する時に知っておきたい重要トピックを解説</title><link>https://ledge.ai/articles/expo2024-live-webinar</link><description>:::box
Ledge.aiが6月に開催したオンラインイベント「{target=“_blank”}」のうち、終盤に実施したライブ配信による解説ウェビナーには多くの好評をいただいた。この反響を受け、イベントの追加コンテンツとして、7月31日までLIVEウェビナーの追加企画を実施している。また、それに伴って一部コンテンツは延長公開中だ。気になるコンテンツがあれば、是非チェックしていただきたい。
:::

## これからのビジネス環境で必須となる生成AI活用の重要トピックを解説
生成AI技術の企業での業務利用は、いまだ慎重論は一定数見られるものの、徐々にその風潮に変化が見られている。
ICT市場調査コンサルティング企業のMM総研が2024年3月に発表した調査結果によると、2025年度には69％の企業が生成AI技術の本格的な利用を検討すると回答している。

:::box
{target=“_blank”}
:::

今はまだ顕在化していないが、今後生成AI技術を効果的に活用できている企業とそうでない企業との間には、ビジネスでの競争力に大きな差を生み出していくことになるだろう。

今回Ledge.aiでは、先月開催したオンラインイベント「{target=“_blank”}」の追加企画として、昨今の生成AIトレンドの中で、押さえておくべきトピックについて解説するLIVEウェビナーを開催する。

:::button

:::

## 配信ラインナップ紹介
以下がこの先の配信予定だ。一度参加登録することで、すべての配信に視聴参加できるようになるので、合わせてご覧いただきたい。

**「RAGを使った独自データの活用の基本」
配信日時：7/9（火） 15:00-15:30**
大規模言語モデル（LLM）に不足している知識を補い、独自の情報を反映した回答を出力させることができる「RAG（Retrieval-Augmented Generation）」という手法について、その基本的な仕組みや活用方法について解説する。
なぜ独自の情報を参照させる必要があるのか？といった背景知識を押さえた上で、外部から与えた知識の処理プロセスや、精度向上の鍵となる技術要素など、RAG導入の基本となるポイントを押さえる。

**「今話題の生成AIツールを紹介」
配信日時：7/11（木） 15:00-15:30**
ChatGPTやGemini、Claudeといった会話型AIツールだけでなく、昨今生成AI技術を活用した様々なツールが登場している。本配信では、その中でも最近特に注目度の高いツールを2つ紹介する。
一つ目は、誰でも手軽にLLMアプリケーションが構築できるLLMアプリ開発プラットフォーム「Dify.AI」を紹介する。RAGを使ったエージェント形式のチャットボットや、複数のタスクを組み込んだワークフローなどが実際にどれくらい簡単に作れるのかをLIVEでデモ実演する。
２つ目は、テキストや画像から高品質な動画を生成することができるサービスとして話題になっている動画生成AI「Luma Dream Machine​」だ。活用ケースを想定しながら、実際にプロンプトを送り、どのような動画が生成されるのかをデモ実演する。

**「RAGの回答精度を上げるためにすべきこと」
配信日時：7/16（火） 15:00-15:30**
7/9配信のRAG解説に続く発展編として、RAGの性能を向上させるための手法・テクニックを解説する。「質問に関連するドキュメント群を探し出すこと」、「取得したドキュメント群から正しい回答を生成すること」という２つの要素に分解して、RAGの回答精度向上につながる重要なアプローチをいくつかピックアップして紹介する。
RAGに取り組んでみたけどうまくいかない、これから実装を検討する上で躓くポイントが知りたいという方は、是非参考にしていただきたい。

**「優秀なAI部下で管理業務を楽にする！上司が知りたい生成AIの活用術」
配信日時：7/18（木） 15:00-15:30**
2022年のChatGPTの登場から進化が止まらない生成AI。新しいモデルや新機能の発表で、なかなかアップデートが追いつかず、使いこなせていない読者も多いのではないだろうか。本ウェビナーでは、生成AIを優秀な部下として活用し、業務効率を上げるためのテクニックを解説します。ChatGPTなどの会話型AIツールを使ってはみたものの、途中で挫折してしまった方も、このウェビナーを通じて、仕事で使えるテクニックを学び、あなただけの優秀なAI部下を作り、育てていくきっかけとして活用いただきたい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button

:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。


## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
配信形式：zoomウェビナー（LIVE）
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Mon, 08 Jul 2024 10:25:57 +0000</pubDate></item><item><title>松尾研インターンから42へ　基礎カリキュラムを最速で終了した学生がAI開発企業の人事統括になるまで　42Tokyo特別インタビュー【第3回】松本悠秀さん</title><link>https://ledge.ai/articles/42tokyo-3</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第3回。**
:::

※インタビューは2024年4月23日に42Tokyoの校舎にて行われた。

:::box
!
**42 Tokyo卒業生**
**松本悠秀**
東京大学松尾研究室主催のGCIにて優秀賞を受賞し、現在は同講義の教材開発及び講師として関わる。株式会社松尾研究所の複数のプロジェクトにてエンジニア・マネージャーを経験。42 Tokyoのコモンコアを最速で突破。現職ではAIスタートアップにて、プロダクトマネージャー/人事統括を担当している。
:::

## データサイエンスとの出会い　松尾研から42 Tokyoへの挑戦
松本さんは大学4年生で転機を迎えた。それが、データサイエンスとの出会いだったという。普通の大学生からどのようにして「42 Tokyo」への入学を決意したのか、以下のように語ってくれた。

:::box
**松本さん**
僕の経歴は少し特殊で、大学4年生を2度経験しています。入学してから3年間は、サークルへの参加や家庭教師をするなど、普通の大学生活を送っていました。大学4年生に上がったタイミングで経済学部に転学し、教育に携わる仕事に就くために就職活動を進めていました。その後、教育関連企業への内定も決まったのですが、就職活動をしている中でデータサイエンスの重要さを知り、卒業後に良いスタートが切れるように、という思いから松尾研のGCIというデータサイエンスの講義を受講しました。


GCIは、東京大学松尾研究室の研究室が運営するデータサイエンスの講義で、東大以外の人も受講可能です。この講義を受講して、データサイエンスやプログラミングの面白さに気づきました。僕が本格的にプログラミングに触れたのは、この講義がきっかけでした。

この講義が一通り終わったあと、松尾研でのインターンを開始し、GCIの講義開発や講師を務めたり、共同研究において機械学習のエンジニア/プロジェクトマネージャーを経験しました。
:::
松本さんは、希望していた教育関連企業への就職が決まっていたが、子どもと関わりたいという気持ちがある中、自身の強みを活かせるキャリアプランをどのように作っていくか悩んでいたという。

:::box
**松本さん**
松尾研のインターンでは主に機械学習のモデリングを担当していました。その中で、実際に作ったモデルが実社会へ実装されることに興味を持ち、実装にはソフトウェアエンジニアリングが必要だということを知りました。その時、全く関係ない文脈で「教育に興味があるのであれば、42 Tokyoというところに入学してみたらどうか」とお話をいただいたんです。「革新的な教育プログラムらしい」ということを聞き、後から調べたところ、ソフトウェアエンジニアリングを学べることを知りました。まさに求めていたものだと思い、一切の迷いなく入学試験を受けることを決めました。


就職が決まっていた企業での業務は、僕が得意とすることとは少し乖離があったんです。就職について悩んでいたとき、松尾研の方から42 Tokyoの話を聞いて、内定を辞退して学ぶことを選びました。ソフトエンジニアリングの勉強をしたいというのが一番でしたが、独自の教育カリキュラムへの興味もありましたので、とても良いタイミングだったと思います。

試験に合格したあとは、松尾研のインターンをしながら42 Tokyoのコモンコア（基礎カリキュラム）の勉強を始めました。
:::

## 日本最速でコモンコアをクリアした松本さんが語る42Tokyoの学び方
!
通常の授業のように時間が決まっているのではなく、好きな時間に好きなだけ勉強ができるのが「42」の魅力のひとつだ。松本さんは42 Tokyoのコモンコアを開校以来最速でクリアしているが、どのようにして課題を進めていたのだろうか。

松本さんは、42 Tokyoのカリキュラムについて、「今までの学習方式を破壊したような斬新なカリキュラムだった」と語った。
:::box
**松本さん**
コモンコアの修了については急いで終わらせようと思ってやっていたわけではなく、結構黙々と一人で集中して課題に取り組む時間が多かったんです。もちろん周りの人と協力しながら進める場面もありましたが、一人でできるところは黙々と課題を解いていました。


これまで色々な人たちが学問というものを紡いできた歴史がありますよね。今までの一般的な学習方式は、論文や学術本などを発表して、それを授業や研究という形で紡いでいく考えだったのですが、「42」はこれを破壊しているんです。課題を渡されて、自分で考えたり周りに相談しながら答えを導き出して、自分の力で登っていかないといけない。


効率性の観点で考えると、決して効率的とは言えません。しかし、課題をクリアするために自分たちで情報を取得しながら進めなければならないので、「未知のものに対する対応力」という、育成するのが難しい能力を育てる上では、最適な構図だと思います。最初に教科書をもらった方が全部覚えられて学びやすいじゃないですか。
すべての人に刺さる学習方法ではないと思いますが、この方法で学ぶことで得られるものは多いと思います。
:::
松本さんは2度目の大学4年生になることを決意したときから「あと1年しかないのに、この時間を無駄にはできない」と、黙々と課題をこなしていたという。そして、最速でのコモンコアクリアを実現した。自主性を育む環境で、一人で自由に課題を進めることもできる。自分のペースでこなせるところも42Tokyoの魅力なのだ。
:::box
**松本さん**
「42」の学習方法についてですが、例えば、「ウェブページを自分でデザインして作れるようになりたい」という具体的な目標がある場合、42 Tokyoで学ぶことはエンジニアの基礎なので、他のスクールの方がその目的達成のゴール到達は早いかもしれません。
しかし、エンジニアという刻々と変化していく分野において、「基礎・土台となるような力を、時間をかけてでもいいので学びたい」など、幅広く応用の効くところまで学ぶ目的があるのであれば、力を養う学習方法として最も効率的なカリキュラムだと思います。
:::

## 42 Tokyoで得たスキルと知識
!
:::small
42 Tokyoの実際の学習風景
:::
42 Tokyoでの学びを通して、どのようなスキルが身についたのだろうか。特殊カリキュラムをこなす日々の中で身についた知識やスキルについて、松本さんに詳しく聞いた。
:::box
**松本さん**
42 Tokyoでのコモンコアが終了した時点では、正直、自分に身についた知識やスキルについてはあまり実感はなかったんです（笑）目に見えたスキルの習得がゴールになっていないので、実際に課題をこなしているときは「これ、役に立つときが来るのか？」と思っていました。恐らく、僕以外にも同じことを思いながら続けていた人は多いと思います。


しかし、役に立ったと思う日が来たんです。それは、松尾研在籍中、プロジェクトでエンジニアリングをしていた時期があり、定期的に業務の進捗報告をする機会があったんですが、「なぜこのような実装に至ったか」と聞かれたとき、「このような背景があり、こういった意図で実装しています」と、とてもスムーズに説明ができたんです。学生同士でフィードバックしあいながら課題を進める42 Tokyoの学習フローを、ここで活かすことができました。自分が行った作業の内容を、相手がしっかり理解できるように説明しないと課題をクリアできなかったので、そこで“説明力”が身についたのだと思います。


未知の領域に対しての対応力は確実に身につきましたし、自身の技術面の成長も感じました。コモンコアで学んだ内容とは違う技術領域に触れたときに、「これはあの課題で学んだ内容と裏にある理念は共通なのではないか」と気づき、さらに理解が深まった瞬間もありました。

そういった気づきがあるたびに、課題の意味を改めて理解できたと実感しました。
:::
松本さんはさらに、「42 Tokyoの特殊なカリキュラムは、偶発的な学びが起きやすい環境となるよう、意識的に設計されているんだろうと実感した。」と続けた。42 Tokyoを通して身についたスキルの存在に気づくたびに、点と点がつながっていく感覚があったのだという。
## 人事統括担当として描く組織像
42 Tokyoと松尾研の両軸で進んでいった1年間は、どのような将来像を描いて日々を過ごしていたのか。そして、42 Tokyoを卒業した現在は、どのようなビジョンを描いているのか、松本さんは以下のように語った。
:::box
**松本さん**
当時は明確なビジョンを意識していなかったんです。ただ、松尾研も42 Tokyoも同様に、自分の得意分野に気づけたというのは、人生を大きく変えたきっかけでもありますし、人生に与えたインパクトはとても大きいと思います。


42 Tokyoは去年の7月に卒業していて、現在はスタートアップで働いています。所属企業は、オーダーメイドでAIの受託開発を主に行っています。AIを学ぶ環境も展開しており、講義の設計なども行っています。その中で現在は、人事統括及びプロダクトマネージャーとして仕事をしています。人事統括としては、Missionの達成を第一としつつ、メンバーそれぞれの強みを活かしながら、事業を一番成長させられる文化の浸透・採用・アサインを日々模索しています。また、プロダクトマネージャーとしては、プロダクトの設計から、開発や機能検証のマネジメントを行っています。


42 Tokyoに在籍していた当初は明確なビジョンはなかったと話しましたが、現在の僕は、将来的には教育関連に携わることを目標としています。そのためにも、まずは自分の価値を最大限に発揮できる今の会社で、尊敬できる人たちと一緒に会社としての目標を達成していくことが大事だと思っています。
:::
松本さんの所属している企業のビジョンは “テクノロジーですべての「ひと」の力を解き放つ” であり、この「すべて」の部分は、外の人たちだけではなく、会社で働くメンバーも含まれるそうだ。社内外でこのビジョンを達成すべく、現在は業務にあたっているという。

:::box
特集：
:::</description><pubDate>Tue, 02 Jul 2024 02:23:09 +0000</pubDate></item><item><title>日本リスキリングコンソーシアム　最新の生成AI講座「 Google AI Essentials」を先着1万人に無料提供
</title><link>https://ledge.ai/articles/google_ai_essentials</link><description>:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::

2024年6月19日、日本リスキリングコンソーシアムは、 最新の生成AI講座「Google AI Essentials」を新規会員先着10,000人に無料で提供すると{target=“_blank”}した。

本講座は、初心者でも10時間程度でAIの基礎知識と活用方法を習得できる日本語対応のオンライン講座だ。通常8,000円相当の有料講座だが、今回は新規会員の先着10,000人が無料で受講できるという。GoogleのAIエキスパートが講師を務め、受講修了時には認定証が発行される。

### 主な学習内容は以下の通り
- 生成 AI ツールを使って、アイデアやコンテンツを開発し、より多くの情報に基づいた意思決定を行い、日々の作業をスピードアップする
- 明確で具体的なプロンプトを作成し、必要なアウトプットを得る。プロンプトのテクニックを応用して、要約やキャッチフレーズの作成などに役立てる
- AI にありうるバイアスを特定し、その弊害を回避することで、責任を持って AI を使用する
変化する AI の今後の展開の中で常に最新の情報を得るための戦略を立てる

AIに興味はあるが、何から学んだら良いのか迷っている方、日々の業務を効率化したい、AIスキルを習得してキャリアアップを目指す方に推奨の基礎講座で、さらに本講座を受講すると、以下2種の講座も無料で受講が可能だという。

### Google データアナリティクス プロフェッショナル認定証（2022 年提供開始）
データに基づいてビジネス上の意思決定を行うためのデータ収集、変換、整理スキルを学び、データアナリストとして即戦力となるためのスキルを身につけるコース

### Google サイバーセキュリティ プロフェッショナル認定証（2023 年提供開始）
一般的なリスク、脅威、脆弱性を特定する方法やそれらを軽減するテクニックなど、成長著しいサイバーセキュリティ分野で即戦力として活躍するためのスキルを身につけられるコース

!
:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::
学位や事前知識など受講条件はなく、誰でも申込みが可能とのこと。AIの基礎知識を身に着けたい方はぜひお見逃しなく。

:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:41:55 +0000</pubDate></item><item><title>【6/27 15:00開始】 最新モデル「Claude 3.5 Sonnet」の実力に迫るLIVE配信をレッジが開催！GPT-4oやGemini 1.5 Proとの違いなど徹底解説</title><link>https://ledge.ai/articles/expo2024_claude3-5_sonnet_live</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している特設サイト「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 突如発表された最新モデル「Claude 3.5 Sonnet」 その実力を検証するLIVE配信の開催が決定
2024年6月21日にAnthropicが突如として最新AIモデル「Claude 3.5 Sonnet」を発表した。

:::box
{target=“_blank”}
:::

Claude 3.5 Sonnetは、コードの生成やイメージの認識の性能が大幅に向上し、前バージョンの上位モデルであるClaude 3 OpusやGPT-4oなどの競合モデルを上回る性能を持っているという。

現在公開中の「{target=“_blank”}」では、LLM比較というテーマで、GPT-4o（OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった主要LLMの最上位モデルの比較結果のまとめ記事（{target=“_blank”}）を公開している。

今回の発表を受け、EXPO特設サイトでは、上記記事の追加企画として、Anthropicの最新LLM「Claude 3.5 Sonnet」について解説するLIVE配信を行う。

前バージョンのモデルであるClaude 3 Opusとの違いや、GPT-4oやGemini 1.5 Proといった他LLMとの違いを実際のデモを通じて比較しながら、リアルな使用感をお届けする。
主要LLMの最新情報をアップデートしたい読者は、是非視聴してみてほしい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button
{target=“_blank”}
:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。

## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
URL：{target=“_blank”}
配信形式：zoomウェビナー（LIVE）
配信日時：2024年06月27日（木） 15:00〜15:30
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Tue, 25 Jun 2024 13:36:46 +0000</pubDate></item><item><title>NLP（自然言語処理)これまでの80年とこれからの20年（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-msd-short</link><description>
:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

## ChatGPTなどに活用されるNLPの歴史を紐解く
生成AIの台頭により "NLP" が一般的にも広く認知されるようになったが、NLPが80年にわたって発展してきた技術であることはご存じだろうか。実は、NLPの起源を探ると、1940年代の機械翻訳までさかのぼる。

今回は、長年研究されてきた技術であるNLPについて、元女子高生AI「りんな」などで知られるrinna株式会社の元CEOであり、現在はマイクロソフト ディベロップメント株式会社のプリンシパル アプライド サイエンティストであるZhan (Cliff) Chen / 陳 湛 氏にお話を伺った。

:::box
!
**マイクロソフト ディベロップメント株式会社**
**Zhan (Cliff) Chen / 陳 湛 氏**
:::

:::button
{target=“_blank”}
:::

**Cliff 氏**
私は今年の４月にマイクロソフトに入社しましたが、実は入社は２回目です。2015年にマイクロソフトでAIチャットボットのrinnnaを作り、翌年以降もディープラーニングの技術を用いたチャットボットを開発していました。例えば、音声合成、歌、ダンスなど、現在生成AIで話題になっているコンテンツを2017年～2019年ごろに研究していて、2019年にはGPTがチャットボット開発に適していることも発見していました。
そもそもなぜチャットボットなのか？という点ですが、チャットボットは人間の知能に一番近いと考えていたからです。GPTには未来がありそうだと考えていました。2019年11月には、現在「RAG」として認知が広がっている技術も作って、発表も行っていました。

!

2020年にマイクロソフトからrinnaがスピンオフして、rinna株式会社を設立し、そこのCEOに就任しましたが、面白かったのは2021年4月ごろに日本語版のGPT-2のオープンソースで発表したことです。そこからGPTをアップデートし続け、Hugging Faceでオープンソースとしてリリースしていました。
凄く自慢できることがあるのですが、その当時の日本のNLP大会の中で、rinnaのGPT-2の技術を引用した論文が全体の3%から5%程あったことです。その当時はBERTが主流で、GPTはマイナーな技術だったのですが、日本語のGPTの論文の中にrinnaの技術が参照されていたのは印象深かったです。

**箕部（モデレーター）**
RAGの研究に関してもかなり早い段階から行われていたのですね。

**Cliff 氏**
我々もその時、KGC(※)は重要だということをたくさん話していましたが、そもそもGPTがマイナーだったのと、GPTは誤回答をすることから「全然ダメだ」と言われていましたね（笑）

OpenAIのChatGPTが出たことは、アカデミックから見るとそんなに革新的ではないのですが、インダストリーの観点から見ると一般ユーザーのマインドセットが変わった出来事でしたね。

:::box
（※）KGC（Knowledge Graph Construction）：知識グラフの構築のこと。知識グラフとは、知識を抽象化したデータ間の関係性を示すデータベース。知識情報が体系的に整理されることで、検索や情報抽出などのタスクにおいて必要な情報を提供することに役立つ。
:::

**箕部（モデレーター）**
AIを理解するうえで、”これまで” と “これから” を理解していくことが重要だと考えますが、クリフさんは専門だと思いますので、そのあたり詳しくお話を伺えればと思います。

**Cliff 氏**
「今までのNLPの80年」について、つまり、LLM（大規模言語モデル）はどこから来たのか？という話ですが…

※続きは特設サイトよりご覧ください 

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：
開催形式：オンライン（特設サイト）</description><pubDate>Fri, 21 Jun 2024 06:43:48 +0000</pubDate></item><item><title>【主要LLMの最上位モデルを比較】GPT-4o、Gemini Pro1.5、Claude 3 Opus 仕事で使えるLLMはどれか？まとめ記事公開中！</title><link>https://ledge.ai/articles/expo2024-llm-comparison</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

大規模言語モデル（LLM）は、チャットボットや文章生成、翻訳、要約、コード生成などの様々なタスクで活用されている。その一方で多くのLLMが存在しており、どれを選べばよいか頭を悩ませている読者も多いと思われる。

6月10日（月）より公開しているLedge.ai EXPO 2024 Summerでは、GPT-4o（ChatGPT / OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった最新モデルを比較したまとめ記事を公開している。いわゆるLLMのスペック比較ではなく、実際の出力結果を比較し、その使用感や出力の特徴を解説しているので、自社にとって最適なLLMを探す際の参考情報としてご覧いただきたい。

:::button
{target=“_blank”}
:::

## ビジネスシーンでの活用を想定した３つのタスクの実行結果を比較
今回の比較記事の中では、以下３つの主要LLMの最上位モデルを対象として比較を行っている。

- GPT-4o（ChatGPT / OpenAI）
- Gemini 1.5 Pro（Gemini / Google）
- Claude 3 Opus（Claude / Anthropic）

パラメータ数や学習データの範囲といったスペック比較は既に様々なところで行われているため、今回は仕事で実際に使えそうか？という観点で、企画、データ分析、ルーティンワークといった切り口で、LLMのアウトプットの比較を行った。
ビジネスシーンでの活用を想定した３つのタスクとその結果の一部を以下に紹介する。

## 企画：アイデアを創造する能力を比較
記事の中では、各LLMに「新しいテクノロジー製品のアイデアを提案してください。」というプロンプトを送り、それぞれの出力結果を比較している。
LLMは、学習した膨大な過去データから確率的な推論を行い、もっともらしい出力を行うものである。よくも悪くも私たち人間の一般的な価値観に合わせた平均的な回答の生成が得意なLLMが、新しいアイデアの発想において、現在どの程度のアウトプットを出すことができるのかをまとめている。

例えばOpenAIが開発した最新の大規模言語モデルGPT-4oでは、アイデアの中身については、真新しさや面白みには欠けるのは否めないというのが正直な評価であった。しかし出力に関する指示はなくとも、文章の項目構成を整理したアイデアが出力してくれる点には有用性も感じられた。アウトプットをそのまま使うレベルではないものの、着想のきっかけを得るための手段としては十分に使えるものではないだろうか。

!
:::small
GPT-4oが出力した企画案
:::

その他の２つのLLMの実行結果も記事の中で取り上げている。詳細は是非記事をご一読いただきたい。

## データ分析：データを理解し、可視化する能力を比較
２つ目のデータ分析の比較も興味深い示唆が得られる内容になっている。比較の内容としては、ChatGPTで生成したマーケティングデータのサンプルファイルを元に各LLMに分析結果を出力してもらった。上述した企画よりも、LLM毎の違いが見受けられた。

特にGeminiは、出力後もグラフをインタラクティブに操作でき、その場でデータの編集ができる。またGoogleスプレッドシートとの連携もスムーズにできる点などは、Google製品で業務を行っているビジネスマンにとっては、有力な選択肢となりそうだ。

!
:::small
Gemini 1.5 Proでのグラフ編集の動画も公開している
:::

## ルーティンワーク：記事を要約する能力を比較
最後に記事要約の実行結果をまとめている。シンプルなタスクであるがゆえに、LLMが有する言語処理能力がわかりやすく現れる内容といえるだろう。
今回は以下の記事の原稿ファイルを読み込ませ、要約を実行した。

:::box
{target=“_blank”}
:::

要約の内容については、どのLLMも違和感はなく、十数秒ほどで得られるクオリティとしては十分なものだった。しかし要約の仕方にはそれぞれ違いがあり、この部分は個人によって判断が分かれるように思われる。記事内の実行結果をその目で見て判断いただきたい。

!
:::small
Claude 3 Opusが出力した要約結果
:::

今回はプロンプト内で出力の形式などを特段指示していないため、プロンプトの作り込みで変わってくる部分もあるだろう。しかし同一の条件の元で、各LLM毎のアウトプットの違いを把握しておくことは、LLMを選ぶ際の重要な参考情報となりうる。記事をきっかけに是非お手元で試し、実際の使用感を体験いただきたい。
比較記事の全文は以下の特設サイトより閲覧できる。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 20 Jun 2024 06:38:09 +0000</pubDate></item><item><title>AWSが新AI認定試験を発表　2024年8月13日より開始、初の「ベータ試験」での日本語試験も提供</title><link>https://ledge.ai/articles/aws_crtified_ai_practitioner</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年6月14日、Amazon Web Services, Inc.（AWS）は、AI人材育成に関する説明会で、AIスキルを証明できる「AWS Certified AI Practitioner」と「AWS Certified Machine Learning Engineer（MLA）」の2種の新しい認定試験が2024年8月13日から開始することを{target=“_blank”}した。

**「AWS Certified AI Practitioner」**
AI、機械学習（ML）、および生成AIのコンセプトやツールに精通していることを証明する際に役立つ、AIに特化した資格だ。この資格は、AWS認定試験の4つのレベルの中でも基礎的な知識習得を目的とした「Foundational」のカテゴリに位置づけられる。

**「AWS Certified Machine Learning Engineer（MLA）」**
こちらは、AIやMLソリューションの構築、デプロイ、保守に必要なスキルを証明するものであり、モデルパフォーマンスの最適化、計算資源の管理、モデルのバージョンアップ、AIソリューションの保護などをスキル対象とする技術者向けの認定資格だ。AWS認定試験の「ASSOCIATE」のカテゴリに位置づけられる。

新たな2種の認定資格は、2024年8月13日から「ベータ試験」として登録を開始する。通常は英語での実施だが、このベータ試験は同社として初の試みである日本語試験も提供をする予定だという。
</description><pubDate>Thu, 20 Jun 2024 09:19:07 +0000</pubDate></item><item><title>その日から使えるデモも実演！「マルチモーダルAI」の概念を15分で丁寧に解説するウェビナーが公開中</title><link>https://ledge.ai/articles/expo2024-webinar-multimodalai</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 多種多様なデータを扱うことが生成AIをビジネスで活用する際の重要な鍵となる
生成AIは、ビジネスの多岐にわたる分野で急速に活用されている。生成AIは、テキスト、画像、音声、ビデオなどの多種多様なデータを扱う能力により、より高度な意思決定や業務効率化を実現するツールとして注目を集めている。特に、マルチモーダルAIの多様なデータソースを統合して分析・生成する能力は、ビジネスの競争力を高める鍵として注目を集めている。

とはいえマルチモーダルAIという言葉こそよく耳にする機会は増えてきたものの、実はまだその概念について良くわかっていない読者も多いのではないだろうか？

6月10日（月）より開催している「Ledge.ai EXPO 2024 summer」オンライン特設サイトでは、マルチモーダルAIについて15分で基本的な概念を解説するウェビナーを公開している。マルチモーダルAIの概要を短時間で学べるため、興味のある方は是非動画をご覧いただきたい。



:::button
{target=“_blank”}
:::

## マルチモーダルAIとは何か？
マルチモーダルAIとは一言で説明すると、複数種類の情報を組み合わせて高度な判断を行うAIのことである。モーダルとはデータの種類を指し、テキストや画像、音声、映像など様々なデータを扱うことが含まれている。
ビジネスの現場で扱うデータが多様化してきたことで、このマルチモーダルAIが今注目を集めている。

!

私たちがこれまでAIとして扱ってきたいわゆるシングルモーダルAIでは、単一のデータ形式に特化していた。マルチモーダルAIでは、異なるデータ形式間の関連性を学習し、それを基にした高度な予測や判断を行うことが可能になる。これにより単一のデータ形式だけでは得られない複雑な処理結果を引き出すことができる。

!

## 大規模言語モデルとの統合でマルチモーダルAIの能力は飛躍的に向上
大規模言語モデル（Large Language Models, LLM）は、テキストデータの処理に特化したAIモデルであり、膨大なテキストデータから学習することで、高度な言語理解能力を持っている。この言語処理能力が、異なるデータ形式間の関連性の理解においても非常に高い性能を発揮し、主要な大規模言語モデルにも、画像、テキスト、音声などのデータを統合して処理するマルチモーダル機能が強化される動きが加速した。

ウェビナーの中でも国内外の主要な大規模言語モデルを4つほどピックアップしているので、是非チェックしてみてほしい。

!

## マルチモーダルAIでどんなことができるかをデモ実演
ウェビナーの中では、OpenAIの最新モデル「GPT-4o」を使い、ビジネスシーンでの活用を想定したデモを実演している。すぐ試すことができるデモ内容になっているので、是非動画を参考に自身の業務の中でも活用してみてもらいたい。

今回は
- ホワイトボードの会議メモの整理
- 手書きのラフデザインからhtmlのソースコードを生成

の2種類のデモを行った。
ホワイトボードの会議メモを整理するデモについてその一部を簡単に紹介する。

会議でディスカッションした内容をホワイトボードに書き込んで記録することは、ビジネスの現場でよく見られる光景だ。
ホワイトボードの内容を構造化して整理しておきたい場合に、手打ちでテキストメモに書き起こしたりしていないだろうか？
こうした作業は、マルチモーダルAIを活用することで、作業を大幅に効率化できる。

!
!

デモの中では、ホワイトボードを撮影した画像と簡単な指示テキストを与えるだけで、情報が整理されたテキストメモが出力される過程を確認することができる。さらにそのメモからアイデアをブラッシュアップするといった追加指示を与えて、ただの文字起こしに＋αのタスクを実行させるところまで実演しているので、このあたりも注目してみてもらいたい。

ーーー

マルチモーダルAIは、大規模言語モデルと統合し、より自然で人間らしいインタラクションが実現可能になり、さまざまな分野での応用が期待されている。
この機会にぜひ動画をご覧いただき、ビジネスの現場でどのように活用できるかを学び、実際に導入するためのヒントとなれば幸いである。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）

</description><pubDate>Fri, 14 Jun 2024 04:03:02 +0000</pubDate></item><item><title>生成AIの未来を掴むための3つのキーワード（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-keyword-short</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

生成AIの発展は目覚ましいものである。その中で特に「マルチモーダルAI」「AIエージェント」「独自データ活用」の3つは、今期の企業の生成AI活用において、押さえておきたい重要キーワードだ。

「マルチモーダルAI」とは、テキストや画像、音声など複数の情報形式を統合的に理解・生成する技術で、「AIエージェント」とは特定のタスクを自律的に実行するAIプログラムであり、ビジネスプロセスの自動化と効率化を実現できるものである。また、最近の生成AI活用事例で多く耳にするようになった「独自データ活用」は、企業が保有するデータを活用してAIモデルのトレーニングを行う、または、保有データを参照して企業に特化した回答を生成する手法だ。

この3つのキーワードは、生成AIの未来を切り拓くために不可欠な要素であり、企業の競争力を高め、ビジネスの成長を加速させるものである。生成AIの社内活用を推進している、または、今後更なるAI活用を検討するユーザーは必見の内容だ。ぜひ特集サイトから一読いただきたい。

:::button
{target=“_blank”}
:::
## 目次
1. マルチモーダルAI：データの壁を越える技術
2. AIエージェント：企業のパートナーとしての役割
3. 独自データ活用：基盤モデルをベースに競争力強化
4. まとめ

## マルチモーダルAI：データの壁を越える技術
マルチモーダルAIは、テキスト、画像、音声などの複数のデータ形式を同時に解析する技術だ。これにより、単一のデータ形式では得られない洞察を引き出すことができる。例えば、画像とテキストを組み合わせることで、物体認識とその説明を同時に行うことが可能となる。こうした技術は、特に多様なデータを扱う現代のビジネス環境において非常に重要だろう。

技術的な中核には…

※続きは特設サイトよりご覧ください。

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 13 Jun 2024 03:47:03 +0000</pubDate></item><item><title>AWSが、生成AI業務アプリを作成する「AWS App Studio」のプレビューを公開　開発スキルがなくても自然言語で利用できる</title><link>https://ledge.ai/articles/aws_app_studio_public_preview</link><description>:::small
画像の出典：{target=“_blank”}
:::

現地時間の2024年7月10日、米Amazon Web Services（AWS）は、ニューヨークで開催された「AWS Summit New York 2024」で、生成AIでアプリ作成ができる「AWS App Studio」のパブリックプレビューを{target=“_blank”}した。

「AWS App Studio」は、専門的なソフトウェア開発スキルがなくても、自然言語で作成したい業務アプリの説明を行うと、数分で業務アプリを作成することができる。

以下のように、左側に作成したい業務アプリの説明を入力をすると、入力されたプロンプトをもとに、生成AIがアプリのユースケース、操作の流れや主要機能を右側に書き出す。内容に問題がなければ生成を開始すると、わずか数分でアプリを作成することができる。さらに、生成されたアプリは公開前に実際のデータソースを使用して、プレビューで検証することもできるという。

!

:::small
画像の出典：{target=“_blank”}
:::

また、AWS App Studioの利用料金は無料で、開発されたアプリを使用した分だけ支払うシステムとのこと。例えば、企業で今後3ヶ月以内にAWS APP Studioを使用して2つのアプリを作成予定だった場合、2つのアプリを公開後1ヶ月のうちに10日間各アプリを使用した場合は、以下のような料金体系となる。

!

:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::

:::box

:::
</description><pubDate>Tue, 16 Jul 2024 13:58:52 +0000</pubDate></item><item><title>AGI実現への一歩となるコンテスト「ARC Prize 2024」開催中　賞金総額は約1億8000万円！</title><link>https://ledge.ai/articles/arc_prize_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月11日より、Zapier社の共同創設者マイク・クヌープ氏とGoogleの研究者フランソワ・ショレ氏が提案する「ARC」（Abstraction and Reasoning Corpus）を用いたコンテスト「ARC Prize 2024」が{target=“_blank”}されている。

ARCは、AGI（汎用人工知能）に向けた進歩を測定するAIベンチマークであり、人工知能と人間の知能を比較することを目的として作られた。これまでの競争では、人間の平均84％の正解率に対して、AIの最高スコアは34％程度となっている。これらの根本となる知識は、人間が子供の頃から自然と身につけている感覚のため、人間にとっては簡単だがAIには難解なテストだという。

現代のAI研究は大規模言語モデル（LLM）に重点を置いているが、これらのモデルは基本的な新しい発明や単純な問題への適応ができないため、真の知能とは言えない。この問題に対処するため、ARCというベンチマークテストが注目を集めている。

「ARC Prize 2024」は、LLMを超えた新しいアイデアを研究者が探求し、その進歩をオープンソース化することを目的としている。コンテスト提出締切は11月10日で、12月3日に賞の発表を予定しているとのこと。

テスト内容は以下のとおり、カラフルなグリッド図形から規則性を見つけ、右側のテスト用のアウトプットにその規則性に基づいた図形を表現する簡単なテストだ。
!
:::small
画像の出典：{target=“_blank”}
:::

【ARC Prize 2024の概要】
**グランプリ**
・1位：25万ドル（約3,500万円）
・2位：10万ドル（約1,400万円）
・3～5位：5万ドル（約700万円）
・追加グランプリ：50万ドル（約8,081万円）
※人間の正解率が平均84％のため、85％以上の精度スコアを達成した上位5チームに追加のグランプリ50万ドルを分配。
**2024進歩賞**
・1位: 2.5万ドル（約404万円）
・位: 1万ドル（約161万円）
・3〜5位: 各5,000ドル（約80万円）
※2024年の競争期間中に最高スコアを記録した上位5チームに授与
**論文賞**
・優勝: 4.5万ドル（約727万円）
・次点: 5,000ドル（約80万円）
※ARC-AGIでの性能を実現する方法についての理解を最も進展させた論文に授与
**参加条件**
・提出物のコードと手法はパブリックドメインのオープンソースライセンスの下で公開する必要がある
・第三者のコードや手法もオープンソースライセンスの下で利用可能でなければならない

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 11 Jul 2024 07:18:15 +0000</pubDate></item><item><title>OpenAI が開発者向けQ&amp;AコミュニティサイトStack Overflowと新たなAPIパートナーシップを発表</title><link>https://ledge.ai/articles/openai_stackoverflow_api_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、OpenAIとStack Overflowは、開発者向けに最適化された技術情報とAI開発ツールを提供する新しいAPIパートナーシップを{target=“_blank”}した。

このパートナーシップにより、OpenAIのユーザーや顧客は、Stack Overflowが提供する正確で検証済みのデータを基に迅速な問題解決を図り、重要なタスクに集中できるよう支援されるという。

この協業の一環として、OpenAIはStack Overflowの「OverflowAPI」を利用し、ユーザーにStack Overflowの検証済み技術知識を直接提供する。これにより、ChatGPTはStack Overflowの豊富な技術データベースと連携し、利用者に対してより精度の高い支援を提供できるようになる。また、Stack Overflowは、OpenAIのAIモデルを利用して「OverflowAI」の開発を行い、内部テストから得た洞察を活かしてAIモデルの性能向上を図る。

このパートナーシップは、技術者が直面する課題への対応速度を向上させ、開発者コミュニティ全体の生産性とエンゲージメントの向上を目指している。両社は、開発者が必要とする情報や解決策を、より迅速かつ正確に提供できる環境を整備することで、技術開発の新たなスタンダードを築くことを目指している。

Stack Overflowは2月29日にGoogle Cloudとの協業を発表しており、「Gemini for Google Cloud」との統合を進めている。この連携ではGoogle Cloudのプラットフォーム上でStack Overflowの情報を活用し、開発者が容易に重要なナレッジベース情報やコーディング支援を利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 12:52:43 +0000</pubDate></item><item><title>AWSが「Amazon Q」の一般提供を開始　企業内データを活用したAIアプリケーション開発の加速を目指す</title><link>https://ledge.ai/articles/amazon_aws_q</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）は2024年4月30日、生成AIアシスタント「Amazon Q」の一般提供を開始したと{target=“_blank”}した。

このサービスは、開発者が自社のデータを活用してAIアプリケーションを構築できるよう支援することを目的としており、特にソフトウェア開発の加速と企業データの活用が可能になるという。

Amazon Qは、コード生成、テスト、デバッグ、計画立案、推論機能を備え、開発者はコードの自動変換やアップグレード（Javaバージョンアップグレードなど）、新しいコードの実装が可能となる。この生成AIアシスタントは、エンタープライズデータリポジトリへの接続もサポートしており、企業のポリシー、製品情報、業績、コードベース、人材に関する質問への回答や、データの論理的な要約、トレンド解析、データ関連の対話が行えるとのこと。

また、社内データから生成AIアプリの構築を可能にする新機能「Amazon Q Apps」も同時に発表された。従業員は自然言語でアプリについて記述するだけで、必要とされる業務を遂行するアプリを生成できるという。この機能により、日常業務の簡素化と自動化が促進される。

さらに、Amazon Qは40以上の一般的なビジネスツールと簡単に接続でき、企業は自社のデータを効率的に集約し、アクセスできるようになる。この広範なデータ統合能力により、企業はよりデータ駆動型で効率的な運営が可能になる​とのことだ。


:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 11:42:47 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>Microsoftがスプレッドシートなどの表計算ソフトを理解できる大規模言語モデル「SpreadsheetLLM」を発表　複雑なスプレッドシートの処理を削減</title><link>https://ledge.ai/articles/spreadsheet_llm_microsoft</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月12日、Microsoftの研究チームは、大規模言語モデルを活用してスプレッドシートの処理を効率的に行う技術「SpreadsheetLLM」を{target=“_blank”}した。

スプレッドシートは、ビジネスで広く使用されるデータ管理ツールだ。しかし、その複雑なレイアウトや多様なフォーマットで大量のデータを効率的に処理することは従来の手法では困難だったという。この課題改善のために、スプレッドシートの理解および、効率的に処理することを目的として「SpreadsheetLLM」が開発された。

SpreadsheetLLMの中心となるのは、「SheetCompressor」という手法で、表計算シート内で重要な構造を特定し、その情報を保持しながらデータ量を大幅に削減する。SheetCompressorは、表計算データを平均して25倍に圧縮することに成功しており、LLMが一度に処理できるデータ量が増加する。これにより、複雑な表計算ファイルの分析が可能となり、データ処理にかかる計算コストも96％削減されたという。

実験結果において、SpreadsheetLLMは表計算検索タスクで従来のモデルを12.3％上回る性能を達成したと発表している。
!

:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Jul 2024 14:44:17 +0000</pubDate></item><item><title>OpenAI　開発コードは「Q*」から「Strawberry」に。推論能力を向上し、数学などの高正答率を目指す新たなAI技術の開発が進んでいる</title><link>https://ledge.ai/articles/openai_strawberry</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月12日、ChatGPTを開発したOpenAIが「Strawberry」というコードネームの新しいAI技術に取り組んでいることが、内部文書と関係者の証言により明らかになった。{target=“_blank”}によれば、プロジェクトはMicrosoftが支援するOpenAIがAIモデルの推論能力を向上させるために進めているという。

OpenAIの内部文書によると、Strawberryは単に質問に答えるだけでなく、インターネットを自律的かつ信頼性を持ってナビゲートし、「深い研究」を行う能力を持つことを目指している。推論能力の向上により、AIモデルが複雑なタスクを計画し実行する能力を持つことが期待されているとのこと。

Strawberryプロジェクトは以前「Q*」として知られており、すでに社内で画期的なものと見なされていた。内部文書には、Strawberryモデルが複雑な科学や数学の質問に答えるデモを行うことができ、90%以上の正答率を記録していると記されている。

OpenAIは、この技術を使用してAIモデルの推論能力を大幅に向上させると期待を寄せており、特に、自動化された深い研究やソフトウェア・機械学習エンジニアの業務を行う能力を持たせることが目標だという。これにより、AIモデルが自主的にウェブを閲覧し、研究を行うための「CUA」（コンピュータ利用エージェント）を使用することが可能になる。

AIの推論能力が向上すれば、科学的発見の促進や新しいソフトウェアアプリケーションの計画・構築が可能となり、人間または超人間レベルの知能を実現する鍵となる。OpenAIのCEOであるサム・アルトマン氏も、AIにおける最も重要な進歩は推論能力の向上であると述べているという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 07:34:17 +0000</pubDate></item><item><title>Google DeepMind　Gemini1.5を使ってオフィス道順案内などのタスクを自然言語で実行させる</title><link>https://ledge.ai/articles/google_deepmind_mobility_vla</link><description>
:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年7月10日、同社のAIモデル「Gemini 1.5」の最大100万トークンという長大なコンテキストウィンドウを活用することで、オフィス内でのタスクを自然言語で解決させたと{target=“_blank”}した。この様子をデモ動画に納め、AIがオフィス内での道案内やタスク実行を行う様子を紹介している。例えば、「どこで絵を描けるか教えて」といった指示に対して、AIがユーザーをホワイトボードに案内する様子が示された。

!
:::small
画像の出典：{target=“_blank”}
:::

Gemini 1.5の特徴に「Mixture-of-Experts（MoE）」アーキテクチャが挙げられる。この技術により、AIモデルは入力に応じて関連する部分のみを活性化することができ、効率的に動作する。これにより、長文のQAや長時間の動画の理解など、従来のモデルでは困難だったタスクも高い精度で実行できるという。

Mobility VLAと呼ばれるナビゲーションポリシーは、長大なコンテキストウィンドウを持つ視覚と言語を組み合わせたAI（VLM）と、地図のような役割を果たすトポロジーグラフを使って、ロボットがどこに行くべきかを決定する仕組みを組み合わせている。このAIは、デモンストレーションツアービデオとユーザーからの指示をもとに、最適なルートを導き出す。

下図は、Mobility VLAのアーキテクチャを示している。デモンストレーションツアービデオとマルチモーダルユーザー指示を使用して、目標フレームを特定し、オフラインで構築されたトポロジーグラフを使用してロボットのアクションを生成する仕組みが描かれている。

!
:::small
画像の出典：{target=“_blank”}
:::

論文では、AIが自然言語での指示に基づいて、オフィス内の特定の場所にユーザーを案内する様子が紹介された。例えば「これを戻すべき場所は？」といった質問や、「スマートフォンを充電する場所は？」という指示に対して、AIが正確に応答することが示された。

研究チームは、Gemini 1.5が現実世界の大規模な環境での複雑な推論やマルチモーダルなユーザー指示において、最大90％の成功率を達成したと発表している。このモデルは、データセンターからモバイルデバイスまで幅広いプラットフォームで効率的に動作し、今後のAIの可能性に期待すると述べた。



:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Jul 2024 05:32:50 +0000</pubDate></item><item><title>スマホ上でも高速動作可能　NICTが21言語対応のニューラル音声合成技術を開発</title><link>https://ledge.ai/articles/nict_mobile_presen_tra</link><description>:::small
画像の出典：{target=“_blank”}
:::

国立研究開発法人情報通信研究機構（NICT）は2024年6月25日、ユニバーサルコミュニケーション研究所において、21言語に対応した高品質なニューラル音声合成技術開発に成功したことを{target=“_blank”}した。

この技術により、CPUコア一つで1秒の音声をわずか0.1秒で高速合成することが可能となり、従来モデルの約8倍の速さを実現した。また、ネットワークに接続されていないミドルレンジスマートフォン上でも、テキスト入力からわずか0.5秒で音声を生成できるという。

@


この新技術は、NICTが運用するスマートフォン用多言語音声翻訳アプリ「{target=“_blank”}」のサーバに搭載され、既に一般公開されている。今後は、商用ライセンスを通じて多言語音声翻訳やカーナビなど、様々な音声アプリケーションへの導入が期待される。

## 開発の背景
NICTのユニバーサルコミュニケーション研究所では、言語の壁を超えた音声コミュニケーションを実現するため、多言語音声翻訳技術の研究開発を{target=“_blank”}。特にテキスト音声合成技術は、音声認識や機械翻訳と同様に、多言語音声翻訳の実現に不可欠な技術である。従来の音声合成技術では、ネットワークに接続されていないスマートフォン上での合成が困難だったが、今回の開発によりその課題が解決されたとのこと。

## 技術の詳細
この技術は、入力テキストを中間特徴量へ変換する「音響モデル」と、中間特徴量を音声波形へ変換する「波形生成モデル」から成り立っている。「音響モデル」には、高速・高性能なConvNeXt型エンコーダとデコーダが使用されており、従来のTransformer型モデルに比べて3倍の高速化を実現。また、「波形生成モデル」には改良型のMS-FC-HiFi-GANが導入され、合成速度を4倍に引き上げているという。


!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::

</description><pubDate>Mon, 15 Jul 2024 14:08:36 +0000</pubDate></item><item><title>10億のペルソナで合成データを生成、LLM開発に新たな可能性</title><link>https://ledge.ai/articles/tencent_ai_lab_persona_hub</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

中国Tencentの研究チームは2024年6月28日、新しいペルソナ駆動型データ合成手法を{target=“_blank”}した。論文「Scaling Synthetic Data Creation with 1,000,000,000 Personas」では、10億の多様なペルソナを活用し、大規模な合成データを生成する「Persona Hub」の構築とその応用について詳述されている。
## Persona Hubの概要
「Persona Hub」は、ウェブデータから自動的に収集された10億の多様なペルソナで構成されている。これにより、LLMは多くの視点や知識を反映したデータを生成できる。このペルソナは、MinHash法と埋め込みベースの手法を用いて重複を排除し、多様性を維持しているという。


!
:::small
画像の出典：{target=“_blank”}
:::

## ペルソナ駆動型データ合成手法
この手法は、データ合成プロンプトにペルソナを統合することで、LLMにそのペルソナの視点を持たせ、データを生成するもので、以下３つのプロンプト方法が提案されている：

- **ゼロショットプロンプト:**  既存の例を使用せず、LLMの創造性を活かす
- **フューショットプロンプト:** いくつかのデモを提供して要件を満たすデータを合成する
- **ペルソナ強化フューショットプロンプト:** デモごとに対応するペルソナを派生させ、データ合成能力を向上させる
## 実験結果と応用
ペルソナ駆動型手法の有効性は、数学や論理的思考の問題作成、ユーザーインストラクションプロンプト、知識豊富なテキスト、ゲームのNPC（ノンプレイヤーキャラクター）、ツールや関数の開発といった多様なシナリオで実証された。具体的には、数学の問題生成では、ペルソナを追加することで、そのペルソナに関連するコンテキストで問題が作成されることが確認されたという。また、プロフェッショナルなペルソナを用いることで、より深い理解を必要とする高度な問題も生成可能とのこと。

このペルソナ駆動型データ合成手法は、LLMの多様な視点と知識を活用し、スケーラブルかつ多様な合成データを生成する手法であると研究者は述べる。これにより、LLMのトレーニングやテストに必要なデータの作成が大幅に効率化され、研究や開発において大きな影響を与えることが期待されるという。


:::box

:::
:::box

:::

</description><pubDate>Sun, 14 Jul 2024 13:14:09 +0000</pubDate></item><item><title>LLMはRAGと事前知識をどう使い分けるのか　マサチューセッツ大とMicrosoftの研究グループが発表</title><link>https://ledge.ai/articles/from_rags_to_rich_parameters</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年6月18日、大規模言語モデル（LLM）の推論能力向上を目指す研究が{target=“_blank”}された。研究者らは「検索拡張生成（RAG）」を活用した新たな手法により、LLMがどのように内部知識と外部情報を使い分けているかを詳細に分析した。
## RAGの役割とメリット
RAG（Retrieval-Augmented Generation）とは、LLMがユーザーの質問に対してより適切な回答を生成するための手法である。この手法は、外部のデータソースから関連情報を検索し、その情報をモデルの入力に追加することで、モデルの性能を向上させる。特に、訓練データが古くなった場合や、最新の情報を含んでいない場合に有効となる。

## 研究の手法と結果
研究者らは、LLMが事実に基づく質問に答える際に、内部知識（パラメトリック情報）とRAGによって取得された外部情報のどちらに依存するかを調査した。主な手法は以下の通りである。

**1. 因果追跡（Causal Tracing）：** モデルの特定の隠れ層が事実の予測にどのように寄与しているかを調査。これにより、どの層が内部知識に基づく推論を行っているかが特定された。
**2. パラメータ編集：** モデルのパラメータを直接編集し、知識を更新する手法を使用。この手法により、モデルの内部知識がどのように変化するかが観察された。
**3. RAGによる外部情報の利用：** RAGが提供する外部情報がどの程度モデルの回答に影響を与えるかを評価。外部情報が追加された際のモデルの回答と、内部知識のみに基づいた回答を比較した。

研究の結果、LLMは内部知識が豊富な場合にはそれに依存し、事前知識が不完全または古い場合にはRAGから得た外部情報をより活用することが明らかになった。具体的な質問に対しては、RAGが提供する最新情報がモデルの回答を大きく改善することも確認された。

また、RAGによって取得された外部情報を利用することで、モデルのハルシネーション生成頻度が減少することが示されたという。これにより、より正確で信頼性の高い回答が得られることが実証されたとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Jul 2024 07:00:05 +0000</pubDate></item><item><title>OpenAI「現在ChatGPTはレベル１」AIシステムの進化を測定する新たな内部評価スケールを導入</title><link>https://ledge.ai/articles/openai_sets_levels_to_track_progress_toward_superintelligent_ai</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

OpenAIは、大規模言語モデル（LLM）がAGI（人工汎用知能）に向けてどれだけ進歩しているか評価するための自社の判定基準となるスケールを作成したことを{target=“_blank”}が2024年7月12日に報じている。このスケールは、AIがAGIに到達するまでの進捗を5段階で評価するもので、現在のChatGPTのようなチャットボットはレベル1に位置づけられているという。

### OpenAIのスケールは以下のように定義されている。
**レベル1：** 基本的な会話や情報提供を行う現在のチャットボット
**レベル2：** PhDレベルの人間と同等に基本的な問題を解決できるAI
**レベル3：** ユーザーの代わりに行動を起こせるAIエージェント
**レベル4：** 新しいイノベーションを創出できるAI
**レベル5：** 人間の組織全体の業務を遂行できる完全なAGI

OpenAIは、今日のチャットボットはレベル2に近づいていると主張しており、AGIを「ほとんどの経済的に価値のあるタスクにおいて人間を超える高度な自律システム」と定義している。同社のCEOであるサム・アルトマン氏は、AGIに到達するまでに「おおよそ5年の猶予がある」と述べているが、実現には莫大な計算リソースが必要であり、現実的にはまだ遠い未来の話とされている。

この新しい評価スケールの導入は、OpenAIとロスアラモス国立研究所の協力{target=“_blank”}の翌日に行われたとのこと。この協力は、GPT-4oなどの高度なAIモデルがバイオサイエンス研究をどのように安全に支援できるかを探ることを目的としているという。プロジェクトマネージャーは、このプロジェクトがGPT-4oの能力をテストし、安全性やその他の評価基準を設定することを目指していると述べた。

2023年5月にOpenAIの安全チームが解散されたことにより、安全性に対する懸念が高まっている。共同創設者のイリヤ・サツケヴァー氏の退社後、同チームだった研究者のヤン・ライケ氏も「安全文化とプロセスが『輝く製品』の背後に置かれている」と主張し、{target=“_blank”}。OpenAIはこれに対して否定的なコメントを出しているが、AGIが実現した場合の影響については依然として議論が続いている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 09:52:08 +0000</pubDate></item><item><title>SelfGoal: LLMエージェントの高難易度タスク解決を飛躍的に向上させる新手法</title><link>https://ledge.ai/articles/ai_agent_selfgoal</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月、特定の高難易度タスクにおけるLLM（大規模言語モデル）エージェントの性能を大幅に向上させる新しい手法「SelfGoal」が{target=“_blank”}された。研究者たちは、この手法がエージェントに複雑な問題解決能力を与え、ゲームやプログラミングなどの分野での応用が期待されていると述べている。

SelfGoalの核となるのは、最終目標をより実践的なサブゴールのツリー構造に分解し、状況に応じてサブゴールを更新する点にあるという。エージェントは環境の変化に柔軟に対応しながら、最適なサブタスクを特定し、段階的に目標達成を目指すことが可能となる。

従来、LLMエージェントは抽象的な指示に対応するのが難しく、「この勝負に勝ってください」や「お金を稼いでください」といった指示を正確に理解して遂行することが課題となっていた。既存のアプローチでは、タスクを細かなサブタスクに分解する方法や、事前知識を活用してタスクを遂行する方法が提案されていた。しかし、これらの方法には、環境の変化に対応できない柔軟性の欠如や、単純で体系的でない行動を導くという問題があった。

SelfGoalは、最終目標をツリー構造のサブゴールに分解し、エージェントの置かれた状況に応じて最も有用なサブゴールを特定しながらツリーを段階的に更新していく。この動的なサブゴールの更新により、エージェントは柔軟に状況に対応しながら、効率的にタスクを遂行できるという。
## SelfGoalの仕組み
SelfGoalは、主に「探索モジュール」「分解モジュール」「実行モジュール」の3つのモジュールで構成されている。下図は、このSelfGoalの概要を示している。

!
:::small
画像の出典：{target=“_blank”}
:::

- **探索モジュール：** 現在の状況に最も適したサブゴールを選択する。事前知識を利用して、GOALTREEの中から最適なノードを選定する。
- **分解モジュール：** 選択されたゴールノードを具体的なサブゴールに分解する。新たなサブゴールが既存のノードと類似しないようにフィルタリングしながら、ツリーを成長させる。
- **実行モジュール：** 選択されたサブゴールを基に行動を指示し、エージェントが環境と相互作用する。
- ## 具体的な適用例
SelfGoalは、特に次のような分野で有効だという。

- **ゲーム：** ゲームの目標をサブゴールに分解し、状況に応じて戦略を変更することで勝利を目指す
- **プログラミング：** 複雑なプログラミングタスクを段階的に解決し、最終的なプログラムの完成を目指す

実際のタスクでの応用例として、「交渉タスク」におけるSelfGoalの効果が挙げられる。下図は、交渉タスクにおいてSelfGoalが他の手法と比較してどのように優れているかを示している。

このタスクでは、エージェントがアイテムの配分について交渉するシナリオを示している。エージェント（例えば、Alice）がパートナー（Bob）とアイテム（本、帽子、ボール）の配分について話し合い、利益の差を最小化することを目指している。
CLIN、ADAPTという別の手法に比べ、SelfGoalは「相手の評価を明確にする質問をする」など、具体的な行動指針を提供し、交渉の進行に応じて戦略を柔軟に調整している。

!
:::small
画像の出典：{target=“_blank”}
:::

SelfGoalの導入で期待できる効果として、研究グループはLLMエージェントの柔軟性・効率性の飛躍的な向上が期待され、今後さらに高度なタスクに対してもLLMエージェントが有効に活用されることが予想されると述べた。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Thu, 11 Jul 2024 13:17:57 +0000</pubDate></item><item><title>内省メカニズムで進化するLLMエージェント「悪魔の代弁者」　GoogleDeepMindなどの研究チームが発表</title><link>https://ledge.ai/articles/google_deepmind_devils_adovocate</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Google DeepMindとペンシルベニア大学研究チームは2024年6月、大規模言語モデル（LLM）エージェントの適応力と一貫性を向上させるための内省メカニズムを導入する新たなアプローチを{target=“_blank”}した。LLMエージェントが複雑なタスクを効率的に解決できるようにすることが主な研究目的だという。

研究のタイトル「Devil’s Advocate: Anticipatory Reflection for LLM Agents（「悪魔の代弁者」LLMエージェントのための予期されたリフレクション）」は、人間の内省プロセスにおける「悪魔の代弁者」的な役割をエージェントに持たせることを示唆している。つまり、エージェントが自らの決定や行動を事前に批判的に見直すことで、潜在的な失敗を予測し、より効果的な対策が立てられるというアプローチである。

## 内省メカニズムの概要
研究では、LLMエージェントがタスクをサブタスクに分解し、行動と結果について内省を行うように促す以下の3つの内省メカニズムが提案された。

**1. 予期的内省 (Anticipatory Reflection)：** 
行動実行前に潜在的な失敗を予測し、代替案を考慮する。これにより、計画がスムーズに実行されるようになる。

!
:::small
画像の出典：{target=“_blank”}
:::

**2. 行動後の評価とバックトラッキング (Post-action Evaluation and Backtracking)：** 
各行動の実行後、その行動と結果がサブタスクの目的と一致しているかを評価し、一致しない場合は前の状態に戻り、代替行動を取る

**3. 計画修正 (Plan Revision)：** 
計画が失敗した場合、実行された行動と記録を見直し、問題を特定して未来の計画を改善する​。


## 実験と結果
この内省アプローチを用いた実験は、WebArenaというシミュレーション環境で実施された。812のタスクにおいて、LLMエージェントの適応力と一貫性が評価されたとのこと。実験結果は以下の通り。

- **適応力の向上:** 予期せぬ状況に柔軟に対応できるようになった
- **一貫性の維持:** 計画の頻繁な変更が減少し、エージェントの混乱が防止された
- **効率性の向上:** タスク達成までの時間が短縮された

提案された内省アプローチを用いることで、試行回数と計画修正回数が45%削減され、成功率は既存の手法に比べて3.5%向上したという。



:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Jul 2024 05:44:10 +0000</pubDate></item><item><title>神経系と連携し「義足が自分の体の一部と感じられる」自然な歩行を可能に　MITの研究チームが発表</title><link>https://ledge.ai/articles/mit_continuous_neural_control_of_a_bionic_limb</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

マサチューセッツ工科大学（MIT）の研究チームが2024年7月1日に{target=“_blank”}した研究によると、特殊な外科処置と神経系で直接制御できる義足の組み合わせにより、脚を失った患者が従来よりも自然な歩行が可能になることが明らかになった。

{target=“_blank”}
!
:::small
動画の出典：{target=“_blank”}
:::


## 残存する神経を義足に接続し、神経フィードバックを得る
従来の義足技術では、事前に定義された歩行アルゴリズムに基づいて動作するため、動きが限定され、患者は自然な歩行感覚を得ることが難しかった。しかし、研究チームは残存する神経を義足に接続し、神経フィードバックを得られるようにする特殊な外科処置を開発。この新しい義足は、患者の神経系からの信号を受け取り、その信号に基づいて動作するため、より柔軟で自然な動きを実現するという。

実験では、義足を装着した患者が従来の義足と比較して、より自然に歩行できることが確認された。神経フィードバックを得ることで、歩行の安定性やバランス感覚も向上し、患者は義足を自分の体の一部として感じることができると報告している。


### 特殊な外科処置と神経フィードバックを得るための神経接続を示した図
!
:::small
画像の出典：{target=“_blank”}
:::

研究を主導したMITの研究者は、「この技術は、義肢使用者の生活の質を大幅に向上させる可能性がある」と述べている。今後の研究では、さらに多くの患者に対する実験や、長期間の使用による効果の検証が行われる予定だ。


### 義足の自律的な制御と神経系との接続方法を示す詳細な図

!
:::small
画像の出典：{target=“_blank”}
:::

この画期的な技術は、義足技術の新たな可能性を示しており、事故や病気で脚を失った人々の生活に大きな変革をもたらすと期待されていると研究チームは述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 09 Jul 2024 07:45:37 +0000</pubDate></item><item><title>Meta　従来の3～10倍速、60秒以内で高品質3Dアセットを生成する「Meta 3D Gen」を発表</title><link>https://ledge.ai/articles/meta_3d_gen</link><description>:::small
画像の出典：{target=“_blank”}
:::

Metaは2024年7月2日、新しいAIツール「Meta 3D Gen」を{target=“_blank”}した。テキストから高品質な3Dアセットを60秒以内に生成でき、従来の3～10倍の速度で3Dモデルを作成するツールだ。

Meta 3D Genは、シェーディングビューとアルベドビューを作成するAssetGenと、テクスチャを改良するTextureGenの二段階プロセスを採用している。これにより、ゲーム開発、建築設計、VR/AR分野での利用が期待されるという。
## Meta 3D Genの特徴
- **高速生成:** テキストプロンプトから60秒以内に3Dアセットを生成
- **高品質な3Dモデル:** 立体の造形とテクスチャを両方生成
- **多彩なテクスチャ:** プロンプトに忠実なテクスチャを生成

## 生成プロセス
**1. AssetGen：** テキストプロンプトから3DメッシュとPBR（物理ベースレンダリング）マテリアルを生成
**2. TextureGen：** AssetGenで生成されたテクスチャを改良し、ビュー空間とUV空間を統合して一貫性のあるモデルを作成
　※物理ベースレンダリング（PBR）: 高品質なリライト（再照明）が可能な3Dアセットを生成する
　※高忠実度: 複雑なテキストプロンプトに対しても高い忠実度を保つ

下図：Meta 3D Genの概要。このパイプラインは、テキストプロンプトを入力としてテキストから3D生成を行い（ステージI）、その後テクスチャの改良を行う（ステージII）。ステージIIは、ユーザーが提供する新しいテキストプロンプトに基づいて生成またはアーティストが作成した3Dメッシュのリテクスチャリングにも使用できる。

!
:::small
画像の出典：{target=“_blank”}
:::

## 利用例
- **ゲーム開発:** 環境やキャラクターのプロトタイプを迅速に作成
- **建築:** テキストから詳細な3Dモデルを生成
- **VR/AR:** 没入型の環境やオブジェクトを簡単に作成

下図：すべての業界ベースラインと比較したテキストプロンプト忠実度の定性的比較（挑戦的なプロンプトで）。Meta 3D Genは、他の方法と比べて複雑なプロンプトに対しても高い忠実度を保つ。
!
:::small
画像の出典：{target=“_blank”}
:::

Meta 3D Genは、物理ベースレンダリング（PBR）をサポートし、リアルな3Dアセットの生成が可能となる。この技術の導入により、3Dコンテンツの作成プロセスが大幅に効率化されることが期待されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 09 Jul 2024 04:08:11 +0000</pubDate></item><item><title>長尺のビデオを理解する「LongVA」大規模マルチモーダルモデルの進化　シンガポールの研究グループが発表</title><link>https://ledge.ai/articles/long_va_lmms_lab</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年6月25日、シンガポールの研究チームが{target=“_blank”}した「LongVA（Long Video Assistant）」が、大規模マルチモーダルモデル（LMMs）の長尺ビデオ理解における新たな指標を示した。
## 主要な特徴と技術的背景
近年、大規模なマルチモーダルモデル（LMMs）が注目を集めているが、長時間の動画理解には限界がある。この問題に対し、研究者たちは新たなアプローチとして「LongVA」（Long Video Assistant）を開発した。このモデルは、従来の方法とは異なり、言語モデルのコンテキスト長を拡張することで、長時間の動画理解能力を飛躍的に向上させているという。

LongVAという新たなアプローチでは、まず言語モデルの文脈長を拡張し、その後、画像データを用いて視覚と文脈の整合性を図ることで、長いビデオの理解を可能にする。

下図: LongVAのアプローチ。左側は従来の視覚トークン削減手法を示し、右側はLongVAが言語モデルの長い文脈を視覚データに転移させる方法を示している。短い画像データで訓練し、テスト時には非常に長いビデオをゼロショットで処理する。

!
:::small
画像の出典：{target=“_blank”}
:::

これにより、従来の視覚トークン削減の手法を使わずに、2000フレーム以上、200K以上の視覚トークンを処理できるようになったという。

## 性能評価と結果
LongVAは、特に「V-NIAH（Visual Needle-In-A-Haystack）」という新たなベンチマークテストで、その性能を発揮している。このテストは、非常に長いビデオの中から特定のフレームを見つけ出し、その内容を理解する能力を測定するものである。

V-NIAHテスト結果は下図の通り。x軸はビデオ全体のフレーム数を示し、y軸は針（特定フレーム）の位置を示している。黒の点線は言語モデルの訓練文脈長を示し、各フレームは144トークンに相当する。


!
:::small
画像の出典：{target=“_blank”}
:::

実験の結果、LongVAは2000フレーム以上の入力に対しても高い精度で情報を取得できることが示された。また、他のビデオベンチマーク（Video-MME）においても、LongVAは7Bスケールのモデルの中で最先端の性能を達成している。特に、フレームを密にサンプリングすることで、その性能がさらに向上することが確認されたという。
## Video-MMEベンチマークでの最高性能
LongVAは、Video-MMEベンチマークにおいて、7B規模のモデルの中で最高性能を達成した。特に、入力フレーム数を増やすと性能が向上し、長い動画での性能向上が顕著であった​とのこと。

## 定性的な結果
LongVA-DPOの定性的な結果も評価されている。このモデルは、短いビデオと長いビデオの両方に対して優れた理解能力を示している。例えば、短いビデオでは、人々が調味料で遊んでいるシーンを正確に説明し、長いビデオでは、列車の色やシーン内で使用されている傘の色など、特定の詳細を識別する能力を示している。

下図は、LongVA-DPOの定性的結果。モデルは短いビデオや長いビデオにおける特定の詳細を正確に識別し、理解する能力を示している。

!
:::small
画像の出典：{target=“_blank”}{target=“_blank”}
:::

LongVAのコード、デモ、およびモデルは、{target=“_blank”}および{target=“_blank”}でオープンソースとして公開されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 06 Jul 2024 16:34:09 +0000</pubDate></item><item><title>つくば市　NECとLLMおよび画像分析技術を活用した防災実証実験を実施</title><link>https://ledge.ai/articles/nec_tsukuba_supercity</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::


NECは2024年7月12日、茨城県つくば市において、大規模言語モデル（LLM）と画像分析技術を活用し、災害に強いまちづくりを目指す実証実験を行うと{target=“_blank”}した。この実証実験は、2024年11月から2025年1月まで行われ、住民が投稿した画像から街の状況をリアルタイムに可視化し、災害時の迅速な状況把握と対応を支援することを目的とする。

!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みは、2024年度の内閣府「先端的サービスの開発・構築及び規制・制度改革に関する調査事業（スーパーシティ・デジタル田園健康特区対象）」に採択されたことを受けて行われる。つくば市は2022年にスーパーシティに指定されて以降、「つくばスーパーサイエンスシティ構想」を掲げており、NECはその一環として本実証実験を実施するとのこと。

## 実証実験の概要
つくば市内の一部エリアで行われるこの実験は、住民が投稿した画像を収集し、LLMと画像分析によりダッシュボード上に可視化する。つくば市公式アプリ「つくスマ」を通じて、違法駐車や混雑する場所などの平時の状況を可視化し、災害時にはこれらのデータを活用して迅速な初動対応を可能にするという。

また実験では、災害時に投稿される画像に含まれる個人情報の取り扱いについても検証を行う。防災分野におけるデータ活用の可能性を広げ、より安全で安心な防災・減災対策の実現を目指すとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

NECは、この実証実験を通じて得られた結果をもとに、データ連携基盤の活用によるさらなるサービスの高度化を検討する予定だ。また、将来的にはデジタルツインの実装も視野に入れており、取得した情報を基に平時・災害時を通じた多様なサービスの開発を進めていく計画だという。



:::box

:::
:::box

:::

</description><pubDate>Wed, 24 Jul 2024 03:54:20 +0000</pubDate></item><item><title>AWS、政府のAI支援プロジェクト「GENIAC」における計算リソース提供者に選定</title><link>https://ledge.ai/articles/aws_selected_as_geniac_computational_resource_provider</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）2024年7月19日、経済産業省とNEDOが推進する国産生成AI開発力強化プロジェクト「GENIAC」（Generative AI Accelerator Challenge）において、同社が計算リソース提供者として選定されたと{target=“_blank”}した。このプロジェクトは、生成AI基盤モデルの開発を通じて日本国内の技術力を底上げし、企業のイノベーションを促進することを目的としている。
## プロジェクト概要
2024年2月に{target=“_blank”}したGENIACは、国内の生成AI開発力を強化することを目指している。このプロジェクトは、生成AIの基盤モデル開発に必要な高性能な計算資源を提供するだけでなく、開発者同士の連携や国際的な発信活動を支援することで、広範な技術革新を促進する。

## 助成内容
GENIACでは、スタートアップ企業や中小企業、学術機関に対して計算リソース利用料の2/3を助成し、その他の企業や団体には1/2を助成する。総助成額は最大245億円に達する予定。

プロジェクトでは、計算リソースの確保方法として二つの選択肢が設けられている：
1. 提案者が計算リソース提供事業者と個別に調整し、直接確保する方法
2. 経済産業省が計算リソース提供事業者から一括で確保し、提案者に提供する方法

AWSは後者の一括確保方法における計算リソース提供事業者として選定された。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 03:50:50 +0000</pubDate></item><item><title>内閣府　AI戦略会議で「AI制度研究会」のメンバーを発表、座長には東大松尾教授　AIに関する法規制のあり方を議論</title><link>https://ledge.ai/articles/cabinet_office_announces_members_of_ai_system_study_group</link><description>:::small
画像の出典：{target=“_blank”}
:::

内閣府は2024年7月19日、AIに関する法規制のあり方を議論するための「AI制度研究会」のメンバーを{target=“_blank”}した。研究会の目的は、AI技術の進展とそれに伴う社会的影響を考慮し、適切な法規制の枠組みを検討することである。

研究会の座長は、東京大学大学院の松尾豊教授が務める。その他のメンバーには以下の専門家が選ばれた（敬称略）

- 江間有沙（東京大学国際高等研究所東京カレッジ准教授）
- 岡田淳 （森・濱田松本法律事務所弁護士）
- 川原圭博 （東京大学大学院工学系研究科教授）
- 北野宏明 （株式会社ソニーリサーチ代表取締役プレジデント）
- 佐渡島庸平 （株式会社コルク代表取締役社長）
- 田中邦裕 （さくらインターネット株式会社代表取締役社長）
- 山口真一 （国際大学グローバル・コミュニケーション・センター准教授）

この発表は、同日に持ち回りで開催された第10回AI戦略会議において行われ、「AI制度研究会」の設置案が原案の通り決定された。同研究会は、AI技術の健全な発展とその利活用を促進するための法的課題や倫理的問題について、多角的な議論を進めることを目指すという。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 07:53:28 +0000</pubDate></item><item><title>気候変動による猛暑とAIで世界の電力需要急増、17年ぶりの増加率に　IEA報告</title><link>https://ledge.ai/articles/iea_reports_global_electricity_demand_to_surge_with_extreme_heat_and_aiiea_reports_global_electricity_demand_to_surge_with_extreme_heat_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

国際エネルギー機関（IEA）は2024年7月17日、2024年と2025年の電力需要は過去17年で最高の増加率を示す見込みだと最新のレポートを{target=“_blank”}した。特に気候変動による気温上昇、AI技術の普及が主な要因となっており、太陽光発電がその増加の半分を賄うとされている。
## AIとデータセンターの影響
AIの普及に伴いデータセンターの電力需要が急増しており、より信頼性の高いデータと精度の高い評価が求められている。IEAは、エネルギー部門とデジタル化の関係を研究する最前線に立っており、新たなイニシアティブ「エネルギーのためのAIとAIのためのエネルギー」を開始した。この一環として、IEAは政府、産業界、研究者、民間専門家と協議を行う予定である。2024年12月5日にパリで開催される「エネルギーとAIに関する国際会議」が重要なマイルストーンとなるとのこと。
## 需要の急増と再生可能エネルギーの拡大
IEAの「電力半期更新」報告によると、2024年の世界の電力需要は約4％増加し、これは2007年以来の最高年次成長率となる（金融危機やCOVID-19パンデミック後の特異な反発を除く）。この強い増加は2025年にも続き、同様に約4％の増加が見込まれている。

再生可能エネルギーの電力供給も急速に拡大し、2023年の30％から2025年には35％に増加すると予測される。2025年には、再生可能エネルギーによる発電量が石炭を上回る見通しで、特に太陽光発電が2024年と2025年の電力需要増加の約半分を賄う見込みである。太陽光と風力を合わせると、需要増加の約3/4を占めるとされる。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jul 2024 07:48:24 +0000</pubDate></item><item><title>これは読むべき！経産省発表の音楽産業のビジネスモデルに関するレポートが興味深い　生成AIによる楽曲制作が業界に与える影響についての分析にも注目</title><link>https://ledge.ai/articles/meti_musicindustry_2024report</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月17日、経済産業省は「音楽産業の新たな時代に即したビジネスモデルの在り方に関する報告書」を{target=“_blank”}した。この報告書は、ストリーミング時代を迎えて大きく変化する音楽産業について、定量的な分析や新たなトレンドの可視化を目的とし、各種調査の結果を基に作成されたものだ。

SNSでは、「これは読むべき！」「経産省の本気を見た」などの高評価を得ており、評判となっている。また、音楽業界のみならず、他の業界にも応用可能なビジネスモデルの洞察を提供しているとの声も高い。
## SNSとストリーミングの影響
報告書では、SNSとストリーミングの普及が音楽の消費行動に与える影響を強調している。YOASOBIの「アイドル」やHoneyWorksの「可愛くてごめん」など、SNSでのバズが音楽ヒットに繋がっている具体例が挙げられている。ユーザー生成コンテンツ（UGC）の増加が他のアーティストやインフルエンサーによる発信につながり、さらなる人気を博していることが示されている。

下図：YOASOBIの「アイドル」に関連する公式動画とユーザー生成動画の視聴回数を示したもの。UGCが公式コンテンツ以上に多くの視聴を集めていることを示しており、SNSや動画プラットフォームでのバズの重要性を示唆している。

!
:::small
画像の出典：{target=“_blank”}
:::
## ボカロPとデジタルマーケティング
ボーカロイドを活用した音楽制作の普及により、SNSや動画配信プラットフォームを駆使するボカロP出身のアーティストがデジタルマーケティングに秀で、海外でも人気を得ているという。代表例としてYOASOBIや米津玄師氏が挙げられ、デジタル時代の新たな音楽ビジネスモデルが形成されている。

!
:::small
画像の出典：{target=“_blank”}
:::
## ヒットの事例にみられる要因
報告書では、SNSバズやバイラルによる成功法則の多様性を説明し、ヒット曲が生まれる要因には、特に二次創作の促進がバズの機会を創出することを強調している。

!
:::small
画像の出典：{target=“_blank”}
:::

その他にも、報告書では、生成AIによる楽曲制作が音楽業界に与える影響についての分析や、諸外国において日本の音楽がどのように受容されているかについても触れている。

この報告書の洞察は音楽業界に限らず、他の業界にも応用可能な示唆を含んでいる。デジタルマーケティングの重要性やUGCの効果的な活用、グローバル市場への展開戦略など、多くのビジネスに共通する課題と解決策が示されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Jul 2024 11:35:56 +0000</pubDate></item><item><title>ベネッセコーポレーションが、小学生と保護者による「生成AIの利用に関する調査」の結果を発表　前年より肯定的な意見が増加</title><link>https://ledge.ai/articles/benesse_survey_on_the_use_of_AI</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月17日、ベネッセコーポレーションは、小学生とその保護者を対象にしたChatGPTなどの生成AIの利用に関する調査の結果を{target=“_blank”}した。

## 保護者の認知度と利用に関する意向
調査によると、保護者の53％が生成AIを「知っている」と回答した。「知っている」と回答した保護者のうち66％が「子どもに使ってほしい」と肯定的な意見を示した。「積極的に使ってほしい」と答えた保護者は14％、「少し使ってみてほしい」と答えた保護者は52％で、{target=“_blank”}に比べて肯定的な回答が10ポイント増加したという。

!

:::small
画像の出典：{target=“_blank”}
:::
肯定的な理由としては、「新しい技術の活用力を養う良い機会になりそうだから」（35％）、「子どもが新しい興味に出会えそうだから」（22％）、「自分で考える力が伸びそうだから」（13％）が挙げられた。一方で、否定的な回答をした保護者の理由としては、「自分で考えなくなりそうだから」（48％）、「自分で書いて表現することをしなくなりそうだから」（23％）、「情報の正誤の判断がつかなくなりそうだから」（12％）が主な理由として挙げられた。
## 子どもの認知度と利用状況
子どもに生成AIを知っているか調査をしたところ、「知っている」と答えた子どもは20％、「聞いたことはあるがどんなものか分からない」と答えた子どもは28％、「知らない」と答えた子どもは52％で、前年調査に比べ「知らない」と答えた割合は9ポイント低下していた。

生成AIを知っている子どもの利用状況については、「よく使っている」子どもは16％、「時々使っている」子どもは28％、「試しに使ってみたことがある」子どもは26％、「全く使ったことがない」子どもは29％であった。
!

:::small
画像の出典：{target=“_blank”}
:::


**調査概要**
2024年6月24日から26日にかけてインターネットを通じて行われ、小学3年生から6年生の児童とその保護者1032組を対象にアンケート調査を実施。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Jul 2024 14:36:03 +0000</pubDate></item><item><title>一般にはほぼ無名のAIエンジニア安野たかひろ氏が、急激に支持者を集め都知事選で15万票を獲得するまでを振り返る　最新小説も発売！</title><link>https://ledge.ai/articles/takahiroanno_reflections_on_the_campaign</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月7日に行われた東京都知事選において、政治の世界ではほぼ無名の状態から15万4638票を都民から集め、結果5位に食い込んだというAIエンジニアの安野たかひろ氏が、自身のnoteで都知事選を振り返る記事を{target=“_blank”}した。

「なぜ無名のエンジニアは都知事選で15万票獲得できたのか」と題されたその記事では、「テクノロジーで誰も取り残さない東京を作る」と掲げた自身の選挙活動が、どのように認知を得て得票につながったのかを分析し、その影響について語った。

## AIと双方向コミュニケーション
!
:::small
画像の出典：{target=“_blank”}
:::

安野氏の選挙活動は、従来の政治キャンペーンとは一線を画していた。選挙活動の核となったのは、「ブロードリスニング」と称される、双方向のコミュニケーション手法であった。有権者の意見を直接聴き、それを政策に反映させることで、多くの支持を得た。AI技術を活用した意見収集ツールや、政策のアップデートを行うプラットフォームを駆使して、リアルタイムで有権者との対話を続けた。

安野氏は、選挙活動の過程で、1000万回以上SNSで拡散された{target=“_blank”}を基に、具体的な政策を提示し、有権者からのフィードバックを取り入れ続けた。このプロセスで、6月20日に公開した96ページのマニフェストを何度もアップデートし、最終的に232件の課題提起と104件の変更提案が反映されたという。

また、選挙活動には、AIを活用した「AIあんの」が大きな役割を果たした。YouTubeや電話を通じて、8600回以上の質問に回答し、有権者とのコミュニケーションを拡張することで、支持を広げた。また、街頭演説やメタバースでの活動も行い、直接的な対話の機会を増やした。

@


選挙結果としては5位に終わったが、無名のエンジニアが15万票以上を獲得したことは過去の都知事選の中でも異例であり、特に30代の候補者としては記録的な数値だという。

今後も政治活動に関与する意向を示しており、今回の選挙で得た知見やツールをオープンソースとして公開する予定であると述べた。同氏は、テクノロジーを活用した分断のない政治の実現を目指し、引き続き取り組んでいくとの意向を示している。


2024年7月4日、Ledge編集部でのインタビュー
@


なお、作家としても活動する安野氏のデビュー2作目となる長編小説「松岡まどか、起業します──AIスタートアップ戦記」が7月18日、早川書房より発売された。AIと働き方をめぐる令和の ”お仕事小説” とのことで、ハヤカワ・SFコンテスト優秀賞を受賞した1作目「サーキット・スイッチャー」とはまた違った世界が描かれているようだ。

!
:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 06:22:18 +0000</pubDate></item><item><title>総務省　2024年版「情報通信白書」より、生成AI利活用の現状と潜在的な可能性が明らかに</title><link>https://ledge.ai/articles/mic_2024_white_paper_on_Information_and_communications</link><description>:::small
画像の出典：{target=“_blank”}
:::

総務省は2024年版「情報通信白書」にて、日本国内外における生成AIの利用状況に関する詳細な調査結果を{target=“_blank”}した。この調査により、日本における生成AIの利用率は他国と比較して著しく低いことが明らかになったが、潜在的なニーズの存在も示された。

## 日本の生成AI利用率の低さ
調査によると、日本における生成AIの個人利用率は9.1%と低水準であり、米国（46.3%）、中国（56.3%）、ドイツ（34.6%）、英国（39.8%）と比較して大きく劣っている。利用しない理由としては「使い方がわからない」「自分の生活には必要ない」という回答が多く、セキュリティや情報漏洩に対する懸念は比較的少なかったとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

## 企業における生成AIの利用状況
企業向けの調査でも、日本企業の生成AI利用率は低いことが判明した。生成AIを「積極的に活用する方針を定めている」企業の割合は15.7%であり、米国（46.32%）、中国（71.2%）、ドイツ（30.1%）と比較して低い。特に、メールや議事録、資料作成などの補助業務での生成AIの使用率は、日本では46.8%にとどまり、他国の90%程度に比べて低水準である。

!

!


:::small
画像の出典：{target=“_blank”}
:::

## 潜在的な利用意向の存在
一方で、生成AIの利用意向については、「ぜひ利用してみたい」「条件によっては利用を検討する」と回答した割合は6～7割程度あり、潜在的なニーズがあることがうかがえた。生成AIの具体的な利用場面としては、コンテンツの要約・翻訳、画像や動画の生成、旅行の計画やイベントの企画などが挙げられている。

!

:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 01:43:51 +0000</pubDate></item><item><title>AIでクラスメイトのディープフェイクポルノを生成　スペインで15人の生徒に1年の保護観察処分の判決</title><link>https://ledge.ai/articles/deep_fake_images</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月9日、AIで女子生徒の画像を作成し拡散したとして、スペイン南西部の裁判所が15人の生徒に1年間の保護観察処分を言い渡したことを{target=“_blank”}が報じた。

この事件は、2024年3月にスペイン南部のアルメンドラレホという町で発生した。AIポルノアプリ「ClothOff」で生成した数十枚のヌード画像が、他の生徒が作ったWhatsAppグループで数週間にわたり拡散されていたという。ディープフェイクのヌード画像が拡散された少女たちは、学校に行くことを拒否し、パニック発作に苦しみ、恐喝やいじめの被害を受けている。ディープフェイクポルノを生成・共有したとして、15人の生徒が起訴された。

そして今回、これらの生徒に対して、「20件の未成年者の児童虐待画像を作成した罪」と「20件の被害者に対する道徳的誠実さに対する罪」で、バタホス市の少年裁判所が1年間の保護観察処分の判決を下した。スペインの法律で起訴できない13歳以下の子どもに対しては、児童保護サービスに送致されリハビリコースへの参加が命じられる可能性もあるとのこと。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 09:46:37 +0000</pubDate></item><item><title>経産省　ゲーム・アニメ・広告を対象に「コンテンツ制作のための生成AI利活用ガイドブック」を公開　スクエニ、伊藤園、パルコなど実例満載</title><link>https://ledge.ai/articles/meti_ai_guidebook</link><description>:::small
画像の出典：{target=“_blank”}
:::

経済産業省は7月5日、生成AI技術をコンテンツ制作に活用するための「コンテンツ制作のための生成AI利活用ガイドブック」を{target=“_blank”}した。このガイドブックは、生成AIの利活用によるコンテンツ制作の新たな方向性を示すもので、特にゲーム、アニメ、広告といった産業での具体的な利用事例や法的留意点を網羅している。
## ガイドブックの目的と内容

ガイドブックの内容は以下の通り
**１．生成AIの利活用の方向性：**
コンテンツ産業における生成AIの適切な利活用の方向性を示すため、知的財産権等の権利・利益の保護に十分に配慮しつつ、生成AIの活用事例を紹介
**２．具体的な利活用事例：**
ゲーム、アニメ、広告の各産業における生成AIの活用ケースを詳細に紹介し、それぞれの制作工程での具体的な活用方法を提示
**３．法的留意点と対応策：**
生成AIを利用する際の著作権や肖像権などの法的問題点について、具体的な対応策を示し、クリエイターが安心して生成AIを活用できるよう支援

生成AIが進化し続ける中、その可能性に着目してきたという経産省。今回のガイドブックは、生成AIの利活用を促進するために、特に注目すべき利用ケースと法的問題点を整理したものだ。

スクウェア・エニックス、伊藤園、パルコなど、企業による生成AI活用事例が紹介されている。例えば、画像生成AIを用いて線画に彩色や仕上げを行う方法や、テキスト生成AIを使用して広告コピーを作成する方法などが具体的に説明されている。また、著作権や肖像権の侵害を避けるための留意点や対応策も詳細に記載されている。


利活用例：ガイドブックより抜粋

!
:::small
画像の出典：{target=“_blank”}
:::


!
:::small
画像の出典：{target=“_blank”}
:::

## 関連省庁とガイドブックの位置づけ
下図は、生成AIに関連するガイドラインとその関係省庁の役割を示す。経済産業省、総務省、内閣府、文化庁などが連携し、AIの利活用に関する統一的な指針を提供する枠組みを説明している。

!
:::small
画像の出典：{target=“_blank”}
:::

同ガイドブックは、「令和5年度コンテンツ海外展開促進事業（コンテンツ産業における先端的技術活用に関する調査）」の成果物として作成され、{target=“_blank”}と一体となっている。同報告書も80ページにわたるボリュームで、精度の高いレポートがまとめられている。

コンテンツ制作に携わる企業にとって、生成AIは効率化や新たなクリエイティビティの創出に寄与する強力なツールとなる。しかし、法的な留意点をしっかりと理解し、適切な対応策を講じることが重要である。経済産業省のガイドブックは、そのための具体的な指針を提供するものとなる。なお、ガイドブックの表紙デザインには生成AIが活用されているとのこと。

ガイドブックは経済産業省の公式サイトから{target=“_blank”}可能。コンテンツ制作に携わるすべての企業やクリエイターにとって必携の資料となり得る。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Jul 2024 12:36:46 +0000</pubDate></item><item><title>岸田首相　東南アジア諸国のLLM開発支援を表明　各国の豊かな言語と文化に根ざした取り組みが必要</title><link>https://ledge.ai/articles/asia_business_summit</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月5日、東京で開催された「アジア・ビジネス・サミット」において、岸田文雄首相は東南アジア諸国に対するAI基盤整備支援を{target=“_blank”}した。日本は東南アジアの言語と文化に適応した生成AI技術の基盤構築を技術と財政の両面で支援する。これは、先端技術での遅れを懸念する東南アジア諸国と協力し、地域全体のAI開発環境を向上させる狙いだという。

岸田首相はスピーチの中で、AIが産業競争力と国力を左右する重要な技術であると強調し、特に大規模言語モデル（LLM）の開発において、各国の豊かな言語と文化に根ざした取り組みが必要であると述べた。日本のAI技術者のノウハウが他のアジア諸国のLLM開発に貢献できるとし、具体例として、日本のスタートアップであるイライザがタイ語を学習したLLMを開発中であることを紹介した。このような取り組みを日本政府として支援し、シンガポール、マレーシア、ベトナムなどの主要企業との連携を促進するとした。

さらに、岸田首相は5年間で10万人の高度デジタル人材を育成する計画を明らかにし、日本とアジアの人材交流を進めることによって、AIイノベーションを推進するコミュニティをアジアに築くことを目指すと述べた。また、昨年の広島G7サミットで開始された「広島AIプロセス」に基づき、生成AIのリスクに対処するための国際的な取り組みを推進し、安全で信頼できるAIの実現に向けてアジア諸国と協力する意向を示した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Jul 2024 11:55:05 +0000</pubDate></item><item><title>テネシー州　AIによる無断歌声使用を防ぐ新たな法律「エルビス法」を施行　違反には最大2,500ドルの罰金も</title><link>https://ledge.ai/articles/elvis_law</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月1日、テネシー州で「エルビス法」が施行され、AI技術を用いた無断の歌声使用に対する保護が強化された。この法律は、歌手エルビス・プレスリーの名前にちなんで命名され、アーティストの「声」を個人の財産として保護することを目的としている​ 。同法律は3月21日にテネシー州のビル・リー知事によって署名され、{target=“_blank”}。
## 背景
近年、AI技術の進化により、有名アーティストの声を模倣するサービスが急速に広がり、SNSで注目を集めている。例えば、2023年にはドレイクやザ・ウィークエンドの声を模倣した「Fake Drake」という楽曲が話題となり、これが問題視される{target=“_blank”}となった​​。こうしたAIによる無断の声のクローン作成は、アーティストの権利侵害に繋がり、音楽業界における重大な課題として浮上していた。

エルビス法は、従来の「名前」「写真」に加え、「声」も保護の対象に含めることで、無断使用を防止する初の法律だ。この法律に違反した場合、最大2,500ドルの罰金が科されるほか、民事訴訟の対象にもなる可能性があるという。
## アーティストのAIへの対抗運動
エルビス法の施行と同時期となる4月2日、アーティスト権利連盟（Artist Rights Alliance, ARA）は、200人以上のアーティストの支持を受けて、AI開発者やテクノロジー企業、プラットフォーム、デジタル音楽サービスに対し、人間のアーティストの権利を侵害し価値を減じるAIの使用を停止するよう呼びかける公開書簡を{target=“_blank”}した​。

ARAの公開書簡では、AIが無許可で音楽作品を使用し、アーティストの声を模倣する「コピーキャット」や、ロイヤリティの支払いを回避するためにAIを利用することが問題視された。ビリー・アイリッシュ、ノラ・ジョーンズ、ボン・ジョヴィなど、多くの著名なアーティストが署名している。この手紙は、「AI技術が人間のアーティストの芸術性を損なうことなく、公正な報酬を得られるようにすることが重要である」と強調している​。 


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 04 Jul 2024 11:26:15 +0000</pubDate></item><item><title>Sakana AIが新たな浮世絵生成モデルを開発　日本の伝統美をAIで再現</title><link>https://ledge.ai/articles/sakana_ai_evo-ukiyoe_evo-nishikie</link><description>:::small
画像の出典：{target=“_blank”}
:::

Sakana AIが2024年7月21日、浮世絵風画像生成モデル「Evo-Ukiyoe」と、浮世絵をカラー化できるモデル「Evo-Nishikie」を{target=“_blank”}した。これらのモデルは、同社が2024年4月に発表した、画像生成モデル{target=“_blank”}を基盤として開発された。
## Evo-Ukiyoe-浮世絵風画像生成モデル-

!

:::small
画像の出典：{target=“_blank”}
:::

Evo-Ukiyoeは、日本語のプロンプトから浮世絵風の画像を生成するモデルだ。風景や着物姿の人など、浮世絵によく取り上げられる題材について、高品質な画像を生成することができる。このモデルは、立命館大学アート・リサーチセンター（ARC）所蔵の24,038枚の浮世絵デジタル画像を学習データセットとして利用し、浮世絵の特徴を詳細に学習している。

桜や富士山、着物を着た人物など、Evo-Ukiyoeが認識しやすいプロンプトを入力することにより、浮世絵に近い画像を生成することができる。しかし、利用する上で「人物」の画像を生成する際の課題も挙がっているそうだ。「男性」と入力しても、女性の着物や髪型を生成してしまうことがあるため、この場合は男女を明確にする必要がある。プロンプトに「男性」、ネガティブプロンプトに「女性」と加えることで、よりイメージに近い画像を生成できるとのこと。
## Evo-Nishikie-浮世絵カラー化モデル-
!

:::small
画像の出典：{target=“_blank”}
:::

一方でEvo-Nishikieは、墨一色で摺られた浮世絵を、多色摺の浮世絵風にカラー化するモデルだ。江戸時代の本の挿絵をカラー化して、現代の絵本のように楽しむことができる。

これらのモデルは、本物の浮世絵と生成した浮世絵を比較することで、浮世絵の特徴を学ぶ材料となり、歴史や文化を学ぶための新たなコンテンツ作成のツールとしても利用できる。浮世絵や日本文化に興味を持つきっかけになることを期待しているそうだ。

Sakana AIは、公式サイトでEvo-UkiyoeとEvo-Nishikieのデモを公開している。ただし、各モデルは研究開発目的で商用利用などは想定しない。「本モデルの使用に伴うリスクを十分に理解し、自己の判断で使用する必要がある」とのこと。

:::box

:::

:::box

:::
:::box

:::
</description><pubDate>Wed, 24 Jul 2024 09:04:15 +0000</pubDate></item><item><title>ディズニー内部Slackデータ1.1TiB流出「生成AIからアーティストの権利を擁護するハッカー集団」Nullbulgeの攻撃</title><link>https://ledge.ai/articles/disney_slack_leak</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月、ハッカー集団「Nullbulge」がウォルト・ディズニー・カンパニーの内部Slackチャンネルから約1.1テビバイト（TiB）のデータを流出させたと{target=“_blank”}した。

!
:::small
画像の出典：{target=“_blank”}
:::

上記のメッセージは、ハッカー集団Nullbulgeがディズニーの内部Slackデータを流出させ、その中には未公開のプロジェクト、ログイン情報、内部APIのリンクなどが含まれていることを伝えるもの。また、内部協力者が途中で撤退したことについて言及し、将来の警告として個人情報を公開するとしている。

Nullbulgeは、約10,000のSlackチャンネルから収集したメッセージやファイル、未公開プロジェクトの詳細、ログイン情報、内部APIやウェブページのリンクなどを含む1.1TiBのデータを公開したと主張している。このデータは、ハッキングフォーラムやソーシャルメディアで広く共有されているという。

同集団は、ディズニーがアーティストとの契約を不適切に扱い、AI技術の導入に対するアプローチが問題であり、さらに消費者を無視していると主張し、このハッキングを行った理由を説明している。特に、ディズニーが「スター・ウォーズ」や「エイリアン」シリーズの作者に対するロイヤリティの支払いを停止したことが批判の中心となっている。

現在、ディズニーはこの事態を調査中であり、公式なコメントはまだ出されていない。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Jul 2024 08:59:41 +0000</pubDate></item><item><title>安達寛高（乙一）ら原作・監督　全編生成AI制作の映画「generAIdoscope：ジェネレイドスコープ」2024年公開予定</title><link>https://ledge.ai/articles/the_film_generaidoscope_produced_entirely_with_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

映画や映像の企画・立案などを行うリアルコーヒーエンタテインメントは2024年7月10日、同社による企画で全編生成AIで制作されるオムニバス形式の映画「generAIdoscope：ジェネレイドスコープ」の製作を{target=“_blank”}した。2024年内の劇場公開を予定しているとのこと。


!
:::small
画像の出典：{target=“_blank”}
:::

「generAIdoscope：ジェネレイドスコープ」は、その全編が生成AIによって制作されるという点が最大の特徴だ。映像、音声、音楽すべてがAI技術を駆使して生成されることで、従来の映画制作とは一線を画す新しい試みとなっているという。映画の原作・監督には、各ジャンルで活躍する映像作家が名を連ねている。安達寛高（乙一）、曽根剛、山口ヒロキの3人がそれぞれ独自の物語を手がける。

### 安達寛高（乙一）氏「モンキーズ・オデッセイ」
大航海時代を舞台に、船乗りが猿たちの住む無人島に漂着する物語「モンキーズ・オデッセイ」を描く。

### 曽根剛氏「AZUSA」
空想癖のある風変わりな女の子が夢を叶えるために二つの世界を行き来する「AZUSA」。この作品では、ファンタジーとリアリティの融合が見どころとなる。

### 山口ヒロキ氏「グランマレビト」
遠い未来の世界を舞台に、元魔術師の老婆が架空の国家を旅する「グランマレビト」を監督。壮大な未来世界のビジョンと共に、人間ドラマが展開される。


@


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 10:07:20 +0000</pubDate></item><item><title>優勝はモロッコのAI美女　世界初のAIビューティーコンテスト「Miss AI 2024」の受賞者発表</title><link>https://ledge.ai/articles/fanvue_miss_ai_winners</link><description>
:::small
画像の出典：参加者たちのインスタグラムより
:::

World AI Creator Awards（WAICA：世界AIクリエーター賞）が2024年7月、「Miss AI 2024」の受賞者を{target=“_blank”}した。このコンテストは、AIによって生成されたモデルが参加する世界初のビューティーコンテストとして、Fanvueとの共同開催で実現したという。

## 受賞者一覧
### 第1位：Kenza Layli（ケンザ・ライリ）氏　モロッコ出身
!
:::small
画像：{target=“_blank”}
:::

1位の栄冠に輝いたモロッコ出身のケンザ・ライリ氏は5,000ドルの賞金に加え、3,000ドル相当のAIメンターシッププログラム、および5,000ドル以上のPR支援を受ける。同氏は、モロッコの文化に根ざした魅力的なコンテンツで19万人以上のフォロワーを獲得し、審査員たちから高い評価を受けたとのこと。

### 第2位：Lalina（ラリーナ）氏　フランス出身

!
:::small
画像：{target=“_blank”}
:::

2位のラリーナ氏には2,000ドル相当のプロモーションパッケージと2,500ドル以上のPR支援が提供された。フランスからの参加で、特に技術力とプロモーション力が評価された。同氏の作品は、その精巧なデザインと高い技術力で注目を集めた。 

### 第3位：Olivia C（オリビア・C）氏　ポルトガル出身
!
:::small
画像：{target=“_blank”}
:::

3位のオリビア・C氏には、2,000ドル相当のプロモーションパッケージとコンサルティングコールを受け取った。ユニークなアプローチと創造性が高く評価された。同氏の作品は、多くのファンから支持を受け、コンテストでも高い評価を得たという。

## コンテストの概要
「Miss AI」は、AIによって生成されたモデルが美しさ、技術力、そしてソーシャルメディアでの影響力を競う新しい形式のビューティーコンテストだ。参加者は、見た目の美しさやポーズ、そしてAIツールを使用した技術力に加え、ソーシャルメディアでのフォロワー数やエンゲージメント率なども評価対象となる。

今回のコンテストには、トルコ、バングラデシュ、ブラジルなど世界中から多くのAIモデルが参加した。参加者たちはそれぞれ独自のAIモデルを作成し、その創造性と技術力を{target=“_blank”}した。


:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Jul 2024 09:45:31 +0000</pubDate></item><item><title>生成される画像の価値とは何なのか？　ライゾマティクスが「AIと生成芸術」がテーマの個展を開催中</title><link>https://ledge.ai/articles/rhizomatiks_beyond_perception</link><description>:::small
画像の出典：{target=“_blank”}
:::

クリエーター集団のライゾマティクスが、AI技術を活用した新しいアートの形を提案している。KOTARO NUKAGA（天王洲）の拡張移転に伴い、2024年6月29日から9月28日までの3ヶ月間にわたり、「AIと生成芸術」をテーマに個展「Rhizomatiks Beyond Perception」を{target=“_blank”}する。

展覧会では、ライゾマティクスが独自に作成した画像のみを学習したAIモデルを新たに開発し、その成果を展示する。現代において誰もがAIを使って画像を生成できる中、ライゾマティクスは「生成される画像の価値とは何なのか？」という問いを観客に投げかける。

展示作品の一環として、初めて販売されるのは “AIモデルデータ” である。購入者はこのAIモデルを使って入力を変えることにより、無限に画像を生成する体験が可能となる。このAIモデルデータは、ライゾマティクス自身の作品108本の映像を静止画に変換した約17万枚の画像を学習データとして使用し、既存の基盤モデルを一切使用せずにゼロから開発されたものだという。

### 展覧会概要
**会期:** 2024年6月29日（土） – 9月28日（土）
**開廊時間:** 11:00 – 18:00（火曜日から土曜日、日月祝休廊）
**会場:** KOTARO NUKAGA（天王洲）
**住所:** 東京都品川区東品川1-32-8 TERRADA Art Complex II 1F
**アクセス:** 東京臨海高速鉄道りんかい線「天王洲アイル駅」から徒歩約8分、東京モノレール羽田空港線「天王洲アイル駅」から徒歩約10分、京急本線「新馬場駅」から徒歩約8分



:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Jul 2024 07:35:19 +0000</pubDate></item><item><title>ハリウッド撮影クルー、AI使用も雇用維持で合意</title><link>https://ledge.ai/articles/hollywood_iatse_amptp_agreement</link><description>:::small
画像の出典：{target=“_blank”}
:::
全米のエンターテインメント産業の撮影現場で働く労働者の組合「IATSE」と主要スタジオを代表する「AMPTP」は2024年6月27日、AIの使用を認めながらも雇用を維持することで合意に達したと{target=“_blank”}した。
この合意は、「ハリウッド基本合意」と「ビデオテープ合意」の枠組みで成立し、IATSEの約50,000人のメンバーに影響を与えるものだという。
## 合意の詳細
今回の合意には、AIの使用に関する新たな保護措置が含まれている。具体的には、AIが労働者の職を奪うことがないようにするための条項が盛り込まれ、労働者がAIプロンプトを提供する場合でも、それが雇用喪失につながらないようにする対策が取られている​。また、賃金の引き上げも合意され、契約期間中3年間で7%、4%、3.5%のスケール賃金率の引き上げを予定しているとのこと。

## 交渉の背景
IATSEは衣装デザイナーやヘアスタイリスト、照明技術者、カメラオペレーターなど、多岐にわたる職種の労働者を代表している。今回の合意は、生成AIの台頭により雇用の危機感が高まる中で、労働条件の是正を求め{target=“_blank”}したものだ。特にコロナ禍のパンデミック以降、ハリウッドの労働者たちは自身の権利と雇用条件についてより積極的に声を上げている。

この合意はまだIATSEのメンバーによる批准が必要だが、正式に承認されれば、ハリウッドの労働環境におけるAIの影響を適切に管理しながら、労働者の権利と雇用を保護する新たな枠組みが確立されることになる見通し。また、同様の合意が他の労働組合との間でも期待されており、エンターテインメント産業全体での労働環境の改善が見込まれているという。

全米の映画俳優組合（SAG-AFTRA）によるストもAMPTPとの暫定合意に達し、2023年11月に終結している。


:::box

:::
:::box

:::

</description><pubDate>Fri, 05 Jul 2024 07:31:03 +0000</pubDate></item><item><title>大阪・関西万博に実物大ガンダム登場へ　バンダイナムコHDが展示計画を発表
</title><link>https://ledge.ai/articles/bandainamco_gundam</link><description>:::small
画像の出典：{target=“_blank”}
:::

バンダイナムコホールディングスは2024年6月26日、2025年に開催される大阪・関西万博で「機動戦士ガンダム」の実物大模型を展示すると{target=“_blank”}した。このガンダム像は、かつて横浜で展示されていた動く実物大ガンダムの部材を再利用しており、関西での展示は初めてとのこと。

展示されるガンダム像は高さ約17メートルで、片膝を立て片腕を上げたポーズを取っている。2020年から2024年3月末まで横浜市の「GUNDAM FACTORY YOKOHAMA」で展示されていた動く実物大ガンダム像の装甲部分を、頭部から足までほぼ再活用しているが、今回の展示では動くことはないという。

このガンダム像は、大阪・関西万博のパビリオン「GUNDAM NEXT FUTURE PAVILION」の近くに展示される予定。パビリオン自体は内装を除き2024年7月の完成を予定しているという。

@

バンダイナムコホールディングスでガンダムシリーズの知的財産戦略を担当する榊原博社長は、「ファンの方と一緒につながりたい」と述べ、ファン参加型の企画を計画していると明らかにした。2024年は「ガンダム」のテレビアニメ放映45周年にあたり、全国で関連イベントが開催される予定だ。SNS上でファンからのメッセージを募集し、その一部はパビリオン内で投影される。


:::box

:::
:::box

:::
</description><pubDate>Mon, 01 Jul 2024 13:23:40 +0000</pubDate></item><item><title>Mantraが7.8億円調達を実施　画像認識とLLM（大規模言語モデル）を併用したマンガ特化の翻訳ツール開発　</title><link>https://ledge.ai/articles/mantra_engine_ai_manga</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月26日、マンガAI翻訳技術の開発を行うMantra株式会社は、集英社、小学館、KADOKAWA、スクウェア・エニックス・ホールディングスなどから、総額7億8000万円の資金調達を行ったことを{target=“_blank”}した。

Mantraが開発した「Mantra Engine」は、AIを活用したマンガ/縦スクロールコミックの翻訳を効率化するクラウドツールだ。画像認識とLLM（大規模言語モデル）を併用し、キャラクターやストーリーを考慮しながら、ブラウザ上で翻訳に関わるすべての作業を完結させる。現在は、国内外の出版社や翻訳会社、配信事業者を中心に利用されており、集英社の人気マンガ『ONE PIECE』『SPY×FAMILY』のベトナム語版などの制作にも用いられている。

今回の資金を活用し、向こう5年を目処に「エンドユーザーが楽しんで読める」を目指し、マンガAI翻訳の精度向上に取り組むと同時に、小説やゲーム、動画への翻訳技術転用を本格化させる研究開発も進めていくという。

Mantraの代表取締役である石渡 祥之佑氏は、「エンタメから言語の壁をなくしたい」という明確な目的意識を創業前から持っており、昨今の急速に進むLLMや画像生成AIの進化を見て、「言語の壁がなくなる未来が少しずつ現実のものとして想像できるようになった」と述べている。

:::box

:::

:::box

:::

:::box

:::

</description><pubDate>Sun, 30 Jun 2024 21:14:19 +0000</pubDate></item><item><title>KRAFTON JAPAN　GPT-4o搭載の推理アドベンチャーゲーム『Uncover the Smoking Gun』を正式リリース</title><link>https://ledge.ai/articles/uncover_the_smoking_gun</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月25日、KRAFTON JAPAN株式会社は、AI技術を搭載した推理アドベンチャーゲーム『Uncover the Smoking Gun』をリリースしたと{target=“_blank”}した。

『Uncover the Smoking Gun』は、KRAFTON JAPAN傘下のクリエイティブスタジオ「ReLU Games」が制作した、ロボットと人間が共存する近未来を舞台にした没入型推理アドベンチャーゲームだ。プレイヤーがAI専門の探偵となり、事件の手がかりを追いながら、容疑者であるロボットに対してチャットで尋問していく。

OpenAIがリリースした「GPT-4o」を搭載しており、容疑者のロボットは単純に質問に回答するだけではなく、プレイヤーの性格に合わせた口調で、まるで実際に人とチャットで会話しているような感覚で楽しめるという。ロボットの曖昧な証言を見極め、真実にたどり着くために鋭い質問を投げかけながら、事件解決を目指す没入型の推理ゲーム。

『Uncover the Smoking Gun』は、現在Steamでダウンロード可能。日本語、韓国語、英語、中国語など全8言語に対応しており、詳細はSteamページおよびReLU Games公式サイトで確認できる。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:57:02 +0000</pubDate></item><item><title>Google DeepMindが動画に合うBGMや効果音を生成するAI「Video to Audio」を発表</title><link>https://ledge.ai/articles/google_deepmind_v2a</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年6月17日、新たな技術「Vide to Audio（V2A）」を{target=“_blank”}した。Generative Mediaチームの発表したこの技術は、動画の映像情報とテキストのプロンプトを用いて、映像にぴったりと合ったサウンドトラックを生成する能力を持つ。

現在、映像生成モデルは急速に進化しているが、多くの現行システムは無音の出力しか生成できない。V2Aは、この課題を解決し、生成された映像にリアルな音響を付与するための重要なステップとなる。

V2Aは、映像ピクセルと自然言語テキストプロンプトを組み合わせて、画面上のアクションに対してリッチな音響効果を生成する。例えば、ドラマチックなスコア、リアリスティックな音響効果、またはビデオのキャラクターやトーンに合ったダイアログを生成することが可能だ。

{target=“_blank”}（音声プロンプト： 映画、スリラー、ホラー映画、音楽、緊張感、雰囲気、コンクリートの上の足音）

!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}（音声プロンプト: 月に向かって吠えるオオカミ)

!
:::small
画像の出典：{target=“_blank”}
:::

## V2Aの技術的詳細
V2Aシステムは、ビデオ入力を圧縮された表現にエンコードし、拡散モデルがランダムなノイズから音声を逐次的に洗練させる。このプロセスは視覚的入力と自然言語プロンプトによってガイドされ、プロンプトに密接に一致する現実的な音声を生成する。最終的に音声出力がデコードされ、音声波形に変換され、ビデオデータと組み合わせられる。

また、高品質な音声を生成するために、詳細な音の説明や音声トランスクリプトを含むAI生成のアノテーションを追加情報としてトレーニングプロセスに加えた。これにより、特定の音声イベントを様々な視覚シーンと関連付けることが可能となり、アノテーションやトランスクリプトで提供された情報に基づいて音声を生成できるという。

!
:::small
画像の出典：{target=“_blank”}
:::


## 創造的なコントロールと今後の展望
V2Aは、任意のビデオ入力に対して無限のサウンドトラックを生成する能力を持つ。ユーザーは「ポジティブプロンプト」を定義して望ましい音にガイドするか、「ネガティブプロンプト」を使用して望ましくない音を排除することができる。この柔軟性により、V2Aの音声出力を迅速に実験し、最適なマッチを選択することが可能だという。


以下は、同じ動画に対して複数のサウンドを生成した例
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）
{target=“_blank”}(音声プロンプト: 優美なチェロの雰囲気）
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）

!
:::small
画像の出典：{target=“_blank”}
:::


Google DeepMindは、責任あるAI技術の開発を重視し、クリエイティブコミュニティからの多様な視点や洞察を収集し、研究と開発に反映させているとのこと。また、AI生成コンテンツに透かしを入れるためのSynthIDツールキットも導入し、この技術の誤用を防ぐための対策を講じている。V2A技術は公開前に厳格な安全評価とテストを経る予定だという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 28 Jun 2024 12:32:10 +0000</pubDate></item><item><title>AI音楽生成サービスSunoとUdioを著作権侵害で提訴　ユニバーサル、ソニー、ワーナー含む大手音楽企業</title><link>https://ledge.ai/articles/suno_and_udio_sued_for_copyright_infringement</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

米国の主要レコード会社であるユニバーサルミュージック（UMG）、ソニー、ワーナーを含む複数の企業が、AI音楽生成サービス「Suno」と「Udio」に対し、著作権侵害を理由に{target=“_blank”}。

RIAA（アメリカレコード協会）が2024年6月24日、ニューヨーク南部地区連邦地方裁判所およびマサチューセッツ地区連邦地方裁判所にそれぞれ提出した訴状によると、SunoとUdioは、著作権で保護されたサウンドレコーディングを無断でコピーし、自社のAIモデルのトレーニングに利用したという。その生成物が市場に流通しているとされ、複数のジャンルや時代のアーティストの録音が侵害対象となっているとのこと。

訴訟では、以下の3点を求めている。
- サービスが原告の著作権を侵害したことの宣言
- 将来的な著作権侵害を防ぐための差し止め命令
- 既存の侵害に対する損害賠償

## 訴訟の概要
この訴訟は、AI技術が進化し音楽制作の分野においても大きな影響を及ぼしている中、著作権の保護がいかに重要かを問うものである。原告側は、AIサービスが著作権で保護された楽曲を無断で使用し、生成された音楽ファイルが元の作品と酷似していると主張している （下図参照：訴状より）

!
:::small
画像は訴状より：Udioの生成した曲（上）が、マライアキャリー氏の楽曲（下）に酷似している例。譜面の赤い音符が一致している
:::

RIAAの最高法務責任者であるケン・ドロショウ氏も、「これらのケースは、大規模な著作権侵害に関する単純な事例です。SunoとUdioは、自社のサービスを合法かつ健全な基盤に乗せる代わりに、侵害の全貌を隠そうとしています。この訴訟は、AIシステムの責任ある開発を促進し、SunoとUdioの侵害行為を終わらせるために必要なものです」とコメントしている。

これに対しUdioは6月26日、X（旧Twitter）に{target=“_blank”}し、AI技術の使用に著作権で保護された作品を再現する意図はないと主張した。また、著作権侵害を防ぐためのフィルターを実装していると述べている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 26 Jun 2024 04:14:21 +0000</pubDate></item><item><title>演奏会出演辞退する高橋洋子氏「想い異なり、アーティストとして向き合えない」　生成AI画像使用に対し</title><link>https://ledge.ai/articles/ikeaniphil_singer_withdraws_from_concert_because_of_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

歌手の高橋洋子氏は、2024年7月10日開催予定の「池袋アニメーションフィルハーモニー第一回演奏会」への出演辞退することを6月19日、自身のSNSで{target=“_blank”}した。

出演辞退の理由は、同オーケストラがイベントのチラシやホームページに生成AIで作成した画像を使用していたことに起因するという。高橋氏は「運営の姿勢につきまして、高橋洋子の想いと異なり、アーティストとして向き合うことができない出来事がございました」と報告した。

!
:::small
画像の出典：{target=“_blank”}
:::

同じ日、池袋アニメーションフィルハーモニーの実行委員会もSNSの公式アカウントでこの事態について{target=“_blank”}し、「アニメ音楽に関わる立場として、こうした状況での出演は好ましくない」という高橋氏側の意見を受けての辞退であることを明らかにした。

そして「アニメを愛する楽団を名乗っているにもかかわらず、昨今の生成AIを取り巻く問題について自覚が足りなかったことを恥じております。また、作品に対する配慮、アニメやそれに関わるクリエイティブを愛する皆様の気持ちを汲み取れなかったことに気付き、実行委員一同深く反省しております」と謝罪した。

ポスターは手描きイラストに差し替えることを決定し、6月20日以降はポスターやWebサイトに掲載している画像をイラストレーターに依頼した手描きイラストに差し替えた。また、チケットを既に購入した方にはキャンセル・返金対応を行うと発表した。
## 事態の発端
池袋アニメフィルのポスターには、生成AIによる画像が使用されているとの指摘がインターネット上で広まり、アニメ専門オーケストラが生成AI画像を使うことに対する批判が高まった。実行委員会は6月19日に公式声明を発表し、ポスターを手描きイラストに差し替えることを決定。
## 実行委員会の対応
代表の松下洋氏は、生成AI画像を意図して使用したわけではなく、商用利用可能な画像素材からデザインを選んだ際に「AI生成」のタグを見落としたと説明した。実行委員会は「生成AIを取り巻く問題について自覚が足りなかったことを恥じている」とし、今後はより一層の注意を払うと述べた。

## 高橋洋子氏の辞退
この問題を受け、ゲスト出演予定だった歌手の高橋洋子氏は、運営の姿勢に対する違和感から出演を辞退した。同氏は、人気アニメ「新世紀エヴァンゲリオン」の主題歌「残酷な天使のテーゼ」などのヒット曲で知られている。

高橋氏の出演辞退のほか、同演奏家への企業による協賛辞退や、運営メンバーの実行委員会からの脱退および出演辞退などの影響が続いている。


:::box

:::
:::box

:::

</description><pubDate>Sat, 22 Jun 2024 12:16:37 +0000</pubDate></item></channel></rss>