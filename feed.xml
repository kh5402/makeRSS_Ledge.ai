<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Wed, 13 Dec 2023 06:18:25 +0000</lastBuildDate><item><title> KDDI社員1万人が利用できる「KDDI AI-Chat for Teams」を発表--Microsoft Teamsなどの既存プロダクトに生成AIを導入</title><link>https://ledge.ai/articles/kddi_ai_chat_for_teams</link><description>:::small
画像の出典：{target=“_blank”}
:::

KDDIアジャイル開発センター（KAG）は2023年12月6日、同社が利用する「Microsoft Teams」とスクラム開発のふりかえりサポートプロダクト「anycommu」の2つの既存プロダクトに生成AIを導入し、その価値を検証したと{target=“_blank”}した。


「KDDI AI-Chat for Teams」は、2023年5月にKDDI情報システム本部とKAG Generative AI Labが共同で開発した生成AIチャットサービスで、社員1万人規模での日常的な利用が可能とされている。このサービスは、Microsoft Teams上で安全に利用でき、アジャイル開発の知見を活かし短期間での開発が実現したという。

生成AIの導入により、KAG内部でMicrosoft Azureの実装知見を蓄積し、ブラウザ版アプリ用リソースの分離やセキュリティの強化など、開発のコツや後続の開発ノウハウを得られたとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::



「anycommu」には「AIスクラムマスター」機能が実装され、チーム内コミュニケーションの深化や思考促進を目的としている。この機能により、新たな視点からのフィードバックや問いかけが可能となり、チームメンバーの理解を深める助けとなっているという。

!
:::small
画像の出典：{target=“_blank”}
:::

現状ではコメントの的確性にムラがあり、精度向上のための開発が続けられている​​。
AIスクラムマスターの導入後、anycommuの利用チーム数は最大約3倍に増加し、サービスの活発な利用に貢献しているとのこと。



:::box

:::
:::box

:::</description><pubDate>Wed, 13 Dec 2023 06:18:25 +0000</pubDate></item><item><title>イーロン・マスクのAI「GrokAI（ベータ版）」が、Xプレミアムプラス米国会員向けに順次リリース　英語の次は日本語に対応予定
</title><link>https://ledge.ai/articles/grok_ai_for_x</link><description>:::small
画像の出典：{target=“_blank”}
:::

イーロン・マスク氏は2023年12月8日、自身のX（旧Twitter）公式アカウントで、米国のX プレミアムプラスサブスクライバー全員にGrok AI（ベータ版）を展開したことを{target=“_blank”}した。

はじめは色々と問題が起こるかもしれないが、日々、スピーディに改善を目指すと述べている。マスク氏はユーザーからのフィードバックを大いに歓迎する姿勢を示した。

このサービスは、まずは英語ユーザー全員に約1週間後に拡大される予定だという。そして、英語の次にユーザー数の多い日本語ユーザーへの展開が優先される。

全言語へは、2024年初頭までに対応することを目指しているという。


:::box

:::
:::box

:::
</description><pubDate>Tue, 12 Dec 2023 07:29:42 +0000</pubDate></item><item><title>Google独自開発のAI特化型チップ「Cloud TPU v5p」発表　LLMトレーニング速度は前世代の2.8倍　Geminiにも使用</title><link>https://ledge.ai/articles/google_cloud_tpu_v5p</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2023年12月6日、最新のAIアクセラレータ「Cloud TPU v5p」を{target=“_blank”}した。YouTube、Gmail、Google Maps、Google Play、AndroidなどのAI駆動製品の基盤となっていた従来のTPU技術が更に進化し、新型TPUはこれまでで最も強力でスケーラブル、柔軟性に富むという。同じ日に発表された、Googleの最新マルチモーダル生成AIモデル「Gemini」のトレーニングにも使用されていると同社は述べている。

Cloud TPU v5eの後継として登場したこの新型TPU v5pは、前世代のTPU v4に比べて、2倍以上のFLOPS（浮動小数点演算能力）と3倍の高帯域幅メモリ（HBM）を備えている。大規模言語モデル（LLM）のトレーニング速度はTPU v4の2.8倍、埋め込み密度の高いモデルのトレーニングは1.9倍の速さを実現するという。

!
:::small
画像の出典：{target=“_blank”}
:::

TPU v5pはTPU v4の4倍のスケーラビリティを持ち、シングルポッド内のチップ数も倍増しており、トレーニング速度の相対的なパフォーマンスが大幅に向上しているとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
</description><pubDate>Mon, 11 Dec 2023 02:57:17 +0000</pubDate></item><item><title>OpenAI「GPTs Store」開始延期、2024年初旬へ。「予期せぬ出来事あって遅れてしまった」</title><link>https://ledge.ai/articles/gpts_store_delayed_to_2024</link><description>:::small
画像の出典：OpenAIからのメール
:::

OpenAIは2023年12月2日、有料の顧客に宛てたメールで「GPTs Store」の開始を2024年初旬に延期すると発表した。

GPTs Storeは、ユーザーが特定の目的のためにカスタマイズされたChatGPTバージョンを作成し、公開することができる新しいプラットフォームだ。ユーザーは、ChatGPTとの会話を通して、作りたいGPTを作成でき、新たな指示や追加知識を与え、組み込むことができる。GPTs Storeは、当初2023年後半の公開を予定していたが、OpenAIのリーダーシップの変更など予期せぬ事項の対応により延期されたと述べている。

延期により現在ユーザーは、GPTを直接作成し共有することはできるものの、公開リストに掲載されたり、収益分配スキームに参加したりすることはできない。さらに、OpenAIは、アクションの設定インターフェースの更新やワンクリックテストの有効化など、GPTの利便性向上のための改善を実施した。また、Code Interpreterを使用する際のセキュリティ対策として、アップロードされたファイルがダウンロード可能になる問題に対応し、標準でこの機能をオフに設定することを決定。
同社は、GPT開発にかける時間と労力に感謝するとともに、さらなるフィードバックを求める姿勢を示している。


:::box

:::
:::box

:::</description><pubDate>Mon, 11 Dec 2023 02:43:04 +0000</pubDate></item><item><title>NVIDIA、対中輸出規制に準拠対した中国向け GPU「GeForce RTX 4090 D」を開発中か</title><link>https://ledge.ai/articles/nvidia_gpu_rtx4090_d</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::
NVIDIAは、中国市場専用となる新しいゲーム用GPU「GeForce RTX 4090 D」の開発を進めていると{target=“_blank”}が2023年11月29日に報じている。

米国の輸出ポリシーに完全に準拠するため、TPP（Total Processing Performance）レーティングが低めに設定されており、中国で輸出禁止となった既存のGeForce RTX 4090の代替品として提供される予定だという（製品名の「D」は恐らく来年の干支「辰年（Dragon）」が由来）。

新しいRTX 4090Dは、ゲームパフォーマンスとAI向けの能力が標準の「GeForce RTX 4090」と比べやや劣るが、AI機能に関するソフトウェア機能レベルのサポートは維持される見込み。NVIDIAは、中国のAICパートナーを通じてRTX 4090 Dを提供予定。また、2024年初頭に中国向けのAI特化GPUの発表が予定されているとのこと。​

:::box

:::
:::box

:::</description><pubDate>Fri, 08 Dec 2023 16:17:11 +0000</pubDate></item><item><title>オルツ　AIクローンの活躍に応じて社員に給与を追加支給、世界初の試み</title><link>https://ledge.ai/articles/alts_ai_clone</link><description>:::small
画像の出典：{target=“_blank”}
:::

オルツは2023年12月7日、社員のAIクローンに対して給与を支給するシステムを導入したことを{target=“_blank”}した。

同社はP.A.I.®️（パーソナル人工知能）とAIクローン技術の開発を行っており、社員一人ひとりが自己のAIクローンを生成している。このクローンは、日々の業務や情報共有をAIに代替させることで、業務の持続性や生産性を向上させ、人間にしかできない仕事に社員が集中できるようになる。

クローンの活動量に応じた給与システムを導入し、社員一人ひとりが能力を最大限に発揮できる環境を整備することで、社会に新しい価値を提供することを目指している​と同社は述べる。

!
:::small
画像の出典：alt](https://alt.ai/news/news-2408/){target=“_blank”}
:::


@
:::small
{target=“_blank”}
:::

:::box

:::
:::box
</description><pubDate>Fri, 08 Dec 2023 15:11:12 +0000</pubDate></item><item><title>Google、最新マルチモーダル生成AIモデル「Gemini」ついに発表　Bard、Google検索、Pixel 8 Proなどへ続々展開</title><link>https://ledge.ai/articles/google_deepmind_gemini_release</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Googleは2023年12月6日、新たなAIモデル「Gemini」を{target=“_blank”}した。

5月にGoogleが開催した開発者会議「Google I/O」でその存在が明らかにされた「Gemini」は、ChatGPT超えの生成AIとして今秋には公開されるだろうと噂されていた。このモデルは、同社がこれまでに取り組んだ最大規模の科学技術プロジェクトの一環として開発された。

「Gemini 1.0」は、「Ultra」「Pro」「Nano」の異なるサイズで最適化されており、多様なベンチマークで最先端のパフォーマンスを実現している。テキスト、コード、オーディオ、画像、ビデオなど、異なるタイプの情報を一般化し、シームレスに理解・操作するマルチモーダルなモデルだ。以下の動画では、Geminiが音声と動画のコンテキストを理解することが分かる。

@

Geminiは、データセンターからモバイルデバイスまで、幅広いプラットフォームで効率的に動作する柔軟性を備えている。大規模言語モデル（LLM）研究開発で使用される32の学術ベンチマークのうち30において、人間の専門家を上回る90.0%のスコアを達成しており、マルチモーダルタスクを含むさまざまな分野で最先端の成果を上げている。

また、Geminiはより安全で包括的なAIモデルとなることを目指している。開発ではバイアスや有害性に関する徹底した安全評価が行われており、コンテンツの安全性を確認するために、Real Toxicity Promptsなどのベンチマークが使用されている​。

今後同社はGeminiをさまざまな製品やプラットフォームでの展開を予定している。BardにはGemini Proのアップグレード版が導入され、Google検索エンジンではGeminiの効果を検証するテストが実施されている。さらに、Pixel 8 Proのスマートフォンでは、Gemini Nanoが新機能として組み込まれる予定。開発者や企業向けには、Google AI StudioやGoogle Cloud Vertex AIを通じてGemini Proが提供される計画だ。

BardはGemini Proの改良版を使用し、Googleの検索エンジンではGeminiのテストが進行中である。また、Gemini NanoはPixel 8 Proでの新機能に利用され、開発者や企業向けにはGoogle AI StudioやGoogle Cloud Vertex AIを通じてGemini Proが提供される。現在は英語のみ対応。


:::box

:::
:::box

:::</description><pubDate>Thu, 07 Dec 2023 09:04:41 +0000</pubDate></item><item><title>AWS、Amazon Bedrockの新機能発表。基盤モデルのファインチューニング、ガードレール機能など</title><link>https://ledge.ai/articles/amazon_bedrock_finetuning_guardrail</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月28日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて、開発プラットフォーム「Amazon Bedrock」の新機能を{target=“_blank”}した。

## 「Llama 2」「Cohere Command Light」などのAIモデルがファインチューニング可能に

Amazon Bedrockが、Meta Llama 2、Cohere Command Light、Amazon Titan Text Lite、Amazon Titan Text Expressなどの基盤モデル（FM）の{target=“_blank”}をサポートするようになった。ユーザーが、自身のラベル付けされたデータセットを使用して特定のタスクのためにモデルの精度を向上できる。

このプロセスでは、モデルのパラメーターを調整して、特定のビジネスに合わせた出力を生成する。これらのパラメーターはモデルがトレーニング中に学んだ内容を表し、それを調整することで、組織のコンテキスト内での意思決定をより洗練させることができる。

Amazon S3に少量のラベル付き例を使用することで、大量のデータを注釈することなくモデルのファインチューニングが可能。Bedrockは基盤モデルの別のコピーを作成し、このプライベートなコピーをトレーニングする。ユーザーのコンテンツは元の基盤モデルのトレーニングには使用されない。

これらのモデルは現在、米国東部（ノースバージニア）および米国西部（オレゴン）のAWSリージョンでAmazon Bedrock上でファインチューニングが可能だ。

## ガードレール機能「Guardrails for Amazon Bedrock」を公開
発表ではまた、責任あるAIポリシーに基づいたセーフガードを実装する{target=“_blank”}についても触れた。

これは、アプリケーション要件と責任あるAIポリシーにカスタマイズされたセーフガードを実装し、すべてのアプリケーションでAIの安全性を一貫して提供する。Anthropic Claude、Meta Llama 2、Cohere Command、AI21 Labs Jurassic、Amazon Titan Text などの 基盤モデル（FM） やファインチューニングされたモデルに適用できる。

ユーザーは、それぞれが異なるコントロールの組み合わせで構成された複数のガードレールを作成し 、これらのガードレールをさまざまなアプリケーションやユースケースで使用可能だ。ガードレールを Agents for Amazon Bedrock と統合して、責任ある AI ポリシーに合わせた生成 AI アプリケーションを構築することもできるとのこと。

Amazon Bedrockのガードレールを使用して、アプリケーションの文脈で避けるべきトピックのセットを自然言語の説明で定義することができる。例えば、銀行アシスタントは、投資アドバイスに関連するトピックを避けるように設計できる​​。

さらに、責任あるAIポリシーに基づき、有害なコンテンツをフィルタリングが可能。憎悪、侮辱、性的、暴力などのカテゴリにわたるコンテンツフィルターが含まれ、これらのカテゴリにわたって有害なインタラクションをフィルタリングするための閾値を設定できる。例えば、eコマースサイトは、オンラインアシスタントが憎悪表現や侮辱などの不適切な言葉を使わないように設計できる​​。

近日公開の機能として、Guardrails for Amazon Bedrock を使用すると、ユーザー入力および FM 応答内の個人識別情報 (PII) の検出ができるようになるという。ユースケースに基づいて、PII を含む入力を選択的に拒否したり、FM 応答内の PII を編集したりが可能。たとえば、コールセンターで顧客とエージェントの会話記録から概要を生成する際に、ユーザーの個人情報を編集できるとのことだ。


:::box

:::
:::box

:::</description><pubDate>Wed, 06 Dec 2023 11:37:06 +0000</pubDate></item><item><title>オンラインゲームやミーティング中に食べてもバレない？「DORITOS SILENT」咀嚼音をAIが狙って消音</title><link>https://ledge.ai/articles/pepsico_doritos_silent</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

米国ペプシコは2023年11月1日、同社のお菓子ブランド「フリトレー」の商品にちなんだソフトウエア「Doritos Silent」を{target=“_blank”}した。

@
:::small
{target=“_blank”}
:::

「Doritos Silent」は、PCゲーマーが他のプレイヤーを邪魔せずにお気に入りのチップスを楽しむことを可能にする画期的な「クランチ（咀嚼音）キャンセル」技術だ。開発に6ヶ月を費やし、AIは5,000種類以上の異なるクランチ音でトレーニングを受けた。

調査によると、85%のゲーマーがドリトスをスナックとして選んでいるが、ゲーミング中のクランチ音を消す革新的な解決策に対する需要が世界中で高まっているという​​。ドリトスのクランチは消費者が愛する重要な理由であり、この新技術により、他のプレイヤーのパフォーマンスを妨げることなくクランチを楽しむことができる。

同社のグローバルマーケティングヘッド、フェルナンド・カハネ氏は「ドリトスのファンとゲーミングコミュニティとの繋がりは否定できない。両者は大胆かつ堂々と自分たちの個性を披露している。Doritos Silentはこの絆を認識し、ドリトスを選ぶゲーマーの体験を向上させるためのブランドの継続的な革新へのコミットメントを示している」と語った。


:::box

:::
:::box

:::</description><pubDate>Wed, 06 Dec 2023 08:37:26 +0000</pubDate></item><item><title>AWSのビジネス向けAIアシスタント「Amazon Q」公開　ユーザーあたり月額20ドルから</title><link>https://ledge.ai/articles/amazon_bedrock_amazonq</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月28日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて、ビジネス向けAIアシスタント「Amazon Q」を{target=“_blank”}{target=“_blank”}した。

Amazon Qは、企業のニーズに応じて設計されたAIアシスタントで、企業のシステム、データリポジトリ、運用への理解に基づき、自然言語インタラクションを通じて迅速に質問に答え、タスクの効率化、意思決定の迅速化をサポートする​​。セキュリティとプライバシーを重視し、企業顧客の既存のアイデンティティ、役割、権限を尊重し、Amazon Qは企業顧客のコンテンツをモデルトレーニングに使用しない。

AWS上でのアプリケーションとワークロードの構築、展開、運用に関するAWSの知識と経験を基にトレーニングされており、開発者とIT専門家がAWSの機能を最大限に活用し、アプリケーションのアーキテクチャ、トラブルシューティング、最適化を支援するという。

また、Amazon Qは、40以上の一般的な企業システムに接続でき、従業員が役割に応じた詳細かつ正確な回答を得ることができるという。マーケターやプロジェクトマネージャー、セールス担当者などが、問題解決、コンテンツ生成、アクションの実行などに使用できる​​。

このシステムは、開発者が新機能を迅速に開発し、アプリケーションの保守とアップグレードを簡素化するための強力な機能を提供します。Amazon Qは、Amazon QuickSight、Amazon Connect、AWS Supply Chainなど、多くのサービスとアプリケーションで利用できます。


プレビュー版が{target=“_blank”}で公開中。ユーザーあたり月額20ドルからの提供となる。


:::box

:::
:::box

:::</description><pubDate>Wed, 06 Dec 2023 03:15:55 +0000</pubDate></item><item><title>Amazon ２つの画像生成AIを発表　電子透かしで誤情報拡散を防ぐ</title><link>https://ledge.ai/articles/amazon_bedrock_titan_image_generator</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月29日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて、Amazon Titan Image Generator と Amazon Titan Multimodal Embeddings という 2 つの新しいマルチモーダル基盤モデルを{target=“_blank”}した。

「Amazon Titan Image Generator」は、英語の自然言語プロンプトを使って迅速に画像を生成・改良することが可能で、広告、電子商取引、メディア・エンターテインメント分野の企業がスタジオ品質のリアルな画像を大量かつ低コストで作成できる。画像の自動編集や、画像マスクを用いたインペイント、背景の拡張・変更などの機能も備えている​​。

Amazon Titan Image Generatorは、見えない電子透かしをすべての画像に追加している。この透かしは、AIによって生成された画像を識別するための手段の1つとし、誤情報の拡散を防ぐことで、Amazonの責任あるAI使用への取り組みを強調している。また、この電子透かしには、改ざん耐性があるとされており、AIによって生成された誤情報の拡散を緩和するための試みとして機能するとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

「Amazon Titan Multimodal Embeddings」は、テキストと画像の組み合わせを入力として受け入れ、意味的意味とデータ間の関係を捉えるエンベディングを生成する。つまり、データの深い意味合いや、それらがどのように関連しているかを理解して、それを数値のベクトルとして表現する。

このモデルは検索やおすすめのシステムの精度とスピードを向上させるためなどに役立てられる。例えば「What works well with my sofa?（私のソファに合うものは？）」と問うと、ソファの周辺に置くためのお勧めの小物が表示される。

!
:::small
画像の出典：{target=“_blank”}
:::

Titan Image Generatorは現在パブリックプレビュー版として提供されており、AWSのアメリカ東部（バージニア北部）およびアメリカ西部（オレゴン）のリージョンで利用可能。


:::box

:::
:::box

:::</description><pubDate>Tue, 05 Dec 2023 14:15:27 +0000</pubDate></item><item><title>アイリスオーヤマ、DX清掃ロボット「BROIT」を発売 - 自社工場製造で新たな時代へ</title><link>https://ledge.ai/articles/irisohyama_broit</link><description>:::small
画像の出典：{target=“_blank”}
:::

アイリスオーヤマは2023年11月7日、法人向けDX清掃ロボット「BROIT（ブロイト）」の発売を{target=“_blank”}した。製品は同社の大連工場（中国・遼寧省）で製造される初の自社製品で、2024年半ばに市場投入される予定。

「BROIT」は自律走行型で、水拭き清掃に特化した設計となっており、商業施設や介護・医療施設などでの使用に最適化されている。

高齢化や多様化を見据え、作業者が誰でも使いやすいように「操作性」を重視。ルート作成は簡単な3ステップで完了する。清掃現場の多くは、エリアに応じて作業時間が決まっているため、事前のルート作成により清掃計画に沿って正確に清掃可能だという。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::</description><pubDate>Fri, 01 Dec 2023 11:02:05 +0000</pubDate></item><item><title>ノーコード推進協会　ノーコード人材を定義する新たな認定制度「NCPA認定ノーコードパスポート」を開始</title><link>https://ledge.ai/articles/nocode_passport</link><description>:::small
画像の出典：{target=“_blank”}
:::

ノーコード推進協会は2023年11月27日、ノーコード人材育成と適切な理解の普及を目的とした「NCPA認定ノーコードパスポート」の提供開始を{target=“_blank”}した。

同協会は2023年11月1日に一般社団法人化し、ノーコードツールの活用に必要な知識やスキルを証明するこの認定制度を導入している。これにより、IT未経験者も段階的にノーコードスキルを身に付けることが可能となる。

ノーコードパスポートは、ノーコードスキル要素とレベルを設定し、3段階の資格で構成されている。2024年1月より、最初の段階である「NCPA認定ノーコードパスポート サファイア」を開始する予定。試験運営はデータミックス社の「Excert」システムを採用し、初年度の目標受験者数は1,000名とのこと。
詳細ページ：{target=“_blank”}


!
:::small
画像の出典：{target=“_blank”}
:::
 試験詳細は、2024年1月にNCPAのWebサイトにて公開予定


:::box

:::
:::box

:::</description><pubDate>Mon, 27 Nov 2023 03:06:40 +0000</pubDate></item><item><title>無料で機械学習が学べるコンテンツ＋α 特集 2023年・秋版</title><link>https://ledge.ai/articles/free-learning-Autumn</link><description>:::small
画像の出典：Adobe Fireflyでプロンプト[秋にプログラムの勉強をする猫]で生成
:::

近年、人工知能（AI）業界は急速に進化し、機械学習を活用したサービスが登場している。すでに「ChatGPT」や「Microsoft 365 Copilot」などが企業や大学、官公庁の業務効率向上に導入がされており、そのメリットとデメリットを慎重に検討しながら利用されている。使用するデメリットとして、これらのAI・機械学習サービスは情報流出などの予測外のリスクも考慮しなければならない。AI開発者だけでなく、利用者自身も機械学習の基本的な理解を持ち、AIを安全に活用することがこれからの時代に重要なリテラシーだ。

AI開発には特に「Python（パイソン）」というプログラミング言語が注目されている。Pythonは機械学習の開発に広く用いられ、使いやすさと豊富なライブラリが人気の理由である。

幸いインターネット上には、無料で機械学習を学べる多くのコンテンツが存在する。活用すれば個人の仕事や研究にAIを活用することはもちろん、企業や大学のIT担当者として組織の業務全体に必要なAIを選んで導入したり、目的に合わせたAIの開発まで可能になる。

学問に王道は存在しないが、本稿では代表的なオンライン学習サイトを紹介し、それらをどのような順番で利用すべきかを、計画的かつ合理的に解説する。

:::box
**目次**

- **機械学習の学習ロードマップ**
まずは「機械学習基礎」と「Python」を学ぶ  
- 「Aidemy Free」はプログラミング初心者におすすめ
- 「Chainer Tutorial」はプログラミング経験者向き
- 東大「Pythonプログラミング入門」は一度挫折した人にぴったり
- 東工大 「Python早見帳」「機械学習帳」で回帰・分類・教師なし学習に挑戦
- **専門分野「自然言語処理」「コンピュータビジョン」等を学ぶ**
- 「JMOOC」で数学から「データ分析」を学びたい方に
- 「データサイエンススクール」は総務省 統計局が提供する社会人向け講座
- 「Scikit-learn公式ユーザーガイド」は「データ分析」のタスクに必要な部分だけ学べる
- 「キカガク」は無料で「画像認識」「自然言語処理」に必須のライブラリを学べる
- **有料で学習しやすいコンテンツもチェック**
- Udemy  　学びたい人、教えたい人のためのオンラインのマーケットプレイス
- Cousera    修了証明書や専門職資格が取得できるオンライン大学
- PyQ　　　技術本一冊分で学べる機械学習
- Aidemy premium　3ヶ月でAI人材に！Python特化型プログラミングスクール
:::

## 機械学習の学習ロードマップ
無計画で機械学習の学習を進めることは困難である。また計画しようにも何から手をつければいいかわからず、計画段階で心が折れてしまうこともある。

自身の目標や必要な知識を明確にすること、そして学習の進め方を計画することが効率的な学習に重要だ。計画の参考になるよう、以下に学習のロードマップの一例を示す。
!
**0.目標の確認**
はじめに目標を確認し、目的に必要な知識をリサーチすることをすすめる。
膨大な学習を効率化するために重要な項目である。

**1.数学の基礎**
数学（微積・線形代数）の基礎知識があると、機械学習の学習をスムーズに進めることができる。例えばPythonの数値計算ライブラリである「NumPy」を使用する際、線形代数の行列という概念を理解していれば素早く理解できることがある。またデータ分析に役立つ機械学習ライブラリ「scikit-Learn」を学ぶ際には、アルゴリズムの背後にある原理を理解するために微分積分の知識が役立つこともある。

このような数学の知識は、機械学習の理解を深める上で大いに役立つが、あくまで機械学習の基本をより強固にするものである。自身のスキルや目標に合わせて、必要な数学の部分から学んでも良い。

**2.機械学習の基礎**
Pythonの文法と機械学習に必須の３種類のライブラリ「NumPy」「Matplotlib」「Pandas」から学ぶことをおすすめする。

:::box
**ライブラリとは**
「NumPy」「Matplotlib」「Pandas」はPythonのライブラリである。
ライブラリはある特定の機能を、短い記述で実行するための関数の集まりである。
例えば「Matplotlib」はグラフを表示するためのライブラリで、簡単にグラフの種類や、文字の色の変更などを行える。
:::

**3.プログラムの基礎**
機械学習の基本的な概念（教師あり学習、ディープラーニング、強化学習）を学び全体像を掴んでおくことも専門的なタスクを実行するとき、理解への助けになるはずだ。

**4.専門的な学習**
 続いてタスク別の分野「画像認識」「データ分析」「自然言語処理」など、自分が興味のある専門分野を選び、実装を目指す。さらにそれぞれの基本的な概念やライブラリを学習する必要があるためどれか一つに絞ることが得策だ。

本記事ではそれぞれの学習段階を意識して無料で学べるコンテンツを紹介する。


## 完全無料で「Python」と「機械学習の基礎」が学べるコンテンツ
 まずは「2.機械学習の基礎」「3.プログラムの基礎」が無料で学べるコンテンツ紹介。機械学習のためにPythonを使うことが意識された教材を厳選した。

### **プログラミング初心者おすすめ**

:::box
情報の充実度★★☆　わかりやすさ　★★★   　学習スタイル　テキスト+動画＋テスト　完全無料
:::
**学べる内容**
Python、機械学習の基礎、ディープラーニング基礎
!

Aidemy Freeは一度もプログラミングをしたことがない人にもすすめられる。

Aidemy FreeはPythonの実行環境をサイトに搭載しており、環境開発要らずで学習を始めることができる。また各章にテストがあるため、初心者でも着実に学習を進めることが可能だ。完全無料で「Python入門」や「はじめてのAI」「機械学習概論」「ディープラーニング基礎」などのコースを選択することできる。

「機械学習とは？」という全体像を掴むことができ、学習のスタート地点に最適。

### 

:::box
情報の充実度★★★　わかりやすさ　★★☆  学習スタイル  テキストのみ　完全無料
:::
**学べる内容**
Python(NumPy、Matplotlib、Pandas)、数学基礎 、データ分析入門(scikit-learn)
ディープラーニング(Chainer)
!
Chainer Tutorialは「Python以外のプログラム経験がある人」、「数学を復習したい人」にすすめる。

Chainer Tutorialは機械学習の理解への助けとなる数学の解説からはじまり、ディープラーニング実装まで学習できる非常に丁寧な解説かつ情報量の多い完全無料のテキストである。

PythonライブラリのNumPy、Matplotlib、Pandasやデータ分析ライブラリのscikit-learnを詳しく学ぶことができる。自分の力で読み進めてゆける人には最適な教材だ。

### **東京大学 数理**・**情報教育研究センター** 「」

:::box
情報の充実度★★★　わかりやすさ　★★☆  学習スタイル  テキストのみ　完全無料
:::
**学べる内容**
Python(NumPy、Matplotlib、Pandas)、データ分析入門(scikit-learn)、Colaboratory
Jupyter Notebook
!

東京大学 数理・情報教育研究センターの「Pythonプログラミング入門」は実行環境の開発に挫折した人にすすめる。

「Pythonプログラミング入門」はオンライン実行環境であるColaboratoryやJupyter Notebookの使い方が解説されており、簡単に実行環境を用意できる。微分や線形代数を理解していればPythonライブラリのNumPy、Matplotlib、Pandasやデータ分析ライブラリのscikit-learnをスムーズに学習できる。

ただし「機械学習とは？」という全体像を掴むことに適した教材ではないので、そちらは別に学ぶとよいだろう。


### **東京工業大学　岡崎 直観教授** 「」＆「」

:::box
情報の充実度★★★　わかりやすさ　★★☆  学習スタイル  テキストのみ　完全無料
:::
**学べる内容**
Python(NumPy、Matplotlib)、機械学習 (回帰・分類・教師なし学習)
!

東京工業大学　岡崎 直観教授の「Python早見帳」＆「機械学習帳」は機械学習の回帰・分類・教師なし学習を学びたい人にすすめる。

 「機械学習帳」ではイラストを交えながら理論とPythonによる実装をセットで解説が行われており、実際にプログラムの動きを見ながら学習することができる。

## 機械学習の専門分野が無料で学べるコンテンツ

続いて「**4.専門的な学習ができるコンテンツ**」を紹介する。

機械学習には「データ分析」「自然言語処理」「コンピュータビジョン」「ディープラーニング」など様々な専門分野が存在する。以下ではタスク別で、学習コンテンツを紹介する。

!


### **オンライン大学講座のプラットフォーム** 
!
:::box
学習できる内容： 「数学」「データ分析」「機械学習の概要」など
:::
:::small
※上記の学習できる内容は、科目の開講時期によって異なる。
:::
JMOOCは「オンラインで公開された無料の講座を受講し、修了条件を満たすと修了証が取得できる」MOOC（MOOCs）という教育サービスの日本版である。

開講科目は時期によって変更されるが、2023年9月現在は滋賀大学「データサイエンス」早稲田大学「機械学習」、明治大学「線形代数」など様々な講義を無料で受講することが可能だ。

### 
!
:::box
学習できる内容:「 データ分析(理論)」
:::
総務省 統計局が提供する無料のオンライン学習サイトである。統計力向上を目的とした講座で、「社会人のためのデータサイエンス入門」ではデータサイエンスの必要性からビジネスにおける事例と手法を学習することができる。またExcleやR言語を使った演習も体験できる。


###  
!
:::box
学習できる内容: 「データ分析(実装)」
:::
scikt-learnは特に「データ分析」で有効なPythonのライブラリである。scikt-leranのユーザーガイドではモデルごとの実装例と手法が詳しく解説されているため、自分のタスクに必要な部分だけを学習することが可能である。目的が既にあり、統計分野の知識があるかたはこの公式サイトで十分かもしれない。

### 

!
:::box
学習できる内容: 「画像処理」「自然言語処理」「ディープラーニング」の基礎
:::
「画像処理」「自然言語処理」「ディープラーニング」の実装に必要な「TensorFlow」や「PyTorch」を登録なしで、無料で学習することができる。またサイトに登録すれば無料で
「Python&amp;機械学習入門コース」 や 「脱ブラックボックスコース 」を利用できる。

また有料版ではサポート付きの長期コースや、買い切りのオンライン学習コンテンツを選択することができる。


## 有料で学習しやすいコンテンツ

###  「**学びたい人、教えたい人のためのオンラインのマーケットプレイス**」
「」
!
:::box
学習できる内容: 「データ分析」「画像処理」「自然言語処理」「ディープラーニング」など
価格: 1000円~50000円
:::
Udemyはオンライン上で教材の販売、購入が行えるプラットフォームである。
販売されている教材はユーザーレビューが確認できるため、質の高い最新の教材を選択することができる。以上はデータ分析に関する人気教材の例である。

### 「**修了証明書や専門職資格が取得できるオンライン大学**」
「」
:::box
学習できる内容: 「データ分析」「画像処理」「自然言語処理」「ディープラーニング」など
料金: 月額4714~6946円   
:::
Courseraは、多くの有名な大学や教育機関と提携しており、さまざまな分野のオンラインコースを提供している。Courseraでコースを修了すると、修了証明書や専門職資格（Specialization）、学位プログラム（Master's degree、Bachelor's degreeなど）を取得できる場合がある。
これらの証明書や学位は、職業的なスキルの向上やキャリアの発展に役立たせることが可能である。

Courseraは多言語に対応しているが日本語に対応しているコンテンツが少ないため、英語での学習にストレスがない方におすすめする。以上はデータサイエンスに関する人気教材の例である。

### 
!
:::box
学習できる内容: 「データ分析」「ディープラーニング」など
料金: 月額3040円
:::
PyQではブラウザでPythonを実行することができる。これにより、教材を読む→コードを書く→実際に動かすという流れを画面内で完結できる。PyQでの学習は、数個の問題からなる「クエスト」という単位で進む。 600クエスト・1500問以上存在するすべてのクエストは、好きな順に学び放題だ。楽しみながら学習したい人にすすめる。

### 
:::box
学習できる内容: 「データ分析」「画像処理」「自然言語処理」「ディープラーニング」など
料金：528,000円~
:::
Python特化型プログラミングスクールである。未経験から3ヶ月でAI人材を目指すことを目標にしており、短期間で学習を進めることができる。さらに専門知識のあるメンターからサポートを受けることができる。質問をできる環境が欲しい人向きだ。




</description><pubDate>Thu, 28 Sep 2023 06:18:09 +0000</pubDate></item><item><title>Hugging Face(ハギングフェイス)とは｜AI特化版GitHubを手がける成長企業　概要と使い方を解説</title><link>https://ledge.ai/articles/The-Al-community</link><description>
AIについてインターネット検索していると、Hugging FaceというWebサイトにたどり着いたことがあるはずだ。ニコっしながら手を広げている黄色い絵文字が印象的だ。
!
一見するとユーモラスだが、実はAI開発の最先端を行く成長中の企業のものだ。開発者だけでなく、利用者にとってもきわめて重要なサービスを手掛けており、概要をあらためて把握しておこう。一般向けの用語解説もあるので安心して読み進めてほしい。

:::box
目次
- Hugging Faceとは?
- Hugging Faceが提供するサービス
- Hugging Faceが開発した便利な4つのオープンソースライブラリ
- Hugging Face Hubの4つの機能
- Hugging Faceの各種料金プラン
:::

## Hugging Faceとは？

Hugging Face社はアメリカ合衆国で2016年に設立された、主に「AI開発・機械学習をサポートするツール」を開発する企業。ユーザー間の学習モデルやデータセットの共有、クラウド環境で簡単に実行できるデモ、それらを扱うための学習コンテンツまで多岐にわたるサービスを展開している。

2016年に当初はチャットボットを開発する企業として設立。2021年3月に4000万ドルの資金調達に成功し、2022年には時価総額20億ドルを超えるほど期待される企業となった。現在は主力事業としてAI開発・機械学習のためのプラットフォームの運営を行っている。2023年2月にはクラウドサービス大手「Amazon Web Services（AWS）」との提携を発表した。

## Hugging Faceが提供するサービス

Hugging Face社は大きく分けて2つのサービスを展開する。
- AI特化のプラットフォーム「Hugging Face Hub」の運営
- 自社でのオープンソースライブラリの開発

### **AI特化のプラットフォーム「Hugging Face Hub」の運営**

Hugging Face社が運営するWebサイト「Hugging Face Hub」はAI開発・機械学習のためのプラットフォーム。「学習済みモデルや学習用のデータセットの公開・ダウンロード」や「プログラムの共有とバージョン管理」を行うためのAI特化版GitHubのような機能を持っている。すでに開発プラットフォームとして名高い米国Microsoftの「GitHub」のような機能に加え、デモを実行できるクラウド実行機能を持つため、AIモデルの共有を迅速に行うことができます。これらのAI開発からAIモデルの実行・共有までのプロセスを効率化する、いわばGitHub+αな特徴が支持を広げている。

:::box
GitHub (ギットハブ) とは：プログラムのバージョン管理と共有を目的としたWebベースのプラットフォーム。Gitという分散バージョン管理システムをベースにしており、ソースコードの変更履歴を追跡し、チームメンバーや他の開発者との協力や共有を容易にする。
:::

### **オープンソースライブラリの開発**

Hugging Face社はオープンソースライブラリ群も開発、公開している。これらのライブラリをみずからの開発するプログラムに組み込むことで「Hugging Face Hub」で公開されている学習済みモデルやデータセットを、プログラム上で簡単に使用できる。

続いてHugging Face社のオープンソースライブラリやHugging Face Hubがなぜ便利なのか詳しく解説してゆく。

!

上記で水色の枠内に示すのはHugging Face社が開発した代表的な4つのオープンソースライブラリ。これらのオープンソースライブラリはHugging Face社が運営するAI開発プラットフォームHugging Face Hubの「Models」「Datasets」と連携してAI開発をサポートする。

さらに「Models」で公開している学習済みモデルは「Spaces」で簡単にデモアプリケーションを作成し公開することも可能。詳しくは以下で解説する。

## Hugging Faceが開発した便利な4つのオープンソースライブラリ

:::box
ライブラリ： ライブラリは、再利用可能なコードや機能の集まり。開発者はライブラリを使うことで、同じ機能を何度も書く必要がなくなる。既存のコードを活用することで、開発の効率性が向上する。またオープンソースのライブラリは他の開発者が作成したコードを自由に使用できる。これにより開発者同士の協力や共同開発が促進される。
:::

**Diffusers**
Diffusersは、画像生成のタスクに特化したライブラリ。主に画像生成、画像編集、データ拡張などのタスクに使用される。Hugging Face Hubで公開されている画像生成に関する学習済みモデルの呼び出しを簡単に行える。

また画像生成以外の音声認識や分子の3次元構造予測に至るまで様々なタスクにも対応する。事前に学習されたモデルが使用できることでコンピューティングコスト削減や、時間リソースの削減に繋がる。

**Transformers**
Transformersは、自然言語処理（NLP）のタスクに特化したライブラリ。主にモデルの構築、事前学習済みモデルのファインチューニング、文書分類、情報抽出などのNLPタスクに使うことができる。Diffusersと同様の機能を持ち、Hugging Face Hubで公開されているNLPに関する学習済みモデルの呼び出しに必要なライブラリ。

**Datasets**
DatasetsはHugging Face Hubで公開されている音声、画像、テキストなどの学習用データセットへのアクセスがシンプルなコードで行えるライブラリ。大規模なデータセットの前処理を効率的に行える。

**Tokenizer**
Tokenizerは自然言語処理におけるトークン化をシンプルなコードで行えるライブラリ。文章やフレーズを意味の一つのかたまりを示す「トークン」に分割できる。Tokenizerライブラリはさまざまなトークン化アルゴリズムを簡単に実行、かつ高速にデータセットをトークン化することが可能。



## Hugging Face Hubの4つの機能
Hugging Face Hubの特徴である「Models」「Datasets」「Spacies」「Docs」の4つの機能について解説する。

**Models**
Hugging Face HubのModelsは自然言語処理、画像認識、音声認識などのモデルを公開・検索することが可能。
!

このModelsにアップロードされているモデルはDiffusersやTransformersを使うことでパソコンにダウンロードすることなく簡単に使用できる。

Modelsへの理解を深めるため、実際に公開されているモデルを実行する。最もいいね数の多い画像生成AIのを実行して画像を生成する。

### **Modelsからモデルを使用する方法**

**STEP1**
のいいね数順で最上部に表示されている「runwayml/stable-diffusion-v1-5」をクリックする。クリックするとModel Card (モデルカード)が表示される。
!

Model Cardではモデルをアップロードしたユーザーがモデルの使い方や特徴、使用上の注意点を解説する。

**STEP2**
Model Cardに従い、まずはDiffusersとTransformersをインストールする。

```
# diffusers、transformersライブラリをインストール
!pip install diffusers transformers
```



次にModel Cardでモデルについてのコードをコピー＆ペーストして実行する。
```
# diffusers、transformersライブラリをインストール
from diffusers import StableDiffusionPipeline
import torch

## モデルを選択する
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)

# GPU(cuda)で処理を行う
pipe = pipe.to("cuda")

# プロンプト「火星で馬に乗る宇宙飛行士の写真」
prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]  

# 画像を保存する
image.save("astronaut_rides_horse.png")
```
ステップは以上。実行すると以下のような画像が出力された。

「a photo of an astronaut riding a horse on mars」の出力結果
!



DiffusersやTransformersを使うとシンプルなコードで、学習済みモデルを呼び出し、画像を生成することができる。また従来通りに**Files and Version**から学習済みモデルを自分のパソコンにダウンロードして使用することも可能。

**Datasets**
は自然言語処理、画像認識、音声認識に関するデータセットを検索するためのプラットフォームです。以下に示すのはデータセット「OpenOrca」。自然言語処理（NLP)に関するタスクに使用することができる。「OpenOrca」は膨大な容量のデータセットだが、Datasetsライブラリを使用することでダウンロードすることなくストリーミング使用できる。
!

Datasetsからデータセットを使用する方法

```
from datasets import load_dataset
# データセット内のインスタンス名
dataset = load_dataset("Open-Orca/OpenOrca")
```
以上の二行のみでデータセット「OpenOrca」を呼び出すことが可能。

**Spaces**
ではクラウド環境で機械学習モデルのデモを実行することができます。機械学習モデルの公開者はHugging Face社にGPUの使用料を支払うことでSpacesにデモを設置できる。そのためデモ利用者は無料で機械学習モデルを試すことが可能。

公開者がSpacesを設置する際は、機械学習モデルを簡単にWebアプリとして使用できるフレームワークのStreamlit、Gradio、Dockerなどに対応しているため開発に高度な専門知識を必要としない。
!

現在Spacesでは多くの企業、個人開発者が合計50000を超えるデモを公開している。今回はサイト内のトレンド上位(2023年7月)のを利用する。このデモではQRコードと指定したプロンプトから生成する画像を組み合わせ、QRコードアートを作成できる。

**Spacesのデモを実行**
クリックするとWebアプリが表示されます。デモの説明に従ってQRコードを作成する。
!
画像生成のためのプロンプトに「鉱脈で光る金」→「Gold shining in the veins」を入力し
QRコードのリンク先に当サイトを設定した。

**画像生成の結果**
!

絵とQRコードが組み合わされた画像が生成された。実際にこの画像をスマートフォンのカメラなどで読み込むと、「Ledge.ai」にアクセスできる。

このように簡単にデモを利用することができ、機械学習モデルの共有スピードが大幅に短縮されていることが実感できる。製品版の広告としても、チームへの開発段階の共有としても有効。

**Docs**
ではHugging Hubに関するライブラリや、上記で紹介したサイト内の機能を学ぶことができる学習コンテンツが公開されている。全てのコンテンツのチュートリアルから応用まで詳しく解説されているので、詳細は公式サイトを参照することをすすめる。なお公式サイトは全て英語表記のため翻訳ツールなどを駆使すると読みやすい。



## Hugging Faceの各種料金プラン

Hugging Face社はセキュリティの高いソースコード管理ツールのサブスクリプションやクラウド実行環境の使用料で利益を出し運営されている。

Hugging Faceの3つのアカウントプランとその他の有料コンテンツついて解説する。以下に示す料金は2023年7月版。料金プランと内容が変更されている場合がある。

:::box
**HF** **Hub** (**HF ハブ**)
- 個人向け
- 料金 完全無料
- モデルのダウンロード、ファインチューニング、共有ができる。
- コミュニティサポート: 質問や意見を送信することができる。
:::

:::box
**Pro Account** (**プロ アカウント**)
- 個人向け
- 料金 月額 9ドル
- 早期アクセス：新機能やベータ版に早期アクセスできる。
- Auto Train機能の学習制限量が緩和される。
- コミュニティサポート:無料アカウントよりも優先的なサポートが受けられる。
:::

:::box
 **Enterprise Hub** (**エンタープライズ ハブ**)
- 法人向け
- 料金　1人当たり月額 20ドル
- SSO及びSAMLのサポートが受けられる。
- エンタープライズ セキュリティ機能:監視とログ管理、アクセス制御が行える。
:::

### その他の有料コンテンツ
:::box
**Spaces Hardware**
クラウド環境で機械学習モデルを実行できるSpacesは無料でCPUを使用できるが、追加料金を支払うことでGPUにアップグレードすることができる。
- 料金  1時間あたり最低金額0.60ドルから最大4.13ドル(GPUの性能によって変動)
:::

:::box
**Inference Endpoints**
Hugging Face Hub上のNLPモデルを直接Inference Endpointsで簡単にデプロイできる。API/CLI を使用したプログラムによるエンドポイントの管理、モデルのロールバックなどが簡単に行える。
- 料金 1時間あたり最低金額0.06ドルから最大6.50ドル(GPUの性能によって変動)
:::

:::box
**Auto Train**
Auto Trainはノーコードで機械学習のモデルを学習、評価、デプロイすることができる。
料金プランによって学習制限量が変化する。
- HF Hub　　　　  画像タスク最大500枚     NLPの表形式のタスク3000行
- Pro Account        画像タスク最大1500枚   NLPの表形式のタスク5000行
上記以上の学習を行いたい場合以下の追加料金が発生する。
- 画像タスク1枚あたり0.002ドル  
- NLPの表形式のタスク1行あたり0.002ドル
:::

</description><pubDate>Tue, 26 Sep 2023 09:01:42 +0000</pubDate></item><item><title>うんこ先生と学ぶ「AIとのつきあい方」富士通が子ども向けドリルを無償公開</title><link>https://ledge.ai/articles/fujitsu_unkodrill_ai</link><description>:::small
画像出典：{target=“_blank”}より
:::
富士通は2023年9月6日、子ども向け学習ドリル「Fujitsu×うんこドリル AIとのつきあい方」の制作・公開を{target=“_blank”}した。

文響社が刊行する子ども向け学習ドリル「うんこドリル」は、子どもたちが勉強を楽しみながら進められるシリーズ。今回はAIとの付き合い方を楽しく、分かりやすく学べる教材を目指し、富士通が協力、制作した。

!

内容はというと、シリーズ定番キャラクターのうんこ先生が、うんこねこ、うんこいぬといった面々とAIに関して質疑応答しながら進んでゆく。新キャラクターらしきAI「UNKO」も登場し、さまざまな質問に回答するが、現実のChatGPTと同じくいい加減なところがあり、子どもにAIの利点だけでなく危険を意識させるしかけになっている。

ドリルの制作には、富士通研究所 人工知能研究所が携わり、神山学園 神山まるごと高等専門学校の学生たちのアイデアを取り入れた。PDF形式の教材を{target=“_blank”}で2024年8月31日まで公開予定。また希望する教育機関には冊子を無償提供する。

富士通の小学生向け教育支援プログラムやワークショップでも活用する。


:::box

:::
:::box

:::
:::box

:::</description><pubDate>Thu, 07 Sep 2023 06:53:36 +0000</pubDate></item><item><title>東商「中小企業のための『生成AI』活用入門ガイド」発行 - 基礎知識から活用プロンプト例まで</title><link>https://ledge.ai/articles/tokyo_cci_generative_ai_guide</link><description>:::small
画像の出典：東京商工会議所
:::
東京商工会議所の中小企業部は2023年7月28日、デジタルシフト・DX推進委員会の下「中小企業のための『生成AI』活用入門ガイド」を発行したと{target=“_blank”}した。

同所では、生成AIを探求するための研究会を設置し、中小企業における影響や活用方法についての議論を進めてきたという。5月の調査によれば、ChatGPTを含む生成AIを既に活用している企業は約6%であり、今後の活用を検討している企業を含めると3割以上となる。

このガイドでは、ChatGPTをはじめとする生成AIに関する最低限の知識、使用方法、個人情報や著作権の取り扱いに関する注意事項を解説。具体的な経営・業務を想定したプロンプト（入力内容）の例や、中小企業での活用事例も掲載している。

ガイドは{target=“_blank”}より無料でダウンロードできる。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Wed, 16 Aug 2023 03:54:30 +0000</pubDate></item><item><title>経産省 デジタル人材の育成指針に「生成AI」追加 「ITパスポート試験」に反映へ</title><link>https://ledge.ai/articles/meti_adds_generative_ai_to_dx_hr</link><description>:::small
画像はSDXL1.0によりLedge.aiが生成
:::
2023年8月7日、経済産業省は、デジタル時代の人材育成に関する新たな方針「生成AI時代のDX推進に必要な人材・スキルの考え方」を{target=“_blank”}した。

生成AI技術の急速な進化と変動性に対応するため、経産省は「アジャイル」なアプローチを採用。6月より開始した「デジタル時代の人材政策に関する検討会」での議論をもとに、生成AIを効果的に利用するための人材・スキルの在り方についての方針を取りまとめた。

生成AIが社会や企業にもたらすインパクト、デジタル人材育成やスキルへの影響、そして生成AI時代のDX推進に必要な人材・スキルの考え方について示している。

また情報処理推進機構（IPA）と連携し、ビジネスパーソンの学習や企業の教育、採用に役立つよう定めた指針「デジタルスキル標準（DSS）」の改訂、デジタルスキル教育のポータルサイト「マナビDX」への生成AI講座の追加、そして「情報処理技術者試験」の中の「ITパスポート試験」への生成AIに関連する内容の追加、といった政策対応を行う。

!
:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Tue, 15 Aug 2023 04:59:26 +0000</pubDate></item><item><title>【アーカイブ配信】生成AI時代における、エンタープライズAI開発の方法論とは？
#国内企業事例</title><link>https://ledge.ai/articles/webinar-vol56-archive</link><description>※本ウェビナーは7月27日開催のアーカイブ配信となります

## 生成AI時代のAI開発

ChatGPTやBardなど、生成AI、大規模言語モデル（LLM）に関するニュースを見ない日はない昨今。生成AI関連のサービスが続々生まれ、企業においても生成AIを業務に活用する動きが見られます。

生成AIの普及に伴い商用のLLMを利用したり、OSSのLLMを活用したり、自社モデルを作成したりとさまざまなアプローチがある中で、企業は自社に最適な活用方法を、ビジネスユースケースと照合しつつ、将来性やリスクを含めて検討していく必要があるでしょう。

一方で、LLMのトレーニングやファインチューニングには技術・コスト的課題も少なくありません。比較的少ないデータセットを用いつつ、サービスプロバイダへの依存度や方針変動に左右されにくいOSSによるLLMのファインチューニングを選択する企業もいます。その場合、AI開発現場では、

- 「学習に時間と手間がかかる」
- 「複数のAI開発者がそれぞれの学習リソースを保有しており効率が悪い」
- 「スケールしづらく、コラボレーションも発生しづらい」

など複数のデメリットが発生する可能性もあり、AIエンジニアやデータサイエンティストを悩ませています。

そこで本セッションでは、日本ヒューレット・パッカード合同会社 HPC Data&amp;AIソリューション事業統括本部AI BDM / プリセールスコンサルタント 山口 涼美氏をお招きし、生成AI時代におけるAI開発の勘所を語ります。
日本ヒューレット・パッカードとエヌビディア社は、開発者が短期間でAIを構築してハイパフォーマンスデータ分析を行えるように最適化されたエンタープライズプラットフォームを提供し企業のAI活用をサポートしています。

AIエンジニアやデータサイエンティスト、及びそのチームをリードしている立場の方々は、ぜひご視聴ください。

:::button
{target=“_blank”}
:::

## 登壇者
### 日本ヒューレット・パッカード合同会社 山口 涼美氏

!

2018年に日本ヒューレット・パッカード合同会社へ新卒入社し運用保守業務を経験後、AIビジネス推進を目的としたBU横断組織を立ち上げリーダーを務める。現在はHPC・AI系の製品部でAIビジネスデベロップメントマネージャー兼プリセールスコンサルタントとして活動している。趣味はバスケットボール。

### 株式会社レッジ 執行役員 箕部 和也(モデレーター)

!

インターネット広告代理店にてSNSを通じた企業と生活者のコミュニケーションデザインのプランニングに従事。その後オンラインのみではこれからのマーケティングに不十分であると感じIoT案件を多数手掛けるウフルに転籍。従来は取得できなかったフィジカル領域のビッグデータを活用したIoTビジネスのコンサルティングを行った。Ledge参画後は、AIをはじめとする先端技術を活用した自社内外の事業開発を推進している。

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai Webinar vol.56『生成AI時代における、エンタープライズAI開発の方法論とは？』
共催：日本ヒューレット・パッカード合同会社、エヌビディア合同会社
登壇者：
日本ヒューレット・パッカード合同会社 山口 涼美氏
株式会社レッジ 執行役員 箕部 和也(モデレーター)
参加費：無料

!</description><pubDate>Mon, 31 Jul 2023 08:08:30 +0000</pubDate></item><item><title>Stable Diffusionとは｜今からでも遅くない、使い方の基本と知っておくべきこと</title><link>https://ledge.ai/articles/stable_diffusion</link><description>短い文で簡単な指示をするだけで魔法のように美しい風景や、写実的な人物、かわいらしい動物を描き出す「画像生成AI」。その中でも代表的なもののひとつ「Stable Diffusion（ステーブルディフュージョン）」は急速な進歩を続け、2023年も注目を浴び続けている。

画像生成AIが学術研究の領域を超え、広告や娯楽などの産業分野で利用が進むなか、これから新たに学び始めたいという人も増えている。

この記事ではStable Diffusionの成り立ちから、使い方の基本、さらには意図通りの画像を生成する際に役立つ便利な「プロンプト（呪文）」まで紹介してゆく。また画像生成AIの著作権問題についても取り上げる。
:::box
**目次**
- Stable Diffusion（ステーブルディフュージョン）とは何か
- Stable Diffusionの利用方法・どのサービスが使いやすいか
  + 【超初心者向け】無料ですぐにStable Diffusion Onlineを使う方法
  + 【初心者向け】DreamStudioの使い方　
  + 【中級者向け】クラウド環境でStable Diffusion を使用する方法
- Stable Diffusionで使える便利なプロンプト・呪文集
- Stable Diffusionの著作権問題
- Stable Diffusionは今後どうなる？
:::
## Stable Diffusion（ステーブルディフュージョン）とは何か
!
:::small
Stable Diffusionで生成したスーツを着た男性
:::

上記の図はStable Diffusionに「プロンプト」と呼ばれる短いテキストで指示を出すことで生成した、スーツを着た男性の画像だ。

Stable Diffusion、それに「Midjourney」「DALL·E2」といった最近話題の画像生成AIの多くが、テキストによる指示から意図通りの画像を生成できる「t2i（text to image）」という機能を備えている。

このt2i機能によって、「Adobe Photoshop」「Adobe Illustator」などの画像編集アプリケーションを使いこなせるクリエイターでなくとも、高品質の画像を手軽に作り出せるようになった。

驚異の技術を実現したのが、2020年にカリフォルニア大学バークレー校の研究者らが発表した論文「Denoising Diffusion Probabilistic Models」にもとづく「拡散モデル（Diffusion Model）」と呼ばれる仕組み。あらゆる画像はノイズが加わってゆくといずれ完全なノイズになるが、逆にノイズを取り除いてゆけば画像があらわれるという発想から、ノイズを取り除く過程をAIに学習させ、その過程をテキストなどで制御し新たに画像を生成できるようにした。

!
:::small
出典：Denoising Diffusion Probabilistic Models
:::

Stable Diffusionは、Diffusion Modelの最も成功した応用例のひとつだ。ドイツのルートヴィヒ・マクシミリアン大学ミュンヘン（Munich University）の研究グループ「CompVis」が2021年に発表した論文「High-Resolution Image Synthesis with Latent Diffusion Models」などをもとに、英国Stability AIらが開発し、2022年にオープンソースで公開した。

以降、さまざまな企業がStable Diffusionを利用したサービスを立ち上げ、今やパソコンやインターネット環境さえあれば、誰にでも手が届くものとなった。

## Stable Diffusionの利用方法・どのサービスが使いやすいか？
Stable Diffusionの使用方法は大きく分けて以下の2種類がある。

- Stable Diffusionを搭載したWebサイトを利用する方法
- Stable Diffusionをパソコンのようなローカル環境またはクラウド環境で稼働させる方法

この記事では両方を解説してゆく。

まずは前者のStable Diffusionを搭載したWebサイトを紹介する。

|  サービス  |  価格  | 生成の自由度 | 使いやすさ | ログイン |
| ---- | ---- | ---- | ---- | ---- |
|  {target=“_blank”}  |  無料 |  △ |  ◯ | 不要 |
|  {target=“_blank”}  |  無料 |  ◯ |  ◯ | 不要 |
|  {target=“_blank”}  |  課金あり |  ◎ |  ◯ | 不要 |
|  {target=“_blank”}  |  課金あり |  ◎ |  ◎ | 必須 |

早速「超初心者向け」といえる「Stable Diffusion Online」で画像を生成してみよう。

### 【超初心者向け】Stable Diffusion Onlineを使う方法
{target=“_blank”}は、とにかく早くStable Diffusionを試してみたい場合に手ごろなサービス。アカウント登録は不要で、Webサイトにアクセスし画面をスクロールすると以下のようなテキストボックスがあらわれる。

!

テキストボックスにある[ Enter your prompt ]の部分に簡単なプロンプトを英語に翻訳して入力し、[Generate image]をクリックし10~30秒ほど待つと画像を生成できる。

:::box
プロンプト : 生成AIを使用する際に入力するテキストによる指示のこと。Stable Diffusionは、この指示の内容によって生成する画像の内容を変化させる。
:::

[雨が降る東京 東京タワー 美しい景色]→[Raining Tokyo Tokyo Tower Beautiful View]

!
:::small
[Prompt : Raining Tokyo Tokyo Tower Beautiful View]
:::

プロンプトの通り、雨が降る夜の東京タワーの美しい景色が描かれた高品質な画像を簡単に生成できた。注意点として、 再度 [Generate image] をクリックしても同じ画像は生成できず、別の画像を生成する。

なお、Stable Diffusion Onlineは手軽だが機能には制限がある。例えば生成する画像のサイズを指示したり、画像の中に出現させたくない特徴を指示するネガティブプロンプトなどを使用したりはできない。

そこで次節の「初心者向け」では、より多様な機能を備えたサービス「DreamStudio」を紹介する。

### 【初心者向け】DreamStudioの使い方　
{target=“_blank”}は、Stability AIが運営するサービス。アカウントを登録すると無料で25クレジットが配布され、それらを消費することで最大125枚程度の画像が生成できる。より多くの画像を生成したい場合は有料のクレジットを購入する必要がある。

!

使用を始めるにはまずGoogleアカウント、またはコミュニケーションアプリケーション「Discord」のアカウントで登録、ログインする。続いてテキストボックスにプロンプトを入力し、[Dream]ボタンをクリックすれば生成が始まる。

DreamStudioでは画像のサイズやStyle（画風）などさまざまな要素を指示できる。例として「夕焼け、富士山、海の美しい景色」を生成してみよう。プロンプトは英語で、「best high quality landscape, 4K, beautiful sunset, Fuji and the sea」と入力する。4Kと入力するだけで、4K画質のような画像が生成されるのが面白いところだ。

:::box
景色を生成するプロンプトのコツ：プロンプトは単語ごとにカンマ( , )と半角スペースで区切る。また上記のプロンプトでは構図の指示をしておらず、単語の並び順も不規則だが、実際は[品質]→[構図]→[被写体の種類]の順番で単語を入力する方がよい。
:::
!
:::small
Style Photographic
シード値 4109001454
モデル SDXL Beta   
Prompt: best high quality landscape, 4K, beautiful sunset, Fuji and the sea
画像のサイズは横長(3:2)に設定。
:::

#### **Styleの変更**
同じプロンプトで、Styleを変更してみよう。Enhance、AnimeといったStyleごとに、生成できる画像の雰囲気ががらりと変わる。

!

#### **ネガティブプロンプトの追加**
ネガティブプロンプトは、通常のプロンプトとは逆に、画像の中に出現させたくない特徴を指示するために用いる。

例えば左下の画像は前述のプロンプトでStyleをNeon pinkにして生成した画像だが、富士山にはそぐわないヤシの木が生えている。そこでネガティブプロンプトにヤシの木（palm tree）を追加し、通常のプロンプトに松の木（pine tree）を追加して、右下の画像を生成してみる。

!

この通りヤシの木が消えて、富士山に似合う松の木が生えている。

DreamStudioにはStyle、ネガティブプロンプトをはじめとして次のような機能がある。

!

#### **Basic**

|  名称  | 説明  |
| ---- | ---- |
| Style | 生成する画像の画風を16種類から選択できる。 |
| Prompt | 生成したい画像のプロンプトを入力する。 |
| Negative prompt  | 生成したい画像に入ってほしくない要素を入力する。例えば景色だけの画像を生成したい場合「human」と入力すると画像から人物を排除する。 |
| Upload image | 画像を入力すると画像を元にした新たな画像を生成する。また画像の入力後にあらわれる [Image Strength] という項目では、入力した画像が生成する画像に与える影響を0~100％の範囲で変更できる。 |
| Settings | 画像の比率を変更できる。画像サイズが大きくなると使用するクレジットも増加する。 |
| Image count | 生成する画像の数を変更できる。 |

#### **Advanced**

|  名称  | 説明  |
| ---- | ---- |
| Prompt strength | 入力したプロンプトへの忠実度を設定できる。 |
| Generation steps | 画像生成のStep数を設定できる。Step数を増やすとノイズの除去回数が多くなり、生成の質が上がるが時間がかかる。生成したい画像（イラスト、景色、人物等）に合わせて調整する。 |
| Seed  | シード値を設定できる。標準はランダム。シード値を固定すると同じ画像を生成できる。 |
| Model | 使用するStable Diffusionのバージョンを選択できる。それぞれ消費するクレジットが異なる。Stable Diffusion v2.1 (1枚当たり0.33クレジット）／Stable Diffusion v2.1-768 (1枚当たり1.51クレジット）／SDXL（StableDiffusion XL）（1枚当たり0.83クレジット） |

DreamStudioのようなWebサイトは便利だが、画像を生成しているうちにクレジットを使い切ってしまう場合がある。そこで次節「中級者向け」ではクラウド環境でStable Diffusionを使用する方法を紹介する。

### 【中級者向け】クラウド環境でStable Diffusion を使用する方法   
!
:::small
Stable Diffusionで生成したスーツを着た女性
:::

超初心者向け、初心者向けで紹介したWebサイトを使用しない場合、ローカル環境にGPUを搭載したパソコンを用意し、Stable Diffusionを動作させるか、またはインターネットを通じてGPUを搭載したサーバーを使えるクラウド環境を活かす方法がある。

ここではクラウド環境を活かす方法を取り上げる。Webブラウザ上からPythonプログラムを実行できるサービス「Google Colaboratory（Google Colab）」が手ごろだ。無料で約10時間程度までGPUを搭載したサーバーを使用できる。より自由度の高い有料版も選べる。

さらにソフトウエア開発プラットフォーム「GitHub」上で有志が公開している以下のツールを組み合わせると、より簡単な手順で作業を進められる。

- Stable Diffusion web UI（{target=“_blank”}氏作成）
- ChilloutMix（{target=“_blank”}氏作成）

これらを簡単に扱えるよう、{target=“_blank”}氏がGitHubで公開しているPythonプログラムのソースコードを使用するのも一案だ。

Google Colabolatoryからソースコードにアクセスできるようにしてみた。{target=“_blank”}をクリックすると以下のような画面があらわれるはずだ。

!

矢印が示す再生ボタンをクリックすることですぐにソースコードを実行できる。7~10分ほどで以下のようにURLがあらわれる。

!

URLをクリックすると、以下のような画面が展開する。

!

これで準備が完了し、クラウド上で画像の生成が可能になる。

注意点として、再生ボタンをクリックした後は常にGoogle Colaboratory上でGPUを使用している状態になる。 使用時間を節約するためには、画像を生成していない場合はセッションを切断しておく方がよいだろう。

さて今回使用するツールのうちChilloutMixは写実的な人物の画像を出力することが得意なモデルだ。

:::box
モデル： AIにおけるモデルとはもっぱら「機械学習モデル」を指し、入力したデータに対して何らかの結果を導き出す仕組みを意味する。Stable Diffusion、DALL-E、Midjourneyなどはいずれもプロンプトという入力データに対し画像を生成するという結果を導き出せるモデルだ。

またStable Diffusionなどをもとにさらに画像を学習させ、ファインチューニング（微調整）を施したChilloutMixのようなモデルも存在する。このようなモデルは、それぞれ特定の分野の画像生成を得意とすることが多い。たとえば風景、2次元の美少女、写実的なアジア人などだ。
:::

ChilloutMixで、男女のビジネスパーソンの画像を生成すると次のようになる。

!

スーツの広告に使用されていても気がつかないようなできばえではないだろうか。使用したプロンプトなどは以下の通り。

|  項目  | 内容  |
| ---- | ---- |
| プロンプト | Ultra high res, best quality, professional lighting, (((upper body))), 1 girl ,business suit, smile, (beautiful face),  detailed beautiful skin, black hair, medium hair, sharp focus,  street snap, soft light |
| ネガティブプロンプト | painting, sketches, (worst quality:2), (low quality:2), ((monochrome)), ((grayscale)), missing fingers , skin spots, acnes skin, blemishes, nsfw | 
| 設定 | Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 3301637184, Size: 768x512, Model hash: fc2511737a, Model: chilloutmix | 

※男性の画像はプロンプトの1 girl を1 boyに変更するだけで生成できる。

上記のプロンプトの服装や髪型、表情に当たる単語を変更すれば簡単に画像のバリエーションも作り出せる。プロンプトを工夫してうまく画像を生成するためのコツは、次節の「Stable Diffusionで使える便利なプロンプト・呪文集」で紹介している。

なお、操作画面に登場するそのほかの項目の説明は以下の通りとなっている。

|  項目  | 内容  |
| ---- | ---- |
| Sampling method | ノイズ除去のためのアルゴリズムを変更できる。 |
| Sampling steps | 画像生成のStep数を設定する。Step数を増やすと、ノイズの除去回数が多くなり、生成の質が上がりますが時間がかかる。出力したい画像のタイプ(イラスト、景色、人物など）に合わせて調整することで快適に画像生成できる。 | 
| 　 | ! |
| Restore faces | 被写体の人物の顔が崩れて生成された場合に、補正できる。 | 
| Hires.fix | 画像解像度を上げる。 | 
| 　 |  ! |
| Batch count | 生成を何段階に分けて行うかを決定できる。 | 
| Batch size | 1回の生成で同時に演算を行う画像の数。Batch count × Bath size = 生成する画像の数
| CFG Scale | 入力したプロンプトへの忠実度を設定できる |
| 　 |  ! |

## Stable Diffusionで使える便利なプロンプト・呪文集
Stable Diffusionのような画像生成AIでは、プロンプトを直観的に入力した場合でも、ある程度まで意図に沿った画像を生成できる。

しかし自分の頭の中で想像している構図をより適切に反映させたり、写実的で高品質な画像を生成したりしたいとなると、プロンプトの構文や単語の組み合わせに独特のコツが必要で、それが「呪文」とも呼ばれる所以になっている。現在進行形で試行錯誤が進む分野で、いまだ完璧な正解はないが、以下に基本的な例を示す。

#### **プロンプトの構文の基本**

**被写体が人物の場合**
[品質]→[構図]→[モデルの数]→[モデルの外見]→[モデルのポーズ]→[背景]　の順番で構成するのが望ましい。

**被写体が景色(自然や建物)の場合**
[品質]→[構図]→[被写体の種類]の順番で構成するのが望ましい。

#### **単語への注目度の変更**

|  プロンプト  | 期待する効果 |
| ---- | ---- |
| (word) | 単語への注目度1.1倍 |
|  ((word)) | 単語への注目度1.1倍×1.1倍 |
|  (word:数字) |  (word:0.5)なら単語への注目度0.5倍 |

#### **品質**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| 4k(8k) | 4K（8K）画質 | 4K（8K）画質になる |
| masterpiece | 傑作・名作 | 品質が向上する |
| best quality | 最高品質 | 品質が向上する |
| ultra high res | 超高解像度 | 品質が向上する |

#### **画風**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| photo | 写真 | 写真のような画像になる |
| painting | 絵 | 絵のような画像になる |
| psketches | スケッチ | スケッチのような画像になる |
| watercolor painting | 水彩画 | 水彩画のような画像になる |
| oil painting | 油絵 | 油絵のような画像になる |

#### **構図**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| low angle shot | 低い角度から撮影 | 下から見上げた画像になる |
| high angle shot | 高い角度から撮影 | 上から見下ろした画像になる |
| full body shot | 全身撮影 | 被写体の全身が写る |
| upper body| 上半身 | 被写体の上半身が写る |
| close up of face shot | 顔に注目した撮影 | 顔がアップの写真になるる |

#### **モデルの数**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| 1girl | 女性が1人 | 被写体の女性が1人になる |
| 2girl | 女性が2人 | 被写体の女性が2人になる |
| 1boy | 男性が1人 | 被写体の男性が1人になる |
| 2boy | 男性が2人 | 被写体の男性が2人になる |

#### **髪の長さ**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| very long hair | ベリーロングヘアー | 膝までの髪 |
| long hair | ロングヘアー | 腰までの髪 |
| medium hair | ミディアムヘアー | 肩までの髪 |
| short hair | ショートヘアー | 首上までの髪 |
| bold | 坊主 | 坊主になる |

#### **髪型**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| pony tail | ポニーテール | ポニーテールになる |
| hair bun | お団子ヘア | お団子ヘアになる |
| twintails | ツインテール | ツインテールになる |

#### **髪色**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| black hair | 黒髪 | 黒髪になる |
| blond hair | 金髪 | 金髪になる |
| light brown hair | 茶髪 | 茶髪になる |

#### **表情**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| smile | 笑顔 | 笑顔になる |
| evil smile | 悪い笑顔 | 笑顔になる（嘲笑） |
| angry | 怒り | 怒った表情になる |

#### **服装**
|  プロンプト  |  日本語訳  | 期待する効果 |
| ---- | ---- | ---- |
| business suit | ビジネススーツ | 服装がスーツになる |
| t-shirt | Tシャツ | 服装がTシャツになる |
| hooded sweatshirt | パーカー | 服装がパーカーになる |
| coat | コート | 服装がコートになる |

これらの構文や単語を組み合わせることで、より意図に沿った画像を生成できる。生成の結果を見ると、まさしく呪文、魔法のように感じられるが、果たして使用する側にとってリスクはないのだろうか。次節では画像生成AIと著作権の問題について触れる。

## Stable Diffusionと著作権問題
!
:::small
出典：文化庁
:::

画像生成AIは急激に普及しつつあり、また専門家の予想さえ越える速さで進歩している。これまでAIに仕事を奪われるのは遠い未来の話だと考えられていたが、今や画家、イラストレーター、写真家を脅かすほどの高品質な画像が登場し始めた、という意見もある。

AIに高品質な画像が生成できるようになると当然のように商業利用も始まる。重要になるのが著作権の問題だ。この分野もまだ手探りが続いており、国や地域によって法律やその解釈も異なる。

ここでは文化庁の{target=“_blank”}の見解を紹介する。日本において、AIに関する著作権は「AI開発・学習段階」と「生成・利用段階」で著作物の利用行為が異なり、関係する著作権法の条文が異なるため、両者は分けて考えるべきだとされている。

#### **AI開発・学習段階での著作物の利用**

AI開発・学習段階とは

- 著作物を学習用データとして収集・複製し、学習用データセットを作成する
- データセットを学習に利用してAIを開発する

ことを意味する。開発・学習段階の著作権は以下のように考えられている。

:::box
AI開発のための情報解析のように、著作物に表現された思想又は感情の享受を目的としない利用行為は、原則として著作権者の許諾なく行うことが可能です。(文化庁 AIと著作権 p37) 
:::

「享受」とは、著作物を通して利用者等の知的・精神的欲求を満たす効用を得ること、とされている。また享受を目的としない場合でも、「著作権者の利益を不当に害する場合」は著作権侵害に当たるとされ、著作者が明確に学習への利用を禁止している場合も該当する。

「著作権者の利益を不当に害する場合」に該当するか否かについては、最終的に司法の場で個別具体的に判断される。

学習が著作権侵害にあたるかどうかについて世間の注目度は高い。すでに自身の著作物が無断利用されることを危惧したイラストレーターが、イラストSNS「pixiv」上に掲載していた作品を削除・非公開にする動きが出ている。

:::box

:::

##### **生成・利用段階での著作物の利用**

生成・利用段階とは

- AIを利用し画像等を生成する
- 生成した画像等を公表、販売する

ことを意味する。生成・利用段階の著作権は以下のように考えられている。

:::box
AIを利用して画像等を生成した場合でも、著作権侵害となるか否かは、人がAIを利用せず絵を描いた場合などの、通常の場合と同様に判断されます。（文化庁 AIと著作権 p43）
:::

この判断は「類似性」と、画像が既存の著作物を利用して作出されたものであるかの「依拠性」により行われる。「依拠性」をどのように考えるかについては精力的に議論が行われている。「著作物が生成AIの学習に使用されている場合は必ずその著作物への依拠性が認められる」という見解さえある。

なお、私的に鑑賞するための画像を生成する等の行為は「権利制限規定」に該当し、著作者の許諾なく行うことが可能とされている。一方で生成した画像等をアップロードして公表する、販売する行為は権利制限規定に該当しない場合があり、著作者の利用許諾なく行った場合は著作権侵害となる恐れがある。こちらも最終的に司法の場で個別具体的に判断される。

## Stable Diffusionは今後どうなる？
!
Stability AIは2023年6月に「Stable Diffusion XL（SDXL）」の最新バージョン「SDXL 0.9」を発表。併せて「SDXL1.0」を7月中旬にオープンリリースする予定も明らかにした。性能はますます向上し、より高解像度（1,024×1,024）での生成が可能になったほか、従来画像生成AIが苦手としてきた人間の手の表現などに大幅な改善が見られ、本物の写真と見分けがつかない画像をより容易に生成できるようになっている。

Stable Diffusionの進歩は目を引くが、振り返ってみるとその周囲を取り巻く環境は安定しているとはいえない。著作権の問題では、写真素材（ストックフォト）大手の米国Getty Images（ゲッティイメージズ）が、Stable Diffusionの開発元Stability AIを2月に提訴した件も記憶に新しい。また本物の写真と見分けのつかない偽情報の氾濫をもたらす危惧から、米国マサチューセッツ工科大学（MIT）の研究者等は同月に「Raising the Cost of Malicious AI-Powered Image Editing」と題した論文でその機能に制限をかけるべきと主張している。これに加え欧州連合（EU）を中心に広範な法規制を望む声も高まりつつある。

PhotoshopやIllustlatorなどクリエイター向けのソフトウエアを開発してきた米国Adobe Systemsは3月、Stable Diffusionに対抗するかのように独自の画像生成AI「Firefly」を公開。著作権の切れた画像とオープンライセンス画像のデータベースで学習したことを特徴として打ち出し関心を呼んでいる。

:::box

:::

もしStable Diffusionが著作権侵害や偽情報などの問題に適切に対処できなければ、性能は向上を続けてもいずれ法規制にぶつかり、開発そのものに暗雲が垂れ込める可能性がある。そうなればFireflyをはじめ、より法的、倫理的な対応を重視する競合プロジェクトに台頭の機会を与えるだろう。

革命的とも破壊的ともいえるStable Diffusionは、きわめて便利である一方、社会に大きな反響、そして反発をも呼び起こしている。仕組みや使い方について理解を深めつつも、今後の動向には注視が必要といえそうだ。</description><pubDate>Wed, 12 Jul 2023 06:02:24 +0000</pubDate></item><item><title>7月27日【無料ウェビナー】生成AI時代における、エンタープライズAI開発の方法論とは？</title><link>https://ledge.ai/articles/webinar-vol56</link><description>## 生成AI時代のAI開発

ChatGPTやBardなど、生成AI、大規模言語モデル（LLM）に関するニュースを見ない日はない昨今。生成AI関連のサービスが続々生まれ、企業においても生成AIを業務に活用する動きが見られます。

生成AIの普及に伴い商用のLLMを利用したり、OSSのLLMを活用したり、自社モデルを作成したりとさまざまなアプローチがある中で、企業は自社に最適な活用方法を、ビジネスユースケースと照合しつつ、将来性やリスクを含めて検討していく必要があるでしょう。

一方で、LLMのトレーニングやファインチューニングには技術・コスト的課題も少なくありません。比較的少ないデータセットを用いつつ、サービスプロバイダへの依存度や方針変動に左右されにくいOSSによるLLMのファインチューニングを選択する企業もいます。その場合、AI開発現場では、

- 「学習に時間と手間がかかる」
- 「複数のAI開発者がそれぞれの学習リソースを保有しており効率が悪い」
- 「スケールしづらく、コラボレーションも発生しづらい」

など複数のデメリットが発生する可能性もあり、AIエンジニアやデータサイエンティストを悩ませています。

そこで本セッションでは、日本ヒューレット・パッカード合同会社 HPC Data&amp;AIソリューション事業統括本部AI BDM / プリセールスコンサルタント 山口 涼美氏をお招きし、生成AI時代におけるAI開発の勘所を語ります。
日本ヒューレット・パッカードとエヌビディア社は、開発者が短期間でAIを構築してハイパフォーマンスデータ分析を行えるように最適化されたエンタープライズプラットフォームを提供し企業のAI活用をサポートしています。
AIエンジニアやデータサイエンティスト、及びそのチームをリードしている立場の方々は、ぜひご参加ください。

:::button
[終了しました]
:::

## 登壇者
### 日本ヒューレット・パッカード合同会社 山口 涼美氏

!

2018年に日本ヒューレット・パッカード合同会社へ新卒入社し運用保守業務を経験後、AIビジネス推進を目的としたBU横断組織を立ち上げリーダーを務める。現在はHPC・AI系の製品部でAIビジネスデベロップメントマネージャー兼プリセールスコンサルタントとして活動している。趣味はバスケットボール。

### 株式会社レッジ 執行役員 箕部 和也(モデレーター)

!

インターネット広告代理店にてSNSを通じた企業と生活者のコミュニケーションデザインのプランニングに従事。その後オンラインのみではこれからのマーケティングに不十分であると感じIoT案件を多数手掛けるウフルに転籍。従来は取得できなかったフィジカル領域のビッグデータを活用したIoTビジネスのコンサルティングを行った。Ledge参画後は、AIをはじめとする先端技術を活用した自社内外の事業開発を推進している。

:::button
[終了しました]
:::

## 開催概要
イベント名：Ledge.ai Webinar vol.56『生成AI時代における、エンタープライズAI開発の方法論とは？』
開催形式：Zoom配信
開催日時：2023年7月27日（木）15:00〜
共催：日本ヒューレット・パッカード合同会社、エヌビディア合同会社
登壇者：
日本ヒューレット・パッカード合同会社 山口 涼美氏
株式会社レッジ 執行役員 箕部 和也(モデレーター)
参加費：無料</description><pubDate>Mon, 26 Jun 2023 05:34:35 +0000</pubDate></item><item><title>生成AI関連の無料ウェビナー多数「Ledge.ai EXPO 2023 summer」を7月3日から31日まで開催</title><link>https://ledge.ai/articles/ledgeai_expo_2023_summer</link><description>## Ledge.ai EXPOについて
Ledge.ai EXPOは、DXを実現するプロダクトやサービスの情報を発信する展示会形式のオンラインイベントです。国内最大級のAI関連メディアであるLedge.aiが主催するイベントとして、AI、IoT、DXに興味関心の高いビジネス層が多数訪れています。参加費は無料です。

Ledge.ai EXPOは、新型コロナウイルスの感染拡大により大きな打撃を受けた出展企業の声を聞き、Legde.aiとしてAI業界へ少しでも貢献したい、という思いのもと2020年3月に初開催いたしました。

その後もビジネスマッチングの場としてLedge.ai EXPOを計5回開催し、好評を博しました。イベント参加登録者数は各回1000名（ウェビナー視聴登録、資料DL/問い合わせをしたユーザー数）を超え、AI関連ソリューションのオンライン展示会としての地位を確立しています。

第6回となる今夏開催のLedge.ai EXPOは、昨今著しい進化を見せている「生成AI」をテーマに、オンライン/オフラインのハイブリッドで開催します。合わせてリアルイベントでのビジネス交流会も開催予定です。生成AIの“今”を知り、ビジネスの場を広げたい方はぜひご参加ください。

## 実施概要
イベント名：Ledge.ai EXPO 2023 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催期間：2023年7月3日〜7月31日
開催形式：オンライン（特設サイト上）とオフライン（28日の1日限定）
掲載コンテンツ：キーノート（動画）、ウェビナー動画、ソリューション紹介ページ（動画、記事）、生成AI系記事
 
## 開催テーマ
生成AIが描く日本の未来

生成AIの急速な普及により、見える景色の変化は日々めざましい世の中になっています。生成AIは日本にどのような影響をもたらしていくのか？という問いを立て、進むべき未来への糸口を探るような特集として企画設定いたしました。

## （1）Online contents
■ウェビナー動画

### Google Cloud の次世代AI
### 〜ジェネレーティブAI最新情報
Google Cloud　AI/ML事業開発部長
下田 倫大 氏
  
!

実ビジネスでの活用を見据えながら、Google Cloud で提供されるジェネレーティブ AI のプロダクトを紹介していただきます。

### AIプラットフォームのすすめ
### AIプラットフォームはなぜ必要なのか？AIの説明性、ガバナンスに関する最新情報
Dataiku Japan株式会社　セールスエンジニア
木邑 文彦

!
いまAIプラットフォームがなぜ必要とされるか、そのポイントとともに、AIプラットフォームが提供する主要な機能と、特にAIの説明性とガバナンスについての最新機能をご紹介していただきます。

### 生成AI×企業
### 日清食品HDのChatGPT活用法とは？
一般社団法人日本ディープラーニング協会　理事 事務局長
岡田 隆太朗 氏
日清食品ホールディングス株式会社　執行役員・CIO
成田 敏博 氏
株式会社レッジ　執行役員
箕部 和也

!
日清食品ホールディングスは2023年4月25日、Azure OpenAI Service等を活用して独自開発した対話型AIをグループ従業員に向けて公開。
これら一連の取り組みを推進した執行役員CIOの成田氏へ、同社での展開に至る経緯や実装方法、体制、今後の展望について日本ディープラーニング協会事務局長の岡田氏と共に話をお聞きしました。

その他ゲスト講演

### 大規模言語モデル開発のすゝめ
エヌビディア合同会社　エンタープライズ事業本部長
井﨑 武士 氏

### AIの革新：マイクロソフトの新時代技術である生成AIと未来へのビジョン
日本マイクロソフト株式会社　Global Black Belt Asia Pacific AI/ML Specialist
濵田 隼斗 氏

### デジタルマーケティングにおける生成AI
株式会社オプト　AIソリューション開発部部長
田中 宏明 氏
株式会社デジタルシフト　データインテグレーションコンサルティング部
データコンサルティング / 部長
内田 隼人 氏
株式会社デジタルシフト　データインテグレーションコンサルティング部
データサイエンティスト / PM
髙阪 崇久 氏
株式会社レッジ　執行役員
箕部 和也（モデレーター）

### Alibaba Cloud AIACC Stable Diffusion加速ソリューションのご紹介
アリババクラウド・ジャパンサービス株式会社　アリババクラウド・インテリジェンスビジネスグループ
ソリューションアーキテクト
王 智勇 氏

## ■ピックアップ記事
生成AIに関連する話題として絶対に抑えておくべき情報・知識をLedge.ai掲載記事の中からピックアップいたしました。
「Business」「Academic」「Public」「Learning」の切り口にて厳選した記事は是非とも隅々までご一読ください。

紹介記事の一覧

- エヌビディアCEO「AIに精通しなければ個人も企業も勝ち残れない」
- OpenAI AIモデルを販売できるアプリストアを計画 MicrosoftやSalesforceと競合の可能性 
- NTT、低電力の独自大規模言語モデルを11月に発表。環境負荷低減でChatGPTに対抗 
- Microsoft、「Windows Copilot」発表でWindowsに生成AIを本格導入へ  | 
- みずほ、システム開発保守に生成AIを活用。富士通と実証実験を開始  | 
- 画像生成AI「Stable Diffusion」新モデル「SDXL 0.9」が家庭用PCで利用可能に  | 
- LLMの「幻覚」軽減のカギに？OpenAIが「プロセス監視」による新たなアプローチを発表 
- ChatGPTに高性能をもたらした「RLHF」技術は時給2ドル未満で働く人々に支えられている 
- OpenAIが研究を公表、GPT-4でGPT-2のニューロン解析
- OpenAIのCEO「AIを免許制に」米公聴会にて訴え
- 欧州議会、AI規制案を承認。システム開発に使用した著作物開示を義務付け 
- ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと
- ChatGPTとはどのようなもので、どのように動いているのか？【オルツCTO連載 vol.1】 
- AI(人工知能)の歴史｜時系列で簡単解説 

## （2）Offline contents
開催期間中、抽選にて当選した読者の皆さまと、登壇企業とのミートアップイベントを予定しています。

## ■スペシャルトーク
株式会社アップガレージグループ　代表取締役会長CEO
石田 誠 氏

## ■交流会
ソリューション提供企業様と、活用企業様同士での交流の場を設けています。

:::button
{target=“_blank”}
:::</description><pubDate>Fri, 30 Jun 2023 08:07:39 +0000</pubDate></item><item><title>【新刊情報】「大規模言語モデルは新たな知能か――ChatGPTが変えた世界」</title><link>https://ledge.ai/articles/Is_lmm_new_intelligence</link><description>「大規模言語モデルは新たな知能か――ChatGPTが変えた世界（岩波科学ライブラリー）」（著：岡野原大輔、岩波書店）が6月20日に刊行された。大規模言語モデルの可能性と課題、仕組みを数式を用いず一般向けに解説し、最新の研究成果に基づき現時点でわかっている知見や将来の展望もまとめている。

著者は1982年生まれ。東京大学大学院情報理工学系研究科博士課程を修了し、2006年Preferred Infrastructurを共同で創業、2014年Preferred Networks（PFN）を共同で設立。PFN代表取締役最高研究責任者およびPreferred Computational Chemistry代表取締役社長を務めている。

本書では大規模言語モデルのもつ大きな可能性とともに、人類社会を脅かす可能性のあるリスクについても述べる。また後半では、これまで機械はなぜ人のように話せなかったのか、どのように言語モデルと機械学習が発展してきたか、そして、ChatGPTを実現した大規模言語モデルはどのような仕組みかを数式を用いず解説する。

目次
・序章 チャットGPTがもたらした衝撃
・1 大規模言語モデルはどんなことを可能にするだろうか
・2 巨大なリスクと課題
・3 機械はなぜ人のように話せないのか
・4 シャノンの情報理論から大規模言語モデル登場前夜まで
・5 大規模言語モデルの登場
・6 大規模言語モデルはどのように動いているのか
・終章 人は人以外の知能とどのように付き合うのか
・あとがき

書誌情報
:::box
著者：岡野原 大輔
出版社：岩波書店
刊行日：2023/06/20
ISBN：9784000297196
体裁：B6・並製・136ページ
定価：1,540円
:::

Ledge.ai編集部では「大規模言語モデルは新たな知能か――ChatGPTが変えた世界（岩波科学ライブラリー）」のレビューを掲載予定。

:::button
[ChatGPT(チャットGPT)とは｜今からでも遅くない、使い方の基本と知っておくべきこと
](https://ledge-ai.the-ai.jp/articles/chatgpt)
:::</description><pubDate>Thu, 22 Jun 2023 04:48:14 +0000</pubDate></item><item><title>生成AI関連の無料ウェビナー多数「Ledge.ai EXPO 2023 summer」のティザーサイトを公開</title><link>https://ledge.ai/articles/ledgeai-expo-2023-summer-teaser</link><description>「AIをはじめとする最先端テクノロジーを社会になめらかに浸透させる」をミッションに掲げ、国内最大級のAI（人工知能）関連メディア「Ledge.ai」を運営するほか、AIソリューションの企画・開発を行う株式会社レッジは、7月3日（月）から7月31日（月）にかけて開催する、オンライン/オフラインハイブリッド型の展示会「Ledge.ai EXPO 2023 summer」のティザーサイトを公開しました。

:::button
{target:_blank}
:::

## Ledge.ai EXPOについて
Ledge.ai EXPOは、DXを実現するプロダクトやサービスの情報を発信する展示会形式のオンラインイベントです。国内最大級のAI関連メディアであるLedge.aiが主催するイベントとして、AI、IoT、DXに興味関心の高いビジネス層が多数訪れています。参加費は無料です。

Ledge.ai EXPOは、新型コロナウイルスの感染拡大により大きな打撃を受けた出展企業の声を聞き、Legde.aiとしてAI業界へ少しでも貢献したい、という思いのもと2020年3月に初開催いたしました。

その後もビジネスマッチングの場としてLedge.ai EXPOを計5回開催し、好評を博しました。イベント参加登録者数は各回1000名（ウェビナー視聴登録、資料DL/問い合わせをしたユーザー数）を超え、AI関連ソリューションのオンライン展示会としての地位を確立しています。

第6回となる今夏開催のLedge.ai EXPOは、昨今著しい進化を見せている「生成AI」をテーマに、オンライン/オフラインのハイブリッドで開催します。合わせてリアルイベントでのビジネス交流会も開催予定です。生成AIの“今”を知り、ビジネスの場を広げたい方はぜひご参加ください。

## コンテンツについて
### （1）Online contents
■ゲスト講演
生成AIの急速な普及により、見える景色の変化は日々めざましい世の中になっています。生成AIは日本にどのような影響をもたらしていくのか？有識者の方々から解説や展望をお話しいただきます。

■ソリューション紹介
AIやIoTをはじめ、DXを実現するプロダクトやサービスを持つ企業の紹介コンテンツを紹介するスポンサーブースです。サービスの説明を見ながら、気になるソリューションがあればすぐに資料ダウンロードが可能です。

■ピックアップ記事
現在大きな話題となっている「生成AI」関連の記事を、弊社編集者が厳選し掲載いたします。基本的な情報から、専門的な情報まで幅広く、最先端の情報に触れる場を提供いたします。

### （2）Offline contents
■トークセッション
coming soon

■ビジネス交流会
オフラインコンテンツでは、特別講演と交流会をご用意しています。特別公演は2公演ほどご用意しており、リアルタイムで行われるプレゼンテーションやディスカッションをお楽しみいただけます。

ビジネス交流会では、イベントにご参加いただいた皆様で、AI関連の最新情報の収集や直接のサービスのご相談などをしていただければと思います。また、ささやかではございますが軽食などのご用意もさせていただきますので、この機会にぜひ企業間交流をお楽しみください。

## スポンサーをご検討の方へ
Ledge.ai EXPO 2023 summerでは出展企業様を募集中です。現在、出展をご検討されている企業様で、資料に関するお問い合わせ、説明会に関するお問い合わせをご希望の方は、以下のアドレスでお問い合わせください。

**お問い合わせ先：ld_aiexpo@ledge.co.jp**

## オフラインイベントのお申し込みについて
本イベントは「Offline contents」として、リアルタイムのビジネス交流会も開催予定です。ビジネス交流会へのお申し込みは、ティザーサイト内の「事前申し込み」のご登録時のみ可能です。

お申し込みをご希望の方は、フォーム入力画面の一番下にあります「オフラインイベント参加の抽選申し込み」のチェックボックスをオンにしてお申し込みください。
リアルタイムならではの情報収集や、ビジネスの場を広げたい方におすすめのコンテンツとなっております。ぜひご参加ください。

## 開催概要
イベント名：Ledge.ai EXPO 2023 summer
主催：株式会社レッジ
URL：{target:_blank}
開催期間：2023年7月3日〜7月31日
開催形式：オンライン（特設サイト上）とオフライン（28日の1日限定）
掲載コンテンツ：キーノート（動画）、ウェビナー動画、ソリューション紹介ページ（動画、記事）、生成AI系記事
想定参加者数：500人</description><pubDate>Mon, 12 Jun 2023 10:00:57 +0000</pubDate></item><item><title>古いコードを最新のJavaに生成AIが自動変換「Amazon Q Code Transformation」</title><link>https://ledge.ai/articles/aws_amazonq_code_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Amazon.com傘下のAmazon Web Services（AWS）は2023年11月28日、ラスベガスで開催中の年次イベント「AWS re:Invent」にて「Amazon Q Code Transformation」を{target=“_blank”}した。

この機能はAmazon Qを使用して、古いJavaおよび.NETのコードを最新のJavaにAIが自動変換するツールで、アプリケーションの保守と最新化を簡素化することを目的としている。現在Javaアプリケーションのバージョン8および11から17へのアップグレードが可能で、近い将来にはWindowsベースの.NET Frameworkアプリケーションをクロスプラットフォームの.NETに変換できるようになる予定だという。

かつて開発者は、各アプリケーションのアップグレードに 2~ 3日かかっていたが、同社内部テストでは、手動アップグレードに通常は数日または数週間かかるのに対し、新機能を使用すると数分でアプリケーションをアップグレードでき、別の要件へ集中する時間に充当できたという。

このツールは、既存のコードを自動的に分析し、変換計画を生成して、計画に基づいた変換タスクを完了する。パッケージ依存関係の特定と更新、時代遅れかつ非効率的なコードコンポーネントのリファクタリングを行い、新しい言語フレームワークへの切り替えとセキュリティのベストプラクティスの組み込みを行う。変換が完了すると、ビルドとテストの結果を含む変換されたコードをレビューし、変更を承認することができる。

Amazon Q Code Transformationのプレビューは、 AWS Toolkit for IntelliJ IDEAおよびAWS Toolkit for Visual Studio Code のAmazon CodeWhisperer プロフェッショナル ティアの顧客が利用可能。組織が使用するプロファイルへのアクセスを許可する必要がある。プレビュー中の使用には追加料金不要。


:::box

:::
:::box

:::
</description><pubDate>Fri, 08 Dec 2023 15:20:21 +0000</pubDate></item><item><title>GTP-4を利用した「GitHub Copilot Chat」一般提供12月より「GitHub Universe 2023」で発表</title><link>https://ledge.ai/articles/github_universe2023</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国GitHubは2023年11月8日、サンフランシスコで年次イベント「GitHub Universe 2023」を開催した。1日目の{target=“_blank”}で、CEOのThomas Dohmke氏は「GitHubがGitという仕組みの上に構築されたように、今日私たちはCopilotの上に ”Re-founded”（=再構築）された」と述べた。また、GitHubの掲げるビジョン「Copilot X」は、ソフトウェア開発のライフサイクル全般を支援することを目指すという。

生成AIを活用した「GitHub Copilot」シリーズの進展、特に「GitHub Copilot Chat」の一般提供の発表に注目が集まった。この新機能は、自然言語での指示を通じて、コーディングを支援するもので、すでにベータ版は全個人向けユーザーに9月より無償で提供している。既存のサブスクリプションサービス、GitHub Copilotプランの一部として、organizationおよび個人ユーザーに対して12月より一般提供される予定だ。

Copilot ChatはGPT-4を使用しており、より正確なコードの提案と説明を実現しているという。コードに関する質問や議論を可能にし、さまざまなスラッシュコマンドを通じて、コーディングタスクを簡素化する機能も備えている。このサービスは、GitHubのウェブサイトやモバイルアプリにも統合されており、開発者はいつでもどこでもこの機能を利用できるようになる​​とのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

講演の最後には新機能として、自社のコードをもとにGitHub CopilotのAIモデルをカスタマイズする「GitHub Copilot Enterprise」が紹介された。これにより、組織は自社特有のコードベースに合わせたAIのサポートを受けられるようになる。


:::box

:::</description><pubDate>Wed, 15 Nov 2023 05:08:10 +0000</pubDate></item><item><title>LINEヤフー 全エンジニア約7,000名を対象に「GitHub Copilot for Business」の導入開始</title><link>https://ledge.ai/articles/line-yahoo_github_copilot</link><description>:::small
画像の出典：{target=“_blank”}
:::

LINEヤフーは2023年10月13日、同社の開発業務に関わる全てのエンジニア約7,000名を対象にGitHub社が提供するAIペアプログラマー「GitHub Copilot for Business」の導入を開始したと{target=“_blank”}した。

導入に先駆け、2023年6月から8月の間、LINE株式会社およびヤフー株式会社のエンジニア約550名を対象に「GitHub Copilot for Business」のテスト導入を実施。テスト終了後のアンケートによる定性評価とGitHubでの様々な活動を定量化するアクティビティによる評価の分析の結果、1人あたりのエンジニアの1日のコーディング時間は約1～2時間の削減が行われ、アクティビティでは一部指標における利用前後の比較にて約10～30%の向上が見られたという。


:::box

:::
:::box

:::
:::box

:::</description><pubDate>Sat, 21 Oct 2023 11:09:57 +0000</pubDate></item><item><title>我が子や親の声をAIがまねる「ディープフェイクボイス」詐欺 SNSの3～4秒のデータから1回700円で生成可能</title><link>https://ledge.ai/articles/deepfake_voice</link><description>:::small
画像の出典：写真AC
:::

我が子や親の音声をAIが模倣する「ディープフェイクボイス」による詐欺の懸念が各国で高まっている。米国や中国ではすでに被害が出ており、あらためてニュースメディアを騒がせている。

2023年5月の{target=“_blank”}や9月の{target=“_blank”}などの報道がこの問題を取り上げている。AIを利用すると3～4秒の音声から高精度の合成が可能。かかる費用は1件につき日本円にして700円程度という。素材は動画共有SNS「TikTok」などで個人が家族や友達向けに投稿した映像などから集められる。

米国や中国ではこうした音声による詐欺もすでに起きているもようだ。{target=“_blank”}によれば、2022年には親族や友人を装う詐欺電話が約5,000件あり、被害総額は約16億円。

ディープフェイクボイスによる犯罪を含むと見られ、顕著な例として{target=“_blank”}が2023年4月に報道した事件が最近注目を浴びている。同年1月にアリゾナ州のとある母親のもとに娘の声で助けを求める電話があった。犯罪者は娘を誘拐したとして日本円にして約1億4,000万円相当の身代金を要求。実際は詐欺で、報道時点でAI生成だったという証拠は見つかっていないが、母親は音声の迫真性からほかに考えられないと述べている。


!
:::small
画像出典：マカフィー
:::

5月の{target=“_blank”}によると、7か国の18歳以上の成人7,054人のうち10%の人が「AI音声を用いた詐欺に遭遇した」と回答。また知人が遭遇したと答えた人（15%）を合わせた25%のうち、約8割が金銭を詐取された。

日本はAI音声詐欺に遭遇した割合が少なく、潜在的な被害がある可能性がある。専門家は、被害が広がるのも時間の問題と指摘した。日本国内の2022年の特殊詐欺被害額は370億8,000万円で8年ぶりに増加しており、いわゆる「オレオレ詐欺」が多い。被害防止のための技術が研究されており、一部の金融機関ではすでに実用化している。

:::box

:::
:::box

:::


</description><pubDate>Fri, 22 Sep 2023 06:49:13 +0000</pubDate></item><item><title>コーディング特化のAI「WizardCoder 34B」ChatGPT上回る成績 Code Llama強化し達成</title><link>https://ledge.ai/articles/wizard_coder_34b</link><description>米国Microsoftと香港浸会大学の研究者らが、プログラミングコードの生成に特化した大規模言語モデル（Code LLM）として開発した「{target=“_blank”}」シリーズが注目を浴びている。新版はOpenAIの高性能な対話型AI「ChatGPT」を一部上回る成績も収めた。

2023年6月14日に発表した{target=“_blank”}によると、当初のWizardCoderは米国Hugging Faceが公開したオープンソースのCode LLM「StarCoder」を強化したものだった。StarCoderをはじめとする従来のCode LLMは大量のプログラミングコードから学習しているものの、人間の指示に適切に回答するための調整に弱みがあった。WizardCoderは、人間の代わりにLLMに大量の指示データを生成させ学習に使用する「Evol-Instruct」の手法でそこを補ったという。

さらに8月26日に披露した「{target=“_blank”}」は米国Metaが開発したCode LLM「Code Llama」を強化したもので、AIにプログラミング言語「Python」の問題を解かせて性能を測るベンチマーク「HumanEval」を試したところ、ChatGPTが採用するLLMのうち世代の古い「GPT-3.5」を上回る精度73.2％を達成できた。ただし最新版LLM「GPT-4」の精度82.0％には及ばなかった。

!
:::small
出典：WizardCoder
:::

:::box

:::</description><pubDate>Sat, 09 Sep 2023 02:23:33 +0000</pubDate></item><item><title>OpenAI 世界の開発者を招集する「OpenAI DevDay」11月開催 ライブ配信もあり</title><link>https://ledge.ai/articles/openai_devday</link><description>米国OpenAIは初の開発者会議「{target=“_blank”}」を米国サンフランシスコで2023年11月6日に開催する。開発者は直接会場を訪れることはもちろん、世界中から基調講演をライブ配信することが可能だ。{target=“_blank”}で申し込みを受け付け中。

世界中から何百もの開発者が集まり、新たなツールを披露し、アイデアを交換する。会場に直接訪れる開発者は、OpenAIの技術スタッフが主催する分科会セッションに参加可能だ。

会議の開催に合わせ、OpenAIは外部の開発者との連携する姿勢をあらためて打ち出している。同社は対話型AI（チャットボット）「ChatGPT」の公開に先立つ2020年に、同社のAIを外部から呼び出して利用できるアプリケーションプログラミングインターフェイス（API） を公開。2023年時点では200万超の開発者がAPIを利用し、既存のアプリケーションへスマートアシスタントを統合したり、新たなアプリやサービスの構築を行ったりできるようになっている。

APIを通じて利用できるのは、ChatGPTの中枢である大規模言語モデル（LLM）「GPT-4」「GPT-3.5 Turbo」はもちろん、画像を生成する「DALL·E」、音声を文字起こしする「Whisper」 などだ。今回の会議ではさらに、開発者が新たな製品を構築できるような成果を公開予定だという。なお特設サイトで会員登録すると、数週間以内に登録開始の通知を受け取れる。

:::box

:::</description><pubDate>Fri, 08 Sep 2023 13:38:59 +0000</pubDate></item><item><title>Excelで「Python」が実行可能に 機械学習にも対応</title><link>https://ledge.ai/articles/python_in_excel</link><description>米国Microsoftは、表計算アプリケーション「Excel」でプログラミング言語「Python」が実行可能になったと2023年8月23日に{target=“_blank”}した。統計解析から機械学習まで多用途で役立つ。オフィススイート「Microsoft 365」のさまざまな新機能を試せる「Microsoft 365 Insiders」プログラムに参加すればWindows向けのベータ版が利用できるようになるという。

ベータ版にはPythonのコードをExcelのセルに直接入力できる新たな「PY関数」が加わり、ビジュアライゼーション、データクレンジング、機械学習、予測分析などを行える。

Excelのコネクタ機能とPower Query（パワークエリ）機能で外部データを取り込み、Pythonで処理できる。Excelの既存の数式、ピボットテーブル、グラフなどの機能と互換性があり、例えば「Matplotlib」や「seaborn」などPythonのグラフ作成ライブラリを組み込んで、簡単な棒グラフや折れ線グラフからヒートマップ、バイオリン プロット、群プロットまで描き出せる。

!

「scikit-learn」や「statsmodels」などのライブラリを組み込めば一般的な機械学習、予測分析、回帰分析、時系列モデリングなども行える。具体的にはPythonとExcelのLAMBDA（ラムダ）関数を連携させて天気を予測するモデルを動かす、といったことが可能だ。

!

このほかデータクレンジングの用例についても欠損値の特定、形式の標準化、重複の削除、パターンベースの変換のための正規表現の使用などが挙がっている。

なおExcelのPythonは、クラウドサービス「Azure」上に設置した科学計算ディストリビューション「Anaconda」で実行する。

:::box

:::</description><pubDate>Fri, 25 Aug 2023 10:12:51 +0000</pubDate></item><item><title>Meta エンジニアを助けるコーディングAI「Code Llama」公開 無料で商用可能</title><link>https://ledge.ai/articles/code_llama</link><description>米国Metaはエンジニアのためにプログラミングコードを提案してくれる大規模言語モデル（LLM）「Code Llama」を2023年8月24日に{target=“_blank”}した。研究、商用どちらの目的も無料で導入できる。

7月に公開した汎用LLM「Llama 2」をもとにし、プログラミングコードに特化したデータセットで訓練したもの。コードと人間が日常で使う英語のような自然言語による指示「プロンプト」どちらでも質問ができ、回答としてコードや関連した文章を受け取れる。例えば「Write me a function that outputs the fibonacci sequence（フィボナッチ数列を出力する関数を書いてください）」といった具合だ。

ベンチマークテストではCode Llama の性能はコードに特化したほかのオープンソースのLLMよりも優れていたとしている。

!

不完全なコードの補完や、不具合の修正（デバッグ）にも利用できる。Python、C++、Java、PHP、Typescript (Javascript)、C#、Bash など広く普及したプログラミング言語の多くに対応する。

なおCode Llamaはデータサイズや性能の目安となる「パラメータ数」が70億、130億、340億と異なる3種類の版を選べるようになっている。いずれも5,000億トークンのコードと関連データを使用して訓練してある。70億パラメータ版と130億パラメータ版のベースモデル、インストラクション（指示）モデルは中間補完 (FIM) 方式の訓練もしており、既存のコードに新たなコードを挿入でき、すぐにコード補完などの作業に役立てられる。また例えば70億パラメータ版は単一のGPUで実行できる。340億パラメータ版は最良の結果を返すが、ほかより低速だ。

ファインチューニング（微調整）を施したPython特化の「Code Llama - Python」と自然言語による指示に特化した「Code Llama - Instruct」も公開している。それぞれ70億、130億、340億のパラメータ数が異なる版がある。Metaは自然言語での指示を含むような実際の用途にはCode Llama - Instructを使うよう推奨している。

!

:::box

:::
:::box

:::</description><pubDate>Fri, 25 Aug 2023 11:00:00 +0000</pubDate></item><item><title>「Google検索」に英文の文法チェック機能を追加 AIがより適切な書き方を提案</title><link>https://ledge.ai/articles/google_search_grammer_check</link><description>:::small

:::
Googleは「Google検索」に英語文の文法ミスを見つける機能「{target=“_blank”}」を追加した。2023年8月17日時点では、この機能は英語のみ利用可能だ。

利用方法は簡単で、検索バーにチェックを希望する英文を入力し「grammar check」「check grammar」などのキーワードを併記するだけだ。文法ミスがあれば、Googleは文章を修正し、変更した部分に下線を引く。正しい文章はコピーが可能で、文法ミスがない場合は緑色のチェックマークが表示される。

この文法チェック機能はAIを利用しており、必ずしも100％正確ではないと同社は指摘している。特に不完全な文の場合、注意が必要だ。さらに「危険」「ハラスメント」「ヘイト」などのコンテンツが同社の検索ポリシーに違反する場合、文法チェックは行われない。

なお、AIによる高度な翻訳サービスで知られるドイツDeepLも2023年1月、英語の文章を自然な形に校正する「{target=“_blank”}」を公開している。

:::box

:::

:::box

:::


　
</description><pubDate>Thu, 17 Aug 2023 02:23:11 +0000</pubDate></item><item><title>「GitLab 16」登場 AIワークフロー機能搭載したDevSecOpsプラットフォーム新版</title><link>https://ledge.ai/articles/gitlab16_devsecops_platform</link><description>GitLabは2023年7月6 日、DevSecOpsプラットフォームの新版「GitLab 16」の提供開始を発表した。AIを活用したワークフロー機能が目玉だ。

Development（開発）、Security（セキュリティ）、Operations（運用）の3つの要素をが統合した開発環境。ソフトウェア開発の計画からモニタリングまでを行い、課題管理、バージョン管理、コードレビュー、継続的インテグレーション／継続的デリバリ（CI/CD）、モニタリングをひとつのアプリケーションで完結する。

新版「GitLab 16」は、生成AIの支援でコードを作成できる「Code Suggestions」や、AIを活かしたセキュリティテスト／分析、オブザーバビリティ、プロアクティブな脆弱性検出などの機能を備える。
@
Code Suggestion では、開発の途中でAIの生成するコードの提案を受けながら、効率的にコードが書ける。

AI関連の新機能として「Suggested Reviewers」「Explain This Code」「Explain This Vulnerability」「Value Stream Forecasting」を追加した。これに加え次期機能として「Refactor This Code」および「Resolve This Vulnerability」を予定する。

プライバシーを優先したアプローチにより、企業や規制の厳しい組織でも知的財産を安心してGitLabのインフラストラクチャー内に置くことが可能とのこと。

:::box

:::
:::box

:::</description><pubDate>Wed, 19 Jul 2023 04:58:08 +0000</pubDate></item><item><title>GPT-4 APIの一般提供が開始 DALL-Eや音声テキスト変換「Whisper」のAPIも</title><link>https://ledge.ai/articles/gpt_4_api_general_availability</link><description>OpenAIは、最高性能を誇る大規模言語モデル（LLM）「GPT-4」の機能を外部の製品やサービスから利用できる「{target=“_blank”}」の一般提供を米国時間の2023年7月6日に開始した。有料APIの支払い実績があるすべての開発者に8,000トークンのアクセスを開放。7月末までに新規登録の開発者にも対象を広げる。また順次レート制限の引き上げも検討する。

OpenAIはこれに加えLLM「GPT-3.5 Turbo」、画像生成モデル「DALL-E」、音声テキスト変換モデル「Whisper」のAPIも一般提供している。

### 古いモデルを一部廃止
一方で従来のCompletion APIを用いる古いモデルを6か月以内に一部廃止する計画も明らかにした。当面APIへのアクセスは可能にするが、開発者向けの文書には「レガシー」と表示する。

2024年1月4日より古いモデルは別モデルに置き換わる。古いモデルを利用している開発者はAPIアクセス時のパラメータを変更して対応する必要がある。

!
開発者が古いモデルにファインチューニングを施して利用していた場合は、2023年後半以降、優先的に別モデルでのファインチューニングが可能になる見込み。このほか古い埋め込みモデルを使っている開発者も別モデルへの切り替えが必要となる。

これらの移行には困難が伴うとの予想からOpenAIは開発者に連絡をとったり、必要なサポートを提供したりすると表明している。

:::box

:::
:::box

:::</description><pubDate>Fri, 07 Jul 2023 02:54:50 +0000</pubDate></item><item><title>ChatGPTが開発者コミュニティへのアクセス減少を加速させる</title><link>https://ledge.ai/articles/similarweb-stackoverflow-chatgpt</link><description>Web解析会社のSimilarWebは、開発者たちが人間同士の開発コミュニティStack OverflowよりもChatGPTやGitHub CoPilotからアドバイスを得る傾向にあるとのレポートを2023年4月19日にした。

ChatGPTのトラフィックが指数関数的に成長する一方で、Stack Overflowは一貫して減少を続けており、コーディングの課題への解答を求める開発者が最初に向かう情報源としての地位を一部失いつつあるという。

リサーチ結果の主なポイントは以下のとおり。

:::box
- Stack Overflow（stackoverflow.com）へのトラフィックは、2022年1月から毎月平均6%減少し、2023年3月には13.9%減少している。
- ChatGPTは11月末に開設されたばかりで前年比の実績はないが、短期間でそのサイト（chat.openai.com）は世界で最もホットなデジタル資産の1つとなり、全世界のトラフィックでMicrosoftの検索エンジンBingを上回っている。3月には16億回、4月前半には9億2,070万回のアクセスを記録している。
- GitHubのサイト（github.com）も力強い成長を遂げ、3月には前年比26.4%増の5億2400万アクセスを記録している。これは、CoPilotの全ての利用を反映しているわけではなく、サービスのサブスクリプションを取得するためにウェブサイトを訪れた人も含まれている可能性がある。
- GitHub CoPilotの無料トライアル申し込みページへのアクセスは、2月から3月にかけて3倍以上に増加し、800,000を超えている。
:::

同社の考察によると、Stack Overflowのコミュニティウェブサイトへのトラフィックは2022年初頭から落ち始めており、これがMicrosoftのGitHubビジネスから導入されたコーディングアシスタント「CoPilot」の出現に関連している可能性を挙げた。

CoPilotは、人間の言語とプログラミング言語の両方を処理できる同じOpenAIの大規模言語モデル上に構築されているため、開発者はStack Overflowを検索してコピーアンドペーストする何かを探す代わりに、CoPilotに全体の関数を書くことができる。

ChatGPTは詳細なコードサンプルと完全な関数を生成し、そのコードがなぜ動作するかを説明するチュートリアルコンテンツを単純なテキストプロンプトに対する応答として提供することが分かり、コーディングツールとして短期間で注目を集めた。

その一方Stack Overflowは、同コミュニティ内でのChatGPTコンテンツの投稿を一時的に禁止した。ChatGPTのコーディング質問への答えがあまりにも頻繁に間違っているという理由から、コミュニティの規範に違反しているとみなされたためとサイトの運営者が述べた。

Stack OverflowのCEO、Prashanth Chandrasekarは、彼のチームが将来どのようにコミュニティと生成的AIテクノロジーの最善を組み合わせるつもりであるかを同社で語った。

の取材によると、ChatGPT台頭でアクセス数が減少していることを認めた上で、生成AIの成長は自社にとって大きなチャンスであるとコメント。コミュニティをより強固なものにするポテンシャルがあるとし、この夏を目処にStack OverflowからもAI関連の発表があると述べたという。

:::box

:::</description><pubDate>Wed, 31 May 2023 05:50:21 +0000</pubDate></item><item><title>ChatGPTにトレーニングデータを吐き出させる攻撃手法をGoogleDeepMindの研究者らが公開</title><link>https://ledge.ai/articles/extracting_training_data_from_chatgpt</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Google傘下のGoogle DeepMindの研究者たちは2023年11月28日、ChatGPTを含む機械学習モデルからトレーニングデータを効率的に抽出する新たな攻撃手法に関する研究を{target=“_blank”}した。

研究では、特にChatGPTに対する「発散攻撃（divergence attack）」という、ChatGPTのような言語モデルのアラインメントを標的にした新しい攻撃方法を紹介している。これは、ChatGPTの通常のチャットボットスタイルから逸脱させ、インターネット上の一般的なテキストスタイルで回答させることによって、トレーニングデータを抽出するものだ。

ChatGPTに特定のプロンプトを提供し、モデルを通常のチャットボットの回答スタイルから逸脱させる。すると、モデルはインターネットテキストスタイルで回答を始め、訓練に使用された実際のテキストデータを吐き出すようになる。

!
:::small
画像の出典：{target=“_blank”}
:::

この方法で得られたテキストがインターネット上のどこかに以前存在したかを確認するために、複数の公開トレーニングデータセットを統合し、合計9テラバイトのデータセットを作成。これを用いて、ChatGPTのトレーニングデータセットから10,000以上の例を200米ドルのクエリコストで回収した。

!
:::small
ChatGPTが吐き出したテキストのうち、公開されているデータセットの内容と照合できたテキストが赤くなっている
画像の出典：{target=“_blank”}
:::

研究者らは、この脆弱性をOpenAIに2023年8月30日に報告し、標準的な開示スケジュールに従って90日間の対応期間を設けた後、論文の公開に至った。

なお、この脆弱性はすでに対処されていることが複数メディアで確認されている。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Tue, 12 Dec 2023 07:24:17 +0000</pubDate></item><item><title>心に描いた風景を脳信号から復元、生成AIと数理手法の新技術開発</title><link>https://ledge.ai/articles/mental_image_brain_decoding</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

量子科学技術研究開発機構（QST）、情報通信研究機構（NICT）、大阪大学の研究チームは2023年11月30日、人の心に描かれた風景や物体を脳信号から復元する技術を開発したと{target=“_blank”}した。

これまで、目で見た画像の復元は可能でもメンタルイメージの復元は困難とされていた。この新技術では生成AIとベイズ推定、ランジュバン動力学法を組み合わせ、脳信号から心に描かれたイメージを復元することに成功したという。

!
:::small
画像の出典：{target=“_blank”}
:::

研究チームは、1,200枚の画像とそれに対応する脳信号を用いて「脳信号翻訳機」を構築。これを利用して、被験者のメンタルイメージを正確に読み出し、生成AIによって自然な画像に近づけて復元した。

!
:::small
画像の出典：{target=“_blank”}
:::


この技術は、他者の心の中を客観的に捉える手段として、将来的にはブレイン・マシン・インターフェースの発展や医療機器への応用が期待される。


:::box

:::
:::box

:::</description><pubDate>Fri, 08 Dec 2023 15:03:58 +0000</pubDate></item><item><title>新たな3Dメッシュ生成法「MeshGPT」発表　トランスフォーマーモデルによる高品質な三角形メッシュ生成</title><link>https://ledge.ai/articles/meshgpt</link><description>:::small
画像の出典：{target=“_blank”}
:::

ミュンヘン工科大学、トリノ工科大学、アウディの研究チームは2023年11月27日、新しい3Dメッシュ生成法「MeshGPT」を{target=“_blank”}した。

MeshGPTは、大規模言語モデル（LLM）の進歩に触発されて開発されている。3Dオブジェクトメッシュの大規模なコレクションから得られた幾何学的埋め込みの語彙を学習し、トランスフォーマーモデルを用いてこれらの埋め込みから三角形メッシュを自動的に生成する。このメッシュは、人間が作成したメッシュの効率的な三角形パターンをより密接に模倣し、鮮明なエッジと高い忠実度を持ちつつコンパクトに生成される。


@

:::small
{target=“_blank”}
:::


MeshGPTでは、GPTに「メッシュを話す」ことを教え、トランスフォーマーを使用して直接シーケンスとしてメッシュを生成モデリングする。これを実現するために、まず三角形メッシュの語彙を学習し、それを使用してメッシュの自己回帰生成を行う。広範な形状のコレクションから幾何学的埋め込みの語彙を学習するため、エンコーダー・デコーダーネットワークを用いる。

次に、訓練されたエンコーダーと学習した語彙を使用して、GPTのようなトランスフォーマーを訓練する。訓練が完了すると、この語彙から直接シーケンスとしてメッシュをサンプリングできるようになる。

!
:::small
画像の出典：{target=“_blank”}
:::


MeshGPTは、ポリゴンメッシュ生成のPolygen、凸分解に基づくBSPNet、複数の2D平面からの3Dメッシュを表現するAtlasNet、3D符号付き距離フィールド（SDF）からメッシュを抽出するGET3Dなど、既存の主要なメッシュ生成方法と比較して優れた結果を示した。特に、MeshGPTは、形状カバレッジで9%の増加と、様々なカテゴリーでのFIDスコアで30ポイントの向上を達成したという。

!
:::small
画像の出典：{target=“_blank”}
:::


MeshGPTが、3Dコンテンツ作成の現状を高めるだけでなく、直接的なメッシュ生成に関する研究の促進を目指すと研究チームは述べた。


:::box

:::
:::box

:::</description><pubDate>Thu, 07 Dec 2023 09:10:33 +0000</pubDate></item><item><title>Meta マルチモーダルAIの新機能を公開　料理・スポーツ・音楽など、AIが名人のスキルを学び人間のコーチをする「Ego-Exo4D」</title><link>https://ledge.ai/articles/ego-exo4d</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Metaは2023年11月30日、ビデオ学習とマルチモーダル知覚に関する研究をサポートするための基礎的なデータセットおよびベンチマーク スイート「Ego-Exo4D」を{target=“_blank”}した。Ego-Exo4Dプロジェクトは、AIが人間のスキルを理解するための新たな取り組みだという。

このプロジェクトは、日常的なタスクから高度な技能まで、様々な状況での人間の能力を観察・研究することを目的としている。Ego-Exo4Dは、同種初のビデオデータセットおよびベンチマークスイートを構築することで、AIの人間技能理解を進展させることを目指している。

プロジェクトには、MetaのFAIR (基礎人工知能研究)、Meta のProject Aria 、および世界の15 の大学が協力しており「Ego 4Dコンソーシアム」と称される。日本からは東京大学が参加しており、12月5日にEgo-Exo4Dについて{target=“_blank”}している。

世界中の800人以上から収集した1,400時間以上のビデオデータは、料理からボルダリングまで、8つの物理的および手続き的スキルを示す。参加者や専門家がカメラを装着し、様々な活動を行いながら自身のスキルを撮影。同時に多様な固定視点から三人称視点のビデオも録画される。マルチモーダルデータシーケンスには、カメラのポーズ、高精度な視線ベクトル、3Dポイントクラウド、空間オーディオが含まれている。

人間のスキルを完全に理解するためには、専門家の視点も必要なため、Ego-Exo4Dには、専門家が提供する洞察やヒントが各ビデオに直接リンクされた、同種初の自然言語付随が含まれている。Ego-Exo4Dのベンチマークタスクは、熟練した活動の重要なステップを認識すること、習熟度を推測すること、一人称と三人称視点の間のオブジェクトを関連付けること、手と体の動きを推定することに焦点を当て、一人称ビデオ理解を進展させることを意図している。

!
:::small
画像の出典：{target=“_blank”}
:::


AIがビデオ内の熟練した人間活動を理解できるようになれば、スマートグラスを装着し、バーチャルAIコーチと共に学ぶことが可能になる。また、ロボットが新しいスキルを観察し、ほとんど物理的な経験なしに実行することも想像できるとMetaは述べる。


:::box

:::
:::box

:::</description><pubDate>Wed, 06 Dec 2023 03:19:20 +0000</pubDate></item><item><title>さらに進化する動画生成AI　1枚の静止画からアニメーションを生成「Animate Anyone」アリババグループ</title><link>https://ledge.ai/articles/alibaba_anime_anyone</link><description>:::small
画像の出典：{target=“_blank”}
:::

アリババグループのインテリジェントコンピューティング研究所は2023年11月28日、「Animate Anyone」という新しいキャラクターアニメーション技術を{target=“_blank”}した。拡散モデルを利用して、1枚の静止画像からキャラクターアニメーションを生成する技術だという。

@
:::small
研究者のチャンネル：{target=“_blank”}
:::

拡散モデルはその強力な生成機能により、現在視覚生成研究の主流となっているが、画像からビデオへの変換の領域、特にキャラクター アニメーションでは、キャラクターからの詳細情報との時間的な一貫性を維持することが依然として大きな問題となっているという。この技術では、参照イメージからの複雑な外観特徴を保持するために、ReferenceNetを設計し、空間的注意を介して詳細特徴を統合する。

!
:::small
画像の出典：{target=“_blank”}
:::

また、キャラクターの動きを制御し、ビデオフレーム間の滑らかな遷移を保証するために、効率的なポーズガイダーと効果的な時間モデリングアプローチを導入した。訓練データを拡大することにより、任意のキャラクターをアニメーション化し、他のイメージ・トゥ・ビデオ手法と比較して優れた結果をもたらすことができる。


:::box

:::
:::box

:::</description><pubDate>Mon, 04 Dec 2023 12:49:36 +0000</pubDate></item><item><title>1枚の写真から人間の３D画像を生成「Human-SGD」クウェート大・メタ研究チーム</title><link>https://ledge.ai/articles/human_sgd</link><description>:::small
画像の出典：{target=“_blank”}
:::

クウェート大学とメタ社の研究者らが、単一画像から人間の3Dデジタル画像化に関する技術「Human-SGD」を2023年11月15日に{target=“_blank”}した。これは、1枚の写真から、人物を全方位から見たかのような、クリアでリアルな3D画像を作り出す技術だ。形状ガイド付きの拡散モデルを使用し、その姿を360度どの角度からでも見たときの姿を、高解像度でつなぎ合わせて表示することが可能だという。


@
:::small
{target=“_blank”}
:::


NeRFなど従来の方法では、複数の視点からの画像や3Dスキャンが必要であったが、新しい技術では1枚の画像のみを用いる。このアプローチでは、一般的な画像合成タスク用に事前訓練された大容量2D拡散モデルを人間の外観の先行として活用することがポイントだという。複数の視点の画像を合成し、これらを逆レンダリング（通常のレンダリングで光源、形状、色の情報が既知の状態で計算するのとは逆に、描画結果に相当する画像から入力情報を得ようとする手法）融合することで、対象人物の完全なテクスチャ3Dメッシュを生成する。

研究チームは、この技術が従来の方法を上回り、単一画像から多様な衣服のテクスチャを持つ人間をフォトリアリスティックに360度合成できることを実証。これにより、ファッション、エンターテインメント、スポーツ、AR/VRなどの様々な分野での応用が期待されるという。


:::box

:::
:::box

:::
</description><pubDate>Fri, 01 Dec 2023 10:06:21 +0000</pubDate></item><item><title>AI「電子舌」を開発。人間の感覚と情動を統合し食行動を模倣するーーペンシルベニア州立大学研究チーム</title><link>https://ledge.ai/articles/an_electronic_tongue</link><description>:::small
画像の出典：{target=“_blank”}
:::

ペンシルベニア州立大学の研究チームが2023年9月27日、人間の食行動を模倣するための全2Dバイオインスパイアード回路を開発したと{target=“_blank”}した。このシステムは、食事における生物学的な味覚経路を簡略化し、食べ物の化学的な構成を感知するための「電子舌」として機能するグラフェン化学トランジスターを含む。また、食行動を制御する「飢餓ニューロン」と「食欲ニューロン」を含む電子回路が、人間の味覚皮質を模倣するという。

動物の行動は体の機能と心の働きの複雑な組み合わせによって成り立っているが、現在のAIではこの結びつきが十分に理解されておらず、心理学的な側面が考慮されにくい傾向にあるという。例えば、空腹状態だけが食事という行為に即つながるわけではなく「おいしそう」と感じる心の状態が影響することなどは理解されにくいといったことだ。

近年、脳の画像技術や遺伝学の進展により、例えば食事などの行動をコントロールする特定の神経回路が明らかになってきた。この研究では、人間の食行動を模倣する新しいシステムが提案されている。このシステムは、人間が食事をする際の体の状態（例えば空腹）や心の状態（例えば食欲）を考慮する。

研究チームは、この技術が人間の健康への応用や、感情を持つヒューマノイドAIの開発にも影響を与え、人間の味覚のみならず他の感覚システムへの応用が期待できると述べている。

:::box

:::
:::box

:::</description><pubDate>Fri, 01 Dec 2023 09:37:25 +0000</pubDate></item><item><title>任意の文章のLLM事前学習を検出する新ツール発表　ワシントン大学とプリンストン大学
</title><link>https://ledge.ai/articles/detecting_pretraining_data_llm</link><description>:::small
画像の出典：Detecting Pretraining Data from Large Language Models
:::


米国ワシントン大学と米国プリンストン大学に所属する研究者らが2023年11月3日に発表した論文{target=“_blank”}は、任意の文章が大規模言語モデル（LLM）で事前学習されているかを検出するツールを提案したものだ。

大規模言語モデル（LLM）の訓練には、非公開で問題を引き起こす可能性があるテキスト（著作権で保護された文書、個人識別情報、ベンチマークのテストデータなど）が含まれることがある。過去の研究で、LLMが著作権で保護された書籍の一部や個人のメールを生成した事例がある。しかし現在、LLMの訓練データに何がどれだけ含まれているかを知る方法はない。

この研究は、どの事前学習データが使用されたか不明な状況で、特定のテキストが言語モデルの事前学習データに含有されているかを判断できるかを評価するものだ。ベンチマークとして「WIKIMIA」、検出手法として「MIN-K% PROB」が提案されている。

WIKIMIAは、モデル訓練前後のWikipediaデータを利用している。MIN-K% PROBは、外れ値トークンの平均確率を計算するものだ。実験では従来の方法よりも高い性能を示し、特にWIKIMIAでのAUCスコアが7.4%向上した。また「著作権のある書籍の検出」「プライバシー監査」「データセットの汚染検出」で優れた性能を発揮した。

!

:::small
画像の出典：Detecting Pretraining Data from Large Language Models
:::

著作権のある書籍の検出に関する実験では、GPT-3がBooks3データセットに含まれる著作権で保護された書籍を使用して事前学習された可能性が高いことを示す証拠が見つかった。またプライバシー監査の実験では、著作権で保護された書籍の情報を忘れさせるように訓練されたLLMを再検証した。その結果、依然として著作権で保護されたコンテンツを生成する可能性があることを示唆した。



:::box

:::
:::box

:::
</description><pubDate>Wed, 29 Nov 2023 03:55:50 +0000</pubDate></item><item><title>テキストから動画を生成「Stable Video Diffusion」GitHubで公開ーーStability AI</title><link>https://ledge.ai/articles/stable_video_diffusion</link><description>:::small
画像の出典：{target=“_blank”}
:::

Sability AIは2023年11月22日、Stable Diffusionを基にした最初の動画生成用基盤モデル「Stable Video Diffusion」を{target=“_blank”}した。現在は研究プレビューとして、コードは{target=“_blank”}で公開され、ローカルでのモデルの実行に必要なウェイトは{target=“_blank”}のページで確認可能だ。

Stable Video Diffusionは、14フレームおよび25フレームを生成できる2種類の画像からビデオへのモデルとしてリリースされ、3～30フレーム/秒のカスタマイズ可能なフレームレートでの生成が可能だ。このモデルは、単一画像からのマルチビュー合成など様々なタスクに適応可能で、広告、教育、エンターテイメントなど多数のセクターでの実用的な応用が示されている。

@
:::small
{target=“_blank”}
:::

現段階では研究専用であり、実世界や商用アプリケーションでの使用は意図されていないとのこと。


:::box

:::
:::box

:::
:::box

:::</description><pubDate>Fri, 24 Nov 2023 05:44:50 +0000</pubDate></item><item><title>Google DeepMindの気象予測AI「GraphCast」従来型を上回る精度で10日先までの天気を1分未満で予測</title><link>https://ledge.ai/articles/google_deepmind_graphcast</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国Google DeepMindは2023年11月14日、従来の天気予報システムよりも高速かつ精密な中期天気予報を実現する最新のAIモデル「GraphCast」を{target=“_blank”}した。

同日「Sience」に掲載された{target=“_blank”}によると、このモデルは、10日先までの天気を1分未満で予測し、業界の標準である欧州中期天気予報センター（ECMWF）の高解像度予報（HRES）よりも優れた精度を誇るという。

GraphCastは、データ駆動型の深層学習を用いて、地球の天候がどのように進化するかの因果関係のモデルを学習する。これにより、サイクロンの進路予測や洪水リスクに関連する大気河の特定、極端な気温の発生予測が可能となり、これらは災害への備えとして重要な役割を果たす。

また、GraphCastは機械学習とグラフニューラルネットワーク（GNN）を基に構築されており、空間的に構造化されたデータの処理に特に適している。このシステムは、GoogleのTPU v4マシン1台で10日間の予報を1分未満で行うことが可能で、従来の手法と比べて大幅な効率化を実現している。
@
:::small
Google DeepMindチャンネル「10 日間にわたる GraphCast の予測の抜粋」
:::

DeepMind によるとGraphCastは、従来の他の予報モデルと比較して、1380のテスト変数と予報期間のうち90％以上でより正確な予測を提供。特に、地球表面に最も近い大気圏である対流圏において、99.7%のテスト変数でHRESモデルを上回っているという。

同社はGraphCastのモデルコードを{target=“_blank”}し、世界中の科学者や予報者が利用できるようになっている。すでにECMWF を含む気象機関によって使用されており、 Web サイトではモデルの{target=“_blank”}を実行している。


:::box

:::
:::box

:::
:::box

:::</description><pubDate>Tue, 21 Nov 2023 01:08:16 +0000</pubDate></item><item><title>LLMにおけるハルシネーションの包括的調査を発表ーーハルビン工業大学とHuawei研究チーム</title><link>https://ledge.ai/articles/a_survey_on_hallucination_in_llm</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2023年11月、中国のハルビン工業大学とHuaweiの研究チームは、大規模言語モデル（LLM）内で発生する「ハルシネーション（幻覚）」に関する包括的な調査結果を{target=“_blank”}した。

研究チームは、幻覚を「実際性幻覚（factuality hallucination）」と「忠実性幻覚（faithfulness hallucination）」の2つのカテゴリーに分類。実際性幻覚は、生成された内容が実際の事実と矛盾する場合を指し、忠実性幻覚は、提供されたコンテキストに対して不一致な内容を生成する場合を指す。

論文では、これらの幻覚が発生する原因を深く探究し、訓練データの質の問題や学習アルゴリズムの不備、モデルの推論プロセスに関連する課題が主要な原因であることを明らかにしている。

!
:::small
画像の出典：{target=“_blank”}
:::


また、研究チームは、幻覚の問題を特定し対処するための具体的な戦略を提示している。これには、データの質の向上、訓練プロセスの改善、推論戦略の最適化が含まれる。これらの対策は、LLMがより正確で信頼性の高い生成内容を提供するための鍵となる。

未解決の課題と将来の研究方向性についても、幻覚のさらなる理解、新たな検出および対処方法の開発、実際のアプリケーションにおける影響の評価などを今後の研究の重点として提案した。


:::box

:::
:::box

:::</description><pubDate>Mon, 20 Nov 2023 02:43:45 +0000</pubDate></item><item><title>GPT-4は研究論文を査読できるか？スタンフォード大らNature等論文約4,800本で検証「LLMは査読にも有用」</title><link>https://ledge.ai/articles/llm_can_provide_useful_feedback</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2023年10月3日、大規模言語モデル（LLM）が研究論文の査読プロセスにどの程度有用であるかを示す研究結果が{target=“_blank”}された。この研究は、スタンフォード大学を始めとする研究チームによって行われた。Nature系列の論文3,096本とICLRの論文1,709本、合計4,805本の論文を対象に、GPT-4を使用して生成されたフィードバックと人間による査読フィードバックの有用性を比較した。その結果、LLMが科学的フィードバックの生成に有用であり、人間の査読プロセスに役立つことが示された。

この研究の背景には、科学的フィードバックの提供プロセスが、従来の査読や会議ディスカッションなどの手段によって提供される場合に、時間などのリソースや専門知識の制約に直面しているという課題がある。特に、学術論文の急速な増加と科学知識の専門化が進む中、高品質なフィードバックを提供できる査読者の確保が困難になっている。この課題に対応するため、LLMのような技術を活用して科学的フィードバックを効率的に提供する方法が求められている。

研究結果によれば、GPT-4によるフィードバックの品質は、Nature系列の論文で平均30.85%、ICLRで39.23%の一致率を示し、これは2人の人間による査読者間の一致率（Nature系列で28.58%、ICLRで35.25%）と比較しても高いことが判明した。また、研究者308名からのフィードバックによれば、57.4%の研究者がGPT-4によるフィードバックを有用と感じ、82.4%が一部の人間の査読者よりもGPT-4のフィードバックの方が有益だと感じたとのこと。
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::</description><pubDate>Thu, 02 Nov 2023 07:41:22 +0000</pubDate></item><item><title>国税庁、企業の税務調査にAI本格活用　追徴課税3500億越え　過去10年で最多に</title><link>https://ledge.ai/articles/national_tax_agency_uses_aI_for_tax_audits</link><description>:::small
画像の出典：{target=“_blank”}
:::

国税庁は法人税の税務調査などへAI技術を活用し始めている。2023年11月、令和4事務年度の税務調査成果を{target=“_blank”}した。日経新聞では11月29日、同年度の法人税、消費税、源泉所得税の追徴税額が3563億円に達し、前年度比では40.5%増加しており、10事務年度で最高額と[報じて](https://www.nikkei.com/article/DGXZQOUE277TW0X21C23A1000000/
){target=“_blank”}いる。

6月に改訂された国税庁の「{target=“_blank”}」によると、AI技術は、大量のデータを分析し、異常を特定し、税逃れの可能性があるケースをフラグ付けするために利用されている。このアプローチにより、税務申告の不整合をより効率的かつ正確に検出することが可能になり、税務調査の効果が向上する。また、AIの使用は、税務管理に関わる膨大なデータを扱う際のプロセスを効率化し、税金徴収をより効果的にすることを支援する。

!
:::small
画像の出典：{target=“_blank”}
:::

国税局ではこのほか、e-Taxのユーザーインターフェースとユーザーエクスペリエンスの改善、自動入力システムの導入、オンライン手続きの拡充など、AIやデータ分析を含むデジタルツールの活用を通じ、納税者の利便性を高め、課税・徴収事務の効率化及び高度化を図る。

:::box

:::</description><pubDate>Tue, 12 Dec 2023 07:18:58 +0000</pubDate></item><item><title>EUがAI規制の包括的規範を示す世界初の「AI法」に合意　重大な違反には罰則規定も</title><link>https://ledge.ai/articles/eu_aiact</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年12月9日、欧州議会は理事会と共に、AIの安全性、基本的人権の尊重、民主主義の保護、ビジネスの繁栄と拡大を目的としたAI法案（AI Act）についておおむね政治的合意に至ったことを{target=“_blank”}した。この規制は、高リスクAIによる基本的人権、民主主義、法の支配、環境持続性の保護を目的とし、革新を促進し、欧州をこの分野のリーダーにすることを目指している。規則は、AIの潜在的リスクと影響レベルに基づいて義務を設定する。

欧州委員会委員長のウルズラ・フォン・デア・ライエン氏は、自身のX（旧Twitter）に「The EU AI Act is a global first.（ AI Actは世界初のものです）」と{target=“_blank”}している。


この法案では、市民の権利と民主主義に対する特定のAIアプリケーションの潜在的な脅威を認識し、以下のアプリケーションを禁止することに合意した：

- 政治的、宗教的、哲学的信念、性的指向、人種などの敏感な特性を使用するバイオメトリック分類システム
- 顔認識データベースを作成するためのインターネットや監視カメラ映像からの顔画像の無差別スクレイピング
- 職場や教育機関での感情認識
- 社会的行動や個人的特性に基づく社会的評価
- 人間の行動を操作して自由意志を回避するAIシステム
- 年齢、障害、社会的または経済的状況による人々の脆弱性を悪用するAI

さらに、一般的なAI（GPAI）システムと、それらに基づくGPAIモデルには、当初議会が提案した透明性要件が適用されることが合意された。これには、技術文書の作成、EU著作権法の遵守、トレーニングに使用されたコンテンツに関する詳細な要約の普及が含まれる。

システムリスクの高いGPAIモデルには、より厳格な義務が課せられる。これらのモデルが特定の基準を満たす場合、モデル評価の実施、システムリスクの評価と軽減、敵対的テストの実施、重大なインシデントに関する欧州委員会への報告、サイバーセキュリティの確保、エネルギー効率に関する報告が必要とされる。議会交渉者は、調和されたEU規格が公開されるまで、システムリスクを有するGPAIは、規制に適合するための実践コードに依存することができるよう主張した​​。

ルールに従わない場合の制裁も定められている。違反の程度と企業の規模に応じて、最大3500万ユーロまたはグローバル売上の7％、または750万ユーロまたは売上の1.5％の罰金が課される可能性がある​​という。

合意文書は正式に欧州議会と理事会によって採択される必要があり、その後EU法となる。欧州議会の内部市場および市民の自由委員会は、今後の会合でこの合意について投票が予定されている。


:::box

:::
:::box

:::
</description><pubDate>Mon, 11 Dec 2023 05:55:46 +0000</pubDate></item><item><title>G7首脳、生成AIの国際ルールを承認　「広島AIプロセス」で合意</title><link>https://ledge.ai/articles/g7_hiroshima_ai_process_approval</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年12月6日、主要7カ国（G7）の首脳は、日本が議長国として主催したオンライン会議で、12月1日に開催したG7デジタル・技術大臣会合で採択された生成AIに関する新たな国際ルール「広島AIプロセス G7デジタル・技術閣僚声明」を{target=“_blank”}した。この会議は、日本議長年を締めくくるG7首脳テレビ会議として開催され、生成AI技術の進展とその社会への影響を総括する目的で行われた。

会議では、「広島AIプロセス」と称される共通の基本的な方針に各国が合意。AIの開発者や利用する企業に安全性の確保などを求める内容を含む。また、G7は生成AIに関する初の包括的な国際ルールについても合意し、AIによる情報生成が偽情報の拡散につながることへの懸念に基づき、AIの開発者から利用者までを含む世界初の包括ルールをまとめた。

10月30日には、G7首脳が広島AIプロセスに関するG7首脳声明を発出し、高度なAIシステムを開発する組織向けの広島プロセス国際指針を確立。生成AIや没入型技術に関するG7の価値に沿ったガバナンスの必要性が確認され、特に生成AIについては、広島AIプロセスの下で担当閣僚が速やかに議論を進め、本年中に結果を報告することで一致した。



:::box

:::
:::box

:::
</description><pubDate>Mon, 11 Dec 2023 05:51:20 +0000</pubDate></item><item><title>MetaとIBMが新団体「AI Alliance」立ち上げ。産業界、政府機関、学界にわたる主要組織と共にオープンで責任あるAIを目指す
</title><link>https://ledge.ai/articles/the_ai_alliance</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国MetaとIBMは2023年12月5日、共同で新団体「AIアライアンス」を立ち上げたことを{target=“_blank”}した。この国際的なコミュニティは、50以上の創設メンバーおよびコラボレーターと共に、オープンで安全かつ責任あるAIの進展を目指している。

参加施設は、AMD、Anyscale、CERN、Cerebras、Cleveland Clinic、コーネル大学、Dartmouth、デルテクノロジーs、EPFL、ETH、Hugging Face、ロンドン王立大学、インテル、INSAIT、Linux Foundation、MLCommons、NASA、NSF、Oracle、Partnership on AI、Red Hat、Roadzen、SakanaAI、ServiceNow、ソニーグループ、Stability AI、カリフォルニアバークレー大学、イリノイ大学、ノートルダム大学、東京大学、イエール大学など。

安全性、多様性、経済的機会を優先しながらAIのイノベーションを取り入れるためには、研究者、開発者、採用者に情報とツールを提供することが不可欠。そのため、業界、スタートアップ、学術界、研究機関、政府などが協力し、オープンイノベーションとオープンサイエンスをサポートするAIアライアンスを立ち上げたという。

AIアライアンスは、オープンなコミュニティの育成と、AIにおける責任あるイノベーションの加速を目指しており、科学的厳密さ、信頼性、安全性、セキュリティ、多様性、経済競争力を確保するために、主要な開発者、科学者、学術機関、企業、その他のイノベーターと協力して、安全性の懸念に対処し、世界中の研究者、開発者、採用者のニーズに合ったソリューションを共有し開発するプラットフォームを提供する​​。

:::box

:::
:::box

:::</description><pubDate>Thu, 07 Dec 2023 07:14:39 +0000</pubDate></item><item><title>JAXA、夏頃からサイバー攻撃を受けていたーーネットワークにはロケットや衛星などの機微情報なし</title><link>https://ledge.ai/articles/unauthorised_access_to_jaxa</link><description>:::small
画像の出典：{target=“_blank”}
:::

宇宙航空研究開発機構（JAXA）が2023年夏ごろにサイバー攻撃を受け、内部ネットワークに不正アクセスされていたと11月29日に各メディアが報じた。この攻撃は外部機関の通報により発覚し、役職員5000件余りの個人情報などが内部のサーバーから漏えいした可能性があるという。JAXAおよび文部科学省は、攻撃されたネットワークがロケットや衛星の運用に関するものではないため、機密性の高い情報の漏えいは低いとしている。

JAXAは現在、関係機関と連携し、被害範囲や攻撃方法の詳細調査を進めている。同機構はセキュリティ関連の事案のため、詳細については回答を控え、引き続き調査と対策を行っていくとしている。

この日の内閣定例記者会見では、松野官房長官が、JAXAの内部調査結果を踏まえ、不正アクセスの可能性を確認し、早急な調査と対策を進めるよう指示したことを{target=“_blank”}。JAXAは影響調査を直ちに開始し、関連ネットワークの遮断などの対応を実施している。

同日参議院の{target=“_blank”}でも、この件が質問に挙がり、自民党の赤松議員がJAXAに対し、報道からJAXAがサイバー攻撃を受け機微な情報が漏洩した可能性があるのではと指摘した。JAXA理事長の山川氏は、攻撃を受けたことは事実だが、機微な情報は別のネットワークで管理しており、漏洩していないと説明。JAXAは情報セキュリティを重視しており、本件も含め対策を講じていると述べ、議員は引き続き調査するよう求めた。

:::box

:::
:::box

:::</description><pubDate>Fri, 01 Dec 2023 11:04:55 +0000</pubDate></item><item><title>日米英などG7含む計18か国が参加、国際AIセキュリティガイドラインに共同署名</title><link>https://ledge.ai/articles/guidelines_for_secure_ai_system_development</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

内閣府科学技術・イノベーション推進事務局と内閣サイバーセキュリティセンターは2023年11月28日、英国国家サイバーセキュリティセンター（NCSC）と米国サイバーセキュリティ・インフラストラクチャー安全保障庁（CISA）等が作成した「セキュアAIシステム開発ガイドライン」に共同署名したと{target=“_blank”}した。日本のほかG7各国含む計18か国が参加した。

この文書は「セキュアバイデザイン」（特にソフトウェアなどのIT製品について、セキュリティを確保した設計を行うこと）の観点から、AIシステムの構築を支援する指針となっているという。このガイドラインは、G7広島AIプロセスを補完するものであり、高度なAIシステム開発組織向けの国際行動規範も記載されている。

内閣府は、この文書がAIのセキュリティ強化に貢献し、国際連携の基礎となるとして共同署名に加わった。今後も、技術の進歩を踏まえ、産業界との対話を継続し、AI及びサイバーセキュリティ分野での国際連携を強化していく予定だ。

参考：{target=“_blank”}
{target=“_blank”}

:::box

:::
:::box

:::</description><pubDate>Fri, 01 Dec 2023 10:13:48 +0000</pubDate></item><item><title>神戸市、業務でAIを利用する際のルールを条例化へ</title><link>https://ledge.ai/articles/kobe_new_ordinance_ai</link><description>:::small
画像の出典：神戸市
:::

神戸市は2023年11月24日、業務でAIを利用する際のルールを条例化すると{target=“_blank”}した。「（仮称）神戸市における AI の活用等に関する条例」の制定を予定しており、本条例の制定に向けた有識者会議の設置及び意見募集手続きを実施する。


神戸市は、全国に先駆けてChatGPTを含む生成AIに関する「神戸市情報通信技術を活用した行政の推進等に関する条例」を5月に改正した。今後さらにAI技術の幅広い活用が見込まれるため新たな条例を制定し、AIを安全かつ効果的に活用する社会を目指す。

条例（案）には基本指針の策定、リスクアセスメントの実施、AIチャットボット、市民・事業者のAI活用施策、学校教育でのAI適正使用教育、AI活用アドバイザーなどが含まれる。条例は神戸市および市の業務を請負・受託する事業者が対象であり、市民や一般事業者のAI活用を制限するものではない。

条例制定にあたり、市民・事業者からの意見募集を2023年11月24日から12月25日まで実施する。AI条例案に対する意見聴取のための有識者会議を設け、第1回は2023年11月30日に開催予定。


:::box

:::
</description><pubDate>Wed, 29 Nov 2023 03:48:19 +0000</pubDate></item><item><title> 物流ドローンが越佐海峡を横断するラストワンマイル配送 -国土交通省の実証事業を公開</title><link>https://ledge.ai/articles/sado_drone_last_one_mile</link><description>:::small
画像の出典：{target=“_blank”}
:::

JR東日本新潟シティクリエイトとAIR WINGSは2023年11月16日、新潟市、佐渡市と協力し、国土交通省が支援するラストワンマイル配送実証事業の一環として、過疎地域でのレベル4飛行に対応するドローン物流の実現を目指す事業を開始したことを{target=“_blank”}した。この事業は、越佐海峡を初めて物流ドローンが横断し、新たな物流動線を開拓する目的を持つ。実証実験のとりまとめとドローン運航責任者であるAIR WINGSは、同月21日と22日に、検証のためのドローン飛行を{target=“_blank”}した。

!
:::small
画像の出典：{target=“_blank”}
:::

実証事業では、同社の列車荷物輸送サービス「はこビュン」と連携し、佐渡の新鮮な海産品（南蛮エビ・メガニ）を東京都内の飲食店にスピーディーに運ぶことを予定している。今回の実証事業では佐渡で獲れる人気の南蛮エビ、メガニが東京のレストランまで配送された。

さらに、復路便では医療物資の輸送も検討されており、ドローンポートを利用した自動受け取り機能と輸送品質の担保に関する検証が実施される。これには、伊藤忠商事株式会社が機材の一部や測定機器を提供し、AIR WINGS合同会社が運航を担当する。この取り組みは、離島医療物流が抱える課題を解決するための有効な手段となることが期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::</description><pubDate>Tue, 28 Nov 2023 07:08:55 +0000</pubDate></item><item><title>ドローン規制緩和案「レベル3.5」新設で無人地帯の物流促す「年内にも事業化をスタート」河野デジタル大臣</title><link>https://ledge.ai/articles/drone_level3-5</link><description>:::small
画像の出典：{target=“_blank”}
:::

デジタル庁の河野大臣は2023年11月20日の定例記者会見で、ドローン規制の緩和について今後の方針を{target=“_blank”}。これは、17日に開かれた規制改革推進会議の{target=“_blank”}で、政府の示した山間地など無人地帯でのドローン利用の規制緩和案に基づくものだ。

新たに「レベル3.5」を設定し、飛行経路下に人がいない場合の補助員の配置を不要とする。これにより道路や鉄道上を飛ぶことが容易になり、迅速な配達が期待されるという。

!
:::small
画像の出典：{target=“_blank”}
:::

ドローン飛行の難易度に応じて、国はレベル4までの分類を設けている。レベル3は目視外飛行を人がいない川や森林で許可しているのに対し、レベル4では住宅地など人口密集地域でも飛行可能となる。現行のレベル3では、人が立ち入る可能性のある鉄道や道路、船の航路などを飛行する際には補助者の配置や案内板の設置が必要とされる。

!
:::small
画像の出典：{target=“_blank”}
:::

新たに導入されるレベル3.5案では、ドローンに搭載されたカメラで歩行者を確認する、保険へ加入する、人を確認した場合は迂回する、などの条件を設定するという。

河野大臣は、各地でドローンを使った実証実験を行っているにも関わらず、実験にとどまり事業化に至らないケースが多い。しかし、無駄な規制を廃することでドローンによる配送の事業化が全国各地で進むようにしたい。また、年内にも事業化をスタートできるようスピード感を持ってやっていきたいと述べた。

:::box

:::
:::box

:::
</description><pubDate>Wed, 22 Nov 2023 06:43:46 +0000</pubDate></item><item><title>「人間中心」を最優先、政府がAI事業者向けのガイドライン原案提示
</title><link>https://ledge.ai/articles/human_centered_guideline_japan</link><description>:::small
画像の出典：写真AC
:::

日本政府がAI関連の国内事業者向けに策定を進めるガイドライン（指針）の原案が判明したと、2023年11月8日に{target=“_blank”}が報じた。全ての事業者が共通して考慮すべき指針として「公平性」「透明性」などの10原則を掲げており、有識者による「AI戦略会議」での議論を経て年末までに決定する方針。

原案は、11月7日の同会議で非公式に提示された。対象は省庁や公的機関も含む、全てのAI事業利用者だ。10原則の中で「人間中心」を最優先とし「個人の尊厳を尊重し、生じうる不利益に慎重に留意する」「人間の意思決定や感情を不当に操作することを目的としたAIの開発・提供は行わない」ことなどを求めた。

偽情報対策については、社会を混乱させるリスクを認識した上で「必要な対策を講じる」とした。公平性の原則では、AIのバイアス（偏り）を防ぐために人間の判断が介在することを強調。

透明性の原則では、データ収集の方法に関する情報提供を、また説明責任の原則ではデータの出所追跡を要求した。具体的な著作権侵害などの課題には触れなかった。

開発事業者には第三者が検証可能な文書化を留意事項とし、提供事業者と利用事業者にもそれぞれ留意事項を記した。



:::box

:::
:::box

:::

</description><pubDate>Fri, 10 Nov 2023 09:49:28 +0000</pubDate></item><item><title>MidjourneyとStability AIの著作権問題「実質的類似性」証明できず　アーティストたちの訴え棄却</title><link>https://ledge.ai/articles/lawsuit_against_stabilityai_dismissed</link><description>:::small
画像の出典：{target=“_blank”}
:::

カリフォルニア連邦地方裁判所は2023年10月30日、Stability AI、Midjourney、DeviantArtを相手取り、サラ・アンダーセン氏、ケリー・マッケルナン氏、カーラ・オルティス氏が提起した集団訴訟案のうち、MidjourneyとDeviantArtに対するすべての申し立てを含む一部の申し立てを{target=“_blank”}。

訴えによると、これらの企業は、著作権で保護された作品を無断で使用してAI「Stable Diffusion」を訓練したとのこと。裁判所は、アンダーセン氏による直接的な著作権侵害の主張の一部を除き、その他の訴えを退けた。

裁判所が訴えの一部を棄却した主な理由は、原告側が著作権侵害の主張に必要な「実質的類似性」を証明できなかったこと、そしてMidjourneyとDeviantArtに対する申し立てについては、それらの企業が画像の「スクレイピング」やAIトレーニングにどのような役割を果たしたかを証明できなかったことが挙げられる。さらに、アンダーセン氏は著作権を登録していたが、マッケルナン氏とオルティス氏が彼らの作品に対して著作権登録をしていなかったため、著作権訴訟を起こすための法的要件を満たしていなかったとした。

裁判官は、AI出力が原告の作品と「実質的に類似していない」と判断し、その主張についてはさらなる証明が必要であると述べた。原告の弁護士は、中心となる主張が生き残ったとし、修正された訴えを提出することで裁判所の懸念を解消すると主張した。

原告の弁護にあたる{target=“_blank”}は、同年1月13日、Stability AI、Midjourney、DeviantArtを相手取り、カリフォルニア州北部地区連邦地方裁判所に訴状を提出した。訴状では、アーティストたちに対する著作権侵害、DMCA違反、パブリシティ権侵害、DeviantArt利用規約違反、不正競争、不当利得を主張している。また、すでに発生した損害を賠償し、将来の損害を防止するために、損害賠償と差止命令による救済措置を求めていた。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Thu, 09 Nov 2023 01:24:18 +0000</pubDate></item><item><title>岸田首相のフェイク動画拡散「政府の情勢を偽り発信することは民主主義の基盤傷付ける」内閣官房長官が懸念示す</title><link>https://ledge.ai/articles/the_prime_ministes_fake_video_spread_on_x</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2023年11月6日、内閣官房長官の{target=“_blank”}で、11月2日に、岸田首相の画像や音声を使ったフェイク動画がSNSに投稿された件について記者が質問をした。これに対し松野官房長官は、岸田総理の偽動画の広まりについて懸念を表明しつつ、SNS上の個別の投稿についてはコメントを控えると前置きした。その上で、政府の情勢を偽って発信することは、場合によっては民主主義の基盤を傷つけかねないため行われるべきではないと一般論として指摘した。

!
:::small
画像の出典：
:::

また海外でのフェイク動画問題を踏まえ、政府は関係省庁と連携し対策を検討していく考えを表明した。
広島AIプロセスにおいて議長国である日本は、国際的な指針や行動規範、偽情報対策に関するプロジェクトベースの取り組みを提案しており、偽情報対策の中では、コンテンツの出所を特定する技術についても議論しているという。

!
:::small
画像の出典：
:::

問題となった動画は、日テレNEWSのロゴを使用し、ニュース番組の画面に見せかけたフェイク動画で、首相の声を生成AIに学習させて作られたものと考えられている。今年の8月にニコニコ動画に投稿されていたものが一部切り取られ、11月2日再度X（旧Twitter）に投稿された。11月3日放送の「news zero」で日本テレビは「放送、番組ロゴをこのようなフェイク動画に悪用されたことは、到底許すことはできません。フェイク動画について今後も必要に応じて然るべき対応をして参ります」と{target=“_blank”}した。


:::box

:::
:::box

:::
:::box

:::</description><pubDate>Tue, 07 Nov 2023 13:48:18 +0000</pubDate></item><item><title>ディープニューラルネットワーク（DNN）で自然な歌声を合成『Synthesizer V AI Megpoid（メグッポイド）』12月20日発売</title><link>https://ledge.ai/articles/synthesizer_v_ai_megpoid</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年11月21日、株式会社インターネットが歌声合成データベース『Synthesizer V AI Megpoid（メグッポイド）』を12月20日に発売することを{target=“_blank”}した。

「Synthesizer V AI Megpoid」は、同社と株式会社AHSが共同で開発したDNN（ディープニューラルネットワーク）を搭載した歌声合成技術による人間らしい歌唱が可能な歌声データベースだ。Synthesizer V Studio Proを使用することで、多言語歌唱、様々なボーカルスタイル、AIリテイク機能が利用できる。特に、ラップ歌唱機能は、日本語、英語、中国語のラップに対応し、リアルなラップフローの再現が可能だという。

@

「Synthesizer V」は、Dreamtonics株式会社が開発する強力な音声処理エンジンと直感的に操作可能なUIを併せ持つボーカルシンセサイザーで、メロディーと歌詞を入力することでオリジナルソングを作成できる。歌声合成ソフトウェア「Synthesizer V Studio Basic」が付属している。

『Megpoid(GUMI)』は、声優・歌手の中島愛の声を元に制作され、2009年にVOCALOID2で登場した。VOCALOID6対応のボイスバンク「VOCALOID6 Voicebank AI Megpoid」が2022年10月に発売されている。

:::box

:::</description><pubDate>Fri, 08 Dec 2023 15:15:07 +0000</pubDate></item><item><title>AIで蘇る伝説のレーサーたちがリアルF1ドライバーとバーチャル対決「Lap of Legends」米で24年春テレビ公開予定</title><link>https://ledge.ai/articles/lap_of_legends</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国ビールメーカーAnheuser-Busch のビールブランド Michelob ULTRA は2023年11月17日、 Williams Racingとのパートナーシップを祝い、45年にわたるレースの歴史を振り返る「Lap of Legends」テレビスペシャルを公開すると{target=“_blank”}した。

この番組はAIとARを利用し、実在のF1ドライバーが Williams Racingの伝説的なドライバーたちのバーチャルアバターと対決するという、リアル対バーチャルのレースを特徴としている。

Michelob ULTRAとWilliams Racingが、数千時間のレース映像と歴史的データを分析し、AIを用いてF1の伝説のドライバーたちのスピード、レーシングスタイル、技術、戦略を模倣してバーチャルドライバーを作り上げた。ジェンソン・バトン、ジャック・ヴィルヌーヴ、マリオ・アンドレッティなど、F1の異なる世代のドライバーが特集される。

@


番組は、2024年春にAMC、BBCアメリカ、The Roku Channelで放映されたのち、世界28カ国で配信の予定。


:::box

:::
:::box

:::</description><pubDate>Fri, 08 Dec 2023 15:07:34 +0000</pubDate></item><item><title>FIAが走路外走行の検出にAIとコンピュータービジョンを導入、F1アブダビGPから</title><link>https://ledge.ai/articles/fia_insights_computer_vision</link><description>:::small
画像の出典：FIA
:::

国際自動車連盟（FIA）は2023年11月23日、F1第23戦アブダビGPで、AIとコンピュータービジョンを走路外走行の検出に導入したと{target=“_blank”}した。

F1レースではドライバーがギリギリのラインを攻めるため、車両の全輪が白線外に出る走路外走行が発生することがある。2023年7月のF1第10戦オーストリアGPでは、20人のドライバーのうち走路外走行をしなかったのは2人だけで、走路外走行の可能性が指摘された件数は1200件以上に上ったという。

FIAによると走路外走行かどうかをチェックする人員は4人で、83件が違反と認められたが、すべての違反の可能性を検証することはできなかった。参加チームからは、レース中の指摘に対する不満の声が上がっていた。

実際に第18戦カタールGPから、チェック人員を8人に増員。第23戦アブダビGPでは、コンピュータービジョンとAIを用いた走路外走行の検出が導入された。

FIAはAIシステムを導入しても、最終的な判断は人間が行い、AIは明らかに走路外走行ではないものを除外する役割を担当するとしている。AIシステム導入により、1レースあたりの手動審査件数を約50件に減らしたいとのこと。

:::box

:::</description><pubDate>Fri, 01 Dec 2023 10:03:00 +0000</pubDate></item><item><title>独自のAI活用アニメーション構築フローで制作の工程を効率化‐‐KaKa Creation1.6億円の資金調達完了</title><link>https://ledge.ai/articles/hinahima_kakacreation</link><description>:::small
画像の出典：{target=“_blank”}
:::

KaKa Creationは2023年11月22日、約1.6億円の資金調達を完了し、AIアニメ制作事業をはじめとする制作・プロデュース事業を開始したことを{target=“_blank”}した。

「AIの力で、創造する人に力を。もっと、世界をつなぐクリエイションを」というミッションのもと、同社は独自のAIアニメーション構築フローを開発し、様々なアニメコンテンツを世界に向けて展開する。AIで作業工数を削減させ、人間のクリエイターは創造的な作業に尽力できる世界を目指す。

アニメ制作においては、主にTikTokやYouTube Short などのプラットフォームを中心に縦型ショートアニメの制作を行う。第一弾として、TikToker「ひなひま」という双子のアニメキャラクターを登場させた。

このキャラクターは主に、CGソフトとAIソフトの2つを使用してアニメ制作を行っている。3DアニメをStable Diffusionでセルアニメに変換するというアイディアをベースにした独自のワークフローを構築。

Stable Diffusion単体でのアニメ制作が難しい仕様であったため、サブツールとしてMaya（Autodesk社）、Unreal Engine5（Epic Games社）などで作成したCG映像を、AIがアニメ生成をする際の参照元データと設定。最終的にStable Diffusionでアニメを制作したという。


@
:::small
{target=“_blank”}
:::

KaKa Creationは、AIの活用を「工程の効率化」と捉え、人を感動させられるのは人間の創造力と意志であると考えている。AIをサポートツールとして用いる「サポーティブAI」という概念を採用し、アニメ業界の課題解決を目指す。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Fri, 01 Dec 2023 09:40:35 +0000</pubDate></item><item><title>AIと人間の共同創作「ブラック・ジャック」新作完成『TEZUKA2023プロジェクト』週刊少年チャンピオンで公開</title><link>https://ledge.ai/articles/tezuka2023_blackjack_heartbeat_markII</link><description>:::small
画像の出典：{target=“_blank”}
:::

「TEZUKA2023」プロジェクトの一環として、AIと人間の協力により制作された「ブラック・ジャック」の新作『TEZUKA2023 ブラック・ジャック 機械の心臓―Heartbeat Mark II』が、2023年11月22日に「週刊少年チャンピオン」52号（秋田書店）に{target=“_blank”}。

この企画は、クリエイターと「ブラック・ジャック」を学習したAI のインタラクティブなやりとりにより、「ブラック・ジャック」の新作を制作するもの。「TEZUKA2020」として2019年にスタート。

2020 年7月「インタラクティブなストーリー型コンテンツ創作支援基盤の開発」として国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）「人と共に進化する次世代人工知能に関する技術開発事業」に採択され、に慶應義塾大学 栗原教授はじめ、手塚プロらが中心となるチームにて研究が継続された。

2023年6月に手塚プロダクションが「TEZUKA2023」プロジェクトとして誕生50周年を迎える名作漫画「ブラック・ジャック」の完全新作の制作開始を{target=“_blank”}し、完成が待たれていた。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Wed, 29 Nov 2023 05:41:26 +0000</pubDate></item><item><title>AIが、ジョン・レノンの声だけ採り出し完成　ビートルズ最後の新曲『Now and Then』ミュージックビデオ公開</title><link>https://ledge.ai/articles/beatles_ai_nowandthen</link><description>:::small
画像の出典：{target=“_blank”}
:::

ビートルズ最後の新曲「Now and Then」が2023年11月2日にリリースされた。YouTubeの TheBeatles 公式チャンネルでは、オフィシャルの音源と共にミュージックビデオとドキュメンタリー・ショートフィルム『The Beatles - Now And Then - The Last Beatles Song』を{target=“_blank”}した。ドキュメンタリーでは、どのようにこのプロジェクトが進められたかを追っている。

@

今年の6月、元メンバー、ポール・マッカートニー氏がBBCのインタビューで、AIを使用して制作されたビートルズの最後の楽曲が年内にリリースされることをし話題となった。

「Now and Then」は、1995年にビートルズ・アンソロジー・プロジェクトの一環としてポール、ジョージ、リンゴによって始められたが、70年代にジョンが録音したボーカルとピアノの音を分離させる技術的な課題が乗り越えられず、一旦お蔵入りとなっていた。しかし、2022年、ミュージックビデオの監督ピーター・ジャクソン氏と彼のチームが開発したAIを活用したシステムが、ドキュメンタリーシリーズ「Get Back」の製作を通じて使用され、ジョンのボーカルをピアノパートから分離する道を開いた。

ドキュメンタリーの中でリンゴとポールが、ジャクソン氏の「MAL」と呼ばれるシステムがなんでも取り出してくれるため、ジョンのデモテープを渡して、彼の声を取り出してもらうことにした、と語っている。

@


:::box

:::
:::box

:::</description><pubDate>Fri, 17 Nov 2023 07:18:49 +0000</pubDate></item><item><title>渡辺謙氏「ようやくお知らせすることができます」ハリウッドストが終結し宣伝活動も解禁</title><link>https://ledge.ai/articles/hollywood_strike_comes_to_an_end</link><description>:::small
画像の出典：{target=“_blank”}
:::

俳優の渡辺謙氏が2023年11月9日、自身のXやInstagramなどの公式SNSアカウントで、アメリカ俳優組合のスト終結に伴い、出演作品の宣伝がようやくできると{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

このストライキは、同年7月14日、全米の俳優ら16万人が加入する映画俳優組合（SAG-AFTRA）によって決行され、映画やドラマの製作現場に多大な影響を与えた。

{target=“_blank”}は11月10日、2023年TV/映画契約の仮合意を承認し、組合員への承認投票を呼びかけた。この内容は、映画・テレビプロデューサー連盟（AMPTP）との間で11月8日に暫定合意に達したもの。組合の全国理事会は賛成多数でこの合意を承認し、組合員にも「yes」と投票することを推奨した。

主な合意内容は、新たな賃金と福利厚生制度の資金として総額10億ドル以上に相当する契約、AIの使用に関する意味ある保護（合意と報酬に関する情報の提供を含む）、そして初めての史上最大の賃金増加（2024年7月に11.28%、2025年7月に3.5%の増加）が含まれているという。

AMPTPは、この暫定合意について「新しいパラダイムを代表するものであり、SAG-AFTRAにとって史上最大の契約上の利益をもたらすものである。これには、過去40年間で最大の最低賃金の増加、ストリーミングプログラムのための新たな残業代、AI使用に関する広範な同意と報酬の保護、そして全面的な契約項目の大幅な増加が含まれている」と{target=“_blank”}いる。

:::box

:::
:::box

:::</description><pubDate>Wed, 15 Nov 2023 05:15:37 +0000</pubDate></item><item><title>「テキストからベクター生成」Adobe Illustratorが生成AI「Adobe Firefly」を搭載し進化</title><link>https://ledge.ai/articles/adobe_firefly_text_vector</link><description>:::small
画像の出典：Adobe
:::

米国Adobeは2023年10月10日、年次イベント{target=“_blank”}において「Illustrator」のアップデートを発表した。生成AI「Adobe Firefly」を使った新機能として{target=“_blank”}を披露。プロンプトを入力するだけで、ベクターイメージを生成できる。

Adoobe Illustratorデスクトップ版に導入されたこの新機能は、シンプルなテキストプロンプトからベクターグラフィックが生成可能だ。Adobe Fireflyを搭載し、さまざまな用途に対応できる。

生成したベクターアートは瞬時にアードボード上に表示され、編集や拡大縮小が可能だ。
生成AIモデルは商用利用を想定し、Adobe Stockやパブリックドメインのコンテンツで学習している。

新しい機能には、グラデーションの作成、整理された出力、シームレスなパターン、正確なジオメトリなどが含まれる。また他の生成AIツールとも併用可能だ。デザインにはコンテンツクレデンシャル機能が自動追加され、生成技術と作成ツールの情報を付与。新しいコンテンツは新規レイヤーに作成され、オリジナルのアートワークは保持される。

また「テキストからベクター生成」と同時に、Retype （ベータ版）、モックアップ（ベータ版）、Adobe Illustrator web版（ベータ版）も発表した。


:::box

:::
:::box

:::
</description><pubDate>Wed, 18 Oct 2023 06:30:09 +0000</pubDate></item><item><title>AI Picasso 商用利用できるAIアート用画像生成AI「Emi」と「Manga Diffusion」を無償公開</title><link>https://ledge.ai/articles/ai_picasso_emi_manga_diffusion</link><description>:::small
画像の出典：{target=“_blank”}
:::

AI Picassoは2023年9月25日、AIアート用画像生成AI、Emi (Ethereal master of illustration) を商用利用可能で無償公開すると{target=“_blank”}した。
Emiは商用利用が可能で、追加学習において無断転載画像を学習していない。{target=“_blank”}より無償利用が可能だ。

また、Emiと同時にクリーンな画像生成AI「Manga Diffusion」の概念実証版も{target=“_blank”}。この画像生成AIはパブリックドメインの画像や著作権者から学習を許可された画像だけを学習している。


このモデルは、アニメやマンガのようなAIアート生成に特化している。NVIDIAのGPU「H100」とStable Diffusion XL1.0に同社のノウハウを用いて開発されたとのこと。これまでの生成画像よりも約2倍高精細になり、最近の画風になるように調整されている。

以下は、同じプロンプト（文章による指示）を使用し、これまでのモデルと今回のモデルを比較している。「空、ひまわり、ショートボブヘア、茶色の目、一人の少女」を入力し生成した。
左： Picasso Diffusion 1.1／右： Emi
!
:::small
画像の出典：{target=“_blank”}
:::

その他の特徴には、追加学習に無断転載画像を使用していないこと、商用利用が可能になったことが挙げられる。
ライセンスの商用利用を可能とした理由として同社は
１. 画像生成AIが普及するに伴い、創作業界に悪影響を及ぼさないように、マナーを守る人が増えてきたと感じられるため
２. 他の画像生成AIが商用可能である以上、非商用ライセンスである実効性がなくなってきたため
の2点を挙げた。

AI Picassoは、クリエイターとの協力関係や対話に重きを置いていると述べる。
たとえば同社は「いらすとや」を運営する、みふねたかし氏と約１年相談しながら画像とその説明文を学習用に提供を受け「AIいらすとや」をリリースした。クリエイターからのデータ提供に対する適切な報酬や、生成されたイラストに対する利益配分の仕組みを取り入れているという。また、長期的な関係を通してクリエイターたちと意見交換を行い、信頼関係を築いている。Emiだけでなく、モデルのあり方について、XやDiscordのコミュニティでの対話が続いているという。

:::box

:::
:::box

:::
:::box

:::</description><pubDate>Fri, 13 Oct 2023 05:16:55 +0000</pubDate></item><item><title>ガンダムと人類が共存する次なる未来『GUNDAM NEXT FUTURE PAVILION』大阪・関西万博パビリオン名発表ーーバンダイナムコ</title><link>https://ledge.ai/articles/gundam_next_future_pavilion</link><description>:::small
画像の出典：{target=“_blank”}
:::

バンダイナムコホールディングスは2023年10月6日、大阪・関西万博に出展予定の同グループパビリオンを「GUNDAM NEXT FUTURE PAVILION」と名付け、新たなキービジュアルとパビリオンの外観デザインなどを{target=“_blank”}した。

「機動戦士ガンダム」は、1979年のTVアニメーション放送から40年以上、映像作品や商品・サービスを通じて多くのファンに愛されてきた。これにより、ガンダムは社会的アイコンとしての位置付けを目指している。

「GUNDAM NEXT FUTURE PAVILION」は、「もうひとつの宇宙世紀」をテーマに、ガンダムと人類が共存する未来を示唆している。外観デザインは未来のスペースエアポートを想起させ、人類が宇宙に生活圏を拡大する世界観を反映している。2024年はガンダムの生誕45周年を迎えるため、これまでのそのさらなる可能性に関する考察がパビリオンでの発表が期待されている。

大阪・関西万博は、SDGsの達成と「いのち輝く未来社会」の実現を目指している。この「NEXT FUTURE」プロジェクトは、ガンダムの未来だけでなく、ガンダムとともにある未来を考えることを目的としているという。

:::box

:::
:::box

:::</description><pubDate>Wed, 11 Oct 2023 02:40:04 +0000</pubDate></item><item><title>シンギュラリティのその先を、100年前に重ね合わせてみる「モダン・タイムス・イン・パリ 1925－機械時代のアートとデザイン」展</title><link>https://ledge.ai/articles/pola_museum_modern_times_in_paris1925</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年9月27日、箱根のポーラ美術館が「モダン・タイムス・イン・パリ 1925－機械時代のアートとデザイン」展の開催を{target=“_blank”}した。
会期：2023年12月16日（土）～2024年5月19日（日）

産業革命後の19世紀から20世紀初頭を「機械時代（マシンエイジ）」と呼び、アートの文脈においては、20世紀初頭の工業化とそれに伴う技術的進歩が芸術やデザインに与えた影響を指す。ポーラ美術館では、第一次世界大戦からの復興によって工業化が進む1920年代のパリを中心とした華やかでダイナミックな機械時代に光を当て、1920〜1930年代のパリを中心に、ヨーロッパやアメリカ、日本における機械と人間との関係をめぐる様相を紹介する。

展覧会のみどころとして、同館では「AI時代のはじまりに、機械と人間の関係を問いかける」ことを挙げている。
1920年代、人間の力を大きく凌駕する自動車や航空機という機械文明が急速に普及し、アートの世界でもレジェやブランクーシ、そしてシュルレアリスムの作家などが、機械への賛美や反発を表現していた。
この様相を、AIが人類の知能を超えるとされる「シンギュラリティ」の到来に重ね合わせ、現代を生きる人々へ機械と人間との様々な関係性を問いかけるという。

:::box

:::
:::box

:::</description><pubDate>Fri, 06 Oct 2023 05:33:06 +0000</pubDate></item><item><title>AI進化で地球はどうなる「DXP（デジタル・トランスフォーメーション・プラネット） ―次のインターフェースへ」金沢21世紀美術館でアート展開催</title><link>https://ledge.ai/articles/kanazawa21_dxp</link><description>:::small
画像の出典：{target=“_blank”}
:::

金沢21世紀美術館が主催するアート展「DXP（デジタル・トランスフォーメーション・プラネット）次のインターフェースへ」の開催概要が2023年9月27日に{target=“_blank”}された。

AI、メタバース、ビッグデータなどのデジタルテクノロジーによって地球や人々の生き方や感性がどのように変わっていくのか、アーティスト、建築家、科学者、プログラマーなど、さまざまな分野の専門家が集い、８つのテーマに沿った構成で展示を行う。

会期： 2023年10月7日（土）～2024年3月17日（日）

展覧会構成
1.GAMEの新しい見方：Play-Theater
2.衣：デジタルを身につける
3.住：環境／デジタル
4.食：データを摂取する
5.AIと生きる：AIがどこまで人間性を獲得できるか
6.デジタルを買う：デジタルの中の新しい物質性
7.データと新しい表現：絵画・インスタレーション
8.ラディカル・ベタゴジー（新しい教育学）

特別企画として、会期中の10月13日（金）、14日（土）には、金沢21世紀美術館のシアター21にて、音楽家 渋谷慶一郎氏と東京大学教授の池上高志氏が協力し、ステージ上でアンドロイドと渋谷氏が音楽パフォーマンス{target=“_blank”}を行う。

パフォーマンスに参加するアンドロイド「Alter3」は、展覧会にも出品予定だ。東京大学池上研究室によって開発された発話されたテキストをGPTで動きに翻訳するプログラムによって運動制御されている。一方でアンドロイド「Alter4」は、電子音楽家のプログラムにより音楽の音量、音程、音密度に対して全身をシンセサイザーのようにモジュレートさせて運動し、２台は全く異なる制御によって展開されるという。

!
:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::</description><pubDate>Wed, 04 Oct 2023 07:33:00 +0000</pubDate></item></channel></rss>