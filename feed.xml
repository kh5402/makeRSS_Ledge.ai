<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Thu, 11 Jul 2024 13:17:57 +0000</lastBuildDate><item><title>コーレ株式会社が、広告DXサービス「AI MIX AD PROMOTION」を提供開始　AIモデルとリアル商品を自然に組み合わせて画像を生成</title><link>https://ledge.ai/articles/ai_mix_ad_promotion</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月8日、コーレ株式会社は、AIモデルとリアルな商品の物撮りを組み合わせた広告・プロモーション画像を制作するタレント広告DXサービス「AI MIX AD PROMOTION」の提供を{target=“_blank”}した。

「AI MIX AD PROMOTION」は、AIで生成したモデルやタレントと実際に撮影された商品画像を組み合わせ、自然なシーンを作り出すサービス。ターゲット層や商品イメージに合わせて、国籍、性別、年齢、髪型、肌の色、服装、ポージング、背景などをカスタマイズできる点が特徴だ。
## 実例
例えば、スキンケア商品「HERBNEIGE」の広告画像を作成する場合
!
:::small
画像の出典：{target=“_blank”}
:::

従来の画像生成AIでは商品画像を読み込ませても、ロゴや色、材質が変わってしまい、別商品の広告になってしまう。
!

:::small
画像の出典：{target=“_blank”}
:::

しかし、「AI MIX AD PROMOTION」では元の商品画像をそのままに、AIモデルに自然に商品を持たせることが可能であり、理想的な広告画像を作成することができる。
!

:::small
画像の出典：{target=“_blank”}
:::

従来の画像生成AIでは、商品画像をもとに新しく画像を生成するため、本来の商品画像とは異なる画像が生成されるが、本サービスではリアルな商品画像を維持しながら多様な広告パターンを高速で生成できる。これにより、企業は効率的かつ効果的に広告制作を行い、大幅なコスト削減を実現することが可能だという。

:::box

:::

:::box

:::

:::box

:::</description><pubDate>Thu, 11 Jul 2024 05:20:42 +0000</pubDate></item><item><title>国産EPRベンダー先駆けワークスアプリケーションズが「HUE」と「Microsoft Copilot」の連携開始</title><link>https://ledge.ai/articles/worksap_hue_collaborate_with_microsoft_copilot</link><description>:::small
画像の出典：{target=“_blank”}
:::

ワークスアプリケーションズは2024年7月8日、自社の大手企業向けERPパッケージ「HUE」とMicrosoftの生成AIアシスタント「Microsoft Copilot」の連携を開始したと{target=“_blank”}した。

この取り組みは、国産ERPベンダーとして先駆けたもので、ユーザー企業は自社の業務に最適化されたAIを活用し、データ入力やルーチン業務の効率化、自動化を実現できるという。

## 「HUE」と「Microsoft Copilot for Microsoft 365」の連携
「HUE」と「Microsoft Copilot for Microsoft 365」のプラグイン連携により、ユーザーがMicrosoft Teamsのチャットで質問をすると、生成AIが「HUE」内の会計データとMicrosoft 365内の資料やメールなどの企業データを組み合わせて回答する。この連携により、文章作成、データ分析、図表作成などの個人タスクが効率化される。

例えば下図のように、ユーザーがTeams上で「今月の支払依頼書を表形式で表示してください」と指示すると、生成AIがERPシステム「HUE」内のデータベースから支払依頼書を検索し、表形式で整形して表示する。

!
:::small
画像の出典：{target=“_blank”}
:::
## 「HUE」と「Microsoft Copilot Studio」の連携
「HUE」とMicrosoft Copilot Studioとの連携により、データの取得や整形だけでなく、ERPデータを活用した業務プロセスの自動化も可能になるという。Microsoft Copilot Studioは、プログラミング不要で簡単な画面操作で設定でき、ユーザーは複雑な業務フローを構築できる。下図の例のように、与信調査のフローを設定すると、生成AIが過去の取引履歴をチェックし、与信判断を自動で実行することで業務をサポートする。

!
:::small
画像の出典：{target=“_blank”}
:::

HUEは既に2000社以上の大手企業に導入されており、顧客の要望を標準機能に取り込むことで、アドオンやカスタマイズの必要性を最小限に抑えている。また、法改正時のバージョンアップも保守料の範囲内で対応し、SaaS型サービスやECサイト、BIツールなどとの連携基盤も備えている。

今回の連携により、HUEユーザーは業務の自動化と効率化を進め、戦略的な業務に集中できる環境が整うことが期待されるという。


:::box

:::
:::box

:::

</description><pubDate>Thu, 11 Jul 2024 04:41:04 +0000</pubDate></item><item><title>「日本語でできるのか？」 国産LLM開発の苦労をAIスタートアップが明かす</title><link>https://ledge.ai/articles/expo2024-interview-alibaba-short</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

## 「Qwen」での国産LLM開発
アリババクラウド・ジャパンサービス株式会社のウェビナーでは、同社 藤川氏より、AI 系サービスの開発を4兆円超の予算で行っているアリババグループのAI研究所「DAMOアカデミー」についての紹介や、今回のメイントピックであるオープンソースLLM「Qwen」について紹介いただいた。

また、「Qwen」を用いて国産LLM「Karasu」「Qarasu」を開発した株式会社Lightblue の谷口氏にもご登壇いただき、独自開発したLLMについてや開発の苦労まで幅広く話を伺った。

:::box
!
**アリババクラウド・ジャパンサービス株式会社**
**AI/Big Data ソリューションアーキテクト**
**藤川 裕一氏**
大手通信会社入社後、経営コンサルティングファームを経て独立。Web/モバイルアプリ、AIに関する新規事業立ち上げや開発案件を多数経験。その後、スタートアップのCTOを経て、現在はアリババクラウドにて主にAI案件に参画している。
:::

:::box
!
**株式会社Lightblue**
**取締役｜上級研究員**
**谷口 俊一氏**
東京大学大学院工学系研究科修了。建設現場、インフラ等を主に手掛ける。Lightblueでは開発に従事。
:::

:::button
{target=“_blank”}
:::

**藤川氏**
約7年前の2017年にアリババはDAMOアカデミーというテクノロジーの研究施設を設立しました。この研究所のミッションは、「科学技術の研究とイノベーションを通して未知なるものを探求すること」です。ミッションを実現するために、合計4兆8000億円という莫大な予算を費やし、世界トップクラスのAI研究者を集め、 中国だけでなくアメリカにも研究施設を構え、最先端のAI技術を研究しております。このようにして生み出された AI技術を実際にお客様にも提供しており、このDAMOアカデミーの発足以降、アリババクラウドのAIソリューションは大きく進化いたしました。設立当初は画像予測などのシンプルなAI技術でしたが、近年では、LLMと呼ばれる 生成系AIの開発に非常に力を入れています。

「Qwen（クウェン）」という名前のオープンソースLLMを公開していますが、頻繁にアップデートしておりまして、2024年6月7日にバージョン2.0を公開しました。こちらは多言語能力がアップしているのと、トークンサイズも伸びておりまして、非常に重要なアップデートとなっています。Hugging Faceから利用いただけますので、ぜひ1度お試しいただきたいです。

**──実際にQwenを用いて開発をされた谷口様にお伺いします。LLMの基盤モデルは世界的にも数多くあると思いますが、その中でQwenを利用しようと思ったきっかけを教えてください。**

**谷口氏**
何をベースに開発するのが良いかの議論を社内で行いましたが、当然、その当時で一番良いモデルを使いたいという要望はあり、Llama2やMistral Largeも方法としてはありましたが、言語対応において、日本語対応できる点では、Qwenが公開されていたものでトップだと判断したんです。日本語が喋れるモデルをベースにファインチューニングすると精度が全然違う、という点でQwenを選定しました。

弊社のLLM「Karasu」「Qarasu」の特徴としては、エンジニアが手を動かして、日々どういったデータセットがよいかを議論しながらブラッシュアップしているところで、特に日本語に強い点が特徴です。

!
:::small
Lightblue提供資料
:::
**──開発過程で困難だったことはありますか。**

**谷口氏**
特徴でもある、データセットを…

※続きは特設サイトよりご覧ください 

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Wed, 10 Jul 2024 01:11:38 +0000</pubDate></item><item><title>サイバーエージェント　225億パラメータの独自日本語LLM「CyberAgentLM3」を公開　既存モデルを使わずスクラッチで開発</title><link>https://ledge.ai/articles/cyberagent_japanese_llm_ver3</link><description>:::small
画像の出典：{target=“_blank”}
:::

サイバーエージェントは2024年7月9日、新たに225億パラメータを持つ日本語大規模言語モデル（LLM）「CyberAgentLM3」を{target=“_blank”}した。このモデルは、既存のモデルを使用せずスクラッチから開発されたという。

同社は2023年5月に独自の日本語LLM「{target=“_blank”}」を公開。その後も改良を重ね、11月には「{target=“_blank”}」を、2024年6月には視覚機能を追加した大規模視覚言語モデル{target=“_blank”}を公開してきた。これらの技術は、同社の提供する「極予測AI」などのサービスで広く活用されているとのこと。

今回公開された「CyberAgentLM3-22B-Chat」は、既存モデルをベースにせず、まっさらな状態からの開発モデルだ。Nejumi LLMリーダーボード3において、700億パラメータのMeta-Llama-3-70B-Instructと同等の性能を示しており、オープンな日本語LLMとしてはトップクラスの性能を誇るという。

{target=“_blank”}はHuggingfaceにて公開されており、{target=“_blank”}ページでは実際に動作を確認できる。

今回公開された「CyberAgentLM3-22B-Chat」は、商用利用が可能なApache License 2.0で提供されており、多くの企業や研究機関が利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Jul 2024 11:56:24 +0000</pubDate></item><item><title>NEC「匠の熟練の技」をLLMが受け継ぐ　RAGを活用したナレッジ継承支援システムを開発　</title><link>https://ledge.ai/articles/nec_knowledge_sucsession</link><description>:::small
画像の出典：{target=“_blank”}
:::

NECは2024年6月18日、製造業におけるナレッジ継承の課題を解決するために、大規模言語モデル（LLM）を活用した新しい支援システムを開発したと{target=“_blank”}した。2024年度中の提供開始を目指すとのこと。
## システム概要
NECの新システムは、工場で発生する設備や品質不良、生産効率低下などのトラブルに対応する。作業員がシステムに問い合わせを行うと、LLMが過去のトラブル対応情報や業務ノウハウを基に最適な対処法を提示するとのこと。

システムには、熟練工の知見をデジタル化して構造化したデータモデルテンプレートと、問い合わせを効率化するプロンプトテンプレートが組み込まれており、高精度な回答が可能だという。

!
:::small
画像の出典：{target=“_blank”}
:::

同社が3月に実施した技術検証によると、この実証実験では、RAG（検索拡張生成）の仕組みを用いることで、AIのハルシネーションを抑制しつつ、高精度な情報提供を実現したという。



:::box

:::
:::box

:::

</description><pubDate>Tue, 09 Jul 2024 07:39:26 +0000</pubDate></item><item><title>「イメージングから何ができるか」 エレクトロニクス情報プラットフォーマーのレスターが語る マルチモーダルAIによる社会課題の解決</title><link>https://ledge.ai/articles/expo2024-interview-restar-short</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

## イメージングから社会課題の解決へ
本ウェビナーでは、イメージングの進化 および それらのデジタル技術がどのように社会課題の解決に結びつくか 、ソニーの特約店でもある株式会社レスターの吉本氏に伺った。
:::box
!
**株式会社レスター**
**グループ事業開発本部 副本部長**
**吉本 健氏**
国内半導体メーカーにて30年以上勤務、システム半導体(LSI)のマーケティング、企画および設計開発、欧州LSI開発センター長、システムLSI応用技術部長、技術マーケティング統括部長を経て2021年2月に株式会社レスターエレクトロニクスに入社。2021年7月より現職。
:::

:::button
{target=“_blank”}
:::

**吉本氏**
レスターのビジネスは、画像センサーとそれを出力する液晶パネル、つまり「イメージング」の技術からスタートしました。イメージングをベースに、オーディオを追加した会議システムの構築や、カメラにAI技術を取り入れて従来のカメラでは処理できなかった映像分析、つまりカメラのすぐそばで何があったか認識でき、データとして蓄積できるようになった「遠隔監視」のソリューションもあります。
近年では、カメラと音声認識、サイネージ、さらに生成AIを組み合わせることで、マルチモーダルの自立対話サービスも提供しています。

!

**吉本氏**
マルチモーダルの自立対話サービスは無人で答えられるシステムですが、実際にどのようなやり取りがあったかもデータ化されており、それを分析しながら改良を続けています。
マルチモーダルAIは人間の五感のうちの一部になりますが、触覚を再現する技術や、感情を読み取れる技術も出てきていますので、こういったものを組み合わせた…

※続きは特設サイトよりご覧ください 

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Mon, 08 Jul 2024 10:08:42 +0000</pubDate></item><item><title>IVS 2024閉幕　生成AI・核融合・宇宙ビジネスなどのセッションに注目が集まる</title><link>https://ledge.ai/articles/ivs2024_kyoto</link><description>:::small
画像の出典：{target=“_blank”}
:::

京都市で開催された日本最大級のスタートアップイベント「{target=“_blank”}」が2024年7月6日に閉幕した。

このイベントには投資家や起業家、専門家などが集まり、業界トップリーダーたちが集い各階で行われるセッションが見どころとされた。約200件のセッションで最新の技術トレンドについて議論が行われ、今年は特に生成AIはじめ、核融合、宇宙ビジネスなどに関するセッションが注目を集めたという。

生成AIのセッションでは、日本の生成AI産業の未来について多くの議論が交わされた。リクルート教育AI研究所の小宮山利恵子氏、経済産業省の渡辺琢也氏、ABEJAの岡田陽介氏などが登壇し、生成AI技術がどのように日本の産業を変革する可能性があるかについて語り、参加者は、生成AIがもたらす新たなビジネスチャンスやその社会的影響に大きな関心を寄せたという。

また、核融合や宇宙ビジネス、Web3技術に関するセッションも関心を集めたとのこと。核融合をテーマにした対談で、EX-FusionのCTOである森芳孝氏は「核融合はやろうと思えばできる。やるか、やらないかの問題だ」と強調し、核融合発電の可能性について詳しく説明した。


!
:::small
画像の出典：
:::


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Jul 2024 12:00:49 +0000</pubDate></item><item><title>第2️回 日本ノーコード大賞授賞式を開催　大賞受賞企業は株式会社LIMNO</title><link>https://ledge.ai/articles/nocode_taisho_2</link><description>2024年6月21日、一般社団法人ノーコード推進協会（NCPA）主催の日本ノーコード大賞授賞式が{target=“_blank”}された。

日本ノーコード大賞は、ノーコードを活用して実現した優れた事例に対して表彰される。

## 大賞受賞企業は「株式会社LIMNO」　会社を丸ごと変革
!

現場主導でDXが推進され、DX推進の起爆剤、そして促進剤にもなったのがノーコードアプリ開発ツール「Platio」だったという。

DX推進にあたっては、ITに対するアレルギー、仕事のやり方を変えることへの抵抗感があったことから、ITのリーダーに「他は考えなくても良いからノーコードアプリ開発ツールを使用してDXを推進して欲しい」と依頼をして社内にDXを推進する。さらに、ノーコードツールベンダーであるアステリア社のエバンジェリストの担当者から、DXとは何かといった解説や、ノーコードアプリ開発ツールの「Platio」の良さを学び、その日から現場で社員によるアプリ開発が始まったそうだ。

受賞した株式会社LIMNO 代表取締役社長 木村裕一氏は以下のように述べている。

DXを推進するにあたって、ノーコードアプリ開発ツールがどれだけ役に立つのかを改めて実感しています。日本が失われた30年から大きく経済活性化をしようとしている今、すべての日本企業において、現場の創意工夫をそのまま活かせるノーコードアプリ開発ツールは間違いないと私たちが証明できたと思います。この賞は現場の志のある、会社を丸ごと変革していこうと努力している社員たちに贈られた賞だと思っています。この受賞を通じて社員たちも勇気づけられることに感謝しています。

## 特別賞
!
:::small
左から株式会社エネコープ・株式会社ALLCONNECT・写真甲子園実行委員会
:::

以下で受賞企業とコメントを紹介していく。
・株式会社エネコープ
栄えある賞をいただき大変嬉しく思っております。弊社は、AppSheetで灯油タンク点検アプリを開発し、業務効率化を目指しました。このように、私たちの取り組みが評価されたことを大変嬉しく思うとともに、今後もより一層業務改善やDXを推進していきたいと思っております。

・株式会社ALLCONNECT
名誉ある賞をいただきありがとうございます。今回の事例を新卒3年目で実現することができ、スキルや年齢にかかわらず、活躍できる場があるノーコードツールが好きです。今後もノーコードツール、DX化を推進してまいります。

・写真甲子園実行委員会
北海道東川町の写真甲子園という素晴らしい取り組みがより多くの方へ広まったこと、東川町の皆さんにノーコードの可能性を感じていただいたことを非常に嬉しく思っております。

## 優秀賞
!
:::small
左から茨城県下妻市・大日本印刷株式会社
:::

・茨城県下妻市
茨城県下妻市がDX化を進めるにあたって、1年間無料キャンペーンを実施していたノーコードツールKintoneを活用しました。現在下妻市ではKintoneアプリを200以上、そして9割の職員が活用しています。ノーコードを活用したいがなかなか活用の幅が広がらないという話を耳にしますが、私たちは積極的に利用するように研修会を実施したりサポートをしております。私たちの取り組みによって、少しでも皆様の課題解決に役立てばと思っております。

・大日本印刷株式会社
私たちは、生成AIラボという生成AIを活用して様々なユースケースを具現化していくために、プロジェクトを立ち上げました。プログラミング経験がない社員に対して、ノーコードAppSheetを使用しノーコードの教育を実施しており、社員皆一丸となりアイデアを具現化することを目標に活動しています。開発をきっかけに皆で知識を高め、さらに良いものを作りだそうという会社の風土の変化も見られました。

## 日本デジタルアダプション協会賞
!

日本デジタルアダプション協会は、2021年9月にデータ庁が提唱した、「誰一人取り残されないデジタル社会の実現」の一助となるべく、2022年に設立された。デジタルの活用と定着化を定義として、どのようなステップでデジタルを定着化させるのかを考え、学びの場を提供するために作られた。

・株式会社東急コミュニティー
今回私たち東急コミュニティーが行った取り組みは、DXツールの利活用の定着を当たり前に使える環境を整えることです。そして、社員に対してのIT知識の教育を実施しました。社内のITリテラシー向上のために、IT部署が代理で操作をするサポート体制ではなく、教育もパーソナライズ化を試みました。Pendoを利用してすべて数値化し、データをもとに苦手な分野をどう教育するかを考えていく組織を構築し、デジタル成熟度の向上を目指しました。

## NCPA認定制度「NCPA認定ノーコードパスポート　サファイア
!
:::small
画像の出典：{target=“_blank”}
:::

今年3月より、教育部会の教育チームがノーコードパスポート試験をスタートした。ダイヤモンド、エメラルド、サファイアの3階級で構成しており、今回のノーコード大賞で発表されたのは一番下の階級である「サファイア」だ。初心者向けの階級で、高校生でもチャレンジできるとのこと。50問中4択設問形式で、40問以上正解で合格するシステム。見事合格すると合格証が発行されるそうだ。
受験費用は5,000円だが、ノーコード推進協会に加盟している企業は全社員が半額で受験ができるとのこと。ノーコードの概念、およびノーコードツールに興味関心のある方、ビジネスでノーコードツールを活用したい方はぜひお見逃しなく。</description><pubDate>Mon, 08 Jul 2024 03:14:08 +0000</pubDate></item><item><title>GPT-4o? Claude3.5？無料でどの回答がよいか選べる「天秤AI byGMO」GMOインターネットグループが公開</title><link>https://ledge.ai/articles/gmo_tenbin_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GMO教えてAI株式会社は、2024年6月20日、生成AIプロンプトポータル「教えてAI byGMO」をリニューアルし、新たに「天秤AI byGMO」として{target=“_blank”}した。ユーザーは、最大6つの生成AIモデルを同時に実行し、複数モデルの回答を比較しながら最適解を選べるという。


!
:::small
画像の出典：{target=“_blank”}
:::

「天秤AI byGMO」では、Anthropicの最上位モデルであるClaude 3 Opusや、GPT-4o、Gemini 1.5 Proなど最新の生成AIモデルが無料で利用可能だ。また、新機能として履歴保持機能が追加され、過去に実行したプロンプトとその結果を自動的に保存可能となった。

同サービスは、生成AIモデルの性能を比較するためのツールとして利用でき、回答の精度や速度、表現の違いを評価することで、各AIモデルの特徴を把握し、最適なモデルを見つける手助けをする。また、複数のAIモデルの回答をまとめて網羅的な回答も作成可能とのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Jul 2024 02:46:52 +0000</pubDate></item><item><title>Gateboxが、GPT-4oを活用した飲食店向けサービス「AI幹事」を開発　乾杯の挨拶もAIにおまかせ</title><link>https://ledge.ai/articles/gatebox_ai_kanji</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月3日Gatebox株式会社は、飲食店向けAI接客サービス「AI幹事」の開発を{target=“_blank”}した。

AI幹事は、飲食店に特化したAIの接客サービスだ。顧客がグラスを手にして乾杯しようとすると、AI幹事が率先して乾杯の挨拶を行ってくれる。

このサービスはOpenAI社の生成AI「GPT-4o」の画像認識技術を活用しており、カメラを通してグラスの空き具合や、料理の残量をAIがリアルタイムで把握する。さらに、おすすめの料理やドリンクの追加注文を提案してくれる機能も搭載しており、人間が出席者の状況を小まめに確認することなくAIがその役割を果たしてくれる便利なサービスだ。

タブレットに表示されるキャラクターは雰囲気に合わせて自由にカスタマイズが可能とのこと。
@


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Jul 2024 01:56:14 +0000</pubDate></item><item><title>ぶっちぎりの中国　生成AI特許出願数で独走1位　2位の米国引き離す　日本は4位</title><link>https://ledge.ai/articles/china_based_inventors_filing_most_genai_patents_wipo_data_shows</link><description>:::small
画像の出典：{target=“_blank”}
:::

世界知的所有権機関（WIPO）が2024年7月3日に{target=“_blank”}したレポートによると、中国は過去10年間で生成AIに関する特許出願数において圧倒的なリードを示しており、総計3万8000件以上を出願している。この数字は世界全体の生成AI特許出願数5万4000件の約70％に相当し、2位のアメリカ（6276件）の約6倍に上る​という。
## 特許出願数の順位
**中国:**  3万8000件以上
**アメリカ:**  6276件
**韓国:** 4155件
**日本:** 3409件
**インド:** 1350件
## 上位特許出願企業
**テンセント**: 2074件
**平安保険** : 1564件
**Baidu:**  1234件
**中国科学院:**  607件
**IBM:** 601件
**アリババ・グループ:**  571件
**サムスン電子:**  468件
**アルファベット:**  443件
**ByteDance:**  418件
**Microsoft:**  377件

## 特許の内訳
**画像・映像データ関連:** 1万7996件
**テキスト関連:** 1万3494件
**音声・音楽関連:** 1万3480件
**分子・遺伝子・タンパク質データ関連:** 過去5年間で年平均成長率78％


WIPOによると、2017年にディープニューラルネットワークのアーキテクチャが登場して以降、生成AI特許数は急増し、2023年時点でその数は8倍に増加。2023年に公開された生成AI関連の特許は全体の25％以上に達する一方、全AI特許のうち生成AIの割合はまだ6％と低い​。



:::box

:::
:::box

:::
</description><pubDate>Sun, 07 Jul 2024 11:43:37 +0000</pubDate></item><item><title>第3回 日本DX大賞2024授賞式を開催　132エントリーの中から選ばれた優れた取り組みを発表</title><link>https://ledge.ai/articles/dx_taisho_3</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月21日、一般社団法人日本デジタルトランスフォーメーション推進協会主催の「日本DX大賞2024」の授賞式が{target=“_blank”}された。

日本DX大賞は、自治体、民間企業、産官学などから自社のDX推進の取り組みをプレゼンテーション形式で発表していく。日本におけるデジタルトランスフォーメーメーション（DX）を推進する優れた取り組みを表彰し、その成果を広く社会に共有することを目的としている。

今回で3回目の開催となる本式典だが、5つの主要部門に加え、特別賞、サイボウズ賞、ポスターセッションの各カテゴリーで表彰される。132エントリーから選ばれた優れた取り組みを行った企業を以下で各部門ごとに紹介していく。

## 行政機関・公的機関部門
!

**大賞**
都城市
プロジェクト：全国初！自治体専用生成AIプラットフォーム「zevo」で自治体の未来を切り拓く

生成AI「zevo」を都城市が開発し、自治体での利用を促進。従来、自治体はセキュリティリスクやLGWAN非対応により生成AIの利用が困難だったが、民間企業との共創でこれらの課題を克服した。令和5年6月に自治体専用回線で利用できる生成AIプラットフォーム「zevo」をリリースした。現在、9割以上の部署で利用され、文書作成や校正、プログラミングなど幅広く活用されている。

**佐藤 泰格氏**
都城市は3大会連続で決勝進出を果たし、昨年も大賞を受賞しました。しかし、今回は大賞をいただけるとは思っておらず、私自身も戸惑っております。今回開発した生成AIに、決勝進出団体の情報を認識させてどの企業が大賞なのかを質問したところ、都城市ではなかったのです。やはり行政も変革の時代になっているので、一度大賞を受賞したからそれで終わりではなく、さらに新しいデジタル化を推進する必要があると思います。都城市は全分野でのデジタル化を進めておりますので、また来年もステージに立てるように尽力して参ります。

**優秀賞**
福島市
プロジェクト：高齢者にやさしいデジタル化から自治体ビジネスまで　～福島市が目指す地域全体のデジタル化～

佐賀市
プロジェクト：住民・地域・企業・行政　みんなで創る「佐賀市公式スーパーアプリ」～佐賀市版ＤＸで日本一便利なまちへ～

## ビジネストランスフォーメーション（BX）部門
!

**大賞**
株式会社バルカー
プロジェクト：設備点検プラットフォーム 「MONiPLAT」～創業96年の製造業、初めてのSaaS事業へ挑戦

バルカーは、液体・ガス漏れ防止のハード製品から「安全を漏らさない」新たな価値を提供するために、設備保全プラットフォーム「MONiPLAT」を開発。2021年に中澤氏がCDOとして入社し、メンテナンス領域のデジタル化を推進。2023年4月に「MONiPLAT」をローンチし、1年で500社以上の顧客を獲得。これによりハード商材のクロスセルが増加し、CBM事業の拡大にも取り組んでいます。創業96年の老舗企業にデジタル人材をスカウトし、コアチームを形成することでプロジェクトを成功させた。

**川上 孝弘氏**
今回は絶対に大賞を受賞したいという思いでこのプロダクトを進めてきましたので、非常に嬉しく思っています。全社一丸となって新事業を展開しており、将来的には世界で展開していきたいと思っています。開発メンバー、営業メンバーとともに、もっと良いプロダクトにして会社を盛り上げていきたいです。

**優秀賞**
資生堂インタラクティブビューティー株式会社
プロジェクト：新会社設立でデジタルIT人材を育成し、 事業モデルを革新！

株式会社クレディセゾン
プロジェクト：CSDX ー 全社DX推進の実現

## サイボウズ賞
!

株式会社後藤組
プロジェクト：中小建設業が挑むデータ・ドリブン経営：ノーコード活用と「全員DX」

**後藤 茂之氏**
責任者として任命した笹原は、文系の営業マンでDXのDの字も分からない状態でした。今回、DXプロジェクトの責任者として社員全員を牽引し、日々試行錯誤してここまで来ることができました。社員が日常業務で手一杯の中で、“毎月生産性向上するアプリを必ず1個作成する”という私の無茶振りに応えるために、毎日コツコツDXに取り組んでくれました。こういった毎日の積み重ねが今回の大きな成果に結びついたのだと思います。今後も、建設業全体の生産性向上に向けた取り組みを続けていきたいです。

## マネジメントトランスフォーメーション（MX）部門
!
:::small
画像の出典：{target=“_blank”}
:::

**大賞　サイボウズ賞と同時入賞を果たした後藤組**
プロジェクト：中小建設業が挑むデータ・ドリブン経営：ノーコード活用と「全員DX」

株式会社後藤組は、建設業界の担い手不足を解消するため、若手社員の早期育成と定着を目指してDX改革に取り組んでいた。kintoneを活用し、データに基づく意思決定を可能にする組織を目指し、自社開発の業務サービスや蓄積データの活用で業務改善を行った。「全員DX」をテーマに、全社員がアプリ開発やデータ分析を行い、ワークショップや大会、社内資格制度を通じてDX推進を行っている。デジタル化により業務効率化を実現し、残業時間を21.1%削減、生産性を向上させた。

**後藤 茂之氏**
先程も申しましたが、社員にはだいぶ無茶振りをしました。少しずつ慣れてきた頃には、自分たちの業務を効率化できるものを作り出していくことができ、私たちのDXレベルは日本一だと社員には伝えておりました。サイボウズ賞をいただいたので、大賞は取れなかったのかと相当落ち込んでいたのですが、大賞を受賞することができて本当に嬉しく思います。社員に日本一のレベルだと伝えられることが本当に嬉しいです。これを機会に、建設業全体の生産性を上げられるように、舵を切って私たちの会社が貢献できるようになっていきます。

**優秀賞**
松本興産株式会社
プロジェクト：DXで重苦しい文化を軽やかに 皆が自立し意思決定できた

日清食品ホールディングス株式会社
プロジェクト：経営トップの発信による全社的な生成AI活用の企業風土の醸成

## サステナビリティトランスフォーメーション（SX）部門
!

:::small
画像の出典：{target=“_blank”}
:::


**大賞**
株式会社果実堂
プロジェクト：未来の農業を創る！休める稼げる農業DXの展望

果実堂は熊本県に本社を置くベビーリーフの生産量日本一の農業生産法人。日本の農業界で進まないDXの背景には、農業者の高齢化と旧態依然とした事務作業がある。果実堂は、DXを活用して年間6,000時間の事務作業削減を目標に、RPAやノーコード・ローコードツールを導入し、業務の自動化と効率化を推進した結果、114項目を自動化し、年間約4,229時間の業務削減を達成し、過去最高益を更新した。

**高瀬 貴文氏**
みんな、やったよ！
社員一同の努力で農業者でもできるということを証明でき、一歩踏み込めたと実感しています。これで終わることなく、コツコツ積み上げて農業者全体でデジタルフォーメーションを推進していこうと思っております。

**優秀賞**
株式会社天地人
プロジェクト：宇宙×水道DXの実現へ　持続可能性の維持向上を目指す水道事業体様向けサービス「宇宙水道局」

株式会社誠和
プロジェクト：廃棄物をバイオマス資源に変換する農工連携型の資源循環社会を創るエネルギーデザインシステム

## カスタマーエクスペリエンス（CX）部門
!
:::small
画像の出典：{target=“_blank”}
:::

**大賞**
三井住友カード株式会社
プロジェクト：モバイル総合金融サービスOlive

Oliveは、金融サービスを便利でお得かつわかりやすくすることを目指して開発された、SMBCグループのモバイルベースの総合金融サービス。2023年3月に提供開始され、「利便性」と「安心安全」の特徴を持ちます。アプリで銀行口座、クレジットカード、証券口座の申し込みを一括で行い、即時利用が可能。カード番号はアプリで確認でき、万一の紛失時も安心です。三井住友銀行と三井住友カードが2年半をかけて企画推進し、初年度には200万人以上のユーザーを獲得。

**伊藤 亮佑氏**
Oliveのプロジェクトを進めていく段階で、若者向けのアプリにする意見もありましたが、リテールの中心で進めることを決意し、三井住友銀行のアプリとして実現することができました。このプロジェクトには、グループ会社を含め1000人ほどの人が関わっているので、そのすべての方々に感謝申し上げます。

**優秀賞**
株式会社ヤマップ
プロジェクト：４トンのゴミ削減 ＆ 絶滅危惧種ライチョウを救う！登山者と社会を巻き込んだ循環する「共助のDX」成功事例

株式会社エアークローゼット
プロジェクト：曖昧性の高いファッション領域における顧客体験のDX〜ChatGPTを活用した対話型スタイリング提案システム〜

## 特別賞
!

佐賀県
プロジェクト：産業DXフロントランナー"SAGA"プロジェクト　～そのモヤモヤを、明日のワクワクに。～

株式会社IACEトラベル
プロジェクト：「創業40年の旅行会社が挑むDX」　経営危機を乗り越え、労働集約型サービスからの脱却を果たす

日本電気株式会社
プロジェクト：サイバーセキュリティダッシュボードによるデータドリブンなセキュリティカルチャー変革

あいおいニッセイ同和損害保険株式会社
プロジェクト：DXソリューションパッケージ　～誰もが安全・安心に暮らせる地域・社会の実現に向けて～

アフラック生命保険株式会社
プロジェクト：ADaaS／Aflac Digital as a Service ～リアルとデジタルの融合による一貫した体験価値の提供～

## ポスターセッション
!

**最優秀賞**
富士油圧精機株式会社
プロジェクト：失われた30年をDXの力で取り戻す

**優秀賞**
コマツ株式会社/同志社大学 理工学部 インテリジェント情報工学科 知的機構研究室
プロジェクト：壁紙のAI識別アプリ「かべぴた」 ～人力で数時間かかった品番識別が数秒で完結！～

株式会社成田デンタル
プロジェクト：強い営業組織を作るためのマネジメントDX
</description><pubDate>Mon, 08 Jul 2024 02:44:02 +0000</pubDate></item><item><title>コンサルからエンジニアへ　東京・パリで学び、データ分析でグローバルな活躍を目指す　42 Tokyo特別インタビュー【第4回】小林 瑠理さん</title><link>https://ledge.ai/articles/42tokyo-4</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第4回。**
:::

※インタビューは2024年1月30日に行われた。

:::box
!
**42 Paris 在学生**
**小林 瑠理**
新卒で外資系コンサルティング企業に入社し、ビジネスアナリストを経験したのち、転職してIT企業に転身。その会社でエンジニア養成機関「42 Tokyo」を勧められ、2022年4月に入学。仕事と並行しながら基礎カリキュラムを修了し、現在は「42 Paris」に留学中。 現在は勉強と並行して、フリーランスエンジニアとして、アメリカの企業でwebオートメーション支援と日本のベンチャー企業でLLM活用支援をおこなっている。
:::

## 未経験からの挑戦　42 Tokyoで見つけた学びの道

:::box
**小林さん**
大学卒業後は、ITのシステムインテグレーターの会社に入社して、ビジネスコンサルとして仕事をしていましたが、そこでエンジニアリングに興味を持ち、未経験でITエンジニアとして転職しました。しかし、全く教育を受けていない状態で転職したため、自主学習も思うように進まずに悩んでいたんです。そんな中、社内の技術担当の方から「42 Tokyo」を教えていただき、入学試験「Piscine（ピシン）」を受験しようと決意しました。

42 Tokyoを教えてもらうまでは、オンライン講座を受講したり、本を読んだりしていましたが、自分でプログラムを最初から作るのが一番習得への近道だと思っていたので、42 Tokyoでは実践的にプログラムを作り、その過程を学べるのがとても魅力的でした。

一般的な学習方法である教師がいる環境もメリットはあると思うのですが、インターネットで情報が簡単に手に入る今の時代の中で、教師がいることで受け身になってしまう部分もあるように感じていました。42 Tokyoは、教師がいないからこそ主体的に動けるのではないかと思い、興味が湧いてきたんです。

年末の休みと有給休暇を利用してPiscineを受験して無事に合格し、入学しました。
:::

小林さんは、Piscineを受験した時はC言語にも触れたことがなく、ロジックの組み立て方も分からず、なかなか思うように進められずに焦る場面もあったという。周りがどんどん進んでいく中、「なんで自分はできないんだ」と落ち込むことも何度かあったというが、落ち込みながらも合格まで辿り着くことができた。その理由を小林さんは以下のように振り返った。

:::box
**小林さん**
当時は本当に簡単なコードの書き方も全然分からない状態だったので、進みが遅い自分に焦りを感じ、落ち込むことが多かったです。何度か心が折れたこともありました。最後まで乗り切れたのは、相談しあったり、励まし合ったりできる仲間がいたからだと思います。仲間がいなかったら合格まで辿り着けなかったかもしれません。その点でも、仲間の存在はとても大きかったですね。

入学試験を受けている仲間同士で学業以外のこと、人生相談など結構深い話もしていました。年齢層やバックグラウンドが皆様々で、18歳から60代歳まで幅広い年齢層の人が集まっているので、課題の合間に皆でコミュニケーションを取っていましたね。"意欲的に何かを成し遂げたい"と強い意志を持ってチャレンジしている方が多く、良い刺激を受けていました。友達というよりは、ともに試験合格を目指す“仲間”と呼べる存在でした。
明確な目的があって、自分のやりたいことを探求したい野心的な人は42 Tokyoで能力を発揮できると思います。実際に42 Tokyoでは、目的意識が高い人が多く、自分の目的を達成するために課題と向き合う強い意志が大切なので、そういった意志がある人にはピッタリな環境ですし、普通の大学や職場では得られないことが経験できる環境だと思います。
:::

## 42 Tokyoでの実践的な学びの風景　仲間とともに挑む課題と成長
!

:::small
42Tokyoの学習風景
:::

無事に入学試験をクリアして42 Tokyoに入学した小林さんだが、仕事を休職することなく、学業と両立していくことを選んだという。どのように両立していたのか、42 Tokyoでの学習環境を詳しく聞いてみた。

:::box
**小林さん**
課題を進めるにあたって、週に35〜40時間は必要なので、仕事と学業の両立がすごく大変でした。朝早く起きて仕事が始まる前に勉強して、仕事が終わってからも勉強して、土曜日は一日中校舎に行って課題を進める生活を1年半ほど続けていました。当時勤めていた会社は人を大切にする会社で、42 Tokyoに通うことを応援してくれたり、様々な場面で助けていただきました。学業と両立できたのは、会社の皆さんの協力あってのことだと思います。

42 Tokyoの課題をこなす時は、実際にプログラムを書いて仲間同士で教えあったり、時には突っ込まれたりもするんですが、そういった生徒同士で教え合いながら学ぶ学習方法が想像以上に濃い内容でした。課題を提出したあとに3回レビューをするのですが、相手が全くの知識0の人もいれば、すでにかなりの知識を備えた熟練者だったり、色々なレベルの人とランダムでマッチングする形式なので、相手に合わせた説明が求められるんです。

例えば、知識が0の人には基礎から分かりやすく説明して理解してもらう必要がありますし、逆に熟知している人からは、自分の説明に対して鋭い指摘を受けて、少しずつ直していく、ということの繰り返しでした。同じ課題でも、相手によって自分も視点を変えて学習した内容を分かりやすく説明する必要がある。そういったことから、今振り返るとコミュニケーション能力や説明能力も身についたと思います。
:::

課題のレビューは生徒同士で行う。相手によって説明内容や視点を変えることで、改めて課題への理解が深まったという。レビューをし合う中での発見や、印象に残っていることを小林さんは以下のように語った。

:::box
**小林さん**
レビューはポイント制になっていて、自分がレビューをすると1ポイント加算され、そのポイントを使用して課題を提出してレビューを依頼するシステムなので、必ず交互にランダムでマッチングする形式になっています。

最初は知識がない中でレビューをしなければならないので、相手の説明を正しく理解することを心がけていました。自分でも正誤が分からない状態なので、分からないことは理解できるまで教えてもらったり、自分でも調べながらレビューをしていました。一年ほど経ってくると自分の知識も広がっているので、「良いコードだな」と、自分で判断できるようになり、「ここのコードはこうやって書き直すとより見やすいんじゃないか」など、アドバイスができるようになりました。

とにかく実践的に課題に取り組むカリキュラムなので、本を読むよりも自分には合っていると思います。課題の進捗をチームごとに確認できるのですが、課題が進んでいる人を見ると、良い意味で競争心が掻き立てられて、「もっと頑張ろう」と意気込んでいました。
:::

課題をクリアするには、3回レビューを通さなければならないルールがある。1、2回目はクリアできても3回目で返されるとまた1回目から再度レビューになるため、3回目で返されるのが一番キツかったと話す小林さんだが、そのレビューがきっかけで自身の考え方が大きく変わったという。

:::box
**小林さん**
課題の説明をする上で、その結論に至るまでの “過程” の部分にこだわりを持つ人が多かったので、その相手の主張に対して、「私はこういう理由で実装した」と論理的に伝えることが難しく、苦労しました。意見が対立した時に、私は逃げてしまうタイプだったのですが、何故この考えに至ったのかを論理立てて主張することの重要さを学びました。

相手にも意見があって、別に精神的な攻撃をしたいわけではない、建設的な議論がしたいんだと思えるようになったので、メンタルにくることも少なくなりました。自分の意見をしっかり伝えることの大切さに気づけたことが私自身に大きなプラスとなりましたし、社会人としても成長できたと思います。
:::

## 42 Tokyo卒業後の挑戦　42 Paris本校への留学と新たな目標

小林さんは42 Tokyoの基礎カリキュラム（コモンコア）を1年半で修了した後、会社を退社し、42 Paris本校へ留学をした。インタビューの最後に、パリでの生活や42 Paris校の様子、そして今後の展望を語ってくれた。

:::box
**小林さん**
東京で働いていた時は主にアプリ開発をしており、その間に42 Tokyoのコモンコアで基礎であるC言語の勉強を行っていました。コモンコアを修了後は、別の国の42に移籍できるようになるので、データ分析を学ぶためにパリに移籍をしました。もちろん42 Tokyoでもデータ分析は学べますが、もともとグローバルに働いてみたいという思いがあり、パリを選択しました。

パリに来て言語の不安がありましたが、ほぼ全員が英語が流暢に話せるので、今は英語で勉強をしています。仕事と学業の両立をしていた日本での生活と比べると、今は自分の時間も確保できますし、勉強の時間もしっかり取れているので、充実した生活を送っています。データ分析の基礎を楽しみながら学んでいるので、今後はデータ分析に関連する仕事に就きたいと思っていますが、ロケーションを日本にするかヨーロッパにするかはまだ決めていません。
今はパリの生活を存分に楽しみたいと思います。おしゃれな街並みに囲まれて、すぐ近くには美術館があったり、ミーハーなだけかもしれないですが結構楽しんでいます（笑）

42 Parisは、東京校と比べると学校の雰囲気が違います。規模も大きいですし、人数も多いので両隣の人との距離が近くて教室での密集度がかなり高いです。東京校の方が自分の空間が取れてその点は東京校の方が過ごしやすくて好きでした。

42 ParisではRNCPという職能資格を習得できる制度があり、そのためにインターンシップ経験が必要なので、インターンでも様々な経験を積んでより知識を深めていきたいと思います。基本的に勉強が好きなので、身につけた技術を仕事に活かしつつ、新しい技術の勉強はずっと続けて、両輪で生きていく人生にしたいと思っています。
:::

:::box
特集：
:::</description><pubDate>Mon, 08 Jul 2024 07:44:09 +0000</pubDate></item><item><title>【無料LIVEウェビナー】RAGの活用方法や最新AIツールを紹介！生成AIを活用する時に知っておきたい重要トピックを解説</title><link>https://ledge.ai/articles/expo2024-live-webinar</link><description>:::box
Ledge.aiが6月に開催したオンラインイベント「{target=“_blank”}」のうち、終盤に実施したライブ配信による解説ウェビナーには多くの好評をいただいた。この反響を受け、イベントの追加コンテンツとして、7月31日までLIVEウェビナーの追加企画を実施している。また、それに伴って一部コンテンツは延長公開中だ。気になるコンテンツがあれば、是非チェックしていただきたい。
:::

## これからのビジネス環境で必須となる生成AI活用の重要トピックを解説
生成AI技術の企業での業務利用は、いまだ慎重論は一定数見られるものの、徐々にその風潮に変化が見られている。
ICT市場調査コンサルティング企業のMM総研が2024年3月に発表した調査結果によると、2025年度には69％の企業が生成AI技術の本格的な利用を検討すると回答している。

:::box
{target=“_blank”}
:::

今はまだ顕在化していないが、今後生成AI技術を効果的に活用できている企業とそうでない企業との間には、ビジネスでの競争力に大きな差を生み出していくことになるだろう。

今回Ledge.aiでは、先月開催したオンラインイベント「{target=“_blank”}」の追加企画として、昨今の生成AIトレンドの中で、押さえておくべきトピックについて解説するLIVEウェビナーを開催する。

:::button

:::

## 配信ラインナップ紹介
以下がこの先の配信予定だ。一度参加登録することで、すべての配信に視聴参加できるようになるので、合わせてご覧いただきたい。

**「RAGを使った独自データの活用の基本」
配信日時：7/9（火） 15:00-15:30**
大規模言語モデル（LLM）に不足している知識を補い、独自の情報を反映した回答を出力させることができる「RAG（Retrieval-Augmented Generation）」という手法について、その基本的な仕組みや活用方法について解説する。
なぜ独自の情報を参照させる必要があるのか？といった背景知識を押さえた上で、外部から与えた知識の処理プロセスや、精度向上の鍵となる技術要素など、RAG導入の基本となるポイントを押さえる。

**「今話題の生成AIツールを紹介」
配信日時：7/11（木） 15:00-15:30**
ChatGPTやGemini、Claudeといった会話型AIツールだけでなく、昨今生成AI技術を活用した様々なツールが登場している。本配信では、その中でも最近特に注目度の高いツールを2つ紹介する。
一つ目は、誰でも手軽にLLMアプリケーションが構築できるLLMアプリ開発プラットフォーム「Dify.AI」を紹介する。RAGを使ったエージェント形式のチャットボットや、複数のタスクを組み込んだワークフローなどが実際にどれくらい簡単に作れるのかをLIVEでデモ実演する。
２つ目は、テキストや画像から高品質な動画を生成することができるサービスとして話題になっている動画生成AI「Luma Dream Machine​」だ。活用ケースを想定しながら、実際にプロンプトを送り、どのような動画が生成されるのかをデモ実演する。

**「RAGの回答精度を上げるためにすべきこと」
配信日時：7/16（火） 15:00-15:30**
7/9配信のRAG解説に続く発展編として、RAGの性能を向上させるための手法・テクニックを解説する。「質問に関連するドキュメント群を探し出すこと」、「取得したドキュメント群から正しい回答を生成すること」という２つの要素に分解して、RAGの回答精度向上につながる重要なアプローチをいくつかピックアップして紹介する。
RAGに取り組んでみたけどうまくいかない、これから実装を検討する上で躓くポイントが知りたいという方は、是非参考にしていただきたい。

**「優秀なAI部下で管理業務を楽にする！上司が知りたい生成AIの活用術」
配信日時：7/18（木） 15:00-15:30**
2022年のChatGPTの登場から進化が止まらない生成AI。新しいモデルや新機能の発表で、なかなかアップデートが追いつかず、使いこなせていない読者も多いのではないだろうか。本ウェビナーでは、生成AIを優秀な部下として活用し、業務効率を上げるためのテクニックを解説します。ChatGPTなどの会話型AIツールを使ってはみたものの、途中で挫折してしまった方も、このウェビナーを通じて、仕事で使えるテクニックを学び、あなただけの優秀なAI部下を作り、育てていくきっかけとして活用いただきたい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button

:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。


## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
配信形式：zoomウェビナー（LIVE）
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Mon, 08 Jul 2024 10:25:57 +0000</pubDate></item><item><title>松尾研インターンから42へ　基礎カリキュラムを最速で終了した学生がAI開発企業の人事統括になるまで　42Tokyo特別インタビュー【第3回】松本悠秀さん</title><link>https://ledge.ai/articles/42tokyo-3</link><description>:::box
**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第3回。**
:::

※インタビューは2024年4月23日に42Tokyoの校舎にて行われた。

:::box
!
**42 Tokyo卒業生**
**松本悠秀**
東京大学松尾研究室主催のGCIにて優秀賞を受賞し、現在は同講義の教材開発及び講師として関わる。株式会社松尾研究所の複数のプロジェクトにてエンジニア・マネージャーを経験。42 Tokyoのコモンコアを最速で突破。現職ではAIスタートアップにて、プロダクトマネージャー/人事統括を担当している。
:::

## データサイエンスとの出会い　松尾研から42 Tokyoへの挑戦
松本さんは大学4年生で転機を迎えた。それが、データサイエンスとの出会いだったという。普通の大学生からどのようにして「42 Tokyo」への入学を決意したのか、以下のように語ってくれた。

:::box
**松本さん**
僕の経歴は少し特殊で、大学4年生を2度経験しています。入学してから3年間は、サークルへの参加や家庭教師をするなど、普通の大学生活を送っていました。大学4年生に上がったタイミングで経済学部に転学し、教育に携わる仕事に就くために就職活動を進めていました。その後、教育関連企業への内定も決まったのですが、就職活動をしている中でデータサイエンスの重要さを知り、卒業後に良いスタートが切れるように、という思いから松尾研のGCIというデータサイエンスの講義を受講しました。


GCIは、東京大学松尾研究室の研究室が運営するデータサイエンスの講義で、東大以外の人も受講可能です。この講義を受講して、データサイエンスやプログラミングの面白さに気づきました。僕が本格的にプログラミングに触れたのは、この講義がきっかけでした。

この講義が一通り終わったあと、松尾研でのインターンを開始し、GCIの講義開発や講師を務めたり、共同研究において機械学習のエンジニア/プロジェクトマネージャーを経験しました。
:::
松本さんは、希望していた教育関連企業への就職が決まっていたが、子どもと関わりたいという気持ちがある中、自身の強みを活かせるキャリアプランをどのように作っていくか悩んでいたという。

:::box
**松本さん**
松尾研のインターンでは主に機械学習のモデリングを担当していました。その中で、実際に作ったモデルが実社会へ実装されることに興味を持ち、実装にはソフトウェアエンジニアリングが必要だということを知りました。その時、全く関係ない文脈で「教育に興味があるのであれば、42 Tokyoというところに入学してみたらどうか」とお話をいただいたんです。「革新的な教育プログラムらしい」ということを聞き、後から調べたところ、ソフトウェアエンジニアリングを学べることを知りました。まさに求めていたものだと思い、一切の迷いなく入学試験を受けることを決めました。


就職が決まっていた企業での業務は、僕が得意とすることとは少し乖離があったんです。就職について悩んでいたとき、松尾研の方から42 Tokyoの話を聞いて、内定を辞退して学ぶことを選びました。ソフトエンジニアリングの勉強をしたいというのが一番でしたが、独自の教育カリキュラムへの興味もありましたので、とても良いタイミングだったと思います。

試験に合格したあとは、松尾研のインターンをしながら42 Tokyoのコモンコア（基礎カリキュラム）の勉強を始めました。
:::

## 日本最速でコモンコアをクリアした松本さんが語る42Tokyoの学び方
!
通常の授業のように時間が決まっているのではなく、好きな時間に好きなだけ勉強ができるのが「42」の魅力のひとつだ。松本さんは42 Tokyoのコモンコアを開校以来最速でクリアしているが、どのようにして課題を進めていたのだろうか。

松本さんは、42 Tokyoのカリキュラムについて、「今までの学習方式を破壊したような斬新なカリキュラムだった」と語った。
:::box
**松本さん**
コモンコアの修了については急いで終わらせようと思ってやっていたわけではなく、結構黙々と一人で集中して課題に取り組む時間が多かったんです。もちろん周りの人と協力しながら進める場面もありましたが、一人でできるところは黙々と課題を解いていました。


これまで色々な人たちが学問というものを紡いできた歴史がありますよね。今までの一般的な学習方式は、論文や学術本などを発表して、それを授業や研究という形で紡いでいく考えだったのですが、「42」はこれを破壊しているんです。課題を渡されて、自分で考えたり周りに相談しながら答えを導き出して、自分の力で登っていかないといけない。


効率性の観点で考えると、決して効率的とは言えません。しかし、課題をクリアするために自分たちで情報を取得しながら進めなければならないので、「未知のものに対する対応力」という、育成するのが難しい能力を育てる上では、最適な構図だと思います。最初に教科書をもらった方が全部覚えられて学びやすいじゃないですか。
すべての人に刺さる学習方法ではないと思いますが、この方法で学ぶことで得られるものは多いと思います。
:::
松本さんは2度目の大学4年生になることを決意したときから「あと1年しかないのに、この時間を無駄にはできない」と、黙々と課題をこなしていたという。そして、最速でのコモンコアクリアを実現した。自主性を育む環境で、一人で自由に課題を進めることもできる。自分のペースでこなせるところも42Tokyoの魅力なのだ。
:::box
**松本さん**
「42」の学習方法についてですが、例えば、「ウェブページを自分でデザインして作れるようになりたい」という具体的な目標がある場合、42 Tokyoで学ぶことはエンジニアの基礎なので、他のスクールの方がその目的達成のゴール到達は早いかもしれません。
しかし、エンジニアという刻々と変化していく分野において、「基礎・土台となるような力を、時間をかけてでもいいので学びたい」など、幅広く応用の効くところまで学ぶ目的があるのであれば、力を養う学習方法として最も効率的なカリキュラムだと思います。
:::

## 42 Tokyoで得たスキルと知識
!
:::small
42 Tokyoの実際の学習風景
:::
42 Tokyoでの学びを通して、どのようなスキルが身についたのだろうか。特殊カリキュラムをこなす日々の中で身についた知識やスキルについて、松本さんに詳しく聞いた。
:::box
**松本さん**
42 Tokyoでのコモンコアが終了した時点では、正直、自分に身についた知識やスキルについてはあまり実感はなかったんです（笑）目に見えたスキルの習得がゴールになっていないので、実際に課題をこなしているときは「これ、役に立つときが来るのか？」と思っていました。恐らく、僕以外にも同じことを思いながら続けていた人は多いと思います。


しかし、役に立ったと思う日が来たんです。それは、松尾研在籍中、プロジェクトでエンジニアリングをしていた時期があり、定期的に業務の進捗報告をする機会があったんですが、「なぜこのような実装に至ったか」と聞かれたとき、「このような背景があり、こういった意図で実装しています」と、とてもスムーズに説明ができたんです。学生同士でフィードバックしあいながら課題を進める42 Tokyoの学習フローを、ここで活かすことができました。自分が行った作業の内容を、相手がしっかり理解できるように説明しないと課題をクリアできなかったので、そこで“説明力”が身についたのだと思います。


未知の領域に対しての対応力は確実に身につきましたし、自身の技術面の成長も感じました。コモンコアで学んだ内容とは違う技術領域に触れたときに、「これはあの課題で学んだ内容と裏にある理念は共通なのではないか」と気づき、さらに理解が深まった瞬間もありました。

そういった気づきがあるたびに、課題の意味を改めて理解できたと実感しました。
:::
松本さんはさらに、「42 Tokyoの特殊なカリキュラムは、偶発的な学びが起きやすい環境となるよう、意識的に設計されているんだろうと実感した。」と続けた。42 Tokyoを通して身についたスキルの存在に気づくたびに、点と点がつながっていく感覚があったのだという。
## 人事統括担当として描く組織像
42 Tokyoと松尾研の両軸で進んでいった1年間は、どのような将来像を描いて日々を過ごしていたのか。そして、42 Tokyoを卒業した現在は、どのようなビジョンを描いているのか、松本さんは以下のように語った。
:::box
**松本さん**
当時は明確なビジョンを意識していなかったんです。ただ、松尾研も42 Tokyoも同様に、自分の得意分野に気づけたというのは、人生を大きく変えたきっかけでもありますし、人生に与えたインパクトはとても大きいと思います。


42 Tokyoは去年の7月に卒業していて、現在はスタートアップで働いています。所属企業は、オーダーメイドでAIの受託開発を主に行っています。AIを学ぶ環境も展開しており、講義の設計なども行っています。その中で現在は、人事統括及びプロダクトマネージャーとして仕事をしています。人事統括としては、Missionの達成を第一としつつ、メンバーそれぞれの強みを活かしながら、事業を一番成長させられる文化の浸透・採用・アサインを日々模索しています。また、プロダクトマネージャーとしては、プロダクトの設計から、開発や機能検証のマネジメントを行っています。


42 Tokyoに在籍していた当初は明確なビジョンはなかったと話しましたが、現在の僕は、将来的には教育関連に携わることを目標としています。そのためにも、まずは自分の価値を最大限に発揮できる今の会社で、尊敬できる人たちと一緒に会社としての目標を達成していくことが大事だと思っています。
:::
松本さんの所属している企業のビジョンは “テクノロジーですべての「ひと」の力を解き放つ” であり、この「すべて」の部分は、外の人たちだけではなく、会社で働くメンバーも含まれるそうだ。社内外でこのビジョンを達成すべく、現在は業務にあたっているという。

:::box
特集：
:::</description><pubDate>Tue, 02 Jul 2024 02:23:09 +0000</pubDate></item><item><title>日本リスキリングコンソーシアム　最新の生成AI講座「 Google AI Essentials」を先着1万人に無料提供
</title><link>https://ledge.ai/articles/google_ai_essentials</link><description>:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::

2024年6月19日、日本リスキリングコンソーシアムは、 最新の生成AI講座「Google AI Essentials」を新規会員先着10,000人に無料で提供すると{target=“_blank”}した。

本講座は、初心者でも10時間程度でAIの基礎知識と活用方法を習得できる日本語対応のオンライン講座だ。通常8,000円相当の有料講座だが、今回は新規会員の先着10,000人が無料で受講できるという。GoogleのAIエキスパートが講師を務め、受講修了時には認定証が発行される。

### 主な学習内容は以下の通り
- 生成 AI ツールを使って、アイデアやコンテンツを開発し、より多くの情報に基づいた意思決定を行い、日々の作業をスピードアップする
- 明確で具体的なプロンプトを作成し、必要なアウトプットを得る。プロンプトのテクニックを応用して、要約やキャッチフレーズの作成などに役立てる
- AI にありうるバイアスを特定し、その弊害を回避することで、責任を持って AI を使用する
変化する AI の今後の展開の中で常に最新の情報を得るための戦略を立てる

AIに興味はあるが、何から学んだら良いのか迷っている方、日々の業務を効率化したい、AIスキルを習得してキャリアアップを目指す方に推奨の基礎講座で、さらに本講座を受講すると、以下2種の講座も無料で受講が可能だという。

### Google データアナリティクス プロフェッショナル認定証（2022 年提供開始）
データに基づいてビジネス上の意思決定を行うためのデータ収集、変換、整理スキルを学び、データアナリストとして即戦力となるためのスキルを身につけるコース

### Google サイバーセキュリティ プロフェッショナル認定証（2023 年提供開始）
一般的なリスク、脅威、脆弱性を特定する方法やそれらを軽減するテクニックなど、成長著しいサイバーセキュリティ分野で即戦力として活躍するためのスキルを身につけられるコース

!
:::small
画像の出典：[日本リスキリングコンソーシアム](https://japan-reskilling-consortium.jp/news/248
){target=“_blank”}
:::
学位や事前知識など受講条件はなく、誰でも申込みが可能とのこと。AIの基礎知識を身に着けたい方はぜひお見逃しなく。

:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:41:55 +0000</pubDate></item><item><title>【6/27 15:00開始】 最新モデル「Claude 3.5 Sonnet」の実力に迫るLIVE配信をレッジが開催！GPT-4oやGemini 1.5 Proとの違いなど徹底解説</title><link>https://ledge.ai/articles/expo2024_claude3-5_sonnet_live</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している特設サイト「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 突如発表された最新モデル「Claude 3.5 Sonnet」 その実力を検証するLIVE配信の開催が決定
2024年6月21日にAnthropicが突如として最新AIモデル「Claude 3.5 Sonnet」を発表した。

:::box
{target=“_blank”}
:::

Claude 3.5 Sonnetは、コードの生成やイメージの認識の性能が大幅に向上し、前バージョンの上位モデルであるClaude 3 OpusやGPT-4oなどの競合モデルを上回る性能を持っているという。

現在公開中の「{target=“_blank”}」では、LLM比較というテーマで、GPT-4o（OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった主要LLMの最上位モデルの比較結果のまとめ記事（{target=“_blank”}）を公開している。

今回の発表を受け、EXPO特設サイトでは、上記記事の追加企画として、Anthropicの最新LLM「Claude 3.5 Sonnet」について解説するLIVE配信を行う。

前バージョンのモデルであるClaude 3 Opusとの違いや、GPT-4oやGemini 1.5 Proといった他LLMとの違いを実際のデモを通じて比較しながら、リアルな使用感をお届けする。
主要LLMの最新情報をアップデートしたい読者は、是非視聴してみてほしい。

ーーー
LIVE配信の視聴をご希望の方は、下記より参加登録が必要になります。
:::button
{target=“_blank”}
:::
※ 既に参加登録済みの方には、別途メールにて視聴のご案内をさせていただきます。

## 開催概要
イベント名： 【追加企画】Ledge.ai EXPO 2024 summer  LIVE配信
主催：株式会社レッジ
URL：{target=“_blank”}
配信形式：zoomウェビナー（LIVE）
配信日時：2024年06月27日（木） 15:00〜15:30
視聴には事前の参加登録（無料）が必要になります。</description><pubDate>Tue, 25 Jun 2024 13:36:46 +0000</pubDate></item><item><title>NLP（自然言語処理)これまでの80年とこれからの20年（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-msd-short</link><description>
:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

## ChatGPTなどに活用されるNLPの歴史を紐解く
生成AIの台頭により "NLP" が一般的にも広く認知されるようになったが、NLPが80年にわたって発展してきた技術であることはご存じだろうか。実は、NLPの起源を探ると、1940年代の機械翻訳までさかのぼる。

今回は、長年研究されてきた技術であるNLPについて、元女子高生AI「りんな」などで知られるrinna株式会社の元CEOであり、現在はマイクロソフト ディベロップメント株式会社のプリンシパル アプライド サイエンティストであるZhan (Cliff) Chen / 陳 湛 氏にお話を伺った。

:::box
!
**マイクロソフト ディベロップメント株式会社**
**Zhan (Cliff) Chen / 陳 湛 氏**
:::

:::button
{target=“_blank”}
:::

**Cliff 氏**
私は今年の４月にマイクロソフトに入社しましたが、実は入社は２回目です。2015年にマイクロソフトでAIチャットボットのrinnnaを作り、翌年以降もディープラーニングの技術を用いたチャットボットを開発していました。例えば、音声合成、歌、ダンスなど、現在生成AIで話題になっているコンテンツを2017年～2019年ごろに研究していて、2019年にはGPTがチャットボット開発に適していることも発見していました。
そもそもなぜチャットボットなのか？という点ですが、チャットボットは人間の知能に一番近いと考えていたからです。GPTには未来がありそうだと考えていました。2019年11月には、現在「RAG」として認知が広がっている技術も作って、発表も行っていました。

!

2020年にマイクロソフトからrinnaがスピンオフして、rinna株式会社を設立し、そこのCEOに就任しましたが、面白かったのは2021年4月ごろに日本語版のGPT-2のオープンソースで発表したことです。そこからGPTをアップデートし続け、Hugging Faceでオープンソースとしてリリースしていました。
凄く自慢できることがあるのですが、その当時の日本のNLP大会の中で、rinnaのGPT-2の技術を引用した論文が全体の3%から5%程あったことです。その当時はBERTが主流で、GPTはマイナーな技術だったのですが、日本語のGPTの論文の中にrinnaの技術が参照されていたのは印象深かったです。

**箕部（モデレーター）**
RAGの研究に関してもかなり早い段階から行われていたのですね。

**Cliff 氏**
我々もその時、KGC(※)は重要だということをたくさん話していましたが、そもそもGPTがマイナーだったのと、GPTは誤回答をすることから「全然ダメだ」と言われていましたね（笑）

OpenAIのChatGPTが出たことは、アカデミックから見るとそんなに革新的ではないのですが、インダストリーの観点から見ると一般ユーザーのマインドセットが変わった出来事でしたね。

:::box
（※）KGC（Knowledge Graph Construction）：知識グラフの構築のこと。知識グラフとは、知識を抽象化したデータ間の関係性を示すデータベース。知識情報が体系的に整理されることで、検索や情報抽出などのタスクにおいて必要な情報を提供することに役立つ。
:::

**箕部（モデレーター）**
AIを理解するうえで、”これまで” と “これから” を理解していくことが重要だと考えますが、クリフさんは専門だと思いますので、そのあたり詳しくお話を伺えればと思います。

**Cliff 氏**
「今までのNLPの80年」について、つまり、LLM（大規模言語モデル）はどこから来たのか？という話ですが…

※続きは特設サイトよりご覧ください 

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：
開催形式：オンライン（特設サイト）</description><pubDate>Fri, 21 Jun 2024 06:43:48 +0000</pubDate></item><item><title>【主要LLMの最上位モデルを比較】GPT-4o、Gemini Pro1.5、Claude 3 Opus 仕事で使えるLLMはどれか？まとめ記事公開中！</title><link>https://ledge.ai/articles/expo2024-llm-comparison</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

大規模言語モデル（LLM）は、チャットボットや文章生成、翻訳、要約、コード生成などの様々なタスクで活用されている。その一方で多くのLLMが存在しており、どれを選べばよいか頭を悩ませている読者も多いと思われる。

6月10日（月）より公開しているLedge.ai EXPO 2024 Summerでは、GPT-4o（ChatGPT / OpenAI）、Gemini 1.5 Pro（Google）、Claude 3 Opus（Anthropic）といった最新モデルを比較したまとめ記事を公開している。いわゆるLLMのスペック比較ではなく、実際の出力結果を比較し、その使用感や出力の特徴を解説しているので、自社にとって最適なLLMを探す際の参考情報としてご覧いただきたい。

:::button
{target=“_blank”}
:::

## ビジネスシーンでの活用を想定した３つのタスクの実行結果を比較
今回の比較記事の中では、以下３つの主要LLMの最上位モデルを対象として比較を行っている。

- GPT-4o（ChatGPT / OpenAI）
- Gemini 1.5 Pro（Gemini / Google）
- Claude 3 Opus（Claude / Anthropic）

パラメータ数や学習データの範囲といったスペック比較は既に様々なところで行われているため、今回は仕事で実際に使えそうか？という観点で、企画、データ分析、ルーティンワークといった切り口で、LLMのアウトプットの比較を行った。
ビジネスシーンでの活用を想定した３つのタスクとその結果の一部を以下に紹介する。

## 企画：アイデアを創造する能力を比較
記事の中では、各LLMに「新しいテクノロジー製品のアイデアを提案してください。」というプロンプトを送り、それぞれの出力結果を比較している。
LLMは、学習した膨大な過去データから確率的な推論を行い、もっともらしい出力を行うものである。よくも悪くも私たち人間の一般的な価値観に合わせた平均的な回答の生成が得意なLLMが、新しいアイデアの発想において、現在どの程度のアウトプットを出すことができるのかをまとめている。

例えばOpenAIが開発した最新の大規模言語モデルGPT-4oでは、アイデアの中身については、真新しさや面白みには欠けるのは否めないというのが正直な評価であった。しかし出力に関する指示はなくとも、文章の項目構成を整理したアイデアが出力してくれる点には有用性も感じられた。アウトプットをそのまま使うレベルではないものの、着想のきっかけを得るための手段としては十分に使えるものではないだろうか。

!
:::small
GPT-4oが出力した企画案
:::

その他の２つのLLMの実行結果も記事の中で取り上げている。詳細は是非記事をご一読いただきたい。

## データ分析：データを理解し、可視化する能力を比較
２つ目のデータ分析の比較も興味深い示唆が得られる内容になっている。比較の内容としては、ChatGPTで生成したマーケティングデータのサンプルファイルを元に各LLMに分析結果を出力してもらった。上述した企画よりも、LLM毎の違いが見受けられた。

特にGeminiは、出力後もグラフをインタラクティブに操作でき、その場でデータの編集ができる。またGoogleスプレッドシートとの連携もスムーズにできる点などは、Google製品で業務を行っているビジネスマンにとっては、有力な選択肢となりそうだ。

!
:::small
Gemini 1.5 Proでのグラフ編集の動画も公開している
:::

## ルーティンワーク：記事を要約する能力を比較
最後に記事要約の実行結果をまとめている。シンプルなタスクであるがゆえに、LLMが有する言語処理能力がわかりやすく現れる内容といえるだろう。
今回は以下の記事の原稿ファイルを読み込ませ、要約を実行した。

:::box
{target=“_blank”}
:::

要約の内容については、どのLLMも違和感はなく、十数秒ほどで得られるクオリティとしては十分なものだった。しかし要約の仕方にはそれぞれ違いがあり、この部分は個人によって判断が分かれるように思われる。記事内の実行結果をその目で見て判断いただきたい。

!
:::small
Claude 3 Opusが出力した要約結果
:::

今回はプロンプト内で出力の形式などを特段指示していないため、プロンプトの作り込みで変わってくる部分もあるだろう。しかし同一の条件の元で、各LLM毎のアウトプットの違いを把握しておくことは、LLMを選ぶ際の重要な参考情報となりうる。記事をきっかけに是非お手元で試し、実際の使用感を体験いただきたい。
比較記事の全文は以下の特設サイトより閲覧できる。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 20 Jun 2024 06:38:09 +0000</pubDate></item><item><title>AWSが新AI認定試験を発表　2024年8月13日より開始、初の「ベータ試験」での日本語試験も提供</title><link>https://ledge.ai/articles/aws_crtified_ai_practitioner</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年6月14日、Amazon Web Services, Inc.（AWS）は、AI人材育成に関する説明会で、AIスキルを証明できる「AWS Certified AI Practitioner」と「AWS Certified Machine Learning Engineer（MLA）」の2種の新しい認定試験が2024年8月13日から開始することを{target=“_blank”}した。

**「AWS Certified AI Practitioner」**
AI、機械学習（ML）、および生成AIのコンセプトやツールに精通していることを証明する際に役立つ、AIに特化した資格だ。この資格は、AWS認定試験の4つのレベルの中でも基礎的な知識習得を目的とした「Foundational」のカテゴリに位置づけられる。

**「AWS Certified Machine Learning Engineer（MLA）」**
こちらは、AIやMLソリューションの構築、デプロイ、保守に必要なスキルを証明するものであり、モデルパフォーマンスの最適化、計算資源の管理、モデルのバージョンアップ、AIソリューションの保護などをスキル対象とする技術者向けの認定資格だ。AWS認定試験の「ASSOCIATE」のカテゴリに位置づけられる。

新たな2種の認定資格は、2024年8月13日から「ベータ試験」として登録を開始する。通常は英語での実施だが、このベータ試験は同社として初の試みである日本語試験も提供をする予定だという。
</description><pubDate>Thu, 20 Jun 2024 09:19:07 +0000</pubDate></item><item><title>その日から使えるデモも実演！「マルチモーダルAI」の概念を15分で丁寧に解説するウェビナーが公開中</title><link>https://ledge.ai/articles/expo2024-webinar-multimodalai</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容について紹介するものである。
:::

## 多種多様なデータを扱うことが生成AIをビジネスで活用する際の重要な鍵となる
生成AIは、ビジネスの多岐にわたる分野で急速に活用されている。生成AIは、テキスト、画像、音声、ビデオなどの多種多様なデータを扱う能力により、より高度な意思決定や業務効率化を実現するツールとして注目を集めている。特に、マルチモーダルAIの多様なデータソースを統合して分析・生成する能力は、ビジネスの競争力を高める鍵として注目を集めている。

とはいえマルチモーダルAIという言葉こそよく耳にする機会は増えてきたものの、実はまだその概念について良くわかっていない読者も多いのではないだろうか？

6月10日（月）より開催している「Ledge.ai EXPO 2024 summer」オンライン特設サイトでは、マルチモーダルAIについて15分で基本的な概念を解説するウェビナーを公開している。マルチモーダルAIの概要を短時間で学べるため、興味のある方は是非動画をご覧いただきたい。



:::button
{target=“_blank”}
:::

## マルチモーダルAIとは何か？
マルチモーダルAIとは一言で説明すると、複数種類の情報を組み合わせて高度な判断を行うAIのことである。モーダルとはデータの種類を指し、テキストや画像、音声、映像など様々なデータを扱うことが含まれている。
ビジネスの現場で扱うデータが多様化してきたことで、このマルチモーダルAIが今注目を集めている。

!

私たちがこれまでAIとして扱ってきたいわゆるシングルモーダルAIでは、単一のデータ形式に特化していた。マルチモーダルAIでは、異なるデータ形式間の関連性を学習し、それを基にした高度な予測や判断を行うことが可能になる。これにより単一のデータ形式だけでは得られない複雑な処理結果を引き出すことができる。

!

## 大規模言語モデルとの統合でマルチモーダルAIの能力は飛躍的に向上
大規模言語モデル（Large Language Models, LLM）は、テキストデータの処理に特化したAIモデルであり、膨大なテキストデータから学習することで、高度な言語理解能力を持っている。この言語処理能力が、異なるデータ形式間の関連性の理解においても非常に高い性能を発揮し、主要な大規模言語モデルにも、画像、テキスト、音声などのデータを統合して処理するマルチモーダル機能が強化される動きが加速した。

ウェビナーの中でも国内外の主要な大規模言語モデルを4つほどピックアップしているので、是非チェックしてみてほしい。

!

## マルチモーダルAIでどんなことができるかをデモ実演
ウェビナーの中では、OpenAIの最新モデル「GPT-4o」を使い、ビジネスシーンでの活用を想定したデモを実演している。すぐ試すことができるデモ内容になっているので、是非動画を参考に自身の業務の中でも活用してみてもらいたい。

今回は
- ホワイトボードの会議メモの整理
- 手書きのラフデザインからhtmlのソースコードを生成

の2種類のデモを行った。
ホワイトボードの会議メモを整理するデモについてその一部を簡単に紹介する。

会議でディスカッションした内容をホワイトボードに書き込んで記録することは、ビジネスの現場でよく見られる光景だ。
ホワイトボードの内容を構造化して整理しておきたい場合に、手打ちでテキストメモに書き起こしたりしていないだろうか？
こうした作業は、マルチモーダルAIを活用することで、作業を大幅に効率化できる。

!
!

デモの中では、ホワイトボードを撮影した画像と簡単な指示テキストを与えるだけで、情報が整理されたテキストメモが出力される過程を確認することができる。さらにそのメモからアイデアをブラッシュアップするといった追加指示を与えて、ただの文字起こしに＋αのタスクを実行させるところまで実演しているので、このあたりも注目してみてもらいたい。

ーーー

マルチモーダルAIは、大規模言語モデルと統合し、より自然で人間らしいインタラクションが実現可能になり、さまざまな分野での応用が期待されている。
この機会にぜひ動画をご覧いただき、ビジネスの現場でどのように活用できるかを学び、実際に導入するためのヒントとなれば幸いである。

:::button
{target=“_blank”}
:::


## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）

</description><pubDate>Fri, 14 Jun 2024 04:03:02 +0000</pubDate></item><item><title>生成AIの未来を掴むための3つのキーワード（一部公開）</title><link>https://ledge.ai/articles/expo2024-interview-keyword-short</link><description>:::box
本記事は、国内最大級のAI（人工知能）関連メディアLedge.aiが6月10日（月）より公開している「{target=“_blank”}」において、サイト内で掲載されているキーノートウェビナー、有識者や業界をリードする企業への特別インタビュー、その他おすすめコンテンツの内容の中から、一部を抜粋して紹介するものである。
:::

生成AIの発展は目覚ましいものである。その中で特に「マルチモーダルAI」「AIエージェント」「独自データ活用」の3つは、今期の企業の生成AI活用において、押さえておきたい重要キーワードだ。

「マルチモーダルAI」とは、テキストや画像、音声など複数の情報形式を統合的に理解・生成する技術で、「AIエージェント」とは特定のタスクを自律的に実行するAIプログラムであり、ビジネスプロセスの自動化と効率化を実現できるものである。また、最近の生成AI活用事例で多く耳にするようになった「独自データ活用」は、企業が保有するデータを活用してAIモデルのトレーニングを行う、または、保有データを参照して企業に特化した回答を生成する手法だ。

この3つのキーワードは、生成AIの未来を切り拓くために不可欠な要素であり、企業の競争力を高め、ビジネスの成長を加速させるものである。生成AIの社内活用を推進している、または、今後更なるAI活用を検討するユーザーは必見の内容だ。ぜひ特集サイトから一読いただきたい。

:::button
{target=“_blank”}
:::
## 目次
1. マルチモーダルAI：データの壁を越える技術
2. AIエージェント：企業のパートナーとしての役割
3. 独自データ活用：基盤モデルをベースに競争力強化
4. まとめ

## マルチモーダルAI：データの壁を越える技術
マルチモーダルAIは、テキスト、画像、音声などの複数のデータ形式を同時に解析する技術だ。これにより、単一のデータ形式では得られない洞察を引き出すことができる。例えば、画像とテキストを組み合わせることで、物体認識とその説明を同時に行うことが可能となる。こうした技術は、特に多様なデータを扱う現代のビジネス環境において非常に重要だろう。

技術的な中核には…

※続きは特設サイトよりご覧ください。

:::button
{target=“_blank”}
:::

## 開催概要
イベント名：Ledge.ai EXPO 2024 summer
主催：株式会社レッジ
URL：{target=“_blank”}
開催形式：オンライン（特設サイト）</description><pubDate>Thu, 13 Jun 2024 03:47:03 +0000</pubDate></item><item><title>Microsoftが無料公開　大人にもお薦め！ 中高生向け生成AI教育教材「生成AIを安全かつ責任を持って活用するために」日本語版も利用可能に</title><link>https://ledge.ai/articles/microsoft_unlocking_genai_safely_and_responsibly</link><description>:::small
画像の出典：{target=“_blank”}
:::

Microsoft は2024年6月、教育者と中高生が授業で利用できる生成AIのツールキット「Unlocking Generative AI Safely and Responsibly（生成AIを安全に責任を持って活用するために）」の日本語版をMicrosoft Learnで{target=“_blank”}した。

生成AIは近年教育分野においてもその可能性を広げている。しかし新しい技術の導入には慎重さが求められるため、学生が生成AIを責任を持って使用できるよう教育することが重要だと同社は述べる。同ツールキットは、13歳から15歳の学生と教育者を対象に、デジタルリテラシーとオンライン安全性のスキルを高めることを目的としている。


!
:::small
画像の出典：{target=“_blank”}
:::

教材は、指導情報と、物語パートを組み合わせて作られている。生徒は、物語の主人公Ginaと共に生成AIのケーススタディを通して、内容の捏造、プライバシーの考慮、バイアスの認識、精神的健康などの重要なトピックを学ぶ。教育者はこのリソースを単一のレッスンとして使用することも、4つのパートに分けて使用することもできる。

**プロンプトの解説の例**
!
:::small
画像の出典：{target=“_blank”}
:::

**Ginaと一緒に学ぶアクティビティの例**
!
:::small
画像の出典：{target=“_blank”}
:::

学生はまた、Microsoft Copilotやプロンプトエンジニアリング技術など、さまざまな生成AIツールを探求する演習に参加することで、ファクトチェック、良好なデジタル衛生習慣の育成、データプライバシーの保護、精神的健康の管理などのスキルを身につけることができる。

教材はMicrosoftとシンガポールのテック企業Cyberliteとの協力で開発された。リソースセットは現在、英語（US、UK）、日本語、中国語（ZH）、韓国語（KO）でも提供されている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 06 Jun 2024 08:10:02 +0000</pubDate></item><item><title>公務員からリスキリングで機械学習エンジニアに転身　42 Tokyo特別インタビュー【第2回】第1期生　鈴木昂太さん</title><link>https://ledge.ai/articles/42tokyo-2</link><description>:::box

**昨今のリスキリングブームの中、ITやAIのスキルを身に付けたいと思うビジネスパーソンや大学生は数多くいる。また、簡単なプログラミングをマスターするだけなら過去10数年で見違えるほどハードルが下がった。しかし、それは参入障壁も下がったということであり、陳腐化しない本質的な技術を学ぶことは依然として難しい。**

**では、どういった良質の選択肢があるのか？独自のカリキュラムでこの難題に挑戦する学校がある。フランス・パリ発のエンジニア養成機関「42（フォーティートゥー）」の東京校である、42 Tokyoだ。なんと学費は無料だ。「挑戦したいすべての人に質の高い教育を。」をコンセプトに、実践的なカリキュラムと学習方法で、”即戦力” となるエンジニアを育成し、現在世界31ヵ国で展開されている。東京校は2020年6月に開校。**

**Ledge.ai編集部では、その秘密を求めて事務局長の佐藤 大吾氏と、42 Tokyoで学び、現在はそれぞれの進路で活躍する生徒4名にインタビューを実施した。「42」の革新的な取り組みについて、全5回の連載記事でお送りする。本稿は第2回。**
:::

※インタビューは2024年4月18日、zoomにて行われた。

:::box
!
**42 Tokyo 第1期生**
**鈴木 昂太**
機械学習エンジニア
:::

## 「冒険して尖った人生を送りたい」　公務員からエンジニアに転身した思い


鈴木さんは大学卒業後の進路として、公務員になることを選んだ。しかし現在は、公務員からエンジニアへ大きく転身している。なぜ「42」にチャレンジしようと思ったのか、鈴木さんは以下のように振り返った。

:::box
**鈴木さん**
公務員になる前からAIなどに興味はあったのですが、安定を求めて公務員の道を選びました。ただ、思い返せば公務員の面接時も、全然触っていないにも関わらず「AIやデジタル化に向いた人材になれる」と言っていたので、ずっと自分の中でエンジニアという職業に興味はあったのだと思います。

より強く意識したきっかけは、初めてExcelでマクロを組んで業務の効率化をしたときです。自分でできたという達成感や楽しさ、そして前々から興味があったこともあり、エンジニアに向いているのではないかと思い始めました。

私の中の「冒険して尖った人生にしたい」という気持ちから、エンジニアになりたいという思いが強くなりました。

:::

その後、公務員を続けながらエンジニアスクールに通いはじめたと言う。スクールに通う中で、1か月間の勉強合宿の告知を見つけ「どうしてもこの北海道合宿に参加したい」という思いから、公務員を退職して合宿に参加したそうだ。42 Tokyoとの出会いは、この合宿がきっかけだった。

:::box
**鈴木さん**
海外の42に通う知人がいる人にスクールで出会い、42の東京校を知りました。当時通っていたエンジニアスクールで出会った仲間と一緒に、42 Tokyoの第1回目の試験を受け、第1期生として入学しました。
:::

## 入学試験「Piscine（ピシン）」をゲームに見立て攻略方法を模索

入学試験「Piscine」は通常の試験とは違い、受験者同士が協力して課題を解いていく方式だ。4週間に及ぶ入学試験への向き合い方は様々で、寝ずに徹夜で課題をこなす人、中には仕事と試験を両立している人もいたという。難関ともいわれるこの特殊な試験にどのように挑んだのか、当時の心境を鈴木さんは以下のように振り返った。

:::box
**鈴木さん**
Piscineを受ける時点でエンジニアへの就職（株式会社ラクスパートナーズ）が決まっていたので、試験に落ちたら人生が終わってしまうような切羽詰まった状況ではありませんでした。その中で、「42 Tokyo」というゲームをクリアするにはどうしたら良いか？と、自分なりに攻略方法を探りながら取り組み、ゲーム感覚で楽しみながら続けることができたと思います。

朝9時から夜10時までやったらそこで帰るなど、ルールを設けて効率良く進めることを意識し、試験期間中は校舎の近くに部屋を借りて、試験課題に集中して徹底的にやる！というように集中する環境を整えて挑みました。
:::

## 必要なのは学びたいという「意志」と「継続する努力」

鈴木さんが在籍していた期間はコロナ禍の影響でオンライン学習がメインだった。オンラインというコミュニケーションが取りづらい環境でも、前向きに楽しみながら課題に取り組むことができたのは、ともに学ぶ仲間の存在が大きかったという。

:::box
**鈴木さん**
入学当初は、シェフや音楽家など少し変わった経歴の人が多く在籍していました。尖った人が結構いて面白かったです（笑）ですが、ある程度のコミットメントが必要なので、それが難しく途中で脱落する人もいましたね。少しずつ人が減っていく様子を見て「あの人も辞めてしまったのか」と少し寂しく思う場面もありました。基礎課程修了まで残っていたのは第1期生だと数百人中数十人程度でしたので、諦めずに続けることの難しさを体感しました。


今は環境が変わりオフライン学習がメインなので、校舎に行けば話せる仲間がいます。それが続けるモチベーションにつながるのではないかと思います。
:::

42 Tokyoの学習は「コモンコア」と呼ばれる基礎課程からはじまる。鈴木さんは大学時代に情報系の大学や学部を出ていなかったが、42 Tokyoでは基礎から学べるので、自分の弱みをカバーできると、期待していたという。実際に、ウェブの動きやデータ保管などのウェブ開発やプログラミングに関する学習は、数学の基礎理論とつながっているので、とても面白かったと鈴木さんは振り返った。

:::box
**鈴木さん**
プログラミングの基礎であるC言語の勉強から始めました。実際に基礎から学ぶことで身につく知識も幅広いので、入学当初は単純に「面白い人とたくさん出会えて無料で学べるなら続けない手はない！」と思いました。

本を読んで理論を学ぶいわゆる座学形式ではなく、実践形式のカリキュラムというのも特長ですし、仲間と一緒に期限内に与えられた課題をこなすことで、仲間同士刺激しあいながらチャレンジできる環境は身につく知識も多いと思います。

当時はコロナ禍ということもありオンライン学習だったので、仕事と並行して土日も含め学習に週40時間費やし、ひたすらプログラムを書く生活を続けていました。一番最後の課題は、5人チームで行う、ウェブアプリを制作する内容だったのですが、自分たちの持っている全ての力を注ぎ込み、1〜2ヶ月で集中してやりきりました。
:::

当時の仲間とは卒業後も交流が続いていて、最新ニュースの共有など定期的に連絡をとりあっているそうだ。起業している人や、海外の「42」に留学して勉強を続けている人など、進む道は様々だ。お互いに新しい情報を持ち合うなかで、今も刺激を受けているという。

## 異業種からのチャレンジを経験して改めて思うこと

デジタル化が進む昨今、欠かせない職業になりつつあるシステムエンジニア。公務員から大きな転身を経験した鈴木さんが考える、42 Tokyoの魅力を聞いてみた。

:::box
**鈴木さん**
エンジニアと言っても様々だと思うので、色々なことに触れてみることが大事だと思います。自分がどこまで知りたいか、何を学びたいかが重要で、いきなり転職というよりは、趣味の範囲で良いので調べたり、勉強を続けることが大事だと思います。

「エンジニアになりたい＝42 Tokyoへ行く」というよりは、まずは「自分が何を学びたいか」「どのようなエンジニアを目指しているか」を理解した上で、スクールを選ぶ方がミスマッチも防げると思います。
色々体験してみて面白さを知ったうえで、深い部分まで追究したいと思ったときに、42 Tokyoを受験してみるのは良い判断だと思います。人生は長いですし、経験は無駄にはならないですから。
:::

“この人に聞けばなんでもわかる” というような知識豊富なエンジニアは社内に必ず数人はいるが、必ずしもみんながそうである必要はない。例えば、ウェブアプリ制作の過程で、サーバーや内部まで把握している人、デザイン制作の人など、様々な分野のエンジニアがいる。

「様々な選択肢があるなかで、本当に深いところまで学びたいと思ったら、基礎から実践的に学べる42 Tokyoは最適な環境といえる」と鈴木さんは続けた。

:::box
**鈴木さん**
試験を受けただけの人や入学して基礎課程修了前に辞めてしまった人も見てきましたが、途中で辞めた人もネガティブな辞め方ではなく42 Tokyoで何かを得てそれを糧にして活躍している人が多いので、チャレンジすることで得るものはたくさんあると思います。私自身もこの挑戦を経て、現在機械学習エンジニアとして業務の幅を広げています。

一流のエンジニアを目指している人、深いところまで網羅したい人は、ぜひ基礎から学べる42 Tokyoにチャレンジしてほしいと思います。
:::

:::box
特集：
:::</description><pubDate>Thu, 30 May 2024 12:16:00 +0000</pubDate></item><item><title>OpenAI が開発者向けQ&amp;AコミュニティサイトStack Overflowと新たなAPIパートナーシップを発表</title><link>https://ledge.ai/articles/openai_stackoverflow_api_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、OpenAIとStack Overflowは、開発者向けに最適化された技術情報とAI開発ツールを提供する新しいAPIパートナーシップを{target=“_blank”}した。

このパートナーシップにより、OpenAIのユーザーや顧客は、Stack Overflowが提供する正確で検証済みのデータを基に迅速な問題解決を図り、重要なタスクに集中できるよう支援されるという。

この協業の一環として、OpenAIはStack Overflowの「OverflowAPI」を利用し、ユーザーにStack Overflowの検証済み技術知識を直接提供する。これにより、ChatGPTはStack Overflowの豊富な技術データベースと連携し、利用者に対してより精度の高い支援を提供できるようになる。また、Stack Overflowは、OpenAIのAIモデルを利用して「OverflowAI」の開発を行い、内部テストから得た洞察を活かしてAIモデルの性能向上を図る。

このパートナーシップは、技術者が直面する課題への対応速度を向上させ、開発者コミュニティ全体の生産性とエンゲージメントの向上を目指している。両社は、開発者が必要とする情報や解決策を、より迅速かつ正確に提供できる環境を整備することで、技術開発の新たなスタンダードを築くことを目指している。

Stack Overflowは2月29日にGoogle Cloudとの協業を発表しており、「Gemini for Google Cloud」との統合を進めている。この連携ではGoogle Cloudのプラットフォーム上でStack Overflowの情報を活用し、開発者が容易に重要なナレッジベース情報やコーディング支援を利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 12:52:43 +0000</pubDate></item><item><title>AWSが「Amazon Q」の一般提供を開始　企業内データを活用したAIアプリケーション開発の加速を目指す</title><link>https://ledge.ai/articles/amazon_aws_q</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）は2024年4月30日、生成AIアシスタント「Amazon Q」の一般提供を開始したと{target=“_blank”}した。

このサービスは、開発者が自社のデータを活用してAIアプリケーションを構築できるよう支援することを目的としており、特にソフトウェア開発の加速と企業データの活用が可能になるという。

Amazon Qは、コード生成、テスト、デバッグ、計画立案、推論機能を備え、開発者はコードの自動変換やアップグレード（Javaバージョンアップグレードなど）、新しいコードの実装が可能となる。この生成AIアシスタントは、エンタープライズデータリポジトリへの接続もサポートしており、企業のポリシー、製品情報、業績、コードベース、人材に関する質問への回答や、データの論理的な要約、トレンド解析、データ関連の対話が行えるとのこと。

また、社内データから生成AIアプリの構築を可能にする新機能「Amazon Q Apps」も同時に発表された。従業員は自然言語でアプリについて記述するだけで、必要とされる業務を遂行するアプリを生成できるという。この機能により、日常業務の簡素化と自動化が促進される。

さらに、Amazon Qは40以上の一般的なビジネスツールと簡単に接続でき、企業は自社のデータを効率的に集約し、アクセスできるようになる。この広範なデータ統合能力により、企業はよりデータ駆動型で効率的な運営が可能になる​とのことだ。


:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 11:42:47 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>生成AIプロジェクトの開発者コミュニティ、アメリカ・インドに次いで日本が先導ーGit Hub 2023年の動向レポート</title><link>https://ledge.ai/articles/github_the_state_of_open_source_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2023年11月8日、「オープンソースとAIの現状」に関する報告を{target=“_blank”}した。

報告によると、開発者たちは大量の生成AIプロジェクトに取り組んでいる。特にOpenAIなどの基礎モデルを用いた開発が目立ち、生成AIプロジェクトは2023年のオープンソースプロジェクトのトップ10にランクインしたという。これらのプロジェクトには、全開発者の92%が使用または実験中であると報告されており、GitHub上での次世代AIイノベーションを牽引すると期待されている。

また、2023年はオープンソースへの初参加者が最も多く、これまで商業的に支援されたプロジェクトが初参加者の大部分を占めていたが、今年は生成AIプロジェクトも初参加者向けのトップ10プロジェクトに登場した。GitHub上のプライベートプロジェクトの数は前年比38%増加し、全活動の80%以上を占めている。

全世界で、GitHubを使用してソフトウェアを構築し、共同作業を行う開発者が増加している。アメリカは依然として最大の開発者コミュニティを持つが、他の地域も成長を見せている。

次の5年間で最も成長が見込まれる開発者コミュニティに関する予測では、インドが2027年までにGitHub上で最大の開発者コミュニティになると予想されている。日本の開発者数は約280万人で、世界8位にランクされており、今後の成長が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::

さらに、生成AIは個々のコントリビューターの数において148%の年間成長率を達成し、生成AIプロジェクトの総数も248%増加している。この分野において、アメリカ、インド、そして日本が先導しており、他の地域も追随している。

!
:::small
画像の出典：{target=“_blank”}
:::



報告は、2022年10月1日から2023年9月30日までに、GitHub から取得した匿名化されたユーザーおよび製品データに基づいて作成された。

:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:49:07 +0000</pubDate></item><item><title>AIの遅れ取り返せるか　Appleが開発者向けフレームワーク「MXL」Geminiの裏でひっそりと公開</title><link>https://ledge.ai/articles/apple_released_mlx</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2023年12月、AI分野での新たな取り組みとして、開発者向けのオープンソース機械学習フレームワーク「MLX」を{target=“_blank”}した。GoogleのAIモデル「Gemini」の発表と同時であったと各メディアで報じている。

MLXはAppleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​。

Appleの機械学習研究者であるAwni Hannun 氏は、自身のX（旧Twitter）アカウントで、
「ちょうどホリデーシーズンに間に合うよう、本日、Apple 機械学習研究からいくつかの新しいソフトウェアをリリースします。
MLX は、Apple シリコン (つまり、ラップトップ) 向けに特別に設計された効率的な機械学習フレームワークです」
と{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

{target=“_blank”}は10月に、Appleの経営陣は業界の突然のAIブームに驚かされ、昨年末から急いで対応を図っていたと報じており、MLXの発表は、AI分野での急速な進展に対応しようとするAppleの努力の一環との見方もある。



:::box

:::
:::box

:::</description><pubDate>Fri, 15 Dec 2023 05:44:48 +0000</pubDate></item><item><title>SelfGoal: LLMエージェントの高難易度タスク解決を飛躍的に向上させる新手法</title><link>https://ledge.ai/articles/ai_agent_selfgoal</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月、特定の高難易度タスクにおけるLLM（大規模言語モデル）エージェントの性能を大幅に向上させる新しい手法「SelfGoal」が{target=“_blank”}された。研究者たちは、この手法がエージェントに複雑な問題解決能力を与え、ゲームやプログラミングなどの分野での応用が期待されていると述べている。

SelfGoalの核となるのは、最終目標をより実践的なサブゴールのツリー構造に分解し、状況に応じてサブゴールを更新する点にあるという。エージェントは環境の変化に柔軟に対応しながら、最適なサブタスクを特定し、段階的に目標達成を目指すことが可能となる。

従来、LLMエージェントは抽象的な指示に対応するのが難しく、「この勝負に勝ってください」や「お金を稼いでください」といった指示を正確に理解して遂行することが課題となっていた。既存のアプローチでは、タスクを細かなサブタスクに分解する方法や、事前知識を活用してタスクを遂行する方法が提案されていた。しかし、これらの方法には、環境の変化に対応できない柔軟性の欠如や、単純で体系的でない行動を導くという問題があった。

SelfGoalは、最終目標をツリー構造のサブゴールに分解し、エージェントの置かれた状況に応じて最も有用なサブゴールを特定しながらツリーを段階的に更新していく。この動的なサブゴールの更新により、エージェントは柔軟に状況に対応しながら、効率的にタスクを遂行できるという。
## SelfGoalの仕組み
SelfGoalは、主に「探索モジュール」「分解モジュール」「実行モジュール」の3つのモジュールで構成されている。下図は、このSelfGoalの概要を示している。

!
:::small
画像の出典：{target=“_blank”}
:::

- **探索モジュール：** 現在の状況に最も適したサブゴールを選択する。事前知識を利用して、GOALTREEの中から最適なノードを選定する。
- **分解モジュール：** 選択されたゴールノードを具体的なサブゴールに分解する。新たなサブゴールが既存のノードと類似しないようにフィルタリングしながら、ツリーを成長させる。
- **実行モジュール：** 選択されたサブゴールを基に行動を指示し、エージェントが環境と相互作用する。
- ## 具体的な適用例
SelfGoalは、特に次のような分野で有効だという。

- **ゲーム：** ゲームの目標をサブゴールに分解し、状況に応じて戦略を変更することで勝利を目指す
- **プログラミング：** 複雑なプログラミングタスクを段階的に解決し、最終的なプログラムの完成を目指す

実際のタスクでの応用例として、「交渉タスク」におけるSelfGoalの効果が挙げられる。下図は、交渉タスクにおいてSelfGoalが他の手法と比較してどのように優れているかを示している。

このタスクでは、エージェントがアイテムの配分について交渉するシナリオを示している。エージェント（例えば、Alice）がパートナー（Bob）とアイテム（本、帽子、ボール）の配分について話し合い、利益の差を最小化することを目指している。
CLIN、ADAPTという別の手法に比べ、SelfGoalは「相手の評価を明確にする質問をする」など、具体的な行動指針を提供し、交渉の進行に応じて戦略を柔軟に調整している。

!
:::small
画像の出典：{target=“_blank”}
:::

SelfGoalの導入で期待できる効果として、研究グループはLLMエージェントの柔軟性・効率性の飛躍的な向上が期待され、今後さらに高度なタスクに対してもLLMエージェントが有効に活用されることが予想されると述べた。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Thu, 11 Jul 2024 13:17:57 +0000</pubDate></item><item><title>内省メカニズムで進化するLLMエージェント「悪魔の代弁者」　GoogleDeepMindなどの研究チームが発表</title><link>https://ledge.ai/articles/google_deepmind_devils_adovocate</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Google DeepMindとペンシルベニア大学研究チームは2024年6月、大規模言語モデル（LLM）エージェントの適応力と一貫性を向上させるための内省メカニズムを導入する新たなアプローチを{target=“_blank”}した。LLMエージェントが複雑なタスクを効率的に解決できるようにすることが主な研究目的だという。

研究のタイトル「Devil’s Advocate: Anticipatory Reflection for LLM Agents（「悪魔の代弁者」LLMエージェントのための予期されたリフレクション）」は、人間の内省プロセスにおける「悪魔の代弁者」的な役割をエージェントに持たせることを示唆している。つまり、エージェントが自らの決定や行動を事前に批判的に見直すことで、潜在的な失敗を予測し、より効果的な対策が立てられるというアプローチである。

## 内省メカニズムの概要
研究では、LLMエージェントがタスクをサブタスクに分解し、行動と結果について内省を行うように促す以下の3つの内省メカニズムが提案された。

**1. 予期的内省 (Anticipatory Reflection)：** 
行動実行前に潜在的な失敗を予測し、代替案を考慮する。これにより、計画がスムーズに実行されるようになる。

!
:::small
画像の出典：{target=“_blank”}
:::

**2. 行動後の評価とバックトラッキング (Post-action Evaluation and Backtracking)：** 
各行動の実行後、その行動と結果がサブタスクの目的と一致しているかを評価し、一致しない場合は前の状態に戻り、代替行動を取る

**3. 計画修正 (Plan Revision)：** 
計画が失敗した場合、実行された行動と記録を見直し、問題を特定して未来の計画を改善する​。


## 実験と結果
この内省アプローチを用いた実験は、WebArenaというシミュレーション環境で実施された。812のタスクにおいて、LLMエージェントの適応力と一貫性が評価されたとのこと。実験結果は以下の通り。

- **適応力の向上:** 予期せぬ状況に柔軟に対応できるようになった
- **一貫性の維持:** 計画の頻繁な変更が減少し、エージェントの混乱が防止された
- **効率性の向上:** タスク達成までの時間が短縮された

提案された内省アプローチを用いることで、試行回数と計画修正回数が45%削減され、成功率は既存の手法に比べて3.5%向上したという。



:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Jul 2024 05:44:10 +0000</pubDate></item><item><title>神経系と連携し「義足が自分の体の一部と感じられる」自然な歩行を可能に　MITの研究チームが発表</title><link>https://ledge.ai/articles/mit_continuous_neural_control_of_a_bionic_limb</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

マサチューセッツ工科大学（MIT）の研究チームが2024年7月1日に{target=“_blank”}した研究によると、特殊な外科処置と神経系で直接制御できる義足の組み合わせにより、脚を失った患者が従来よりも自然な歩行が可能になることが明らかになった。

{target=“_blank”}
!
:::small
動画の出典：{target=“_blank”}
:::


## 残存する神経を義足に接続し、神経フィードバックを得る
従来の義足技術では、事前に定義された歩行アルゴリズムに基づいて動作するため、動きが限定され、患者は自然な歩行感覚を得ることが難しかった。しかし、研究チームは残存する神経を義足に接続し、神経フィードバックを得られるようにする特殊な外科処置を開発。この新しい義足は、患者の神経系からの信号を受け取り、その信号に基づいて動作するため、より柔軟で自然な動きを実現するという。

実験では、義足を装着した患者が従来の義足と比較して、より自然に歩行できることが確認された。神経フィードバックを得ることで、歩行の安定性やバランス感覚も向上し、患者は義足を自分の体の一部として感じることができると報告している。


### 特殊な外科処置と神経フィードバックを得るための神経接続を示した図
!
:::small
画像の出典：{target=“_blank”}
:::

研究を主導したMITの研究者は、「この技術は、義肢使用者の生活の質を大幅に向上させる可能性がある」と述べている。今後の研究では、さらに多くの患者に対する実験や、長期間の使用による効果の検証が行われる予定だ。


### 義足の自律的な制御と神経系との接続方法を示す詳細な図

!
:::small
画像の出典：{target=“_blank”}
:::

この画期的な技術は、義足技術の新たな可能性を示しており、事故や病気で脚を失った人々の生活に大きな変革をもたらすと期待されていると研究チームは述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 09 Jul 2024 07:45:37 +0000</pubDate></item><item><title>Meta　従来の3～10倍速、60秒以内で高品質3Dアセットを生成する「Meta 3D Gen」を発表</title><link>https://ledge.ai/articles/meta_3d_gen</link><description>:::small
画像の出典：{target=“_blank”}
:::

Metaは2024年7月2日、新しいAIツール「Meta 3D Gen」を{target=“_blank”}した。テキストから高品質な3Dアセットを60秒以内に生成でき、従来の3～10倍の速度で3Dモデルを作成するツールだ。

Meta 3D Genは、シェーディングビューとアルベドビューを作成するAssetGenと、テクスチャを改良するTextureGenの二段階プロセスを採用している。これにより、ゲーム開発、建築設計、VR/AR分野での利用が期待されるという。
## Meta 3D Genの特徴
- **高速生成:** テキストプロンプトから60秒以内に3Dアセットを生成
- **高品質な3Dモデル:** 立体の造形とテクスチャを両方生成
- **多彩なテクスチャ:** プロンプトに忠実なテクスチャを生成

## 生成プロセス
**1. AssetGen：** テキストプロンプトから3DメッシュとPBR（物理ベースレンダリング）マテリアルを生成
**2. TextureGen：** AssetGenで生成されたテクスチャを改良し、ビュー空間とUV空間を統合して一貫性のあるモデルを作成
　※物理ベースレンダリング（PBR）: 高品質なリライト（再照明）が可能な3Dアセットを生成する
　※高忠実度: 複雑なテキストプロンプトに対しても高い忠実度を保つ

下図：Meta 3D Genの概要。このパイプラインは、テキストプロンプトを入力としてテキストから3D生成を行い（ステージI）、その後テクスチャの改良を行う（ステージII）。ステージIIは、ユーザーが提供する新しいテキストプロンプトに基づいて生成またはアーティストが作成した3Dメッシュのリテクスチャリングにも使用できる。

!
:::small
画像の出典：{target=“_blank”}
:::

## 利用例
- **ゲーム開発:** 環境やキャラクターのプロトタイプを迅速に作成
- **建築:** テキストから詳細な3Dモデルを生成
- **VR/AR:** 没入型の環境やオブジェクトを簡単に作成

下図：すべての業界ベースラインと比較したテキストプロンプト忠実度の定性的比較（挑戦的なプロンプトで）。Meta 3D Genは、他の方法と比べて複雑なプロンプトに対しても高い忠実度を保つ。
!
:::small
画像の出典：{target=“_blank”}
:::

Meta 3D Genは、物理ベースレンダリング（PBR）をサポートし、リアルな3Dアセットの生成が可能となる。この技術の導入により、3Dコンテンツの作成プロセスが大幅に効率化されることが期待されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 09 Jul 2024 04:08:11 +0000</pubDate></item><item><title>長尺のビデオを理解する「LongVA」大規模マルチモーダルモデルの進化　シンガポールの研究グループが発表</title><link>https://ledge.ai/articles/long_va_lmms_lab</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年6月25日、シンガポールの研究チームが{target=“_blank”}した「LongVA（Long Video Assistant）」が、大規模マルチモーダルモデル（LMMs）の長尺ビデオ理解における新たな指標を示した。
## 主要な特徴と技術的背景
近年、大規模なマルチモーダルモデル（LMMs）が注目を集めているが、長時間の動画理解には限界がある。この問題に対し、研究者たちは新たなアプローチとして「LongVA」（Long Video Assistant）を開発した。このモデルは、従来の方法とは異なり、言語モデルのコンテキスト長を拡張することで、長時間の動画理解能力を飛躍的に向上させているという。

LongVAという新たなアプローチでは、まず言語モデルの文脈長を拡張し、その後、画像データを用いて視覚と文脈の整合性を図ることで、長いビデオの理解を可能にする。

下図: LongVAのアプローチ。左側は従来の視覚トークン削減手法を示し、右側はLongVAが言語モデルの長い文脈を視覚データに転移させる方法を示している。短い画像データで訓練し、テスト時には非常に長いビデオをゼロショットで処理する。

!
:::small
画像の出典：{target=“_blank”}
:::

これにより、従来の視覚トークン削減の手法を使わずに、2000フレーム以上、200K以上の視覚トークンを処理できるようになったという。

## 性能評価と結果
LongVAは、特に「V-NIAH（Visual Needle-In-A-Haystack）」という新たなベンチマークテストで、その性能を発揮している。このテストは、非常に長いビデオの中から特定のフレームを見つけ出し、その内容を理解する能力を測定するものである。

V-NIAHテスト結果は下図の通り。x軸はビデオ全体のフレーム数を示し、y軸は針（特定フレーム）の位置を示している。黒の点線は言語モデルの訓練文脈長を示し、各フレームは144トークンに相当する。


!
:::small
画像の出典：{target=“_blank”}
:::

実験の結果、LongVAは2000フレーム以上の入力に対しても高い精度で情報を取得できることが示された。また、他のビデオベンチマーク（Video-MME）においても、LongVAは7Bスケールのモデルの中で最先端の性能を達成している。特に、フレームを密にサンプリングすることで、その性能がさらに向上することが確認されたという。
## Video-MMEベンチマークでの最高性能
LongVAは、Video-MMEベンチマークにおいて、7B規模のモデルの中で最高性能を達成した。特に、入力フレーム数を増やすと性能が向上し、長い動画での性能向上が顕著であった​とのこと。

## 定性的な結果
LongVA-DPOの定性的な結果も評価されている。このモデルは、短いビデオと長いビデオの両方に対して優れた理解能力を示している。例えば、短いビデオでは、人々が調味料で遊んでいるシーンを正確に説明し、長いビデオでは、列車の色やシーン内で使用されている傘の色など、特定の詳細を識別する能力を示している。

下図は、LongVA-DPOの定性的結果。モデルは短いビデオや長いビデオにおける特定の詳細を正確に識別し、理解する能力を示している。

!
:::small
画像の出典：{target=“_blank”}{target=“_blank”}
:::

LongVAのコード、デモ、およびモデルは、{target=“_blank”}および{target=“_blank”}でオープンソースとして公開されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 06 Jul 2024 16:34:09 +0000</pubDate></item><item><title>NICTとKDDI、ハルシネーション抑制とマルチモーダルデータ対応の高性能LLM共同研究を開始</title><link>https://ledge.ai/articles/nict_kddi_launch_llm_collaboration</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

国立研究開発法人情報通信研究機構（NICT）は2024年7月1日、KDDIと共に大規模言語モデル（LLM）の共同研究を開始することを{target=“_blank”}した。

この研究は、NICTの蓄積した600億件以上のWebデータと、KDDIのハルシネーション抑制技術およびマルチモーダルAI技術を組み合わせ、高性能なLLMの実現を目指すものだという。

!
:::small
画像の出典：{target=“_blank”}
:::

NICTは、2023年からLLMに関する研究を本格化させ、2023年7月にはLLMの試作を{target=“_blank”}している。これまでに合計17個のLLMの事前学習を完了しており、特に日本語特化型で世界最大規模の3,110億パラメータを持つモデルも開発したという。

政府もAI開発力強化の一環として学習用データの整備・拡充を目指しており、総務省とNICTは令和5年度補正予算を活用して共同研究の準備を進めてきている。同研究は「我が国における大規模言語モデル（LLM）の開発力強化に向けたデータの整備･拡充及びリスク対応力強化」の共同研究第1弾となる。

研究では、NICTの膨大なWebデータとKDDIの技術を活用し、LLMの課題であるハルシネーションの抑制やマルチモーダルデータの取り扱い技術を研究開発する。具体的には、LLMにおけるハルシネーションを抑制し、テキストに加えて日本の地理空間情報などのマルチモーダルデータを取り扱う技術を開発する。これにより、特定の目的の対話システムや雑談システムの信頼性が向上し、対話における位置関係の把握がより適切に行えるようになるという。

今後、NICTのWebデータを多くの機関に提供し、日本のLLM研究開発力の向上に貢献していく予定だという。NICTはLLMの学習データの開発と事前学習を担当し、KDDIはハルシネーション抑制技術とマルチモーダルAI技術の高度化・評価を担当するとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Jul 2024 09:05:06 +0000</pubDate></item><item><title>AIがAIを訂正する世界への一歩ーーOpenAIが「CriticGPT」を発表　ChatGPTのエラー検出を支援</title><link>https://ledge.ai/articles/openai_criticgpt</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年6月27日、GPT-4ベースの新しいモデル「CriticGPT」を(https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/){target=“_blank”}した。このモデルは、ChatGPTなどの大規模言語モデル（LLM）の出力における誤りを検出し、人間のAIトレーナーによるトレーニングの精度向上を支援することを目的としている。
## 誤り検出を支援するCriticGPTの開発
CriticGPTは、ChatGPTの回答に含まれる不正確な点を指摘するために設計されている。このモデルは、RLHF（人間からのフィードバックによる強化学習）という手法を使用して訓練されており、AIトレーナーがChatGPTの異なる回答を比較評価する際に役立つ。RLHFは、AIトレーナーが提供するフィードバックを通じてモデルの性能を向上させるが、モデルの推論能力が高度化するにつれ、誤りの検出が困難になるという課題があった。
## CriticGPTのトレーニング方法
CriticGPTのトレーニングには、誤りを含む大量の入力データが使用される。具体的には、AIトレーナーがChatGPTによって生成されたコードに意図的に誤りを挿入し、その誤りを発見した際にどのようなフィードバックを行うかを記述した例を学習データとして使用する。その後、同じトレーナーが修正されたコードに対する複数の批評文を比較し、どの批評文が挿入された誤りを正確に指摘しているかを評価する。
## 効果と利点
CriticGPTの導入により、AIトレーナーはモデルの回答の誤りをより効果的に発見できるようになる。研究結果によれば、CriticGPTの支援を受けたトレーナーは、支援なしの場合に比べて約60％の確率でパフォーマンスが向上することが確認されている。また、CriticGPTを使用することで、トレーナーはより包括的な批評文を作成でき、モデル単独での批評よりも誤った指摘を減らすことができる。

下図：CriticGPT は、トレーナーが支援なしの場合よりも包括的な批評を書くのを助け、モデルのみからの批評よりも幻覚が少なくなるという

!
:::small
画像の出典：{target=“_blank”}
:::

## ヤン・ライケ氏のコメント
CriticGPTの発表に対し、かつてOpenAIでSuperalignmentチームのトップを務め、人間より賢いAIの制御を目指していたヤン・ライケ氏も反応している。ライケ氏は、安全性が後回しにされていると批判し、2023年5月17日にOpenAIを退社したが、自身のX（旧Twitter）で「これが公開されたことを非常に喜ばしく思う」とコメントしている。

OpenAIに在籍中のことに触れ、「私たちはコードのバグを見つけるためにLLM批評モデルを訓練し、人間が見逃していた生産タスクの欠陥を発見する手助けをしている。RLHFは人間の評価能力に制約されるため、AIを使って人間の評価を助けるスケーラブルな監視が必要だ。ここでは、批評家を訓練して欠陥を指摘させるというシンプルなアイデアを試した」と述べた。

!
:::small
画像の出典：{target=“_blank”}
:::

現時点でCriticGPTは比較的短いChatGPTの回答を対象にトレーニングされているが、OpenAIは将来的により長文で複雑なタスクを評価できるようモデルを改良する計画を立てている。これにより、AIトレーナーが高度なAIシステムをより効果的に調整できるようになることが期待されている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 01 Jul 2024 02:33:39 +0000</pubDate></item><item><title>最高時速510kmを達成した世界最速ドローン、ギネス認定</title><link>https://ledge.ai/articles/worlds_fastest_drone</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月21日、最高時速510kmに到達したドローンが世界最速としてギネスに{target=“_blank”}された。ドローンを制作したのはルーク・マキシモ・ベル氏。カーボンファイバー製フレームを使用し、バッテリー、モーター、プロペラを厳選して組み合わせたとのこと。

@

ベル氏らのドローン、Peregreen 2は、カーボンファイバー製のフレーム、最適化されたモーター、プロペラ、バッテリーを組み合わせて作られた。この設計には数ヶ月を要し、テスト中にはバッテリーの火災やその他のトラブルが発生したが、最終的には大幅な改良を経て、この速度を達成したとのこと。このドローンは、時速510 kmに達することもでき、前回の記録を大きく上回る結果となったが、公式に認定されたギネス記録は時速480.23となったという。

この記録は「バッテリー駆動の遠隔操作クワッドコプター」というカテゴリーで認定され、同時にカメラ付きドローンとしても世界最速となった。

なお、今回の記録更新は、かつてエナジードリンクメーカーの{target=“_blank”}がF1レースの撮影用に開発したドローンの記録を上回るものだ。当時、レッドブルのドローンは最高時速350kmで世界最速とされていたが、ベル氏のドローンはその記録を大きく更新した。




:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 29 Jun 2024 12:55:12 +0000</pubDate></item><item><title>ロボットに生きた皮膚を密着させる技術　東京大学研究チームが開発　ソフトロボット・美容整形医療にも</title><link>https://ledge.ai/articles/tokyo_univ_robots_with_bio_skin</link><description>:::small
画像の出典：{target=“_blank”}
:::

東京大学の研究チームが2024年6月26日、人の皮膚細胞から作製した“培養皮膚”を利用し、細胞由来の生きた皮膚を持つ顔型のロボットを開発したことを{target=“_blank”}した。

研究は東京大学大学院情報理工学系研究科の竹内昌治教授と河井理雄（現ハーバード大学博士課程）らが中心となって行われた。培養皮膚を利用し、細胞由来の生きた皮膚を持つ顔型ロボットの開発を実現した。

人間の皮膚支帯構造から着想を得、生体組織と人工物とを接着する手法を考案、スムーズに接着された顔型のロボットは笑顔を作ることも可能だという。同技術は、生体機能を有するソフトロボットの活用の他、美容・整形医療分野での応用も期待できるとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

従来、ロボットはシリコンゴムで覆われることで人間らしい外見を持たせていたが、自己修復やセンシング、発汗などの機能が欠けていた。これに対し、研究チームは培養皮膚をロボットの皮膚として活用することで、人間らしい機能を持つロボットの開発に取り組んだとのこと。

皮膚支帯構造に着想を得た「穴型アンカー構造」を開発し、人工物に培養皮膚をスムーズに固定する手法を確立した。実験では、3D顔型模型に生体皮膚を密着させることに成功し、皮膚の収縮を抑制する効果が確認された。また、ロボットの顔に表情を持たせるために、シリコン層を用いたスライド機構を組み合わせ、自然な笑顔を表現できることも示されたという。

今回の研究成果は、人型ロボットの開発にとどまらず、美容・整形医療分野への応用にも期待できるとのこと。シワの形成メカニズムの理解や表情の生理学の解明、化粧品開発や薬剤効能解析のモデルとしても活用が見込まれている。

環境に優しい素材でできたソフトロボットの開発に加え、移植素材としての医療分野や生体素材を用いた人工物の製造分野にも貢献することが期待されているとのこと。


:::box

:::
:::box

:::
</description><pubDate>Fri, 28 Jun 2024 06:37:53 +0000</pubDate></item><item><title>中国のAIスタートアップ「跨維智能（DexForce）」エンボディド(身体性)AIとSim2Real技術でロボット操作をトレーニング</title><link>https://ledge.ai/articles/dexforce_enbodied_ai_sim2real</link><description>:::small
画像の出典：DexForce
:::

中国のスタートアップ企業「跨維智能（DexForce）」が、聯想創投（Lenovo Capital and Incubator）から資金調達を完了したと2024年5月14日に{target=“_blank”}が報じた。この資金は、製品開発、チーム拡大、市場開拓に充てられる予定だという。

DexForceは2021年6月に設立。3Dモデル生成AI、マルチモーダル大規模言語モデル（LLM）、3Dイメージングなどを基盤に、ハードウェアとソフトウェアを一体化したエンボディドAIを提供している。エンボディドAIは環境と相互作用し、継続的に自己改善を行う次世代AIであり、現実世界のデータに代わり合成データを活用する「Sim2Real」技術がそのコアとなっているという。

Sim2Real技術は、物理シミュレーションを通じてロボット操作データを生成し、正確なタグ付けを行った合成データを用いてエンボディドAIを訓練する。これにより、複雑なシーンでのロボットアームの性能を大幅に向上させることができるとのこと。この技術は半導体、自動車、太陽光発電などの製造現場で既に導入されており、コスト削減と効率化に寄与しているという。

## 多様な作業シーンにおける応用拡大例
以下の画像は、DexForceの多様な作業シーンでの応用例を示す。

**左図：**  玩具のピッキングシーン。玩具製造工場で、多種多様な玩具を迅速かつ高効率にピッキングするために使用される。DexForceの製品は、様々な種類の玩具を正確に識別し、ピッキングを行うことができる。

**右図：**  無秩序な作業対象物のピッキングシーン。産業自動化において、無秩序に配置された作業対象物をピッキングし、生産ラインに供給するシステムとして利用される。DexForceの製品は、多様なデータサンプルに基づいたシミュレーションデータを使用して、効果的にこの課題を解決する。

!
:::small
画像の出典：DexForce
:::

同社は今後、Sim2Real技術を基盤に、製品開発と市場拡大を進め、次世代エンボディドAIの普及を目指している。同社のエンボディドAIソリューションは、産業用3Dカメラ「Xema」シリーズなどを含み、ユーザーが二次開発コストを削減できるAPIとSDKを提供している。今後は、自己適応が可能な汎用ロボットの開発にも注力し、多様な産業での応用を拡大していく計画だという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 11:29:20 +0000</pubDate></item><item><title>NTT　世界初、ハイスピードカメラとAIによる高精細な「音の見える化」を実現</title><link>https://ledge.ai/articles/ntt_sound_digital_twin</link><description>:::small
画像の出典：{target=“_blank”}
:::

NTTは2024年6月17日、ハイスピードカメラとAI処理を組み合わせた技術で音の波を高精細に「見える化」する技術を世界で初めて開発したと{target=“_blank”}した。この技術は、音の物理特性を考慮した独自の深層学習モデルを用いることで、ノイズを除去し高感度に音場を捉えることが可能だという。

NTTは、音響デバイスの設計や音に関わる現象の理解、さらには将来的な「音のデジタルツイン」実現への貢献が期待されるとしている。

!
:::small
画像の出典：{target=“_blank”}
:::
## 技術の背景と成果
音は空気の圧力変動として伝わり、これを見える化する試みはこれまで困難であった。NTTでは光学的音場イメージング技術を用い、音を高感度に検出することに成功した。従来のマイクロホンアレイと比較して約100倍の空間分解能を持つこの技術は、レーザー光とハイスピードカメラを用いて音波を動画像として捉えるものである。

## 独自の深層学習モデルによるノイズ除去
今回の成果では、ハイスピードカメラで撮影されたノイズを含む画像から、音波成分のみを抽出するニューラルネットワークを適用することで高精細な音の画像化を実現した。特に、独自の深層学習モデルを用いることで、音の物理的な性質に基づいたノイズ除去を行い、従来技術を大幅に上回る精度を達成している。

!
:::small
画像の出典：{target=“_blank”}
:::


NTTはIOWN構想の中でデジタルツインコンピューティングを提唱し、その研究開発を進めている。今回の技術を活用して「音のデジタルツイン」技術の実現を目指している。これは、空間に存在する音を完全にデジタル化することで、音環境の最適化を図るものである。NTTは今後も、心地よい音環境の創出に向けて研究を進めるとともに、音響デバイスの開発や騒音評価など多方面への応用を目指すとしている。


:::box

:::
:::box

:::

</description><pubDate>Thu, 27 Jun 2024 11:34:00 +0000</pubDate></item><item><title>メタの新技術「AudioSeal」がAI音声詐欺防止に貢献</title><link>https://ledge.ai/articles/meta_audio_seal</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

MetaのFAIR研究所とInriaの共同研究チームは2024年6月6日、ウィーンで開催された国際機械学習会議（ICML）において、新たなAI音声生成検出技術「AudioSeal」を{target=“_blank”}した。AIによって生成された音声を特定するための新しいオーディオウォーターマーキング技術だという。

!
:::small
画像の出典：{target=“_blank”}
:::

## 背景と目的
音声生成モデルの急速な進化により、偽音声の作成がますます容易となっている。特にディープフェイク技術の普及により、誤情報の拡散が大きな問題となっている。過去には、偽の音声を用いて米国の有権者に投票を控えるよう呼びかける{target=“_blank”}も発生しており、このようなリスクを低減するために、規制当局や政府はAIコンテンツの透明性と追跡性を確保する対策を講じている。このような問題に対応するために、AudioSeal は開発されたという。
## 技術の特徴
AudioSealは、AI生成音声の局所的な検出を可能にする初のオーディオウォーターマーキング技術であり、以下の特徴を持つ。

1. **局所的検出:**  音声サンプルレベルでのウォーターマーク検出を実現し、音声のどの部分がAI生成かを正確に特定することができる。
2. **高い秘匿性:**  聴覚マスキングに基づく新しい知覚損失を採用し、人間の耳にはほとんど認識されないウォーターマークを実現している。
3. **高い耐久性:**  現実の音声操作に対する耐久性が高く、自動および人間による評価基準で最先端の性能を達成している。
4. 高速検出: 既存のモデルよりも最大で100倍以上の速度で検出を実現し、大規模かつリアルタイムのアプリケーションに最適である。
## 評価と性能
AudioSealは、多様な音声操作に対する耐久性試験で、従来のウォーターマーキング手法を上回る性能を示したという。また、リアルタイム検出を可能にする効率性も高く、ソーシャルメディアプラットフォームなどでの大規模なAI生成コンテンツの追跡に適しているとのこと。



:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Mon, 24 Jun 2024 06:07:38 +0000</pubDate></item><item><title>経産省　ゲーム・アニメ・広告を対象に「コンテンツ制作のための生成AI利活用ガイドブック」を公開　スクエニ、伊藤園、パルコなど実例満載</title><link>https://ledge.ai/articles/meti_ai_guidebook</link><description>:::small
画像の出典：{target=“_blank”}
:::

経済産業省は7月5日、生成AI技術をコンテンツ制作に活用するための「コンテンツ制作のための生成AI利活用ガイドブック」を{target=“_blank”}した。このガイドブックは、生成AIの利活用によるコンテンツ制作の新たな方向性を示すもので、特にゲーム、アニメ、広告といった産業での具体的な利用事例や法的留意点を網羅している。
## ガイドブックの目的と内容

ガイドブックの内容は以下の通り
**１．生成AIの利活用の方向性：**
コンテンツ産業における生成AIの適切な利活用の方向性を示すため、知的財産権等の権利・利益の保護に十分に配慮しつつ、生成AIの活用事例を紹介
**２．具体的な利活用事例：**
ゲーム、アニメ、広告の各産業における生成AIの活用ケースを詳細に紹介し、それぞれの制作工程での具体的な活用方法を提示
**３．法的留意点と対応策：**
生成AIを利用する際の著作権や肖像権などの法的問題点について、具体的な対応策を示し、クリエイターが安心して生成AIを活用できるよう支援

生成AIが進化し続ける中、その可能性に着目してきたという経産省。今回のガイドブックは、生成AIの利活用を促進するために、特に注目すべき利用ケースと法的問題点を整理したものだ。

スクウェア・エニックス、伊藤園、パルコなど、企業による生成AI活用事例が紹介されている。例えば、画像生成AIを用いて線画に彩色や仕上げを行う方法や、テキスト生成AIを使用して広告コピーを作成する方法などが具体的に説明されている。また、著作権や肖像権の侵害を避けるための留意点や対応策も詳細に記載されている。


利活用例：ガイドブックより抜粋

!
:::small
画像の出典：{target=“_blank”}
:::


!
:::small
画像の出典：{target=“_blank”}
:::

## 関連省庁とガイドブックの位置づけ
下図は、生成AIに関連するガイドラインとその関係省庁の役割を示す。経済産業省、総務省、内閣府、文化庁などが連携し、AIの利活用に関する統一的な指針を提供する枠組みを説明している。

!
:::small
画像の出典：{target=“_blank”}
:::

同ガイドブックは、「令和5年度コンテンツ海外展開促進事業（コンテンツ産業における先端的技術活用に関する調査）」の成果物として作成され、{target=“_blank”}と一体となっている。同報告書も80ページにわたるボリュームで、精度の高いレポートがまとめられている。

コンテンツ制作に携わる企業にとって、生成AIは効率化や新たなクリエイティビティの創出に寄与する強力なツールとなる。しかし、法的な留意点をしっかりと理解し、適切な対応策を講じることが重要である。経済産業省のガイドブックは、そのための具体的な指針を提供するものとなる。なお、ガイドブックの表紙デザインには生成AIが活用されているとのこと。

ガイドブックは経済産業省の公式サイトから{target=“_blank”}可能。コンテンツ制作に携わるすべての企業やクリエイターにとって必携の資料となり得る。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Jul 2024 12:36:46 +0000</pubDate></item><item><title>岸田首相　東南アジア諸国のLLM開発支援を表明　各国の豊かな言語と文化に根ざした取り組みが必要</title><link>https://ledge.ai/articles/asia_business_summit</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月5日、東京で開催された「アジア・ビジネス・サミット」において、岸田文雄首相は東南アジア諸国に対するAI基盤整備支援を{target=“_blank”}した。日本は東南アジアの言語と文化に適応した生成AI技術の基盤構築を技術と財政の両面で支援する。これは、先端技術での遅れを懸念する東南アジア諸国と協力し、地域全体のAI開発環境を向上させる狙いだという。

岸田首相はスピーチの中で、AIが産業競争力と国力を左右する重要な技術であると強調し、特に大規模言語モデル（LLM）の開発において、各国の豊かな言語と文化に根ざした取り組みが必要であると述べた。日本のAI技術者のノウハウが他のアジア諸国のLLM開発に貢献できるとし、具体例として、日本のスタートアップであるイライザがタイ語を学習したLLMを開発中であることを紹介した。このような取り組みを日本政府として支援し、シンガポール、マレーシア、ベトナムなどの主要企業との連携を促進するとした。

さらに、岸田首相は5年間で10万人の高度デジタル人材を育成する計画を明らかにし、日本とアジアの人材交流を進めることによって、AIイノベーションを推進するコミュニティをアジアに築くことを目指すと述べた。また、昨年の広島G7サミットで開始された「広島AIプロセス」に基づき、生成AIのリスクに対処するための国際的な取り組みを推進し、安全で信頼できるAIの実現に向けてアジア諸国と協力する意向を示した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Jul 2024 11:55:05 +0000</pubDate></item><item><title>テネシー州　AIによる無断歌声使用を防ぐ新たな法律「エルビス法」を施行　違反には最大2,500ドルの罰金も</title><link>https://ledge.ai/articles/elvis_law</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年7月1日、テネシー州で「エルビス法」が施行され、AI技術を用いた無断の歌声使用に対する保護が強化された。この法律は、歌手エルビス・プレスリーの名前にちなんで命名され、アーティストの「声」を個人の財産として保護することを目的としている​ 。同法律は3月21日にテネシー州のビル・リー知事によって署名され、{target=“_blank”}。
## 背景
近年、AI技術の進化により、有名アーティストの声を模倣するサービスが急速に広がり、SNSで注目を集めている。例えば、2023年にはドレイクやザ・ウィークエンドの声を模倣した「Fake Drake」という楽曲が話題となり、これが問題視される{target=“_blank”}となった​​。こうしたAIによる無断の声のクローン作成は、アーティストの権利侵害に繋がり、音楽業界における重大な課題として浮上していた。

エルビス法は、従来の「名前」「写真」に加え、「声」も保護の対象に含めることで、無断使用を防止する初の法律だ。この法律に違反した場合、最大2,500ドルの罰金が科されるほか、民事訴訟の対象にもなる可能性があるという。
## アーティストのAIへの対抗運動
エルビス法の施行と同時期となる4月2日、アーティスト権利連盟（Artist Rights Alliance, ARA）は、200人以上のアーティストの支持を受けて、AI開発者やテクノロジー企業、プラットフォーム、デジタル音楽サービスに対し、人間のアーティストの権利を侵害し価値を減じるAIの使用を停止するよう呼びかける公開書簡を{target=“_blank”}した​。

ARAの公開書簡では、AIが無許可で音楽作品を使用し、アーティストの声を模倣する「コピーキャット」や、ロイヤリティの支払いを回避するためにAIを利用することが問題視された。ビリー・アイリッシュ、ノラ・ジョーンズ、ボン・ジョヴィなど、多くの著名なアーティストが署名している。この手紙は、「AI技術が人間のアーティストの芸術性を損なうことなく、公正な報酬を得られるようにすることが重要である」と強調している​。 


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 04 Jul 2024 11:26:15 +0000</pubDate></item><item><title>【緊急開催】本日21:00～ 東京都知事候補 安野たかひろ氏 インタビュー生配信</title><link>https://ledge.ai/articles/Interview_takahiroanno</link><description>本日7月4日（木）21時00分より、東京都知事候補の安野たかひろ氏をお招きし、インタビューを行います。Ledge.aiのYouTubeチャンネルにてライブ配信いたします。

Ledge.aiを運営する株式会社レッジの代表取締役社長 小瀧健太がインタビュアーとなり、AI専門メディアならではの切り口で、AIエンジニアとしての経歴を持つ安野氏の考える東京都のビジョンを深堀りします。

東京都の将来を左右する選挙を目前に、AIの視点から掘り下げるこのインタビューを、是非お見逃しなく。

**ゲスト情報**
:::box
!
**AIエンジニア／起業家／SF作家**
**安野たかひろ**

1990年東京都出身。東京大学工学部。松尾研究室。ボストン・コンサルティング・グループを経て、スタートアップの創業も経験。小説「サーキット・スイッチャー」が第9回ハヤカワSFコンテストで優秀賞を受賞。
:::

**視聴方法**
当メディアのYouTubeチャンネルにて配信します。視聴は無料です。


:::box

:::</description><pubDate>Wed, 03 Jul 2024 11:17:46 +0000</pubDate></item><item><title>イギリスの鉄道駅でAmazonのAI監視技術が国民に伝えられることなく試験導入されていた</title><link>https://ledge.ai/articles/uk_train_stations_trialled_amazon_emotion_detection</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

過去2年間、イギリスの主要な8つの鉄道駅でAmazonのAI監視技術がテスト導入され、乗客の年齢、性別、感情を分析していたことが{target=“_blank”}。このことは2024年6月18日、イギリスに拠点を置く監視社会に対する監視と人権擁護を目的とする市民団体「Big Brother Watch」の調査により判明した。この技術の導入は、乗客の安全確保と特定の犯罪の減少を目的としていたが、広告目的にも利用される可能性があったという。

問題となったテストは、ロンドンのユーストン駅やウォータールー駅、マンチェスターのピカデリー駅を含む主要な鉄道駅で実施された。その他にも複数の小規模な駅が対象となったとのこと。導入されたシステムは、CCTVカメラを使用して乗客の動向を監視し、AI技術を用いて年齢、性別、感情を分析することで、駅スタッフに安全インシデントを警告する。
## プライバシーの懸念
市民団体である Big Brother Watch は、個人のプライバシー保護、政府の監視プログラムの透明性確保、テクノロジーの倫理的利用を推進しており、監視技術やプライバシー侵害に対する監視活動、調査、キャンペーンを行っている。ビッグデータやAI技術の利用に対する警鐘を鳴らし、公共の利益と個人の権利を守るための活動を展開しているとのこと。

調査チーム長のジェイク・ハーフート氏は、「Network Railが英国の主要駅で通勤者に対して信頼性に欠ける感情認識技術を使用する権利はない」と述べ、情報コミッショナーへの苦情を提出した。

同氏はさらに、「技術が鉄道の安全性を高める役割を果たす可能性はあるが、その必要性と適切性についての公開討論が必要だ」と強調した。特に、Network Railが安全技術と疑わしい感情認識ツールを混在させ、広告業者にデータを提供する可能性があることが問題視されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 01 Jul 2024 07:28:19 +0000</pubDate></item><item><title>総務省　自動運転の通信基地局、手続き短縮の方針「レベル４」実現に向け2025年度から新制度運用目指す</title><link>https://ledge.ai/articles/mic_plans_to_shorten_procedures_for_automated_communication_base_stations</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

総務省は自動運転車両の実証実験に必要な電波基地局の設置に関する行政手続きを短縮する方針だと2024年6月23日に{target=“_blank”}が報じている。

従来は半年程度かかっていたこの手続きを数週間に短縮することを目指しており、2025年度から新しい制度の運用を開始する予定とのこと。この動きは、特定の条件下で運転手が操作をしない「レベル4」の自動運転車両の普及を促進するためのものだという。

従来、実験用基地局を設置する際には、同じ周波数帯を使用する放送事業者との電波干渉を確認する必要があり、この手続きが長期化する要因となっていた。新制度では、この確認手続きを簡略化し、迅速に基地局の設置を進められるようにするとのこと。

下図の資料は「中間とりまとめ骨子（案）」より、①5.9GHz帯V2X通信システムの実用化に向けた方策から抜粋したもの。6月6日開催の会議「自動運転時代の“次世代のITS通信”研究会（第8回）」にて{target=“_blank”}されている。

!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
:::box

:::


</description><pubDate>Thu, 27 Jun 2024 11:40:27 +0000</pubDate></item><item><title>デジタル庁、テキスト生成AIのリスク対策ガイドブック（α版）を公開</title><link>https://ledge.ai/articles/digital_agency_genai_guidebook</link><description>:::small
画像の出典：{target=“_blank”}
:::

デジタル庁は2024年5月29日「テキスト生成AI利活用におけるリスクへの対策ガイドブック（α版）」を{target=“_blank”}した。

同庁は、デジタル社会の実現に向けた重点計画（令和4年6月7日閣議決定）に基づき、生成AIの動向を把握し、リスクと対応策を特定するための検討を進めている。生成AI技術の革新に伴い、政府も生成AIの業務利用について議論を重ね、2023年12月より技術検証を実施。その結果を踏まえ、行政サービスでの生成AI利活用時のリスクと対応策を示すガイドブックをα版として公開したとのこと。

行政業務における生成AIの利用にあたり、リスク対策は重要だ。広島AIプロセスやAI事業者ガイドラインを踏まえ、ガイドブックはテキスト生成AIに焦点を当てている。特に、政府調達における具体的なリスクとその対策が詳述されている。
### 対象とするリスク
ガイドブックは、テキスト生成AIのサービス開発者と提供者を対象にしている。生成AIにはテキスト、画像、音声、動画などがあるが、同ガイドブックはテキスト生成AIに限定。基盤モデル開発者やサービス利用者に関するリスク（例えば、学習データのサプライチェーンや権利問題、ディープフェイクのリスク）は含まれていない。

### 利用形態とユースケース
利用形態（特定サービスに組み込まれた状態、大規模言語モデルのWeb API形式など）やユースケースごとに、想定されるリスクは異なる。ガイドブックでは、これらの違いを意識し、デジタル・ガバメント推進標準ガイドライン実践ガイドブックに基づく工程ごとにリスクと留意点を挙げている。


ガイドブックには、技術検証で判明したリスクや留意点を可能な限り記載しているという。今後の更新を重ね、正式版としての公開を目指すとのこと。ガイドブックは本文（前半6章）と発展的内容を含む付録（後半3章）で構成されている。2024年度内を目標に、デジタル社会推進標準ガイドラインへの編入が検討されているとのこと。


政府情報システムへの生成AI導入に関わる行政職員を主な対象としたガイドブックではあるが、自社サービスや業務改善のためにテキスト生成AIの導入を検討する企業担当者にも参考になる内容が含まれている。今後、正式版の公開に向けて内容の拡充と改善が進められる予定。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 23 Jun 2024 12:41:54 +0000</pubDate></item><item><title>Googleと東大松尾研　生成AIモデル実装とAI人材育成で47都道府県の地域課題を解決する取り組みを発表</title><link>https://ledge.ai/articles/google_for_japan_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年6月19日に開催した「Google for Japan 2024」で、AI技術を用いて日本の社会課題解決に向けた新たなプロジェクトを{target=“_blank”}した。Googleは、東京大学 松尾・岩澤研究室と協力し、2027年までに47都道府県の地域課題を解決するための生成AIモデルの実装とAI人材の育成を進める計画を明らかにした。
## 地域課題解決への生成AI活用
Googleは日本が抱える高齢化や労働人口の減少といった社会課題に対処するため、生成AIの力を活用する方針を示した。具体的には、AIを用いて労働力の生産性向上や企業の競争力強化、高齢者の健康支援を目指す。第一弾として、{target=“_blank”}と協力して雇用のミスマッチ解消に取り組む。このプロジェクトでは、AIが就業希望者に適性職種を提案し、企業には採用マーケティング支援を行うという。
## 新たなAI機能と教育プログラム
また、日本向けの新機能として「Googleナウキャスト」を発表。{target=“_blank”}との協力により、最大12時間先までの5分ごとの降水量予測が可能となる。また、ハッシュタグを用いた検索機能も追加され、ユーザーはソーシャルメディアからの最新トレンド情報を容易に取得できるようになるとのこと。

## AIの責任ある活用とサイバーセキュリティ
Google は、インターネット全体の安全性を向上させるため、2023 年 10 月に日本に日本をサイバーセキュリティ研究の拠点とし、政府や教育機関、そして産業界と連携し、知識共有や研究支援、トレーニングプログラムの提供など多岐に渡る取り組みを推進している。
この日同社は、国内大学や研究機関を対象とした研究支援プログラム「Cybersecurity Research Award」の{target=“_blank”}し、医療分野を含む幅広いセキュリティ研究への支援を行うことを発表した。

Googleは、AI技術を活用し、日本社会が抱える様々な課題解決に取り組む姿勢を明確にし、未来のイノベーションを支えるための取り組みを一層強化する意向を示した。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 23 Jun 2024 06:24:04 +0000</pubDate></item><item><title>イギリス版「AIゆりこ」か？　英総選挙にAI候補者「AIスティーブ」出馬中</title><link>https://ledge.ai/articles/ai_steve_uk</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年7月4日に行われるイギリス総選挙に、ブライトンの実業家スティーブ・エンダコット氏が開発したAIチャットボット「{target=“_blank”}」が、独立政党 ”SmarterUK” の候補者として出馬し話題を呼んでいる。AIスティーブは有権者との対話を通じて政策を形成し、エンダコット氏がその政策を議会で代表する。有権者の意見をリアルタイムで反映し、政治の透明性と効率性の向上を目的としているという。
## AIスティーブの仕組み
AIスティーブは、Neural Voice社が開発した対話型AIで、最大1万件の対話を同時に処理できる。これにより、有権者の意見や関心事を迅速に収集し分析することが可能だ。収集されたデータは、一般市民ボランティアからなる「バリデーター」によって評価され、50%以上の支持を得た政策のみが議会に提案される。有権者の声を直接反映し、政治家のより透明で効率的な意思決定を狙うとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

SmarterUKは、スティーブ・エンダコット率いるチームによって、全国およびブライトン・ホーブ地域のための実用的な政策を策定している。キャリア政治家を排し、ビジネスの専門家が実用的で環境に優しい政策を推進するという。テクノロジー改革も掲げ、AIを活用して政府の効率化を図る。

AI Steveは24時間365日、有権者と対話でき、すべての会話は自動で記録・要約される。このデータは政策の基盤となり、独立した「バリデーター」グループが政策を評価することで、一般有権者に訴求するものだけが採用される。

SmarterUKはテクノロジーを駆使して、有権者がMPの投票行動を直接制御できるようにし、政治を市民に取り戻すことを目指しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 22 Jun 2024 12:22:51 +0000</pubDate></item><item><title>「スピーチライターに ”お前クビな” って言っちゃったよ」トランプ氏がAIに原稿を添削させてみた結果</title><link>https://ledge.ai/articles/trump_said_you_are_fired_to_his_speech_writer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年の米大統領選挙を前に、ドナルド・トランプ前大統領がAI技術を活用して演説原稿を添削した経験を明かし、AIの可能性とリスクについて議論が高まっている。トランプ氏は、ユーチューバーのローガン・ポールが配信するポッドキャストに{target=“_blank”}し、AIによる原稿添削のスピードと品質に感銘を受けたことを語った。

@


トランプ氏は、IT業界のトップクラスの人物がAIを用いて演説原稿を短時間で添削した経験について述べた。数回のクリックだけで15秒後には高品質な原稿が生成され、その出来栄えに驚いたという。この出来事を受けて、トランプ氏は「ビンス、きみはクビだ！」と冗談交じりにスピーチライターのビンス・ヘイリー氏に言及したという。

AI技術がもたらす脅威として、ディープフェイクの利用が懸念されている。2024年2月には、バイデン大統領の声を模倣したディープフェイク音声が民主党支持者に投票を控えるよう呼びかけるロボコールで使用された​。このような事例が増える中、連邦通信委員会はAI生成ロボコールの使用を禁止する措置を講じたという。

2024年の米大統領選挙において、AI技術の利用とその規制について注視し続けることが求められている。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 19 Jun 2024 05:28:06 +0000</pubDate></item><item><title>小池百合子都知事の公式Xに“AIゆりこ”出現　都政の取り組みを紹介　都民の税金は使っていない</title><link>https://ledge.ai/articles/ai_yuriko</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月13日、小池百合子氏は自身のX(旧Twitter)公式アカウントで、生成AIで生成した“AIゆりこ”の動画を{target=“blank”}した。
容姿・声ともに小池百合子氏によく似た、AIによる“AI YURIKO NEWS”が配信されており、動画内ではAIが都政の取り組みについて説明している。

突然現れたAIゆりこだが、現在東京都公式サイトでは発表されていない。2024年6月14日午後に公開されたAI YURIKO NEWSによると、このAIは東京都の事業ではなく、政治活動の一環として開発・運用されたものであり、税金は一切使用してないとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

:::box

:::
:::box

:::
:::box

:::



</description><pubDate>Fri, 14 Jun 2024 08:20:44 +0000</pubDate></item><item><title>広島市、AIを被爆の語り部に　AI活用の被爆証言応答装置を製作へ　ハルシネーション防止のため生成AIは使用せず</title><link>https://ledge.ai/articles/hiroshima_to_use_ai_to_tell_the_story_of_the_atomic_bombing</link><description>:::small
画像の出典：{target=“_blank”}
:::

広島市は2024年6月5日、AI技術を活用した「被爆証言応答装置」を製作すると{target=“_blank”}した。

被爆者との対話が困難になる将来を見据え、利用者が画面上の被爆者と疑似的に対話できる装置であり、被爆80年を迎える2025年の夏までに5台の完成を目指す。

## プロジェクトの背景と目的
市長の松井 一實氏は「被爆者の高齢化が進み、確実に被爆者がいなくなる時代が近づいている。人類史上初の被爆の惨禍を経験した方々の心の内を伝えることが重要な課題である」と述べた。従来、被爆証言をビデオに記録し市民が語る取り組みを行ってきたが、被爆証言者がいなくなると直接質問する機会が失われるため、AI技術を活用して次世代に証言を伝える手段を模索していたという。
## 装置の仕組みと設置予定
この装置は、利用者が被爆体験や平和への思いを質問すると、AIが内容を分析し、事前に収録された被爆者のインタビュー映像から最適な回答を再生する仕組みだ。虚偽の情報が含まれないように生成AIは使用されない。松井市長は、「AI技術の進歩により、証言者の思いをフォローしてその方に近い答えを提供できるようになった」と説明した。

装置は広島平和文化センターが進めるプロジェクトの一環で、英語が話せる被爆者を含む5人にインタビューを依頼し、今夏から実施される予定である。完成した装置は広島平和記念資料館と国立広島原爆死没者追悼平和祈念館に1台ずつ設置され、残りの3台は市内の学校などに貸し出されるとのこと。

## 正確性の担保と予算
市長はまた、AI技術の進歩とともに正確性を担保するために、被爆証言者の思いや価値観を整理し、多角的な質問に対する回答を累計化することを考えていると述べた。質問に応じられない場合には「お答えできません」と表示する予備装置を工夫することも検討しているという。

このプロジェクトには約6820万円の予算が計上され、2024年度一般会計の6月補正予算案に含まれている。広島市はこの装置を通じて、被爆者の貴重な証言をより多くの人々に届け、平和の大切さを広めることを目指すとした。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Thu, 13 Jun 2024 11:14:53 +0000</pubDate></item><item><title>生成される画像の価値とは何なのか？　ライゾマティクスが「AIと生成芸術」がテーマの個展を開催中</title><link>https://ledge.ai/articles/rhizomatiks_beyond_perception</link><description>:::small
画像の出典：{target=“_blank”}
:::

クリエーター集団のライゾマティクスが、AI技術を活用した新しいアートの形を提案している。KOTARO NUKAGA（天王洲）の拡張移転に伴い、2024年6月29日から9月28日までの3ヶ月間にわたり、「AIと生成芸術」をテーマに個展「Rhizomatiks Beyond Perception」を{target=“_blank”}する。

展覧会では、ライゾマティクスが独自に作成した画像のみを学習したAIモデルを新たに開発し、その成果を展示する。現代において誰もがAIを使って画像を生成できる中、ライゾマティクスは「生成される画像の価値とは何なのか？」という問いを観客に投げかける。

展示作品の一環として、初めて販売されるのは “AIモデルデータ” である。購入者はこのAIモデルを使って入力を変えることにより、無限に画像を生成する体験が可能となる。このAIモデルデータは、ライゾマティクス自身の作品108本の映像を静止画に変換した約17万枚の画像を学習データとして使用し、既存の基盤モデルを一切使用せずにゼロから開発されたものだという。

### 展覧会概要
**会期:** 2024年6月29日（土） – 9月28日（土）
**開廊時間:** 11:00 – 18:00（火曜日から土曜日、日月祝休廊）
**会場:** KOTARO NUKAGA（天王洲）
**住所:** 東京都品川区東品川1-32-8 TERRADA Art Complex II 1F
**アクセス:** 東京臨海高速鉄道りんかい線「天王洲アイル駅」から徒歩約8分、東京モノレール羽田空港線「天王洲アイル駅」から徒歩約10分、京急本線「新馬場駅」から徒歩約8分



:::box

:::
:::box

:::
</description><pubDate>Fri, 05 Jul 2024 07:35:19 +0000</pubDate></item><item><title>ハリウッド撮影クルー、AI使用も雇用維持で合意</title><link>https://ledge.ai/articles/hollywood_iatse_amptp_agreement</link><description>:::small
画像の出典：{target=“_blank”}
:::
全米のエンターテインメント産業の撮影現場で働く労働者の組合「IATSE」と主要スタジオを代表する「AMPTP」は2024年6月27日、AIの使用を認めながらも雇用を維持することで合意に達したと{target=“_blank”}した。
この合意は、「ハリウッド基本合意」と「ビデオテープ合意」の枠組みで成立し、IATSEの約50,000人のメンバーに影響を与えるものだという。
## 合意の詳細
今回の合意には、AIの使用に関する新たな保護措置が含まれている。具体的には、AIが労働者の職を奪うことがないようにするための条項が盛り込まれ、労働者がAIプロンプトを提供する場合でも、それが雇用喪失につながらないようにする対策が取られている​。また、賃金の引き上げも合意され、契約期間中3年間で7%、4%、3.5%のスケール賃金率の引き上げを予定しているとのこと。

## 交渉の背景
IATSEは衣装デザイナーやヘアスタイリスト、照明技術者、カメラオペレーターなど、多岐にわたる職種の労働者を代表している。今回の合意は、生成AIの台頭により雇用の危機感が高まる中で、労働条件の是正を求め{target=“_blank”}したものだ。特にコロナ禍のパンデミック以降、ハリウッドの労働者たちは自身の権利と雇用条件についてより積極的に声を上げている。

この合意はまだIATSEのメンバーによる批准が必要だが、正式に承認されれば、ハリウッドの労働環境におけるAIの影響を適切に管理しながら、労働者の権利と雇用を保護する新たな枠組みが確立されることになる見通し。また、同様の合意が他の労働組合との間でも期待されており、エンターテインメント産業全体での労働環境の改善が見込まれているという。

全米の映画俳優組合（SAG-AFTRA）によるストもAMPTPとの暫定合意に達し、2023年11月に終結している。


:::box

:::
:::box

:::

</description><pubDate>Fri, 05 Jul 2024 07:31:03 +0000</pubDate></item><item><title>大阪・関西万博に実物大ガンダム登場へ　バンダイナムコHDが展示計画を発表
</title><link>https://ledge.ai/articles/bandainamco_gundam</link><description>:::small
画像の出典：{target=“_blank”}
:::

バンダイナムコホールディングスは2024年6月26日、2025年に開催される大阪・関西万博で「機動戦士ガンダム」の実物大模型を展示すると{target=“_blank”}した。このガンダム像は、かつて横浜で展示されていた動く実物大ガンダムの部材を再利用しており、関西での展示は初めてとのこと。

展示されるガンダム像は高さ約17メートルで、片膝を立て片腕を上げたポーズを取っている。2020年から2024年3月末まで横浜市の「GUNDAM FACTORY YOKOHAMA」で展示されていた動く実物大ガンダム像の装甲部分を、頭部から足までほぼ再活用しているが、今回の展示では動くことはないという。

このガンダム像は、大阪・関西万博のパビリオン「GUNDAM NEXT FUTURE PAVILION」の近くに展示される予定。パビリオン自体は内装を除き2024年7月の完成を予定しているという。

@

バンダイナムコホールディングスでガンダムシリーズの知的財産戦略を担当する榊原博社長は、「ファンの方と一緒につながりたい」と述べ、ファン参加型の企画を計画していると明らかにした。2024年は「ガンダム」のテレビアニメ放映45周年にあたり、全国で関連イベントが開催される予定だ。SNS上でファンからのメッセージを募集し、その一部はパビリオン内で投影される。


:::box

:::
:::box

:::
</description><pubDate>Mon, 01 Jul 2024 13:23:40 +0000</pubDate></item><item><title>Mantraが7.8億円調達を実施　画像認識とLLM（大規模言語モデル）を併用したマンガ特化の翻訳ツール開発　</title><link>https://ledge.ai/articles/mantra_engine_ai_manga</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月26日、マンガAI翻訳技術の開発を行うMantra株式会社は、集英社、小学館、KADOKAWA、スクウェア・エニックス・ホールディングスなどから、総額7億8000万円の資金調達を行ったことを{target=“_blank”}した。

Mantraが開発した「Mantra Engine」は、AIを活用したマンガ/縦スクロールコミックの翻訳を効率化するクラウドツールだ。画像認識とLLM（大規模言語モデル）を併用し、キャラクターやストーリーを考慮しながら、ブラウザ上で翻訳に関わるすべての作業を完結させる。現在は、国内外の出版社や翻訳会社、配信事業者を中心に利用されており、集英社の人気マンガ『ONE PIECE』『SPY×FAMILY』のベトナム語版などの制作にも用いられている。

今回の資金を活用し、向こう5年を目処に「エンドユーザーが楽しんで読める」を目指し、マンガAI翻訳の精度向上に取り組むと同時に、小説やゲーム、動画への翻訳技術転用を本格化させる研究開発も進めていくという。

Mantraの代表取締役である石渡 祥之佑氏は、「エンタメから言語の壁をなくしたい」という明確な目的意識を創業前から持っており、昨今の急速に進むLLMや画像生成AIの進化を見て、「言語の壁がなくなる未来が少しずつ現実のものとして想像できるようになった」と述べている。

:::box

:::

:::box

:::

:::box

:::

</description><pubDate>Sun, 30 Jun 2024 21:14:19 +0000</pubDate></item><item><title>KRAFTON JAPAN　GPT-4o搭載の推理アドベンチャーゲーム『Uncover the Smoking Gun』を正式リリース</title><link>https://ledge.ai/articles/uncover_the_smoking_gun</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年6月25日、KRAFTON JAPAN株式会社は、AI技術を搭載した推理アドベンチャーゲーム『Uncover the Smoking Gun』をリリースしたと{target=“_blank”}した。

『Uncover the Smoking Gun』は、KRAFTON JAPAN傘下のクリエイティブスタジオ「ReLU Games」が制作した、ロボットと人間が共存する近未来を舞台にした没入型推理アドベンチャーゲームだ。プレイヤーがAI専門の探偵となり、事件の手がかりを追いながら、容疑者であるロボットに対してチャットで尋問していく。

OpenAIがリリースした「GPT-4o」を搭載しており、容疑者のロボットは単純に質問に回答するだけではなく、プレイヤーの性格に合わせた口調で、まるで実際に人とチャットで会話しているような感覚で楽しめるという。ロボットの曖昧な証言を見極め、真実にたどり着くために鋭い質問を投げかけながら、事件解決を目指す没入型の推理ゲーム。

『Uncover the Smoking Gun』は、現在Steamでダウンロード可能。日本語、韓国語、英語、中国語など全8言語に対応しており、詳細はSteamページおよびReLU Games公式サイトで確認できる。

:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 27 Jun 2024 03:57:02 +0000</pubDate></item><item><title>Google DeepMindが動画に合うBGMや効果音を生成するAI「Video to Audio」を発表</title><link>https://ledge.ai/articles/google_deepmind_v2a</link><description>:::small
画像の出典：{target=“_blank”}
:::

Google DeepMindは2024年6月17日、新たな技術「Vide to Audio（V2A）」を{target=“_blank”}した。Generative Mediaチームの発表したこの技術は、動画の映像情報とテキストのプロンプトを用いて、映像にぴったりと合ったサウンドトラックを生成する能力を持つ。

現在、映像生成モデルは急速に進化しているが、多くの現行システムは無音の出力しか生成できない。V2Aは、この課題を解決し、生成された映像にリアルな音響を付与するための重要なステップとなる。

V2Aは、映像ピクセルと自然言語テキストプロンプトを組み合わせて、画面上のアクションに対してリッチな音響効果を生成する。例えば、ドラマチックなスコア、リアリスティックな音響効果、またはビデオのキャラクターやトーンに合ったダイアログを生成することが可能だ。

{target=“_blank”}（音声プロンプト： 映画、スリラー、ホラー映画、音楽、緊張感、雰囲気、コンクリートの上の足音）

!
:::small
画像の出典：{target=“_blank”}
:::

{target=“_blank”}（音声プロンプト: 月に向かって吠えるオオカミ)

!
:::small
画像の出典：{target=“_blank”}
:::

## V2Aの技術的詳細
V2Aシステムは、ビデオ入力を圧縮された表現にエンコードし、拡散モデルがランダムなノイズから音声を逐次的に洗練させる。このプロセスは視覚的入力と自然言語プロンプトによってガイドされ、プロンプトに密接に一致する現実的な音声を生成する。最終的に音声出力がデコードされ、音声波形に変換され、ビデオデータと組み合わせられる。

また、高品質な音声を生成するために、詳細な音の説明や音声トランスクリプトを含むAI生成のアノテーションを追加情報としてトレーニングプロセスに加えた。これにより、特定の音声イベントを様々な視覚シーンと関連付けることが可能となり、アノテーションやトランスクリプトで提供された情報に基づいて音声を生成できるという。

!
:::small
画像の出典：{target=“_blank”}
:::


## 創造的なコントロールと今後の展望
V2Aは、任意のビデオ入力に対して無限のサウンドトラックを生成する能力を持つ。ユーザーは「ポジティブプロンプト」を定義して望ましい音にガイドするか、「ネガティブプロンプト」を使用して望ましくない音を排除することができる。この柔軟性により、V2Aの音声出力を迅速に実験し、最適なマッチを選択することが可能だという。


以下は、同じ動画に対して複数のサウンドを生成した例
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）
{target=“_blank”}(音声プロンプト: 優美なチェロの雰囲気）
{target=“_blank”}(音声プロンプト: 宇宙船が広大な宇宙を疾走し、星々が高速で飛び交う。SF）

!
:::small
画像の出典：{target=“_blank”}
:::


Google DeepMindは、責任あるAI技術の開発を重視し、クリエイティブコミュニティからの多様な視点や洞察を収集し、研究と開発に反映させているとのこと。また、AI生成コンテンツに透かしを入れるためのSynthIDツールキットも導入し、この技術の誤用を防ぐための対策を講じている。V2A技術は公開前に厳格な安全評価とテストを経る予定だという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 28 Jun 2024 12:32:10 +0000</pubDate></item><item><title>AI音楽生成サービスSunoとUdioを著作権侵害で提訴　ユニバーサル、ソニー、ワーナー含む大手音楽企業</title><link>https://ledge.ai/articles/suno_and_udio_sued_for_copyright_infringement</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

米国の主要レコード会社であるユニバーサルミュージック（UMG）、ソニー、ワーナーを含む複数の企業が、AI音楽生成サービス「Suno」と「Udio」に対し、著作権侵害を理由に{target=“_blank”}。

RIAA（アメリカレコード協会）が2024年6月24日、ニューヨーク南部地区連邦地方裁判所およびマサチューセッツ地区連邦地方裁判所にそれぞれ提出した訴状によると、SunoとUdioは、著作権で保護されたサウンドレコーディングを無断でコピーし、自社のAIモデルのトレーニングに利用したという。その生成物が市場に流通しているとされ、複数のジャンルや時代のアーティストの録音が侵害対象となっているとのこと。

訴訟では、以下の3点を求めている。
- サービスが原告の著作権を侵害したことの宣言
- 将来的な著作権侵害を防ぐための差し止め命令
- 既存の侵害に対する損害賠償

## 訴訟の概要
この訴訟は、AI技術が進化し音楽制作の分野においても大きな影響を及ぼしている中、著作権の保護がいかに重要かを問うものである。原告側は、AIサービスが著作権で保護された楽曲を無断で使用し、生成された音楽ファイルが元の作品と酷似していると主張している （下図参照：訴状より）

!
:::small
画像は訴状より：Udioの生成した曲（上）が、マライアキャリー氏の楽曲（下）に酷似している例。譜面の赤い音符が一致している
:::

RIAAの最高法務責任者であるケン・ドロショウ氏も、「これらのケースは、大規模な著作権侵害に関する単純な事例です。SunoとUdioは、自社のサービスを合法かつ健全な基盤に乗せる代わりに、侵害の全貌を隠そうとしています。この訴訟は、AIシステムの責任ある開発を促進し、SunoとUdioの侵害行為を終わらせるために必要なものです」とコメントしている。

これに対しUdioは6月26日、X（旧Twitter）に{target=“_blank”}し、AI技術の使用に著作権で保護された作品を再現する意図はないと主張した。また、著作権侵害を防ぐためのフィルターを実装していると述べている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 26 Jun 2024 04:14:21 +0000</pubDate></item><item><title>演奏会出演辞退する高橋洋子氏「想い異なり、アーティストとして向き合えない」　生成AI画像使用に対し</title><link>https://ledge.ai/articles/ikeaniphil_singer_withdraws_from_concert_because_of_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

歌手の高橋洋子氏は、2024年7月10日開催予定の「池袋アニメーションフィルハーモニー第一回演奏会」への出演辞退することを6月19日、自身のSNSで{target=“_blank”}した。

出演辞退の理由は、同オーケストラがイベントのチラシやホームページに生成AIで作成した画像を使用していたことに起因するという。高橋氏は「運営の姿勢につきまして、高橋洋子の想いと異なり、アーティストとして向き合うことができない出来事がございました」と報告した。

!
:::small
画像の出典：{target=“_blank”}
:::

同じ日、池袋アニメーションフィルハーモニーの実行委員会もSNSの公式アカウントでこの事態について{target=“_blank”}し、「アニメ音楽に関わる立場として、こうした状況での出演は好ましくない」という高橋氏側の意見を受けての辞退であることを明らかにした。

そして「アニメを愛する楽団を名乗っているにもかかわらず、昨今の生成AIを取り巻く問題について自覚が足りなかったことを恥じております。また、作品に対する配慮、アニメやそれに関わるクリエイティブを愛する皆様の気持ちを汲み取れなかったことに気付き、実行委員一同深く反省しております」と謝罪した。

ポスターは手描きイラストに差し替えることを決定し、6月20日以降はポスターやWebサイトに掲載している画像をイラストレーターに依頼した手描きイラストに差し替えた。また、チケットを既に購入した方にはキャンセル・返金対応を行うと発表した。
## 事態の発端
池袋アニメフィルのポスターには、生成AIによる画像が使用されているとの指摘がインターネット上で広まり、アニメ専門オーケストラが生成AI画像を使うことに対する批判が高まった。実行委員会は6月19日に公式声明を発表し、ポスターを手描きイラストに差し替えることを決定。
## 実行委員会の対応
代表の松下洋氏は、生成AI画像を意図して使用したわけではなく、商用利用可能な画像素材からデザインを選んだ際に「AI生成」のタグを見落としたと説明した。実行委員会は「生成AIを取り巻く問題について自覚が足りなかったことを恥じている」とし、今後はより一層の注意を払うと述べた。

## 高橋洋子氏の辞退
この問題を受け、ゲスト出演予定だった歌手の高橋洋子氏は、運営の姿勢に対する違和感から出演を辞退した。同氏は、人気アニメ「新世紀エヴァンゲリオン」の主題歌「残酷な天使のテーゼ」などのヒット曲で知られている。

高橋氏の出演辞退のほか、同演奏家への企業による協賛辞退や、運営メンバーの実行委員会からの脱退および出演辞退などの影響が続いている。


:::box

:::
:::box

:::

</description><pubDate>Sat, 22 Jun 2024 12:16:37 +0000</pubDate></item><item><title>Silverside AIが小説を映像化できるAIプラットフォーム「Hypnovels」を発表</title><link>https://ledge.ai/articles/silverside_ai_Hypnovels</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

2024年4月8日、Silverside AIは小説をアニメーション化できる「Hypnovels」を{target=“_blank”}した。

アニメーションを作成するには、通常何ヶ月もの膨大な時間と費用を必要とするが、この「Hypnovels」は、小説の見出しと内容を簡単にテキストで入力、ビジュアルスタイルとナレーターの声を選択するだけで、わずか数時間で魅力的なアニメーションを作成できるという。文章を映像化することにより、新たな小説の楽しみ方ができる。

このアイデアは、作家であるペレイラ氏が自身が発表した小説『The Girl from Wudang』を宣伝する際に、AIを使用したことをきっかけに誕生したそうだ。新たな小説の楽しみ方を提供するだけではなく、マーケティングツールとしても充分に利用できる。自身の作品を映像化して宣伝することで、読んだことのない読者がこの作品と出会えるチャンスにもつながるだろう。

@

:::small
出典：[Hypnovels 公式YouTubeで実際に小説を映像化した動画]
:::
 
:::box

:::
:::box

:::
:::box

</description><pubDate>Thu, 20 Jun 2024 09:25:31 +0000</pubDate></item><item><title>AI美女コンテスト「Miss AI」ファイナリストはこの10名だ！　容姿・影響力・クリエイターの技術力を評価し選考</title><link>https://ledge.ai/articles/fanvue_miss_ai_finalists</link><description>:::small
画像の出典：{target=“_blank”}
:::

世界初のAI美人コンテスト「Miss AI」の最終選考に残った10人のAIモデルが{target=“_blank”}された。
{target=“_blank”}によると、このコンテストには約1500人の応募があり、その中から選ばれた10人のAI生成モデルが最終的な優勝を目指して競い合うことになる​。

4月にソーシャルメディアプラットフォームFanvueが開催発表した「Miss AI」は、AI生成のモデルを対象にした初の美人コンテストで、ルックスや振る舞いといった従来の基準に加え、ソーシャルメディアでの影響力やクリエイターの技術力も評価の対象となる。優勝者は5,000ドルの現金とプロモーションサポートを受けることができる

審査員には、AIインフルエンサーのエミリー・ペレグリーニとアイタナ・ロペスが名を連ねている。これらのAIモデルは、インスタグラムで数十万人のフォロワーを持ち、自身が築いたソーシャルメディアでの成功をもとに、コンテストの参加者を審査するという。

!
:::small
画像の出典：{target=“_blank”}
:::

## ファイナリスト10名はこちら

### {target=“_blank”}
!

### {target=“_blank”}
!

### {target=“_blank”}
!

### {target=“_blank”}
!

### {target=“_blank”}
!

### {target=“_blank”}
!

### {target=“_blank”}
!


### {target=“_blank”}
!

### {target=“_blank”}
!

### {target=“_blank”}
!


これらのファイナリストはそれぞれInstagramで活動しており、フォロワー数や投稿内容が審査の一環として評価されている。例えば、LGBTQ+の支持者でありDJでもあるアイヤナ・レインボーや、環境保全団体のアンバサダーを務めるアン・ケルディなど、各モデルはそれぞれのメッセージを発信している。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 10 Jun 2024 16:12:22 +0000</pubDate></item><item><title>ElevenLabs テキストから効果音を生成するモデル「Sound Effects」公開</title><link>https://ledge.ai/articles/elevenlabs_sound_effects</link><description>:::small
画像の出典：{target=“_blank”}
:::

ElevenLabsは2024年6月1日、新しいAIオーディオモデル「Sound Effects」を{target=“_blank”}した。このツールは、ユーザーがテキストプロンプトを入力するだけで多様な効果音を生成でき、映画、テレビ、ゲーム、ポッドキャストなどのコンテンツ制作に活用できるという。

Sound Effectsは、ユーザーがテキストで必要なサウンドを記述し、生成ボタンをクリックするだけで、即座に関連するサウンドを生成する。各リクエストには少なくとも4つのバリエーションが提供され、ユーザーは最適なものを選んでダウンロードが可能だ。

様々なシチュエーションを演出するプロンプトと生成された音のサンプルが、X（旧Twitter）で{target=“_blank”}されている。

!
:::small
画像の出典：{target=“_blank”}
:::

開発にはShutterstockが協力しており、同社の豊富なオーディオライブラリからライセンスされたトラックを使用してモデルがチューニングされているとのこと。これにより、高品質で多様な効果音を簡単に生成できるようになっている。

Sound Effectsは無料で利用可能だが、商業利用には有料サブスクリプションが必要となる。無料ユーザーは生成したコンテンツを公開する際に「elevenlabs.io」とクレジットを付ける必要があるとのこと。

無料ユーザーは月に10,000文字までのプロンプト入力制限があり、デフォルトの音声クリップの長さであれば1リクエストごとに200文字が消費される。

競合サービスとしては、Stability AIが2023年にリリースした音楽や効果音を生成する「Stable Audio」や、Metaの提供する自然音を生成するモデル「AudioCraft」などが挙げられる。

ElevenLabsは今後、APIアクセスの提供を予定しており、より多くの開発者や企業がこのツールを活用できるようになるとのこと。


:::box

:::
:::box

:::
</description><pubDate>Mon, 10 Jun 2024 02:37:40 +0000</pubDate></item><item><title>AIが生成する画像の「奇妙さ」をホラー作品に昇華　YouTubeショート「群馬旅行の思い出」を見よ</title><link>https://ledge.ai/articles/youtube_short_the_memory_of_gunma</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月24日、生成AIを活用して作成されたホラーショート動画「群馬旅行の思い出」がYouTubeに{target=“_blank”}され、わずか10日で200万再生を越えた。

画像生成AIの Midjourney などを使用し作成された動画「群馬旅行の思い出」は、古びた日本家屋が立ち並ぶ霧がかった田舎町に巨大な怪物たちが佇むシーンから始まる。蜘蛛と牛を掛け合わせたような生物や宙に浮かぶ顔面、骨だけの巨人など、異様な生物が次々と登場し、その不気味な雰囲気が視聴者を引きつける。

投稿者であるSTRANGE LOVE氏は、生成AIを活用してモンスターやホラー系のショート動画を制作し、YouTubeやTikTokで公開している。

生成AIの高いクオリティは評価される一方で、「不気味の谷現象」と呼ばれる、人間に似ているが完全には似ていないために不気味さを感じる現象が生じることがある。STRANGE LOVE氏の作品は、この不気味さをホラー要素としてうまく取り入れている。

この動画に対し、地元住民や群馬県出身者からYouTubeに多くのコメントが寄せられた。その多くが
「急に地元の村長出てきてびびった。元気そうでなにより」「群馬県民です。2つ目の爺さんは、ゴミの分別ができてないと怒ってくれる街の味方です」など、モンスターたちの存在を全肯定するものであふれている。すかさず「群馬県民ノリ良すぎだろ（笑）」とツッコミも入り、コメント欄が賑わいを見せている。

STRANGE LOVE氏のチャンネルには、この動画のほかにも「茨城旅行の思い出」「嫁の実家」など、奇妙で美しく、怖いけど懐かしい、日本古来のノスタルジーとユーモラスな空気感を演出する不思議な世界観が繰り広げられている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 08 Jun 2024 14:06:06 +0000</pubDate></item></channel></rss>