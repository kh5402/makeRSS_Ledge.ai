<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.aiビジネスカテゴリ</title><link>https://ledge.ai/categories/business/</link><description>Ledge.aiのビジネスカテゴリの最新記事</description><language>ja</language><lastBuildDate>Wed, 30 Aug 2023 07:30:48 +0000</lastBuildDate><item><title>Googleいよいよ検索に生成AIを導入 日本でも「SGE」試験運用開始</title><link>https://ledge.ai/articles/google_releases_sge_japanese_version</link><description>米国Googleは生成AIを組み込んだ検索サービス「Search Generative Experience（SGE）」の日本語版を試験運用開始したと、2023年8月30日にした。検索技術の研究組織「Search Labs」の公式サイトでGoogleアカウントを使って登録を済ませると、数日中にパソコン向けWebブラウザ「Chrome」またはiPhoneやAndroidスマートフォン向けの「Google」アプリケーションから利用できるようになる。なお即座に使える場合もある。

GoogleのSGEは5月から米国などで始まり、順次機能の拡充が進んできた。すでに米国Microsoftの生成AI検索「Bing AI Chat（あるいは新しいBing）」が2月に登場し、日本語に対応していることを考えると慎重な動きだった。

新たに試験運用を開始したSGEの日本語版では例えば「残暑見舞いはいつ頃送る? 」という質問をすると、「残暑見舞いは、立秋（8月7日）から8月末頃までの間に送るのが一般的です」といった回答があらわれる。検索の結果見つかった複数のWebサイトの情報をAIが簡潔にまとめた概要だ。表示を切り替えれば概要のどの部分どのWebサイトの情報に基づくのかを参照できる。概要の下には通常の検索結果が続く。

!

さらに「残暑見舞いに何を送ったら喜ばれますか？」「残暑見舞いのマナーは？」といった続く質問の候補も一覧できる。気になった候補を選択すると対話形式で知りたい情報を掘り下げてゆける。候補の代わりに自分で考えた質問をすることも可能だ。いずれの場合はSGEは質問の流れを一定程度覚えているため、自然なかたちでやりとりを続けられる。

なおSGEはGoogleが開発した大規模言語モデル（LLM）を採用しているが、性能に限界があるため検索が常に正しく機能するとはいえず、今後さらに更新予定。当面、検索結果では常にAIがまとめた概要を表示するのではなく、特定の質問だけにとどまるという。このほかSGEも専用枠に広告を表示するが、ほかの部分と区別できるように「スポンサー」と明記する。

:::box

:::
:::box

:::</description><pubDate>Wed, 30 Aug 2023 07:30:48 +0000</pubDate></item><item><title>NVIDIA 純利益9倍・売上高2倍で過去最高 生成AI需要増で 第2四半期決算
</title><link>https://ledge.ai/articles/nvidia_settlement</link><description>米国NVIDIAは2023年8月23日に、2024年度第2四半期（2023年5月～7月）決算を{target=“_blank”}した。生成AIの開発競争が激化しており、AI向け半導体製品の需要が拡大。売上高、純利益とも過去最高を更新した。

売上高は過去最高の135億1,000万ドルで、第1四半期比で88%、前年同期比で101%増加。またデータセンターの売上高は103億2,000万ドルを記録、第1四半期比で141%、前年同期比で171% 増加した。

米国会計基準（GAAP）にもとづく希薄化後1株当たり純利益は2.48ドルで、第1四半期比202％増、前年同期比854％増。 非GAAP基準の希薄化後1株当たり純利益は2.70ドルで、第1四半期比148%増、前年同期比429%増となった。

同社の Jensen Huang（ジェンセン・ファン）創業者兼最高経営責任者（CEO）は「当四半期中、大手クラウドサービスプロバイダーは大規模なNVIDIA H100 AI インフラストラクチャを発表した。大手エンタープライズ ITシステムおよびソフトウェアプロバイダーはNVIDIA AIをあらゆる業界に提供するためのパートナーシップを発表した。生成型AIの導入競争は続いている」と述べている。

:::box

:::
:::box

:::
</description><pubDate>Wed, 30 Aug 2023 01:55:25 +0000</pubDate></item><item><title>MicrosoftはAIを使った人のデータを監視 新規約に明記</title><link>https://ledge.ai/articles/microsoft_terms_revision</link><description>:::small

:::

 米国Microsoftがサービス規約の最新版を2023年7月30日に{target=“_blank”}した。同社の消費者向け製品、Webサイト、サービスを使用する際に適用となるもので、これまで記載のなかったAIサービスに関する文言が追加している。この規約の発効日は9月30日を予定している。
 
新設の「AI サービス」に関する項目では以下の5つを掲げている。

1つ目は「リバース エンジニアリング」。モデル、アルゴリズム、およびシステムの基盤となるコンポーネントを見つけるためにMicrosoftのAIサービスを使用することを禁じる。例えばモデルの「重み付け（weight）」を調べて削除しようとしてはならない、としている。

2つ目は「データの抽出」。明示的な許可のある場合を除いて、MicrosoftのAIサービスに対しWebスクレイピング、WebハーべスティングなどのWebデータ抽出方法を使用することを禁じる。

3つ目は「AIサービスからのデータ使用に対する制限」。MicrosoftのAIサービスやそのデータを使用して、ほかのAIサービスを直接と間接問わず作成、訓練または改善することを禁じる。

4つ目は「お客様のコンテンツの使用」。Microsoftは不正または有害な使用や出力を監視、防止する目的で、AIサービスへの入力とAIサービスからの出力を処理し、保存する。

5つ目は「第三者の申し立て」。例えば利用者がAIサービスで出力した内容について、第三者から著作権侵害などの申し立てがあった場合、責任はMicrosoftではなく利用者自身が単独で負うとしている。なお著作権関連に限定しない法令が対象とのこと。


:::box

:::
:::box

:::


</description><pubDate>Tue, 29 Aug 2023 07:16:37 +0000</pubDate></item><item><title>ChatGPTの法人版「ChatGPT Enterprise」登場 高速GPT-4を無制限に利用可 入力内容は学習に使用せず</title><link>https://ledge.ai/articles/chatgpt_enterprise</link><description>:::small
画像出典：OpenAI
:::
米国OpenAIは、2023年8月28日に対話型AI（チャットボット）「ChatGPT」の法人版「ChatGPT Enterprise」の{target=“_blank”}した。セキュリティとプライバシーの保護水準が高く、入力したデータやプロンプト（文章による指示）をAIの学習に使わない仕様という。米国公認会計士協会のセキュリティ統制基準「SOC 2」にも準拠し、全ての会話を送受信や保存時に暗号化する。

{target=“_blank”}ではまた、OpenAI最新の大規模言語モデル（LLM）「GPT-4」を無制限に利用できる。3万2,000トークン（語彙）の入力を一度に行える。通常版の4倍の長さの文章やファイルをより効率よく処理可能。動作速度も最大2倍に向上している。

これに加え通常版で「コードインタープリター」という名称で導入していたデータ解析機能も無制限に利用できる。市場データを処理する金融研究者、調査結果を解析するマーケティング担当者、データの抽出・変換・書き出し（ETL）用簡易プログラムを調整するデータ サイエンティストなどが数秒で作業を終えられるとのこと。

さらに、組織の必要に応じてChatGPTをカスタマイズ可能。テンプレートを活用し、共同作業や特定のワークフローを構築することが手軽になる。完全なカスタマイズを求める場合、ChatGPTの機能を外部から呼び出すためのアプリケーション・プログラミング・インターフェイス（API）の無料クレジットも利用できる。

なお公式サイトでは「ChatGPT Enterprise」の料金体系を掲載しておらず、OpenAIの営業部門に直接問い合わせるよう案内している。

:::box

:::
:::box

:::
</description><pubDate>Tue, 29 Aug 2023 06:53:13 +0000</pubDate></item><item><title>Zoom 顧客の映像や音声をAI学習に使用の恐れ 批判受け1週間で2度規約改訂</title><link>https://ledge.ai/articles/zoom_updated_terms_of_service_twice_in_a_week</link><description>2023年8月6日に、ビデオ会議アプリケーション「Zoom」の新{target=“_blank”}に関し「利用者のデータをAIの学習に利用できることになっている」と報じたStackDiaryの{target=“_blank”}について、米国の複数メディアが取り上げた。インターネット上の騒然とした反応を受けて開発元の米国Zoom Video Communicationsは1週間で2度にわたり規約を改訂する事態となった。

焦点となったのは、最初に報道があった時点の規約のセクション10.2と10.4。Zoomが利用者のデータ、特にビデオ会議などによって残る「サービス生成データ」の利用に関する広範な権利を持つことを示し、AIや機械学習（ML）といった用途にも言及していた。

Zoomはすでに規約の該当部分を変更したものの、内容についてはさまざまなWebサイトの過去の情報を保存する「{target=“_blank”}」などから確認可能だ。該当部分は3月から8月初旬まで存在したことがわかる。

Zoomは8月7日に事態に対応するため1度目の規約改訂を実施。Eric Yuan（エリック・ユアン）創業者兼最高経営責任者（CEO）は8日にSNS「LinkedIn」で、利用者のデータを同意なくAI学習に使用しないとし、製品を改善しAIを訓練するためのコンテンツの共有についてオプトイン（事前承認）を求めるようになっていることが操作画面から確認できると{target=“_blank”}。

しかし以降も事態は収束せず、8月11日の2度目の規約改訂で、Zoomはデータ使用慣行を明確にし、AIの訓練に会議の音声、動画、チャットなどの内容を使用しないことを強調した。

StackDiaryのAlex Ivanovs氏は、今回の事態は当初から起こるべきではなかったと指摘。AIの学習にデータを使用する場合、事前の告知はもちろんオプトアウト（事後不承認）の選択肢は必須との立場を示した。

:::box

:::
:::box

:::</description><pubDate>Mon, 28 Aug 2023 08:50:55 +0000</pubDate></item><item><title>Meta 声を吹き込むと翻訳するAI「SeamlessM4T」日本語など100言語対応 人間のような「空耳」で誤訳も</title><link>https://ledge.ai/articles/meta_seamless_m4t</link><description>:::small
画像出典：seamless.metademolab.com
:::
Metaは2023年8月22日、音声を入力することで「文字起こし」「別言語への翻訳」「別言語への吹き替え」を実行するAI「{target=“_blank”}」を発表した。日本語を含む多言語に対応する。実際にデモを試すと話した内容の大意を自然なかたちで指定の言語に翻訳し、読み上げるが、人間のような「空耳」や訳し間違いもするようだ。

同AIでは以下のことが可能だ。

・約100種類の言語の音声認識
・約100種類の言語の音声からテキストへの翻訳
・約100種類の言語の音声から英語を含む36種類の言語の音声への翻訳
・約100種類の言語のテキストからテキストへの翻訳
・約100種類の言語のテキストから英語を含む35種類の言語の音声への翻訳

SeamlessM4Tはオープンサイエンスの考えにより、研究ライセンスのもと公開されており、研究者や開発者が該当の技術を活用できる。さらに史上最大というオープンマルチモーダル翻訳データセット「SeamlessAlign」のメタデータも公開された。マイニングによる合計27万時間の音声とテキストのデータで構成されている。

Metaによると、往年のSF小説『銀河ヒッチハイク ガイド』に登場する「Babel Fish（バベル フィッシュ）」のような世界規模の翻訳機の構築はまだ困難。音声から音声、音声からテキストへの翻訳の仕組みがまだ世界の言語の一部にしか対応していないためだ。SeamlessM4Tはそのような問題点の克服、エラーや遅延の減少、翻訳の効率と品質の向上が目標として掲げられている。

今回の技術は、2022年に公開された200の言語に対応する機械翻訳モデル「No Language Left Behind（NLLB）」や、文字体系のない言語である福建語の音声ー音声翻訳システム「Universal Speech Translator」、1,100種類以上の言語の音声認識、言語識別、音声合成を行う研究用モデル「Massively Multilingual Speech」などの実績にもとづく。

なおSeamlessM4Tは{target=“_blank”}が公開されている。実際に機能を試してみると、例えば「私は犬を飼っています。将来的には猫とインコも飼いたいです」と音声入力した場合、前半部分が「私は犬を買っています」と訳された。あらためて「私は犬を飼育しています。将来的には猫とインコも飼育したいです」と入力し、英語・韓国語・ポルトガル語を選択すると、以下画像のような結果が出た。
!
:::small
画像出典：seamless.metademolab.com
:::
「インコ」が「monkey」と訳された。なお吹き替え音声は、再生ボタンをクリックすれば再生できる。

:::box

:::
:::box

:::</description><pubDate>Mon, 28 Aug 2023 06:58:00 +0000</pubDate></item><item><title>VMWareとNVIDIA 生成AIをクラウドに置かず使える 「VMware Private AI Foundation with NVIDIA」</title><link>https://ledge.ai/articles/vmware_nvidia</link><description>米国VMwareはNVIDIAと協力し、生成AIをクラウドに置かなくても構築、運用できる基盤として「{target=“_blank”}」を投入する。2023年8月22日に年次イベント「VMware Explore 2023 Las Vegas」で明らかにした。

VMware Private AI Foundation with NVIDIAは、オンプレミス環境をクラウド環境のように運用できるソフトウエア定義データセンター（SDDC）基盤「VMware Cloud Foundation」とAI開発環境「NVIDIA AI Enterprise」を統合したもの。米国Metaがオープンソースで公開した「Llama 2」をはじめとする大規模言語モデル（LLM）などを企業の社内データで訓練し、データセンターはもちろん主要なパブリッククラウド、そしてエッジ環境に設置できる。

用途はチャットボット、アシスタント、検索、要約などの生成AIアプリケーションを想定している。Dell Technologies、Hewlett Packard Enterprise、Lenovoの製品が対応するという。

「VMware Private AI Reference Architecture for Open Source」も同時に発表した。こちらはオープンソースソフトウェア（OSS）でモデルを構築してVMware Cloud Foundation上で運用できるというものだ。

:::box

:::</description><pubDate>Fri, 25 Aug 2023 12:02:47 +0000</pubDate></item><item><title>Google 大規模言語モデルに「視覚」を与える メルカリと開発した商品画像検索AIも公開</title><link>https://ledge.ai/articles/google_vlm</link><description>「もし大規模言語モデルが画像の意味を理解する視覚を持っていたらどうだろうか？」。米国Googleは2023年8月22日、{target=“_blank”}で問いかけた。答え合わせをするように同社が開発した視覚言語モデル（Vision Language Model：VLM）と、それを生かしてメルカリと共同開発した商品画像検索AIも紹介している。

## 商品の画像を「見て」検索するAI
Googleとメルカリの米国版が共同開発した商品画像検索AIについてはの通りだが、このほど誰でも機能を体験できる{target=“_blank”}も登場した。

試したい場合はまず「MERCARI TEXT-TO-IMAGE」を選択し、例えば「handmade accessories with black and white beads（黒と白のビーズを使ったハンドメイドアクセサリー）」といった具合に、自然な文章で探しているものの情報を入力する。日本語も利用できるが、英語の方が精度が高い。

入力を終えると即座に検索結果があらわれ、関連した商品が画像付きでずらりと並ぶ。商品名や説明文、タグは一切使用せず、VLMが文章と画像の情報を照らし合わせているという。

!

!

企業がクラウドサービス上でAIの訓練や利用を行えるGoogle Cloudの機械学習基盤「Vertex AI」で8月初旬に一般公開が始まった新機能「Vertex AI Multimodal Embeddings」の先行導入事例だ。

この新機能はGoogle Researchが開発した「Contrastive Captioner（CoCa）」というVLMを組み込んでいて、複数の異なる種類の情報を処理する、いわゆる「マルチモーダル」AIを実現できるようになっている。

今回はメルカリの商品画像580万点をVertex AI Multimodal Embeddingsに渡して「埋め込み（ Embeddings）」つまりAIにとって処理しやすいベクトル情報を抽出し、検索する際の索引として利用できるようにしてある。デモで文章を入力するとVLMがベクトル情報を抽出し、先に画像から抽出したベクトル情報と照らし合わせる。

## VLMはどう社会を変えるか
深層学習技術では文章からも画像からもベクトル情報を抽出できるので、両者の関係を学習させれば、VLMは文章から画像（text-to-image）を、あるいは画像から文章（image-to-text）を自在に検索できる。

あらかじめ画像に対してタグやラベルをつけておかなくてもよく、従来の光学文字認識（OCR）も不要。色々な分野に応用のきく便利な仕組みだ。

例えばメルカリのようなアプリで、誰かが販売したい商品の画像を投稿したとする。するとVLMが同じカテゴリやブランド、類似した色やスタイルの既存の商品を検索し、見つけた情報に基づいて商品名、説明、販売価格を提案する。情報をいちいち手動で入力する手間が省ける。

また数千台の監視カメラを設置している施設を考えてみる。毎分何百万もの画像を記録していても、VLMさえあれば「ドアを開けようとしている人」「工場が浸水している」「機械が燃えている」などの自然な文章で条件にあった画像を探し出せる。

!
さらに自動運転技術の開発にも役に立つ。クルマを制御するAIは、運転中に遭遇する不測の事態にどう対処するかを学習せねばならない。事故などに関する写真や動画そのものはすでに大量に蓄積しているが、必ずしもタグやラベルをつけて整理しておらず、そのままでは使用しづらい。だがVLMがあれば「赤信号が点灯している交差点で歩行者が立っている」や「前方の高速道路の真ん中で停止している潰れた車」などの複雑な条件を自然な言語で指定して一致する画像を見つけられる。

LLMの使い道はもはや単なるチャットボットにとどまらず、「視覚」を与えればさまざまな事業で活かせるという示唆だ。

:::box

:::
:::box

:::</description><pubDate>Fri, 25 Aug 2023 16:09:59 +0000</pubDate></item><item><title>OpenAIが「GPT-3.5 Turbo」のファインチューニングに対応 「GPT-4」は今秋にも
</title><link>https://ledge.ai/articles/gpt_finetuning</link><description>:::small
画像出典：OpenAI
:::
米国OpenAIは2023年8月23日、対話型AI（チャットボット）「ChatGPT」などが採用する大規模言語モデル（LLM）「GPT-3.5 Turbo（gpt-3.5-turbo-0613）」が{target=“_blank”}に対応したと発表した。外部のアプリケーションからgpt-3.5-turbo-0613の機能を利用する際、従量課金で目的に合わせたカスタマイズができるようになる。最新版LLM「GPT-4」も同年秋に対応予定だ。

まずLLMの機能を外部から呼び出すアプリケーションプログラミングインターフェイス（API）を通じて学習データの準備とアップロードを行い、新たなモデルを訓練し、しかるのち利用を開始する、という流れ。

利点としては例えば次のようなものがある。ChatGPTは英語の文献を多く学習しているため、別の言語で質問をしても英語で回答する場合があるが、企業の社内チャットボットなどで微調整済みのgpt-3.5-turbo-0613を利用すれば、英語以外の言語で質問した際に同じ言語で回答させられる。

またChatGPTの回答は定まった形式がないが、微調整したgpt-3.5-turbo-0613を利用すれば同じ型を守らせられるようになる。企業ごとのブランドに合わせた言葉選びをさせることも可能だ。また文章による指示「プロンプト」をより簡略にし、処理する文中の語彙「トークン」の数を節約できるので、回答の速度を上げられる。OpenAIのサービスはトークンごとに料金が発生するため、コストを下げる効果も見込める。

なお微調整はプロンプトの書き方を工夫する「プロンプトエンジニアリング」、情報検索（IR）、関数呼び出しなどの手法と組み合わせられる。微調整と関数呼び出しの組み合わせは今秋後半から対応予定。

gpt-3.5-turbo-0613が1度に処理できる語彙は4,000トークンだが、より長い1万6,000トークンを処理できる「gpt-3.5-turbo-16k」の微調整も今秋後半からできるようになる見込み。

gpt-3.5-turbo-0613の微調整にかかる料金は1,000トークンあたり学習が0.008ドル、入力が0.012ドル、出力が0.016ドル。

ちなみに従来の「GPT-3」をもとにしたモデル「ada」「babbage」「curie」「davinci」は 2024年1月4日に終了するが、代替として今回新たに「babbage-002」と「davinci-002」も利用可能になった。微調整も行える。

babbage-002の料金は1,000トークンあたり通常の入力と出力がそれぞれ0.0004ドル。微調整は訓練が0.0004ドルで、入力と出力が0.016ドル。


davinci-002の料金は1,000トークンあたり通常の入力と出力が0.002ドル。微調整は訓練が0.006ドルで、入力と出力が0.012ドル。




:::box

:::
:::box

:::
</description><pubDate>Fri, 25 Aug 2023 06:36:51 +0000</pubDate></item><item><title>無料で使える画像ツール「Adobe Express」に生成AI機能 テキストから画像を出力  </title><link>https://ledge.ai/articles/adobe_express_generative_ai_function</link><description>米国Abobe（アドビ）は2023年8月16日、オンラインの画像編集ツール「{target=“_blank”}」を更新し、生成AI機能を組み込んだ最新版を一般公開した。パソコンのWebブラウザなどから利用できる。

新たにAdobe独自の画像生成AI「Adobe Firefly」（ベータ版）を搭載し、日本語を含む100以上の言語でプロンプト（文章による指示）を入力することで画像やテキスト効果の生成が可能になった。

また既存のAI機能の強化として編集中の画像に適した追加要素をすばやく見つけられるようになり、個々人の作風に合ったテンプレートの提案を受けられるようになった。SNSへ投稿する画像や、動画、ポスター、チラシなどの作成がより容易になったとしている。

これらの新機能はAdobe Expressのデスクトップ版に続きモバイル版でも導入予定。デスクトップ版は会員登録すれば無料で利用できる。なおAdobeの定額課金サービス「Adobe Creative Cloud」を契約していれば有料機能も使える。

:::box

:::
:::box

:::</description><pubDate>Thu, 24 Aug 2023 08:49:15 +0000</pubDate></item><item><title>Bingの背追うGoogleのAI検索「SGE」が拡充 文中の単語の意味を手短かに教える機能など導入
</title><link>https://ledge.ai/articles/search_generative_experience_new_functions</link><description>米国Googleは2023年8月15日、生成AIを利用した検索エンジン「Search Generative Experience（SGE）」の3つの新機能を{target=“_blank”}した。検索結果の文章にあらわれる難しい用語の定義などを確認したり、プログラミングコードをきれい色分けして見られるようになった。SGEは8月現在、米国でのみ利用可能だ。

科学や経済、歴史などに関する情報を検索した場合、結果画面にあらわれる文章から任意の単語を選択すると、単語の定義や関連する図・画像を確認できるようになった。さらに単語についての詳細画面を開けば、より掘り下げた情報を閲覧できる。

またプログラミング関連の情報を検索した際、結果画面にあらわれるコードを構文に沿って色分けし強調表示するようになった。キーワード、コメント、文字列といった要素をより識別しやすくなる。

さらに検索画面から離れていても利用できる「SGE while browsing」という機能も導入する。ニュースサイトなどにある長文の記事を開くと、内容の要点を幾つか箇条書きにして表示し、気になった要点を選択すると記事の該当部分を読める。ただし有料会員のみ閲覧できる「PayWall（ペイウォール）」の仕組みを導入した記事は対象外だ。AndroidやiOSのGoogleアプリケーション、Webブラウザ「Chrome」のデスクトップ版で使用可能。

なおSGEが今回導入した幾つかの機能と類似のものは、競合する米国Microsoftの「Bing」が先行して導入している。

:::box

:::
:::box

:::</description><pubDate>Thu, 24 Aug 2023 05:50:37 +0000</pubDate></item><item><title>6人に1人が生成AIを買い物の参考に利用 -- セールスフォース調査
</title><link>https://ledge.ai/articles/salesforce_connected_shoppers_report</link><description>:::small
画像出典：Connected Shoppers Report
:::


世界各国で買い物客の約6人に1人が生成AIの回答を参考にしているとの調査結果を米国Salesforce（セールスフォース）が2023年8月18日に「{target=“_blank”}」第5版の中で明らかにした。この報告書では新型コロナウイルス感染症流行後の小売業界が新しい技術やデータをどのように活用し、顧客満足度を高めるかについての考察を行っている。

生成AIは小売業界の変革を推進している。買い物客の17%の購入の参考として生成型AIを利用しているばかりか、まだ生成AIを積極的に利用していなくても、どんな贈り物をするか考えるのに役立てたり、家電の情報調べに活かしたりすることに関心を持っている。小売業者もマーケティングやカスタマーサービスにもこの技術の活用を検討している。

とはいえ過去20年間に小売業で導入が進んださまざまなデジタル技術を例にとって考えれば、生成AIをめぐる動きは目新しいものという訳ではない。セールスフォースによると、インターネット通販は2021年には買い物全体の59%を占めるまでになり、2023年にはいったん51%に減少したものの、2025年には再び56%に増加するとの予測だ。小売業者はオンラインとオフラインの販路の統合基盤への投資を進めている。

また2023年時点では実店舗でも買い物客の60%がスマートフォンなどを利用している。インターネットで商品について調べたり（36%）、店内のQRコードを読み取ったり (32％)、さらに読み取った内容をもとに購入手続きを完了する「scan＆go（スキャンアンドゴー）」（18%）を行うためだ。小売業者も客の行動から着想を得て、店員にモバイル機器を装備させていて、2023年時点では推定32%が仕事の一部として使いこなしており、さらに2026年までに41%へ上昇する見込みだ。

こうした既存のデジタル技術に続くように生成AIについても買い物客と店舗の双方に影響が広がったかたちだ。

Connected Shoppers Report第5版の調査は2023年5月18日から6月21日の期間、買い物客2,400人と小売業の意思決定者1,125人に実施した。対象地域はオーストラリア、ベルギー、ブラジル、カナダ、デンマーク、フィンランド、フランス、ドイツ、インド、 日本、ルクセンブルク、オランダ、ニュージーランド、ノルウェー、スペイン、スウェーデン、英国、米国。

:::box

:::
:::box

:::


</description><pubDate>Thu, 24 Aug 2023 04:09:02 +0000</pubDate></item></channel></rss>