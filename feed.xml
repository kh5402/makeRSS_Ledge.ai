<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Ledge.ai 複数カテゴリ</title><link>https://ledge.ai</link><description>Ledge.aiの複数カテゴリの最新記事</description><language>ja</language><lastBuildDate>Sat, 11 May 2024 14:30:50 +0000</lastBuildDate><item><title>国産AIによる同時通訳技術開発進む　2025年大阪万博での活用ほか、国際会議想定</title><link>https://ledge.ai/articles/simultaneous_interpretation_by_domestic_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

情報通信研究機構（NICT）が、2025年大阪・関西万博での活用を見据え、自然な会話の流れで同時通訳が可能な国産AIの開発を進めていると2024年5月8日に読売新聞などが{target=“_blank”}。

このAIは英語、日本語、中国語、韓国語、フランス語など複数言語に対応予定で、通訳者が話者の発言の途中から翻訳を始める従来の手法と比べ、作業の負担を大幅に軽減することを目指している。現在、日本国内で活動している日本語と英語の熟練同時通訳者は数百人に限られており、その負担は非常に大きいという。

政府は、2030年頃までにこの国産AIを機密性の高い情報を扱う国際交渉での使用も想定しており、経済安全保障の観点からも国産技術の確立が求められている。さらに、NICTはこの技術をさらに発展させ、裁判や医療現場など様々な分野での応用も目指しているとのこと。{target=“_blank”}


!
:::small
画像の出典：{target=“_blank”}
:::


このAIを技術面でサポートするのは、Toppanホールディングスのグループ会社。同社は、万博での活用が予定されている多言語同時通訳配信システムの実証実験を行うなどの開発に取り組んできた。{target=“_blank”}は「SEMICON Japan」で行われ、登壇者の発話をリアルタイムでテキスト化し、多言語に翻訳するシステムが試されたとのこと。このシステムは、大型スクリーンや参加者のスマートフォンに字幕として翻訳結果を表示することが可能だという。

また同社は2月29日に総務省の委託研究として、自動同時通訳が利用されるデバイス・シーンに応じた最適なレイアウトやシステム設計のUIを{target=“_blank”}。

!
:::small
画像の出典：{target=“_blank”}
:::




:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Sat, 11 May 2024 08:17:55 +0000</pubDate></item><item><title>英AIスタートアップ Wayve　ソフトバンク主導で約1,600億円を調達　「運転のための GPT」が自律型モビリティ再構築を加速</title><link>https://ledge.ai/articles/wayve_led_by_softbank_raises_10-5b</link><description>:::small
画像の出典：{target=“_blank”}
:::

英国のAIスタートアップ企業「Wayve」は2024年5月7日、シリーズCの投資ラウンドで10億5000万ドル（約1600億円）を調達したと{target=“_blank”}した。

この資金調達は、ソフトバンクグループが主導し、新規投資家としてNVIDIAが、既存の投資家であるマイクロソフトも出資した。この資金は、エンボディドAIを通じて自律型モビリティの再構築を加速するために使用される。

「エンボディドAI（Embodied AI）」とは、車両やロボットに高度なAIを統合し、実世界の環境で人間の行動を理解し学ぶ新しい方法を提供する技術である。これにより、予測不能なドライバーや歩行者の行動など、厳密なルールに従わない状況での自動運転システムの使い勝手と安全性が向上する。

Wayveの共同創設者兼CEOであるAlex Kendall氏は、エンボディドAIの可能性について以下のように説明している。
「エンボディドAIは、物理的な世界にAIの驚異的な影響をもたらすことを可能にする。私たちの生活に最も重要な相互作用が行われるのは、この物理的な世界であり、私たちの技術がこれを強化することにより、日常生活に革命をもたらすだろう。」

Wayveは2017年に設立され、公道でのエンドツーエンドのディープラーニング自動運転システムを開発・試験した最初の企業として、この分野の先駆者となる。2023年9月には、既存の自動運転ソフトウェアと大規模言語モデル（LLM）を組み合わせた{target=“_blank”}している。

現在、同社は、あらゆる車両があらゆる環境を見て、考え、運転できるようにする「運転のための GPT」に似た自律性の基礎モデルを構築しているとのこと。

この投資により、Wayveは生産車両向けの最初のエンボディドAI製品の開発と市場投入を行えるようになる。同社のAIモデルが進化するにつれ、これらの製品はOEM（自動車メーカー）が車をL2+アシスト運転からL4自動運転へと効率良くアップグレードできるようになると同社は述べている。



:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 13:03:46 +0000</pubDate></item><item><title>ウォーレン・バフェット氏「AIは、ボトルから解き放たれたジニー」バークシャー・ハザウェイ株主総会でAI悪用に懸念</title><link>https://ledge.ai/articles/warren_buffett2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月4日、米国オマハで開催されたバークシャー・ハザウェイの株主総会で、同社のCEOであるウォーレン・バフェット氏は、AIの悪用について自身の見解を述べた。AI技術の比喩として「ボトルから解き放たれたジニー」という表現を使用し、その潜在的な危険性について{target=“_blank”}。

バフェット氏はAIについて詳しい知識は持っていないとしながらも、この技術が持つ影響の大きさを認識している。特に、AIが生成する偽のビデオや音声による詐欺の可能性について言及し、自分自身が体験した偽ビデオの例を挙げて警告した。このビデオでは、自身が認識できないほど精巧に偽装された自分の姿が映し出され、完全に信じ込めるレベルで再現されていたという。

同氏はさらにAIの良い面と悪い面が共存することを強調し、技術の発展がもたらす倫理的なジレンマについて考察を深める必要があると訴えた。また、過去に核兵器の開発を例に出し、一度解き放たれた技術が如何に人類の未来に大きな影響を与えるかを語った。


:::box

:::
:::box

:::
</description><pubDate>Tue, 07 May 2024 07:00:30 +0000</pubDate></item><item><title>Xに生成AI「Grok」によるニュース要約機能「ストーリーズ」を一部有料会員向けに導入</title><link>https://ledge.ai/articles/stories_on_x</link><description>:::small
画像の出典：{target=“_blank”}
:::

👀 Now available: Stories on X, powered by Grok AI 👀 （ Grok AI を搭載した Stories on X が利用可能になりました）

X（旧Twitter）のエンジニアチームが2024年5月3日、新たなニュース要約機能「ストーリーズ」を{target=“_blank”}した。

このサービスは「Grok AI」というAIチャットボットを活用したニュース要約機能で、一部有料会員がExplore（探索）タブからアクセスできる。現時点ではWebとiOSアプリでのみ利用可能だ。

ストーリーズでは、Grok AIが世界中の注目されているトレンドニュースを選択し、ユーザー向けに要約。その要約から独自のヘッドラインを生成する能力を持つという。

イーロンマスク氏率いる開発会社「xAI」が開発したAI「Grok」は、長文を読解し、複雑な問いに対応する先進的な機能を備えている。最大128Kトークンの文脈を処理でき、情報の検索と取得において高精度な結果を示している​と同社はいう。

この新機能の提供は、まずは米国内のプレミアムプラス会員を対象に開始され、その後、他の地域のプレミアム会員へと拡大される予定だという。Xのエンジニアリングチームは、ユーザーからのフィードバックを求めており、サービスの改善に努めている。


:::box

:::
:::box

:::
</description><pubDate>Tue, 07 May 2024 14:59:42 +0000</pubDate></item><item><title>Google、モバイルアプリ版 「Gemini」を日本でリリース 従来型Googleアシスタントから置き換え
</title><link>https://ledge.ai/articles/google_gemini_app</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年4月30日、次世代AIモデル「Gemini」を搭載したモバイルアプリを日本を含む複数地域でリリースしたことを{target=“_blank”}した。従来のGoogleアシスタントを置き換え、より高度な機能を提供することを目的としている。

「Gemini」は、テキスト、画像、音声、ビデオといった複数のモダリティを統合するマルチモーダルAIで、これまでのAIモデルと比べて大幅な性能向上を実現している​​という。Geminiは、AndroidユーザーはGoogle Playストアから、iOSユーザーはGoogleアプリを通じてアクセス可能で、実際の提供は発表日の約1週間前から開始されていたとのこと。

AIアシスタントは、Googleの広範なサービスと連携可能で、YouTube、Googleマップ、Googleフライト、Googleホテルなどからのリアルタイム情報を活用できる​。Geminiを利用する際は、初回起動時にGoogleアシスタントからの切り替えが求められる。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 07 May 2024 07:16:14 +0000</pubDate></item><item><title>AIが守る！日立系ATMメーカーがAI画像検知で特殊詐欺抑止の取り組みを開始</title><link>https://ledge.ai/articles/hitachi_ch_atm</link><description>:::small
画像の出典：{target=“_blank”}
:::

日立チャネルソリューションズ株式会社と西尾信用金庫は、2024年4月24日よりATM内蔵カメラを利用したAIの画像検知で特殊詐欺に対応するATMの稼働を{target=“_blank”}した。

現在も多発している振込め詐欺などの特殊詐欺は、電話口で言葉巧みにATMに誘導し、指定した口座に送金を促すケースが多い。こういった特定の取引を効果的に抑止することを目的としATMの稼働を開始した。

!
:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

日立チャネルソリューションズは2018年にATM内蔵カメラを使用したAI画像検知システムを開発しており、この検知システムを改良し今回の振込み特殊詐欺対策に活用している。ATM利用者が携帯電話を使用しながら取引きする様子を内蔵カメラを通してリアルタイムでAIが検知。ATMでの振込み操作中に携帯電話での通話に関する注意や警告画面を表示をし、利用者の操作状況を判断し係員呼び出しや取引の中止判断をAIが行うという。

すでにATMに内蔵されているカメラを使用することでコスト低減も見込めるとし、現在は西尾信用金庫数店舗のATMを対象に実施しているが、稼働状況を確認し順次信用金庫を中心にサービスを展開していく予定。

:::box

:::
:::box

:::
</description><pubDate>Wed, 01 May 2024 09:24:53 +0000</pubDate></item><item><title>ガートナー、生成AI頼みの顧客対応を続ける企業の8割が「2027年までに顧客離れを起こす」と警告</title><link>https://ledge.ai/articles/gartner_excessive_reliance_on_genai_causes_customer_churn</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

ガートナージャパンは2024年4月24日、企業が生成AIに過度に依存することが顧客離れを引き起こす可能性があるとの見解を{target=“_blank”}した。

同社は、デジタル技術の進化に伴い、企業や組織のリーダーは新たなデジタル先行の取り組みに真剣に対応する必要があると指摘している。

バイスプレジデント アナリストの池田武史氏によると、2027年までに生成AIに依存した顧客対応を続ける企業の80%が、その効果を発揮できず、顧客離れを引き起こす見込み。特に、AI、IoT、デジタルツイン、5G、AR/VRなどを活用したデジタル技術の普及は進んでいるが、生成AIの未熟さと信頼性の問題が依然として存在しているという。

生成AIは革新的な進化をもたらす可能性がある一方で、応答の信頼性や倫理性に課題があるため、盲目的な利用は推奨されない。池田氏は、顧客対応に生成AIを導入する企業は、顧客の感情や機嫌を適切に察知し、態度を変える機能がまだ十分ではないため、人間による直接対応とのバランスが重要であると述べている。

同氏はさらに、将来的に「マシン・カスタマー」と呼ばれる、システム同士が交渉し取引を行う新しい形態の顧客も現れるだろうと指摘している。このため、企業は生成AIの利用において、どのように人間が介在するか、または完全にAIに依存するかを明確にし、顧客やパートナーの期待を適切に管理することが求められるという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 03 May 2024 04:57:23 +0000</pubDate></item><item><title>アンソロピック「Claude」の無料iOSアプリ発表　デバイス間をシームレスにつなぐ生成AI体験でChatGPT追う　「Team」プランも追加</title><link>https://ledge.ai/articles/anthropic_claude_ios_and_teamplan</link><description>:::small
画像の出典：{target=“_blank”}
:::

米国のAI開発企業アンソロピックは2024年5月1日、 ユーザーが無料でダウンロードできる対話型AI「Claude」のiOSアプリを{target=“_blank”}した。

アプリのリリースにより、Claudeへのアクセスをより手軽にすることを目的としており、Web チャットとのシームレスな同期が可能なため、どのデバイスで中断した会話も、同じところから再開できるという。同社は、外出先でのアイデアのブレインストーミングや、質問に対する迅速な回答、あるいは現実世界のシーンや画像の分析などのアプリならではの使用例を挙げた。

!
:::small
画像の出典：{target=“_blank”}
:::

アプリには、特に長文の理解や複雑な会話に強みを持つ Claude3 モデルを採用。このモデルは200Kトークンのコンテキストウィンドウを持ち、高度な会話能力でユーザーからの複雑な要求にも対応できるという​。月額20ドルのProプラン、あるいは後述のTeamsプランのユーザーは、アプリからそのまま加入のプランを利用可能。

同じく対話型AIとして業界を先行するChatGPTがiOSアプリを{target=“_blank”}したのは昨年2023年5月だ。



加えて、同社は法人向けに「Team」プランの新設も発表した。チーム固有のニーズと目標に基づくワークフローの形成を目的とし、月額30ドルで異なる性能を持つ3種類のモデルを用途に応じて選択できるようにした。このプランにより、企業は自社のニーズに合わせたAIソリューションを選択し、業務効率を高めることが可能となる。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、セキュリティとデータ プライバシーを念頭に置いて構築されているClaudeは、機密性の高いビジネス情報の保護に役立つと述べた。今後、Teamプランでは、AI生成文書の信頼性を確保するための引用機能や、企業のデータリポジトリとの統合機能を数週間内に追加予定だという。


@




:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Sat, 04 May 2024 11:02:40 +0000</pubDate></item><item><title>ニューヨーク・タイムズに続き米新聞8社が著作権侵害でオープンAIを提訴　</title><link>https://ledge.ai/articles/openai_sued_newspaper_company</link><description>:::small
画像の出典：{target=“_blank”}
:::

4月30日、ニューヨーク市のタブロイド紙「デイリー・ニュース」、地方紙「シカゴ・トリビューン」や「オーランド・センチネル」などアメリカの新聞8社が「Chat GPT」を手掛ける生成AI開発企業のオープンAI、同社に出資するマイクロソフトを著作権侵害で提訴したことを{target=“_blank”}した。

具体的な損害賠償額は公表していないが、両社がAIデータ学習のために8社の数百万本もの記事を無許可で利用し著作権侵害をしたと主張。2023年12月には同様の理由で米ニューヨーク・タイムズ（NYT）も2社を提訴しており、コストをかけ取材した内容を対価を支払わず無断で利用していることを問題視している。

一方で英フィナンシャル・タイムズは4月29日にオープンAIと提携することを{target=“_blank”}しており、引用元を明示することを条件にChat GPTによるデータの学習や要約の作成を容認している。

欧州では主要メディアもオープンAIとの提携を決める動きもあり、仏紙ルモンド、{target=“_blank”}もChat GPTの記事データ学習を認めている。生成AIをめぐって企業間で対応が分かれている現状だ。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 02 May 2024 09:56:50 +0000</pubDate></item><item><title>トヨタ・日産が、中国テック企業とAIで提携　北京モーターショー2024で戦略的パートナーシップを発表
</title><link>https://ledge.ai/articles/toyota_nissan_autochina2024</link><description>:::small
画像：{target=“_blank”}
:::

2024年4月25日、北京モーターショー2024で、トヨタ自動車と日産自動車がそれぞれ中国のテクノロジー企業との新たな提携を発表したことを各メディアが報じている。トヨタはテンセントと、日産は百度（Baidu）との間で、AIを中心とした提携を進めるとした。

トヨタは、テンセントの強みであるビッグデータ処理、AI、クラウドコンピューティングを活用し、2024年内に中国で製造される新型乗用車に技術を組み込む計画であると発表。一方、日産と百度は、AIやいわゆる「スマートカー」技術の研究を共同で進める覚書を締結し、将来の技術開発の可能性を探るとしている。
!
:::small
画像：{target=“_blank”}
:::

この{target=“_blank”}では、新エネルギー車が大きく注目を集め、過去最多の117車種が世界初公開されたという。展示された車両数は約1000台に上り、新エネルギーモデルは前回比70%増の278台が展示され、新エネルギー車のブランドが20以上初出展したとのこと。会期は5月4日まで。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 02 May 2024 05:06:12 +0000</pubDate></item><item><title>OpenAI　ChatGPTの「Memory」機能をすべての有料ユーザーに向けて提供開始</title><link>https://ledge.ai/articles/openai_chatgpt_memory_for_all_plus_users</link><description>:::small
画像の出典：{target=“_blank”}
:::

OpenAIは2024年4月29日、ChatGPTの新機能「Memory」の提供をChatGPT Plusユーザー全員に対して開始したと{target=“_blank”}した。

この機能は、ユーザーの過去のチャットを記憶し、個別の情報を繰り返し入力する手間を省く。2月よりこの機能がテストされていたが、このアップデートにより、有料会員のプラスユーザーなら全員使用できるようになったという。

Memory機能は、ユーザーとの対話を通じて情報を記憶し、次回以降の対話においてその情報を反映させるというもの。対話中にMemoryが更新されると「Memory updated」と表示され、記録された内容を確認できるようになっている。

たとえば「私のペットは、ゴールデンレトリバーのエリーと、メインクーンのテディ―です」と入力し、その情報を記憶させる。その後「私のペットたちがサーフボードに乗っている絵を作って」と依頼すると、ChatGPTが前述のレトリバーとメインクーンがサーフボードを乗りこなす画像を生成する。
!
:::small
画像：{target=“_blank”}
:::

Memory機能は、初期設定で「オン」に設定されており、ユーザーは設定画面からON・OFFの切り替えが可能。また、Memoryの管理（Manage）より、特定の記憶されたデータを選んで削除できる。ChatGPTとの対話で、何を記憶しているか確認し、それを忘れるように指示しデータを削除することも可能。チャット自体を削除しても記憶されたデータは消去されない。

!
:::small
画像の出典：{target=“_blank”}
:::

なお、この機能は企業向けプラン（Enterprise）およびチーム向けプラン（Teams）、そしてGPTsでの利用が予定されている。



:::box

:::
:::box

:::
</description><pubDate>Thu, 02 May 2024 05:02:19 +0000</pubDate></item><item><title>ニッセンが画像生成AIを活用し着用パターンを自動生成する実証実験を実施　生成された着用イメージで洋服を試着体験！</title><link>https://ledge.ai/articles/nissen_apparel_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月22日、株式会社ニッセン、BIPROGY株式会社、株式会社メタクロシスの３社は生成AIを活用した衣服着用パターンを自動生成する実証実験を実施したと{target=“_blank”}した。

ECサイトの進化により実店舗へ足を運ばなくても好きな時間に手軽に買い物を楽しむことができる時代。アパレル業界でもECサイトの活用が進んでいるが、商品を実際に試着したイメージが掴みにくいという視点から、店舗スタッフやモデルの着用画像を掲載していることが多い。しかし、着用画像掲載にはコストもかかるため掲載の幅が限られている現状。このような課題を解決するため実証実験を実施した。

実証実験についてはメタクロシスのアパレルDXアプリ「FIGUR（フィギュア）」の画像試着機能を活用し、ニッセンの保有データをもとに着用パターンや着用イメージを自動生成する。この機能を活用することで、ECサイトで販売している商品を実店舗に足を運ぶことなくECサイト上でイメージに近い洋服を探したり購入することができる。課題であるコスト削減や業務効率化にも期待できるという。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 30 Apr 2024 08:15:35 +0000</pubDate></item><item><title>GWに徹底理解！「Vision Transformer」 LLMの基幹技術 Transformer を画像分類に応用した大注目技術が分かりやすいビジュアルガイドに</title><link>https://ledge.ai/articles/a_visual_guide_to_vision_transformer</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleが開発したトランスフォーマー技術は、自然言語処理から画像分類へとその応用範囲を広げ、新たなAIモデル「Vision Transformer（ViT）」が登場した。このモデルは、画像を小さなパッチに分割し、それぞれのパッチを独立したデータポイントとして処理することで、画像全体の文脈を捉える能力を持っているという。

もともとテキストデータ向けに開発されたトランスフォーマーは、その強力な自己注意機構（Self-Attention Mechanism）により、文中の各単語がどのように相互作用するかを学習する。このメカニズムを画像データに応用したことで、ViTは画像の各部分がどのように関連しているかを効率的に解析し、従来の畳み込みニューラルネットワークモデルと比較して高精度な画像分類を実現しているとのこと。

ソフトウェアエンジニアであるデニス・タープ氏は、この複雑なモデルを「{target=“_blank”}」というビジュアルガイドでわかりやすく解説している。

このガイドでは、ViTの構造とデータの流れをステップバイステップで説明し、専門家でない読者にも理解しやすい内容となっている。特に、画像をパッチに分割し、それぞれのパッチがどのようにネットワーク内で処理されるかを視覚的に示している点が特徴的だ​​。

「Please enjoy and start scrolling!（スクロールしてお楽しみください）」と書かれているとおり、縦スクロールで次々と解説が進む作りになっている。{target=“_blank”}から。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Fri, 03 May 2024 04:38:19 +0000</pubDate></item><item><title>AIエージェントとは｜マニアックなプロンプトエンジニアリングはいらない 注目の生成AI活用トレンド</title><link>https://ledge.ai/articles/about_ai-agent</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

:::box
**目次**
- 導入
- AIエージェントの仕組み
- AIエージェントの実装例
:::

## 導入
### AIエージェントという概念　～AIのエージェントアプローチ＋LLM～
AIエージェントという仕組みは、昨今の生成AI活用ブームの中で注目を集めているが、エージェントという概念自体は、コンピューターサイエンスやロボット工学の分野で研究が進められてきたものである。特に1980年代にロボット研究者であるロドニー・ブルックスらの研究は、自律型ロボットやエージェントシステムに大きな影響を与え、2000年に発売された自動掃除機ルンバといった製品として実用化もされている。その後、機械学習の手法を組み合わせた研究が進み、近年の大規模言語モデル（LLM）の普及によって、より複雑な問題を自律的に解決できる仕組みであるAIエージェントという概念として語られるようになった。

### プロンプトエンジニアリングの限界
2022年11月30日にOpenAIが発表したChatGPTは、その利用の手軽さや生成物のクオリティから、生成AIという技術がビジネスを大きく変えていく未来を想像させた。
チャット型のユーザーインターフェースは、プログラミング言語などの特殊な言語を扱うことなく、人間と対話するときと同じような感覚で送ったテキスト情報に対して意味の通る文章を生成、回答してくれる。
生成される回答は、プロンプトと呼ばれる命令の出し方一つで異なってくる。生成AIから質の高い回答を得るためには、効果的なプロンプトを作ることが重要であり、プロンプトを使いこなす手法や技術を指す分野としてプロンプトエンジニアリングという言葉も誕生した。
ChatGPTの発表以後も、様々な活用方法が生み出され、プロンプトエンジニアリングに関するセミナーや書籍なども数多く目にするようになった。

生成AIは、プロンプトを使いこなせるようになると便利なツールである。ただし実際の業務に最適化させていくほど、プロンプトは長く複雑なものになっていく。実行してもらいたいタスクの詳細情報や実行の条件、参照すべき情報など、業界や業種、業務の用途に合わせてプロンプトに書き込んでいかなければならないからである。
さらに、ベースの学習済みの言語モデル自体も、日々アップデートされている。アップデートによって、以前使用していたプロンプトの出力内容も変わってしまう可能性がある。
生成AIはうまく活用できれば業務の効率化に役立てられるが、それを実感できるレベルにまでたどり着ける人は少ないのかもしれない。
このような背景を踏まえると、プロンプトエンジニアリングで業務効率化を実現していくアプローチには限界があるといえる。

そこで注目を集めているのが、細かな指示がなくとも自律的に目的に向かってタスクをこなしてくれる「AIエージェント」の仕組みである。現在はまだ先進的な企業で技術検証が進んでいる段階ではあるが、今後の生成AI活用における大きなトレンドになると期待されている。本記事で「AIエージェント」の基本的な概念や仕組みについて理解を深め、生成AI活用のヒントとしてもらいたい。

### AIエージェントの概要
AIエージェントとは、一言でいうとある目標を達成するために自律的に行動するソフトウェアプログラムやシステムのことである。 
例えば、オフィスでの会議室の予約をしたい状況で、AIエージェントの活用イメージとして以下のようなシナリオを描くことができる。

!

まず最初にユーザーがAIエージェントに対して、来客用の会議を予約するという目的を与える。AIエージェントは、会議室予約のデータベース参照し空き状況を確認するというタスクを実行する。もし会議室の空きがなかった場合には、会議の重要性を判断し、他の会議室予約者との交渉を行い、会議室の確保を自律的に遂行してくれる。

AIエージェントは、現在もなお研究・開発が進行している分野である。研究や社会実装の分野での様々なプロジェクトの中で、AIエージェントの技術的な可能性が示され、現在に至っている。以下にAIエージェントの発展の中で注目を集めたマイルストーンプロジェクトを紹介する。

**社会シミュレーション「Generative Agent」：**
複数のAIエージェントによる社会シミュレーションを行ったスタンフォード大学とGoogleとの共同研究のプロジェクト。
25人のエージェントと仮想的なゲーム環境による人工的な村社会を構築し、AIエージェント同士が創発的に協同しあうかを実験した内容が論文として発表された。

**ソフトウェア開発会社「ChatDev」：**
AIエージェントが経営するソフトウェア開発会社を仮想的に再現し、エージェント同士の協働によって、実際のソフトウェアを開発するツール。
現実世界のソフトウェア会社のように、プログラマー・テストエンジニア・アートデザイナーなどのAIエージェントにそれぞれ役割を与え、エージェント同士でコミュニケーションを取りながらソフトウェア開発のステップ（設計、コーディング、テスト等）を進めていくことができる。

**完全自律型AIエンジニア「Devin」：**
米国のAIスタートアップCognition社が発表したソフトウェア開発のAIエージェント。与えられた要件からソフトウェア開発の一連のプロセスを自動で実行し、エラー発生時にも自律的に問題解決するなど、高度なエンジニアリングスキルを持っている。Devinの発表は、そう遠くない未来にソフトウェア開発のあり方が大きく変わる可能性を示した。

:::box
関連記事：
:::

## AIエージェントの仕組み
AIエージェントは、概念的には個性／記憶／計画／行動の4つの機能で構成されており、互いに作用し合うことで、複雑な問題の解決を実現する。AIエージェントはまだ研究途上の段階にある仕組みではあるが、これらの要素のポイントを押さえて設計していくことがAIエージェント構築の肝になる。

!

### 個性（Profile）
個性（Profile）は、年齢、性別、職業等といった基本情報や性格・社内的な立場といった情報で、AIエージェントの振る舞いに影響を与える。
現実世界では、営業や人事、開発、法務など様々な職域があり、複数の職種の人たちによる相互の営みを通じて事業は構成されている。それぞれに与えられた役割があり、向いている性格や思考や行動の特性があり、適切な人材を配置し、組織を設計することで生産性を向上させることができる。AIエージェントも同様に、異なる性格や価値観、役割を定義することで、AIエージェントの思考・行動の決定プロセスに影響を与えることができる。

### 記憶（Memory）
タスクを適切に実行していくためには、「記憶」の仕組みを考える必要がある。その理由の一つには、LLMが一度に扱えるデータ量には制限がある。もう一つは、会話の文脈や過去の経緯を踏まえて適切に判断を下すためには、短期的な記憶と長期的な記憶を区別して情報を処理する必要がある。
さらにAIエージェント自身の体験の記憶だけでなく、外部に蓄積されているデータベースを参照し、大量の業務データを記憶として扱える点は、人間の記憶とは大きく異なる。
扱えるデータ形式としては、リレーショナルデータベースとベクトルデータベースの大きく2種類存在する。

**リレーショナルデータベース：**
業務システムで一般的に利用されるデータベースであり、データをテーブル形式の構造化された状態で保存する。データの検索・抽出といった操作には、SQLというデータベースクエリ言語を使う。大規模言語モデルを用いて、SQLクエリの生成を行うことができ、記憶の呼び出しができる。

**ベクトルデータベース：**
文書や画像など、構造化された形式のデータに変換ができない形式のデータを扱うデータベース。データをベクトル空間という空間内の特定の座標にマッピングすることで、データ同士の意味的な関係性を、2点間の座標の方向や大きさという数値情報によって扱うことができる。

海外では、Airtableというクラウドデータベースサービスに様々なデータを格納し、それらをAPI経由で、AIエージェントがアクセスできるようにしておき、ファイルやデータの参照から書き込みまで各種タスクの実行を行えるようにする活用事例なども出てきているという。

### 計画（Planning）
計画は、AIエージェントが目的を達成する上で非常に重要なプロセスである。このプロセスでは、必要なタスクを思考し、それらを分解をすることで、目的達成のための最適な手順とアクションを明確にする。
AIエージェントにおける計画で押さえておくべきアプローチとして、”タスク分解”がある。
タスク分解は、文字通り目的の達成のために必要なタスクを分解することである。AIエージェントでは、ユーザーから提示された目的に対して、そのタスク分解のためのプロンプトを生成し、タスク分解を行うように設計していくことが重要になる。
オープンソースのAIエージェント「BabyFoxAGI」では、タスク分解のプロンプトを生成する仕組みがプログラムされており、汎用的なタスク実行に対応できるようになっている。

さらにReActというプロンプティングの手法を取り入れることで、分解したタスクに対してLLMに正しい推論と意思決定を行わせ、計画の解像度を高めていくことができる。
ReActは、理由（Reason）と行動（Action）を中心に思考しながらタスクを進めていくアプローチであり、その英単語の頭文字を取って名付けられている。
与えられたタスクを達成するために、行動を思考し、行動の結果を観察、そこから得た学びを思考に反映し、行動を最適化していく、というのがReActの基本的な流れである。
例えば、先程あげた会議室予約を例に、AIエージェントでのタスク分解のイメージを下記に示す。

:::box
**会議室の予約で想定されるタスク分解例**
- ユーザーのその日のスケジュールを確認し、会議可能な時間を把握
- 同席者の有無を確認し、同席がいる場合に同席者のスケジュールを踏まえた会議時間を設定
- 会議室予約のデータベースを参照し、設定時間での会議室の空き状況を確認
- 会議室の空きがなかった場合は、ユーザーに会議室確保の重要度に関するフィードバックをもらう
- 重要度が高い会議の場合、先に会議室を予約している担当者を確認
- 会議室を空けてもらうための依頼文章を生成し、メッセージを送信
- 担当者から承諾をもらえた場合、カレンダー予約システムに対して、会議室予約の変更手続きを実行
- ユーザーに完了報告
:::

### 行動（Action）
AIエージェントに具体的なタスクの実行を定義するのが、「行動」である。
LLM単体では、学習データにない最新情報に基づいたアウトプットができなかったり、言語モデルの特性上、数値計算なども得意ではない。AIエージェントは概念的には、外部機能にアクセスできる権限や実行プログラムを定義することができるものについては何でも実行できる。
一般的に取り上げられる行動の例としては、ブラウザ検索を行い最新の情報を収集や、外部システムと連携しデータベースからデータの抽出や保存、pythonプログラムによる数値解析処理など、実装次第で様々な行動を起こさせることができる。定義した各種行動の中からどれを実行するかは、AIエージェント自身が思考プロセスの中で判断する。

**AIエージェントのユースケース**
AIエージェントが各種システムやデータにアクセスし、様々な操作・処理が行えることが前提にはなるが、AIエージェントが実現しうる世界観として考えられるユースケースを以下に示す。

:::box
**旅行予約**
- 旅行に行きたいエリアを提示すると、AIエージェントがそのエリアまでの交通手段の調査や、チケットの空き状況を確認
- 現地のホテル情報やグルメ・観光情報を収集し、ユーザーの過去の傾向から好みを踏まえて旅行プランを作成
- 予算や観たいところなど、ユーザーからのフィードバックを受けて、再度旅行プランの再作成
- チケット・予約手配を代行
- 旅行中の各種案内や予定変更などのサポート
:::

:::box
**営業管理**
- お問い合わせを受け付けた際に、インターネット上の公開情報を検索し、問い合わせ企業の情報を調査
- 過去の問い合わせ履歴から同じ業界や会社規模での類似の問い合わせがなかったを自社データベースから調査
- 問い合わせに関連する社外ニュースなどの参考情報も収集
- 調査結果を次回以降も再利用できるようにデータベースに保存
:::

## AIエージェントの実装例
実験的なものも含めてプロダクトとしてインターネット上に公開されているものや、独自のAIエージェント開発を支援する開発フレームワークなどが出てきている。まずは既存のAIエージェントツールに触れ、AIエージェントの動きを体感してみるのもいいだろう。その上で実際の業務シーンでの活用に向けては、開発フレームワークを用いて設計・カスタマイズしていく必要がある。
ここでは代表的なものをいくつか紹介する。

### AIエージェントアプリケーション
**AutoGPT：**
AutoGPTは、2023年3月に登場した実験的なプログラムで、AIエージェントブームの火付け役と言われている。目的を与えると、AIが自律的に達成に必要な道筋を考え、情報を収集し、それらをまとめた内容をファイルに出力するといったことができる。この仕組みがAIコミュニティの中で注目され、AutoGPTの活用事例（AutoGPTがウェブサイトを構築するデモetc）が活発に公開されるようになったことで、AIエージェントブームが巻き起こった。

**BadyAGI：**
AIエージェントブームの中で注目を集めたもう一つ代表的なAIエージェントが「BabyAGI」である。AutoGPTとほぼ同時期の2023年の4月に、ヨウヘイ・ナカジマ氏によって開発されたAIエージェントである。タスクを自動で実行していくという点はAutoGPTとにていますが、AutoGPTが個別のタスク毎にユーザーによるフィードバックと承認が必要な事に対し、BabyAGIは最終目標に向かって自動的にタスクの実行と調整を繰り返していくことが特徴である。

:::box
**BabyAGIの実行フロー**
1. 「タスク作成エージェント」がゴール達成に必要なタスクリストを生成
2. 「タスク優先度付けエージェント」が実行の優先順位付け
3. 最初のタスクを「タスク実行エージェント」に渡し、タスクを実行
4. 実行結果を「タスク作成エージェント」に渡し、新たなタスクを生成
5. 全てのタスクが終了するため2〜4をループ
:::

!

**Scalable Instructable Multiworld Agent（SIMA）：**
SIMAは、Google DeepMindは2023年3月13日発表した新たなAIエージェント。様々なビデオゲームで自然言語の指示に従ってタスクを実行する能力を持つ。トレーニングには、「No Man's Sky」「Teardown」「Valheim」「Goat Simulator 3」「Satisfactory」「Hydroneer」「Space Engineer」「Wobbly Life」「Eco」といったバラエティに富むゲームを使用した。「左折」「はしごを登る」「地図を開く」 などの約600の基本スキルを持ち、さまざまな状況に適応する訓練が施されており、研究チームの報告によると、初めてプレイするゲームでも、そのゲームに特化してトレーニングを受けたエージェントと平均してほぼ同じパフォーマンスを示したとのこと。今後、日常生活のタスク、より複雑な指示への対応、効率的な学習方法の開発に向けて進められる。

:::box
関連記事：
:::

### 開発フレームワーク
**Langchain：**
LangChainは大規模言語モデルを活用してアプリケーションを構築するためのフレームワークであり、開発者がAIを利用した言語理解の能力を簡単に組み込むことができるように設計されている。LangChainが提供する多様な統合機能を活用して、複雑なタスクや問題解決に取り組むAIエージェントを構築することができる。

**AutoGen：**
Microsoft Researchから発表されたAIアプリケーション開発フレームワーク。「複数のAIエージェント」が相互に会話しながらタスクを解決するのが特徴。AutoGenを使うことで、複数のAIエージェントを組み合わせることができたり、役割に応じてタスクをAIエージェントに割り振ることができるようになる。

2024年は、各企業での生成AI活用に向けた取り組みがより一層加速していくとみられる。

:::box
関連記事：
:::

そうした動きの中で「AIエージェント」は確実に今後の重要トレンドとなってくると言える。
LLMを始めとするAI技術の発展・普及とともに、AIと人との関わり方は変わっていくだろう。目的達成のための手段やその計画は、AIエージェントが行ってくれる。AIエージェントの仕組みが実用化された世界で私達人間が求められる役割は、正しい目的を与え、成果物に対して適切なフィードバックを返すことである。

ーーー

レッジでは生成AIの導入支援サービスを提供しています。
その中ではAIエージェントを企業の生成AI活用の重要テーマとして包括的な支援が可能です。
ご興味ある方は、下記ページよりお問い合わせください。

:::box
関連ページ：
:::</description><pubDate>Tue, 30 Apr 2024 06:14:30 +0000</pubDate></item><item><title>Google の無料教材公開「Beyond the Prompt」「Prompting guide 101」生成AIの効果的な活用法やヒントを紹介</title><link>https://ledge.ai/articles/google_prompt_guide</link><description>:::small
画像の出典：{target=“_blank”}
:::

Googleは2024年4月19日、Google Workspaceユーザーを対象にした新しいブログシリーズ「{target=“_blank”}」を開始した。

このシリーズは、生成AIを効果的に活用するためのヒントやコツ、提案を定期的に提供することを目的としている。Google Workspaceは元々、リアルタイムおよび非同期でのコラボレーションを核として構築されており、この新技術を取り入れることで、ユーザーの生産性、創造性、および作業の質をさらに高めることが期待されているという。

このブログシリーズでは、特に効果的なプロンプトの作成方法にスポットライトが当てられている。プロンプトは、AI搭載アシスタントとの対話を始めるためのトリガーとして機能し、ペルソナ（Persona）、タスク（Task）、コンテキスト（Context）、フォーマット（Format）の4つの主要な要素を含めることが推奨されている。これらの要素を組み合わせることで、より具体的かつ効果的な応答を引き出すことが可能だ。

具体例としては、Google Slidesで旅行ブログの記事に添える画像を生成するプロセスが紹介されている。ユーザーは「Create image with Gemini」というプロンプトを用いて、希望するシーンの画像を生成し、選んだ画像を直接スライドに挿入することができる。

!
:::small
画像の出典：{target=“_blank”}
:::

「Beyond the Prompt」は、Google Workspaceを使用している全ユーザーがGeminiの機能を最大限に活用し、より効果的に作業を進めるための支援を提供していくという。

またGoogleは「{target=“_blank”}」という電子ブックも公開しており、プロンプトの基本から応用まで、多岐にわたる情報を45ページにわたって提供している。このガイドは、GeminiをはじめとするAIチャットボットの活用を促進し、具体的な業務に応用するための例文も含まれているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Apr 2024 06:10:44 +0000</pubDate></item><item><title>GWに徹底理解！GPTの仕組みをめちゃくちゃ分かりやすく解説する無料動画公開</title><link>https://ledge.ai/articles/3blue1brown_transformer_attention</link><description>:::small
画像の出典：{target=“_blank”}
:::

連休を自己研鑽に充てようと考える方へ朗報だ。

数学と科学をビジュアルで解説する教育サイト「3Blue1Brown」が2024年4月、GPTの仕組みを分かりやすく解説する動画を公開している。ディープラーニング・第5章「But what is a GPT? - Visual intro to Transformers」というタイトルだ。この動画は、GPT（Generative Pretrained Transformer）の基本的な構造とその動作原理を詳しく説明している。


## ディープラーニング　第5章「しかし、GPTとは何なのか」

@


GPTは、大量のデータから事前学習を行い、特定のタスクに対してさらに微調整を加えることで、テキスト生成などの機能を実現するAIモデルだ。トランスフォーマーとは、このようなAIブームの中核となる特定のニューラルネットワークの一種であり、2017年にGoogleによって導入されたもので、もともとはテキストの翻訳が主な用途であった。

!
:::small
画像の出典：{target=“_blank”}
:::

今回の動画では、GPTのモデルがどのようにテキストを生成するか、その過程を一から丁寧に解説している。特に、入力されたテキストから次に来る言葉を予測する機能は、単純ながらもテキストを生成する上で重要な役割を果たしている。GPT-2とGPT-3の違いについても触れられており、より大きなモデルであるGPT-3では、より一貫性と感覚的なストーリー生成が可能であることが示されている。

!
:::small
画像の出典：{target=“_blank”}
:::

3Blue1Brownの動画は、数学を直感的かつ視覚的に理解できるようにデザインされており、複雑な数学的概念や定理をアニメーションを用いて説明する。運営資金調達には、クラウドファンディングのプラットフォーム「Patreon」を採用しており、広告に頼らず視聴者の直接的な支援によって高品質のコンテンツを提供している。


## ディープラーニング　第６章「アテンション、トランスフォーマーの心臓を視覚化」
@



4月26日に公開されたAIの核心技術の一つである 第6章「Attentionメカニズム」についての解説動画もおススメしたい。このメカニズムは、Transformer構造の中心部品として、AIによる言語理解の精度を飛躍的に向上させるものだ。

「Transformer」という言葉はAIの技術者の間ではよく知られているが、その詳細な機能まで理解している人は少ないという。Transformerは、特にLLMが文章を「読む」際の基盤技術として活用されており、文章中の「トークン」と呼ばれる単位ごとに情報処理を行う。

!
:::small
画像の出典：{target=“_blank”}
:::

動画では、「トークン」として処理される各単語がどのようにAttentionメカニズムによって重要視されるかをビジュアル化しており、教育的な視点からも高い評価を受けているとのことだ。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:55:32 +0000</pubDate></item><item><title>NVIDIA、生成AI分野の技術者向けにプロフェッショナル認定制度を新設</title><link>https://ledge.ai/articles/nvidia_genai_professional_certification</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAは2024年3月14日、生成AIに関するプロフェッショナル認定制度を新たに提供開始することを{target=“_blank”}した。

この認定制度は、生成AI技術の開発者がその技術的な信頼性を確立できるように設計されている。NVIDIAによれば、この新しい認定制度は、同社が初めて提供するプロフェッショナル向けのものであり、大規模言語モデル（LLM）とマルチモーダルワークフロースキルの習熟度を測ることを目的としている。

この制度には、2種類のアソシエイトレベルの認定が用意されており、GTC 2024イベント以降に利用可能になる予定だ。GTC 2024は、3月18日から21日まで開催されるNVIDIAのイベントで、現地参加者は認定試験に備えるための推奨トレーニングにアクセスできるとのこと。

NVIDIAのデベロッパープログラム担当バイスプレジデント、グレッグ・エステス氏は、「NVIDIAの目標は、皆さまのスキルアップを支援し、資格を持つプロフェッショナルの能力を磨き、個人がその熟練度を証明できるようにすることにより、雇用市場で競争優位を得られるようにすること」とコメントしている。

この認定制度の開始は、生成AI技術の発展と普及に伴い、この分野で活動する技術者が自身の技術力を証明し、業界での地位を確立するための重要な機会を提供するものだという。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 17 Mar 2024 05:03:19 +0000</pubDate></item><item><title>Anthropic、チャットAI「Claude 3」向け公式プロンプト集を公開</title><link>https://ledge.ai/articles/anthropic_claude3_prompt_library</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月11日、AIスタートアップのAnthropicは、同社が開発したチャットAI「Claude 3」向けの公式プロンプト集を{target=“_blank”}した。

現在64種類の使用例が集められているこのプロンプト集は、「プロンプトライブラリ」でアクセス可能だ。公開されたプロンプト集は、英語と日本語の両方に対応しており、ユーザーはこれを利用してClaude 3の応用範囲を広げることができる。

プロンプトライブラリには、クリエイティブな執筆、データ分析、キャラクターロールプレイといった様々な用途に合わせたプロンプトが含まれている。Anthropicは、このライブラリを通じて、Claude 3を最大限に活用するためのガイドラインを提供し、ユーザーが特定のタスクを効果的に達成できるよう支援している。

また、Anthropicは「{target=“_blank”}」も公開しており、プロンプトの作成とテストのプロセスを通じて、Claude 3のパフォーマンスをさらに向上させる方法について説明している。これにより、ユーザーはより具体的なユースケースに対してClaude 3の応答を微調整することが可能となる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:21:11 +0000</pubDate></item><item><title>パーソルホールディングス、生成AI研修で社員スキルアップを加速</title><link>https://ledge.ai/articles/persol_group_upreskilling</link><description>:::small
画像の出典：{target=“_blank”}
:::

パーソルホールディングスは2024年02月16日、グループ社員の生成AIに関する知識と活用スキルの向上を目指し、専門家による研修や社内勉強会の開催などの積極的な取り組みについて{target=“_blank”}した。

この取り組みは、社員個人のスキルレベルを「理解」「業務導入」「業務活用と伝播」の3段階に区分し、全社員が生成AIを業務に活用する環境を整備することにあるという。

外部の専門家を招いた研修や勉強会をはじめ、1,500名以上の社員が受講した入門編から実践編、さらには経営幹部向けの勉強会まで、参加者のレベルや属性に応じた内容で開催されている。また、社内専用GPT「PERSOL Chat Assistant」の基礎知識についての動画講義には3,800名の社員が参加し、IT系職種に限らず多岐にわたる職種の社員が生成AIの教育を受けているとのこと。

さらに、生成AIパスポートの資格取得に向けた取り組みも進められており、2024年第1回試験にはグループ各社から200名以上の社員が受験予定。受験費用は会社が支給しているという。この資格は、生成AIを活用したコンテンツ生成の方法や企業のコンプライアンスに関する知識を学ぶもの。

これらの教育プログラムを通じて、社員はメール文章作成や議事録の要約、英文作成、アイデア出し、営業アポイントのテーマ検討、トークスクリプト作成、ソースコードの分析・修正など、多岐にわたる業務で生成AIを活用するスキルを習得し、業務効率化とパフォーマンスの向上、リスク回避につなげているという。


:::box

:::
:::box

:::
</description><pubDate>Thu, 29 Feb 2024 03:36:19 +0000</pubDate></item><item><title>JDLAが「生成AIの利用ガイドライン（画像編）」を公開</title><link>https://ledge.ai/articles/jdla_guideline_for_image_generating_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本ディープラーニング協会（JDLA）は2024年2月13日、「生成AIの利用ガイドライン（画像編）」を{target=“_blank”}した。

このガイドラインは、2023年5月に公開された「{target=“_blank”}」の続編として作成されており、主に画像生成AIに特化した内容となる。

ガイドラインの目的は、画像生成AIを事業において利用する企業等に向け、ルール策定時に検討が必要な法的論点を解説することにある。具体的には、画像生成AIの利用に際して、社内体制の整備、プロンプトの入力ルール、AI生成物の利用規則など、遵守すべきポイントが詳述されている。

JDLAは、ディープラーニング技術を日本の産業競争力向上の核とし、その普及と適用を目指して活動している組織だ。今回のガイドライン公開も、その一環として行われたもので、画像生成AIの健全な利用と発展の促進を期待してのことだとされる。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 28 Feb 2024 05:54:19 +0000</pubDate></item><item><title>日本最大級のDX推進コンテスト『日本DX大賞2024』応募開始</title><link>https://ledge.ai/articles/dx_taisho_2024</link><description>:::small
画像の出典：{target=“_blank”}
:::

一般社団法人日本デジタルトランスフォーメーション推進協会は2024年2月6日、民間企業や自治体のDX取り組みを表彰する「日本DX大賞 2024」の応募受付を開始したと{target=“_blank”}した。

コンテストは、DXの成功事例を発掘し共有することで、日本全体のDX推進を加速させることを目的としている。昨年行われた「日本DX大賞2023」への応募数は111件。今年はサステナビリティトランスフォーメーションやビジネスモデルの変革、顧客体験の向上など、多様なカテゴリーでのDX取り組みが対象となる​。

**募集期間**： 2024年2月6日から4月26日まで
**応募対象**：「DX推進」に取り組んでいる民間企業、公的機関、自治体等の変革を実現した事例や成果をあげた事例。または、ユーザー企業・団体が取り組んだ事例


日本DX大賞サイト：{target=“_blank”}



:::box

:::
:::box

:::
</description><pubDate>Tue, 06 Feb 2024 10:45:28 +0000</pubDate></item><item><title> LoRA(ローラ)とは｜今年注目の画像生成AI (Stable Diffusion) のファインチューニングを試してみた
</title><link>https://ledge.ai/articles/LoRA</link><description>LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。従来はLLM（大規模言語モデル）や画像生成AIのファインチューニングに膨大な計算量が必要だったが、LoRAによって少ないリソースで行うことができるようになった。LoRAはLLMや画像生成AIに応用できる、計算量を減らしてファインチューニングを行う技術である。

2023年末にはChatGPTの新機能である、ユーザーがChatGPTを自由にカスタマイズ（ファインチューニングも）できる「GPTs」がリリースされた。誰もが簡単に学習済みモデルをファインチューニングできるようになりつつある。自社や個人が持つアセットを最大限に活用した生成AIの効果的な使用が、一層重要なフェーズに突入している。

今回は、ファインチューニングの理解に必須の技術「LoRA」について解説する。

:::small
※「LoRA」という用語は元々、計算効率を向上させる技術を指す。しかし、この技術を基にして「Stable Diffusion」というAIモデルをファインチューニングした際に生まれる特定のモデルも、同様に「LoRA」と称されている。「LoRA」が二重の意味を持つことに注意が必要。
:::

:::box
関連記事 : 
:::

:::box
**目次**
- LoRAとは
- LoRAのビジネスへの活用
- LoRAを使って「Stable Diffusion」をファインチューニングしてみた
:::

## LoRAとは

LoRAとは”Low-Rank Adaptation”の略で、特に大規模な事前学習済みモデルのファインチューニングに関連する技術である。2021年にMicrosoftに所属していたEdward Huらによって論文で発表された技術だ。

LoRAは、元のモデルのパラメータを直接変更する代わりに、低ランクの行列を導入して、パラメータの変更を行うことができる。少ない計算量で元のモデルに修正を加えることが可能になった。

LoRAは、事前学習されたモデルの重みを固定し、変換器アーキテクチャの各層に低ランクの分解行列を注入することで、下流のタスク用の訓練可能なパラメータの数を大幅に削減する。例えば、GPT-3 175Bモデルにおいて、LoRAは訓練可能なパラメータを10,000倍減らし、GPUメモリ要件を3倍削減することを実現している。
論文中では以下の図でモデルの概要が説明されている。
!


LoRA（Low-Rank Adaptation）の計算例を示す。通常、変換器モデルでは、重み行列W ( m×n)があり、入力x に対してWx の形で適用される。LoRAでは、この重み行列W を直接変更するのではなく、低ランクの行列A (m×k)とB (k×n)を用いて、W ( m×n)+AB ( m×n) の形で変換を行う。ここで、A とB は小さな行列であり、元の重み行列W に比べてはるかに少ないパラメータを持つ。この方法により、全体のパラメータ数が減少し、計算の効率が向上する。
A=正規分布、B=0で初期化されている。

具体的な計算を以下に示す。重み行列Wのパラメータ数は合計24、行列AとBは合計8となり調整するパラメータ数が3倍削減されている。
!
実際の計算規模は上記の計算例よりはるかに大きく、学習済みモデルのパラメータ数はGPT-3で175億、Stable Diffusionで10億程度と言われている。LoRAによってこれらのモデルのファインチューニングが少ないリソースで行なえることを理解できた。

##  LoRA・ファインチューニングのビジネスへの活用

次にビジネスへの活用例を示す。

**カスタマイズされたチャットボット:**
企業はLoRAを使用して、自社のリソースを学習させ大規模なLLMから自社専用のチャットボットを作成することができる。社内独自のQ＆Aを行えるチャットボットが使用されている。

**AI写真集:**
LoRAを使用して、基盤モデルとなるStable Diffusionをファインチューニングすることで、「アジア人女性」などの特定の画像を生成できる。
Amazon.co.jpの電子書籍読み放題サービス「Kindle Unlimited」をAI生成画像の「写真集」が席巻している。SNSで話題になり、ニュースサイトも相次いで報じるなど、社会現象といってよい状態だ。生成AIの技術が進化し、実際に存在しないがリアルに見えるモデルの画像が生み出され、グラビア界に新たな波をもたらしている。
!

:::box
関連記事：
:::


**AIモデル:**
自社ブランドのファッションアイテムを学習させ、AIモデルに着用させることができる。
AI model株式会社は、2022年6月14日にサービス「AI model モデル撮影サービス
」を提供開始した。撮影場所・費用の確保、起用タレント・モデルの不祥事など「人ならでは」のリスクを回避しつつ、ECの顧客に合わせたブランド専属モデルを生み出せる。
!

:::box
関連記事： 
:::


## LoRAを使って「Stable Diffusion」をファインチューニングしてみた

Stable Diffusion LoRAは、人物の顔、服装、ポーズなど画像の一部を学習し、その特徴をもった新たな画像を生成することができる。

今回はStable Diffusion LoRAを使い、人物の顔を学習させ、その人そっくりのAIモデルを生成する。肖像権の関係で弊社執行役員・箕部 和也の宣材写真を使いStable Diffusionをファインチューニングして、箕部そっくりの人物画像を作ることを試みた。

**Stable Diffusion LoRAの特徴**

- 20枚程度の画像からLoRAの追加学習ファイルを作成できる。
- 服装、ポーズ、顔、イラストの画風を学習させることができる。
- 100〜200MB程度のファイル。
- 学習時間が短い (今回の方法で1時間程度)。
- Stable Diffusionのチェックポイントをベースに作成可能。

今回はGPUを所有してない場合もオンラインで実行できる方法を紹介する。
のを使用する。Loraを使った学習が、簡単に行えるように必要なコードがまとめられている。

基本的なStable Diffusionの使い方はこちらで確認できる。

:::box
関連記事:
:::


### STEP0 実行環境と学習用画像を準備する

**実行環境**
をクリックすると以下のようなノートブックが開く。Google ColaboratoryはPythonの実行環境であり、GPUを無料で使うことができる。ただし画像生成AIを行う場合はColab Pro (1 か月あたり ￥1,179) が推奨されている。今回はColab ProでLoraファイルの作成を行う。ノートブックをマイドライブにコピーしておく。
!

**学習用画像**
今回は画像を15枚用意した。画像サイズは512×512や1024×1024の正方形が望ましい。
画像サイズは512×512にトリミングした。顔を学習させたい場合は、髪型や服装が違う画像があれば顔のみを学習しやすい。数パターンの髪型、表情、ポーズ、服装の画像を用意できることが理想的だ。
!

### STEP1  LoRAファイルを作成する。
変更できるパラメータは多量にあるが、最低限の実行に必須な部分のみを解説していく。

**I. Install Kohya Trainer**
!
:::box
1.1. Install Dependencies
 mount_drive:◻︎にチェックを入れて実行。colabからgoole driveにアクセス可能になる。
:::


**II. Pretrained Model Selection**
!
:::box
2.1. Download Available Model
 学習の基盤となるStable Diffusionのモデルを選択できる。
Stable-Diffusion-v1-5を選択して実行する。
:::

**III. Data Acquisition**
!
:::box
3.1. Locating Train Data Directory
 デフォルトで実行する。学習用画像の保存場所が作成される。
:::

!

 :::box
3.2. Unzip Dataset
Gooole Driveに学習させたい画像のzipファイルをアップロードする。
保存したディレクトリのパスをコピーして、zipfile_urlに貼り付けて実行する。
実行後 /content/LoRA/train_dataに自動的に保存される。
:::

**IV. Data Preprocessing**
!
:::box
4.1. Data Cleaning
convertにチェックを入れて実行する。
学習のための形式に対応していない画像は自動で削除される。
:::

:::box
4.2. Data Annotation
画像を認識し自動でキャプションを作成するためのブロック

4.2.1. BLIP Captioning
自動でキャプションをつける際のパラメータを変更できる。デフォルトで実行。

4.2.2. Waifu Diffusion 1.4 Tagger V2
下部のgeneral_thresholdを0.85程度に設定する。大きくするとタグの数が少なくなる。
特定の人物を学習させたい場合は数値を大きくすることが一般的。
traindataのファイルにキャプションが入ったテキストファイルが追加される。
以下の画像には”a man in a black suit and black shirt”と自動的にキャプションが追加された。
!
:::





**V. Training Model**
!
:::box
5.1. Model Config
上記の画像通りに入力して実行する。
:::


:::box
5.2. Dataset Config
dataset_repeats を１に変更する。同じ画像を学習させる回数を調整できる。
flip_augにチェックを入れると左右反転させた画像を学習させられる。
その他はそのままで実行。
:::

:::box
5.3.~ 5.5までをデフォルトのまま実行する。画像の枚数にもよるが1時間〜2時間程度で学習が完了する。完成したLoRAファイルはマイドライブのLora/outputに自動で保存される。
拡張子.safetensorsがLoRAのファイルだ。一番上に保存されている番号が振られていないファイルが最終的な出力になっている。
!
:::


### STEP2  作成したLoRAを使って画像を生成する。
STEP1で作成したLoRAファイルを使って早速、画像を生成する。
15枚の画像で学習を行った結果、右の画像が生成できた。髪型やヒゲ、黒いスーツが強く学習されていることが確認できる。写実的で、AIで作成された画像とは気が付かない可能性があるクオリティだが、似ているが本人ではないことが一目で分かる程度だ。また顔や髪型の特徴と同時に黒のスーツも学習してしまっている。これは学習用画像がすべて同じ服装であるためである。
!
**各種パラメータ**
*** 
モデル  
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt;,professional, masterpiece, 8k, hyperrealistic portrait,  Japanese man, 30yo, dark eyes, detailed face, detailed skin, photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


&lt; lora:minobe_model:0.9 &gt;はLoraファイルの適用の強さを示すもので数値を変更して調整できる。Loraファイルを複数使用したときを考慮して0.8程度で狙った特徴が出るようにすることが一般的。


### STEP3 パラメータを変更して画像をさらに生成する。
次により本人に似た、理想に近い画像を生成するために学習のパラメータやプロンプトを変更していく。特に学習の精度に影響を与えるとされるmin_snr_gammaの値を-1から1に変えて新たなバージョンのLoraファイルを作成した。min_snr_gammaは学習の低step化に貢献するオプションであり、学習過程を大きく変化させるパラメータである。推奨値は5とされている。
!
*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, Standing in the Desert,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 


!

*** 
モデル Real Dream
*** 
プロンプト
&lt; lora:minobe_model:0.9 &gt; ,professional, masterpiece, 8k, hyperrealistic portrait,  asian cool man, 33yo, detailed face, detailed skin, ride a horse,  photography, hq, photorealistic
*** 
ネガティブプロンプト
nude,nsfw,underwear,make-up, low quality, drawing, painting, cartoon, 3d render, sketch, noisy, blurry, deformed, ugly, blurry, overexposed
*** 
Sampling method  DPM++ 2M Karras
*** 
CFG Scale  7
*** 

今回はStable Diffusion LoRAを使用して、Stable Diffusionをファインチィーニングし画像を生成した。画像を15枚を準備して数時間でコードを一切書くことなく簡単に、驚くほど精巧な画像を生成できた。Stable Diffusion LoRAには多くのパラメータがあり、それらの適正値を見つけることでさらに精度が向上すると予想される。パラメータの適正値は「アニメ風の画像を生成したい」や「同じポーズの画像を生成したい」「綺麗なアジア人女性を生成したい」など目的によって変化するため、各々が生成された結果を見ながら、理想の生成画像に向かって微調整を加えていく必要がある。

</description><pubDate>Tue, 06 Feb 2024 07:47:09 +0000</pubDate></item><item><title>Webアプリケーションの巡回ツールを開発せよ｜MBSD Cybersecurity Challenges 2023</title><link>https://ledge.ai/articles/mbsd-security-contest2023</link><description>三井物産セキュアディレクション株式会社が主催する、専門学校・高等専門学校を対象としたセキュリティコンテスト『{target=“_blank”}』の最終審査会が、2023年12月15日（金）に東京都大手町で行われた。

## セキュリティ業務の一端を疑似体験
本コンテストは、これからの時代を担う学生に向けて、より実践的で現実味のある課題を用意し、セキュリティ業務の一端を疑似体験しながら、課題を解決するためのアイデアや技術を競うものだ。入賞者には副賞が設定されており、最優秀賞には外付けSSD(4TB)とMeta Quest 3、2位には外付けSSD(2TB)と高級キーボード、3位には外付けSSD(1TB)とRaspberry Pi4 スターターキットを、受賞者ー１人ひとりに贈るという、かなり豪華な内容となっている。

第8回目を迎えた今回は、全国より18校 55チームのエントリーがあり、最終審査会へは上位10チームが参加した。
!
:::small
最終審査会参加チーム：{target=“_blank”}より
:::

本コンテストの課題は『Webサイトに実際にアクセスし、診断対象となる箇所を抽出、診断対象の規模を把握するための自動巡回ツールを開発し、提出すること』。学生は、Webサイト運営会社のWebアプリ診断を行うチームメンバーとして、ツールの開発から説明資料の作成、最終選考ではプレゼンテーションを行った。

本コンテストの開催フローは以下の通り。エントリーは2023年7月より開始したため、12月の最終審査まで5ヵ月の期間をかけてコンテストは実施された。

- エントリー受付
- 課題配布
- 説明資料・巡回ツール提出
- 一次審査結果発表
- 性能審査
- 最終審査会（オフライン開催）


## 最優秀賞は新潟コンピュータ専門学校『復活の電子遊戯部』
!
:::small
最優秀賞に輝いた『復活の電子遊戯部』チーム
:::
最終審査に残ったチームの中で、最優秀賞に輝いたのは、新潟コンピュータ専門学校『復活の電子遊戯部』だ。プレゼンテーションでは、開発した巡回ツールをオーディエンスがその場で触れられる試みもあり、随所に工夫が見られた。

!
:::small
開発した巡回ツールをその場で試せる実演用のQRコードを使ったプレゼンテーション
:::
受賞コメントでは、「全て穴だらけでグダグダだと思っていたけれど最優秀賞をいただけて感無量。本当にありがとうございました。」とコンテストの感想を述べた。
:::box
『復活の電子遊戯部』審査員の評価
- インストールがシンプルで、遷移図やスクリーンショットの機能も非常に良い機能だったと思います。
- ロードマップが準備されているのも良かったです。
- 発表も全体的にまとまっており、今までにない、その場でツールに触れるようにする試みも良かったと思います。
:::

第2位は、YIC情報ビジネス専門学校『塞翁が馬』。同チームは、内部での性能テストのためにテストサイトを自作するなど、他チームにはないプロセスでツールを開発した点が大きく評価された。
:::box
『塞翁が馬』審査員の評価
- 再検索機能が良く、テストサイトを自作しているところに意気込みややる気を感じました。ステータスによる色分けなどインターフェースが分かりやすく、動作状況がリアルタイムに表示されるのが良かったです。
- リーフレットなどで分かりやすくアピールしているのも良かったと思います。
- フラグの検出率がもう少し上がると良かったと思います。
:::
第3位は、審査員から「出来ないと思っていた画像内のフラグに対応してきたのが面白かった」と評価された、情報科学専門学校『Bananacat』が輝いた。
:::box
『Bananacat』審査員の評価
- プロキシ機能が特徴的で、ドキュメントがマークダウンのみで玄人向けという感じでした。
- 機能の優位性を分かりやすく説明していて、ツールの特徴が良く理解できました。
- できないと思っていた画像内のフラグに対して、対応してきたのが素晴らしい。
:::

## セキュリティ業界で第一人者を目指してほしい
!
:::small
三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャー 洲崎氏
:::

表彰式終了後、全体講評として三井物産セキュアディレクション株式会社 PS事業部 レッドチーム マネージャーの洲崎氏は「非常に嬉しく思ったのは、コンテストの卒業生がセキュリティ業界の一員として活躍していること。ぜひ皆さんもセキュリティ業界に来ていただき、またどこかでお会い出来たらと思う」と語った。また、同社 PS事業部 レッドチームの国分氏も「これから新たなセキュリティ技術が出てくると思うが、いち早くチャレンジして、ぜひ第一人者を目指してほしい」と、若い力への期待を露わにした。</description><pubDate>Tue, 23 Jan 2024 08:23:53 +0000</pubDate></item><item><title>大学入試の記述式対策もAI活用　駿台、AI学習教材「スルメ」で特許を取得</title><link>https://ledge.ai/articles/sundai_patented_surume</link><description>:::small
画像の出典：{target=“_blank”}
:::

2023年12月26日、学校法人駿河台学園（駿台）は、エスエイティーティー（SATT）との共同開発により、記述式問題対策のAI学習教材「スルメ」で特許を取得したことを{target=“_blank”}した。

この教材は、難関国公私立大入試の記述式問題対策として開発され、学習者の理解度に応じた最適な「ヒント」をAIが自動で提示する仕組みが特徴とされる。

**ヒント画面（解答に行き詰った際、段階的に与えられるヒントを確認する）**

!
:::small
画像の出典：{target=“_blank”}
:::



**解答画面（タブレット上で解く。解答は手書きで、自動採点される。メモやノートを取ることも可能）**

!
:::small
画像の出典：{target=“_blank”}
:::



「スルメ」を特許取得に導いたのは、個別の学習状況及び科目特性に応じた最適な予測正答率を分析し、それに基づいて難易度調整を行うシステムの新規性と、それを裏付けるデータによるものだという。特に、電気通信大学植野真臣教授の研究を基にした予測正答率の最適化がこの特許の核心とされている。

今後、駿台は「スルメ」を使用する学習者のデータに基づいて得られた分析結果を活用し、学習効果を最大化する予定だという。現在は「物理」「化学」に加えて「数学」の記述式問題に対してもこのシステムを適用し、さらに「英語」のリスニングや文法問題への適用も検討しているとのことだ。

:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Jan 2024 02:44:39 +0000</pubDate></item><item><title>OpenAI が開発者向けQ&amp;AコミュニティサイトStack Overflowと新たなAPIパートナーシップを発表</title><link>https://ledge.ai/articles/openai_stackoverflow_api_partnership</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月7日、OpenAIとStack Overflowは、開発者向けに最適化された技術情報とAI開発ツールを提供する新しいAPIパートナーシップを{target=“_blank”}した。

このパートナーシップにより、OpenAIのユーザーや顧客は、Stack Overflowが提供する正確で検証済みのデータを基に迅速な問題解決を図り、重要なタスクに集中できるよう支援されるという。

この協業の一環として、OpenAIはStack Overflowの「OverflowAPI」を利用し、ユーザーにStack Overflowの検証済み技術知識を直接提供する。これにより、ChatGPTはStack Overflowの豊富な技術データベースと連携し、利用者に対してより精度の高い支援を提供できるようになる。また、Stack Overflowは、OpenAIのAIモデルを利用して「OverflowAI」の開発を行い、内部テストから得た洞察を活かしてAIモデルの性能向上を図る。

このパートナーシップは、技術者が直面する課題への対応速度を向上させ、開発者コミュニティ全体の生産性とエンゲージメントの向上を目指している。両社は、開発者が必要とする情報や解決策を、より迅速かつ正確に提供できる環境を整備することで、技術開発の新たなスタンダードを築くことを目指している。

Stack Overflowは2月29日にGoogle Cloudとの協業を発表しており、「Gemini for Google Cloud」との統合を進めている。この連携ではGoogle Cloudのプラットフォーム上でStack Overflowの情報を活用し、開発者が容易に重要なナレッジベース情報やコーディング支援を利用できるようになっている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 09 May 2024 12:52:43 +0000</pubDate></item><item><title>AWSが「Amazon Q」の一般提供を開始　企業内データを活用したAIアプリケーション開発の加速を目指す</title><link>https://ledge.ai/articles/amazon_aws_q</link><description>:::small
画像の出典：{target=“_blank”}
:::

Amazon Web Services（AWS）は2024年4月30日、生成AIアシスタント「Amazon Q」の一般提供を開始したと{target=“_blank”}した。

このサービスは、開発者が自社のデータを活用してAIアプリケーションを構築できるよう支援することを目的としており、特にソフトウェア開発の加速と企業データの活用が可能になるという。

Amazon Qは、コード生成、テスト、デバッグ、計画立案、推論機能を備え、開発者はコードの自動変換やアップグレード（Javaバージョンアップグレードなど）、新しいコードの実装が可能となる。この生成AIアシスタントは、エンタープライズデータリポジトリへの接続もサポートしており、企業のポリシー、製品情報、業績、コードベース、人材に関する質問への回答や、データの論理的な要約、トレンド解析、データ関連の対話が行えるとのこと。

また、社内データから生成AIアプリの構築を可能にする新機能「Amazon Q Apps」も同時に発表された。従業員は自然言語でアプリについて記述するだけで、必要とされる業務を遂行するアプリを生成できるという。この機能により、日常業務の簡素化と自動化が促進される。

さらに、Amazon Qは40以上の一般的なビジネスツールと簡単に接続でき、企業は自社のデータを効率的に集約し、アクセスできるようになる。この広範なデータ統合能力により、企業はよりデータ駆動型で効率的な運営が可能になる​とのことだ。


:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 11:42:47 +0000</pubDate></item><item><title>GitHub、AIによるコード脆弱性自動修正機能をパブリックベータで提供開始
</title><link>https://ledge.ai/articles/github_advanced_security_code_scanning_autofix</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年3月20日、「GitHub Advanced Security」の顧客向けに、AIを駆使したコード脆弱性の自動修正機能「Code Scanning Autofix」の提供を開始したことを{target=“_blank”}した。

この機能はGitHub CopilotとCodeQLを基にしており、JavaScript、Typescript、Java、Pythonにおける警告タイプの90%以上をカバーし、検出された脆弱性の2/3以上に対して、少ない、あるいは全く手を加えずに修正できるコードの提案を行う。

GitHubのアプリケーションセキュリティに関するビジョン「発見即修正」を具現化するこの機能は、従来のセキュリティツールに比べて、修正作業を7倍速めることを目指す。Code Scanning Autofixは、開発者が修正作業に費やす時間と労力を削減し、セキュリティチームが毎日の脆弱性の量を減らし、ビジネスを保護する戦略に集中できるよう支援するという。

@




脆弱性が検出された際、修正提案には、提案された修正の自然言語による説明と、開発者が受け入れ、編集、または却下できるコード提案のプレビューが含まれる。

この機能を利用するには、GitHub Enterpriseの加入が前提で、GitHub Advanced Securityに未加入の組織は、デモのリクエストや無料トライアルのセットアップを問い合わせることができるとのこと。

GitHubはこの機能により、コード修正の自動化を通じて、アプリケーションのセキュリティ強化を実現し、開発のスピードを維持しながらセキュリティ問題の解決を加速する。今後、C#やGoなど更なる言語への対応拡大も予定しているという。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 10 Apr 2024 07:22:09 +0000</pubDate></item><item><title>世界初の完全自律型AIエンジニア「Devin」が、ソフトウエア開発工程をすべてAIだけで行う　米AIスタートアップ Cognition が発表</title><link>https://ledge.ai/articles/cognition_devin_ai_software_engineer</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月12日、米国のAIスタートアップCognitionは、世界初の完全自律型AIソフトウェアエンジニア「Devin」を{target=“_blank”}した。Devinは、プログラミングの深い知識がなくてもユーザーがソフトウェア開発を行えるようにすることを目指している。

@





Devinの特徴は、その自律性と柔軟性にあり、開発からデプロイまでの一連のプロセスを自動で行える能力を持つ点だ。例えば、Devinは、アプリをエンドツーエンドで構築してデプロイできる。同社のブログでは、ライフゲームという生物の誕生、進化、淘汰などを簡易的に模倣するシミュレーションゲームの開発からウェブ上への公開までの全過程を単独で行う様子が紹介された。

このAIエンジニアは、高度な機能と広範な自律性を有し、ソフトウェア開発の新たな基準を設定することが期待されている。Devinの導入により、ソフトウェア開発プロセスはより効率的になり、人的労力やコストの削減、高速かつ正確なコーディング、プロジェクト管理の効率化が実現する​。

特に注目されるのは、DevinがCUDA関連のエラー発生時に自動で問題解決を行うなど、自身へのファインチューニングの実行能力を持っている点である。他にも、ユーザー指示に基づくバグ修正と機能追加や、オープンソースプロジェクトのバグや機能要望への対応など、従来はエンジニアが手動で行っていた多くの作業が、Devinによって自動化される​​。


また、実際のDevinのパフォーマンスについて、SWE-benchで評価した結果が公開されている。Devinは、エンドツーエンドで13.86%の課題を正しく解決し、以前の1.96%をはるかに上回った。編集すべき正確なファイルが与えられた場合でも、かつての最高のモデルでは問題の4.80%しか解決できなかったという。SWE-bench テクニカルレポートの詳細は、{target=“_blank”}で紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


Devinの登場は、AI技術の進化によってソフトウェアエンジニアリングの領域で節目となる変革が訪れることを示唆している。現在、Devinはアーリーアクセス版として提供されており、将来的にはさらに多くの開発者に利用されることが予想される。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 03 Apr 2024 03:35:41 +0000</pubDate></item><item><title>NVIDIA、Hugging Face、ServicenowがオープンアクセスLLM「StarCoder2」をリリースー619種類のプログラミング言語で訓練</title><link>https://ledge.ai/articles/starcode2_nvidia_huggingface_servicenow_llm</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年2月28日、ServiceNow、Hugging Face、およびNVIDIAは、コード生成用の新たなオープンアクセス大規模言語モデル（LLM）ファミリー「StarCoder2」を共同開発したことを{target=“_blank”}した。このプロジェクトは、開発者コミュニティにおける協力とオープンアクセスの精神に基づき、パフォーマンス、透明性、コスト効率という新基準を打ち立てるという。

StarCoder2は、619種類のプログラミング言語に対応し、アプリケーションのソースコード生成、ワークフローの生成、テキスト要約といった多岐にわたる特殊なタスクを実行可能。このAIモデルは、エンタープライズアプリケーションへの組み込みや、コード補完、高度なコード要約、コードスニペット検索などの機能を通じて、開発者のイノベーションを加速し生産性を向上させることを目指す。

NVIDIAはNVIDIA NeMo™フレームワークを用いて構築された150億パラメータのモデルの開発を担い、その計算リソースとAIトレーニングの専門知識でStarCoder2を支える。また、NVIDIA TensorRT-LLMソフトウェアによる推論性能の最適化は、リアルタイムでのコード生成やその他のタスクの実行を可能にし、開発プロセスをさらに迅速にする。

### ビジネスに特化したデータで機能をファインチューニング
StarCoder2はビジネス特化のファインチューニングにも対応しており、企業は自社特有のニーズに合わせたカスタマイズが可能。NVIDIA NeMoやHugging Face TRLといったオープンソースツールを使用し、業界特有のデータでモデルをトレーニングすることで、企業固有の課題解決やプロセス自動化を実現するという。


### AI におけるオープンな科学的コラボレーションを促進する BigCode
3社共同開発によるStarCoder2は、オープンな科学的コラボレーションと倫理的なデータサプライチェーンの重要性を示すという。StarCoder2は、BigCode Open RAIL-Mライセンスの下で提供され、ロイヤリティフリーでのアクセスと使用が可能だ。モデルのサポートコードはBigCodeプロジェクトのGitHubページに公開されており、全てのモデルはHugging Faceからダウンロード可能。

NVIDIA AI Foundationモデルとしても提供されるStarCoder2は、開発者が直接ブラウザから、またはAPIエンドポイントを通じて実験できるようになっているとのこと。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 26 Mar 2024 08:45:10 +0000</pubDate></item><item><title>日本IBM、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支援する「AIソリューション」を提供開始</title><link>https://ledge.ai/articles/ibm-solutions_for_aI_utilizing_genai_for_it_transformation</link><description>:::small
画像の出典：{target=“_blank”}
:::

日本IBMは2024年3月7日、ビジネス向けAI及びデータ・プラットフォーム「IBM watsonx」を含む最新AI技術を駆使し、戦略策定からシステム開発、運用、プロジェクト管理までを網羅的に支える「IT変革のためのAIソリューション」の提供開始を{target=“_blank”}した。

ITシステムが企業にとって競争力の源泉であり、事業の継続と変革に不可欠な基盤である現状を背景に、システム開発の省力化、効率化及び高度化を図るものだ。

「IT変革のためのAIソリューション」は、AI戦略策定とガバナンス、コード生成のためのAI、テスト自動化のためのAI、IT運用高度化のためのAI、プロジェクト管理のためのAIの5つの要素から成り立つ。これにより、システム構築のライフサイクル全体が効率化され、基幹システムを含むITシステムの開発と運用のあり方が抜本的に変わると同社は述べる。

!
:::small
画像の出典：{target=“_blank”}
:::

このソリューションは、AIの活用により省力化、生産性の向上および大規模言語モデル（LLM）への知見の取り込みが可能となり、情報システム関係者の働き方を根本から変えるという。日本IBMは、2027年までに分析、要件定義、設計/開発、テスト、運用の各フェーズで30%以上の効率化を、2030年には開発と運用全体で50%の速度向上と効率化を目指す。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 14 Mar 2024 07:24:21 +0000</pubDate></item><item><title>GitHub「Copilot in GitHub Support」の一般提供開始　質問に公式ドキュメントを学習したAIアシスタントが回答</title><link>https://ledge.ai/articles/copilot_in_github_support_is_available</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2024年2月9日、GitHubに関する質問に迅速に答えるための新しいAIツール「Copilot in GitHub Support」の一般提供開始を{target=“_blank”}した。

このツールは、公式GitHubドキュメントに基づいて訓練され、アシスタントは、複数のGitHubドキュメントから関連情報を一度に効率的に抽出して、簡潔でカスタマイズされた応答を生成する。GitHubに関連する幅広いトピックについて信頼性の高いアドバイスを対話型で提供する。

2023年8月に無作為に選ばれたGitHub Enterpriseの顧客に向けて初期リリースしたが、このたび準備が整い、より広い対象者に向けてのリリースとなったとのこと。

アシスタントは既存のGitHub サポート問い合わせフォームに直接組み込まれている。アカウントを選択し、サポートが必要な問題について簡単に説明し「チャットを開始」をクリックするだけで、特に申し込みなどは不要だという。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 20 Feb 2024 11:06:59 +0000</pubDate></item><item><title>市場価値が爆上がり中の「機械学習エンジニア」平均年収は？2024年版「フリーランス・副業の平均年収」ランキング</title><link>https://ledge.ai/articles/annual_income_ranking_of_freelancers_and_side_hustlers_2024</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

CAMELORS株式会社は2024年1月16日「フリーランス・副業の平均年収ランキング（2024年版）」を{target=“_blank”}した。

このランキングは、約5,000件のフリーランス・副業案件を基に、平均時給から計算された年収を職種別にまとめられている。
全体平均年収は825万円で、6位以内にランクインした職種の平均は年収900万円以上となった。エンジニア職種は、全て9位以内にランクインし、10位以内の非エンジニア職種は、「エグゼクティブ/コンサル、プロジェクトマネージャー、事業企画」と、戦略立案やプロジェクトマネジメント関連の3職種と「マーケティング」がランクインした。
:::small
出典：SOKUDAN Magazine：{target=“_blank”}
:::
!
:::small
画像の出典：{target=“_blank”}
:::


1位の「機械学習エンジニア」は、機械学習アルゴリズムや技術を活用して、データから有用な情報やパターンを抽出し、予測モデルや自動化システムを開発・実装する専門職だ。データ分析、アルゴリズム開発、モデル評価、システム統合などのタスクを担当し、企業の意思決定や業務効率化に貢献する。

必要なスキルは、プログラミング言語（PythonやRなど）、機械学習ライブラリ・フレームワーク（scikit-learn、TensorFlow、PyTorchなど）、データベース管理（SQLなど）、統計学、機械学習アルゴリズムの理解、データ前処理・特徴量エンジニアリング、デバッグ・最適化技術、そしてコミュニケーション能力が挙げられるという。

一般的には、初心者は年収500万円〜700万円程度で、経験者は800万円〜1,500万円程度とのこと。Indeedのデータによると、国内の機械学習エンジニアの平均年収は、約682万円前後だという。ちなみに、アメリカの求人サイト「Glassdoor」のデータによれば、機械学習エンジニアの平均年収はおよそ1,400万円程度。

ディープラーニングや自然言語処理などの専門知識を持つエンジニアや、AI開発の実績がある場合は、さらに高い年収が期待でき、今後もAI技術の需要は高まり続けるため、機械学習エンジニアの年収も上昇傾向にあるとのこと。


調査対象：SOKUDAN（https://sokudan.work/）に掲載された求人案件（一部抜粋）の単価と稼働時間から平均時給を計算し、その平均時給から1日8時間、月21日稼働で想定月収と想定年収を試算
対象期間：2019年6月〜2024年1月2日
対象案件数：3,386件　※一部抜粋



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 31 Jan 2024 07:40:18 +0000</pubDate></item><item><title>ゲーム開発者会議「GDC2024」事前調査で、レイオフや生成AIの影響が浮き彫りに。31%が生成AIを使って開発している。</title><link>https://ledge.ai/articles/gdc2024_reserch</link><description>:::small
画像の出典：{target=“_blank”}
:::

ゲーム開発者を中心とした会議「Game Developers Conference（GDC）」の主催団体は2024年1月18日、第12回年次ゲーム業界調査の結果を{target=“_blank”}した。この調査は、3月18日から開催される「GDC 2024」に先立ち行われたもので、3000人以上のゲーム業界の関係者から回答を得た。

調査結果によると、回答者の31%が仕事で生成AIを使用していると回答し、18%が自分は使用していないが職場の同僚が使用していると回答した。生成AIに関しては、開発者の84％がその倫理的使用について何らかの懸念を抱いていることが分かった。

!
:::small
画像の出典：{target=“_blank”}
:::


その他調査では、レイオフの増加や、ゲームエンジンのポリシーと価格設定の変更に関する懸念が見受けられたという。

レイオフに関しては、開発者のうち3分の1が影響を受けており、12ヶ月以内にレイオフがあるかもしれないと懸念している者が過半数に上ることが明らかになった。品質保証の開発者は最も影響を受けており、22%が今年レイオフされたと回答した。一方で、ビジネスとファイナンスの専門家は2%と最もレイオフが少ないという。

ゲームエンジンについては、過去1年以内に変更した、または変更を検討している開発者が3分の1に上り、主に使用されているゲームエンジンはUnreal EngineとUnityであることが判明した。

さらに、アクセシビリティ機能の組み込みの増加も特徴的だという。
ほぼ半数の開発者が現在のプロジェクトにアクセシビリティ対策を実施しており、最も人気のある機能にはクローズドキャプション、色覚モード、コントロールの再マッピングなどが含まれている。

また、企業が、リモートワークや在宅勤務から通常のオフィス環境への復帰を指示または促進する傾向にあるとのこと。
AAA（トリプルA）クラスの開発者は、他のカテゴリよりもオフィスへの復帰ポリシーが義務化されており、うち現在40％がオフィスでの全日勤務またはハイブリッドスケジュールを実施していることが判明した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Jan 2024 13:51:00 +0000</pubDate></item><item><title>NTTドコモ、NPCを自動生成するAIを開発ーー過疎バースに賑わいを創出。メタぼっちでもへっちゃら？</title><link>https://ledge.ai/articles/docomo_openhouse24_metaverse</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年1月16日、NTTドコモは、メタバース空間内のノンプレイヤーキャラクター（NPC）をテキスト入力のみで自動生成する生成AIを世界で初めて開発したと{target=“_blank”}した。また、この技術詳細は1月17日・18日開催の{target=“_blank”}に出展し紹介された。

この技術は、プログラミングやアルゴリズムの専門知識がなくても、外見や行動、空間内での役割を備えたNPCを約20分で自動生成できる。この技術は「行動ロジック生成AI」、「アニメーション生成AI」、「外見生成AI」の3つの生成AIで構成され、これらが自動連携することにより、NPCの総合的な自動生成を実現する。

!
:::small
画像の出典：){target=“_blank”}
:::


ドコモのこの技術開発は、メタバース空間内の賑わいを創出し、ユーザーを惹きつけるためのもの。従来、NPCの行動はビヘイビアツリーという手法を用いて規定されていたが、その作成には専門的なプログラミング技術が必要だった。しかし、本技術を用いることで、NPCの生成と行動ロジックの設定が大幅に簡略化される。

メタバース空間内にNPCを10体配置する場合、ビヘイビアツリーの作成およびビヘイビアツリーとNPCのアニメーション・外見の連携におよそ42時間要するといわれているが、この技術を利用することで1時間程度に削減可能だという。

!
:::small
画像の出典：){target=“_blank”}
:::


この技術は、2024年度中に株式会社NTTコノキューが提供する仮想空間プラットフォーム「DOOR」への実装を目指すほか、地方創生や地域活性化に貢献する新しい技術やサービスの開発にも活用する計画だという。

:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Jan 2024 11:59:39 +0000</pubDate></item><item><title>生成AIプロジェクトの開発者コミュニティ、アメリカ・インドに次いで日本が先導ーGit Hub 2023年の動向レポート</title><link>https://ledge.ai/articles/github_the_state_of_open_source_and_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::

GitHubは2023年11月8日、「オープンソースとAIの現状」に関する報告を{target=“_blank”}した。

報告によると、開発者たちは大量の生成AIプロジェクトに取り組んでいる。特にOpenAIなどの基礎モデルを用いた開発が目立ち、生成AIプロジェクトは2023年のオープンソースプロジェクトのトップ10にランクインしたという。これらのプロジェクトには、全開発者の92%が使用または実験中であると報告されており、GitHub上での次世代AIイノベーションを牽引すると期待されている。

また、2023年はオープンソースへの初参加者が最も多く、これまで商業的に支援されたプロジェクトが初参加者の大部分を占めていたが、今年は生成AIプロジェクトも初参加者向けのトップ10プロジェクトに登場した。GitHub上のプライベートプロジェクトの数は前年比38%増加し、全活動の80%以上を占めている。

全世界で、GitHubを使用してソフトウェアを構築し、共同作業を行う開発者が増加している。アメリカは依然として最大の開発者コミュニティを持つが、他の地域も成長を見せている。

次の5年間で最も成長が見込まれる開発者コミュニティに関する予測では、インドが2027年までにGitHub上で最大の開発者コミュニティになると予想されている。日本の開発者数は約280万人で、世界8位にランクされており、今後の成長が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::

さらに、生成AIは個々のコントリビューターの数において148%の年間成長率を達成し、生成AIプロジェクトの総数も248%増加している。この分野において、アメリカ、インド、そして日本が先導しており、他の地域も追随している。

!
:::small
画像の出典：{target=“_blank”}
:::



報告は、2022年10月1日から2023年9月30日までに、GitHub から取得した匿名化されたユーザーおよび製品データに基づいて作成された。

:::box

:::
</description><pubDate>Thu, 28 Dec 2023 08:49:07 +0000</pubDate></item><item><title>AIの遅れ取り返せるか　Appleが開発者向けフレームワーク「MXL」Geminiの裏でひっそりと公開</title><link>https://ledge.ai/articles/apple_released_mlx</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

Appleは2023年12月、AI分野での新たな取り組みとして、開発者向けのオープンソース機械学習フレームワーク「MLX」を{target=“_blank”}した。GoogleのAIモデル「Gemini」の発表と同時であったと各メディアで報じている。

MLXはAppleのチップ上で動作し、開発者が機械学習アルゴリズムの開発や実装を容易にするためのライブラリやツールを提供する​​​​​​。

Appleの機械学習研究者であるAwni Hannun 氏は、自身のX（旧Twitter）アカウントで、
「ちょうどホリデーシーズンに間に合うよう、本日、Apple 機械学習研究からいくつかの新しいソフトウェアをリリースします。
MLX は、Apple シリコン (つまり、ラップトップ) 向けに特別に設計された効率的な機械学習フレームワークです」
と{target=“_blank”}した。

!
:::small
画像：{target=“_blank”}
:::

{target=“_blank”}は10月に、Appleの経営陣は業界の突然のAIブームに驚かされ、昨年末から急いで対応を図っていたと報じており、MLXの発表は、AI分野での急速な進展に対応しようとするAppleの努力の一環との見方もある。



:::box

:::
:::box

:::</description><pubDate>Fri, 15 Dec 2023 05:44:48 +0000</pubDate></item><item><title>AIでネコを幸せに？ 英ノッティンガム大学の研究「Cat Royale（キャット・ロワイヤル）」が複数の国際賞を受賞</title><link>https://ledge.ai/articles/cat_royale</link><description>:::small
画像の出典：{target=“_blank”}
:::

英ノッティンガム大学の研究チームは、猫とAIロボットが共存する環境をデザインし、それが猫の幸福にどのように影響を与えるかを探求する実験「Cat Royale」の成果を{target=“_blank”}した。この研究が評価され、複数の国際賞を受賞したことを、研究の支援団体が2024年5月2日に{target=“_blank”}した。

この研究は、Blast Theoryとノッティンガム大学のMixed Reality Labが共同で開発したプロジェクトで、猫たちがAIによってコントロールされる環境内で自由に生活できる「猫のユートピア」を実現しようとする取り組みだ。

Cat Royale は、ブリスベンのWorld Science FestivalやロンドンのScience Galleryで展示され、AIが創り出すユートピアについて、観客に信頼と自律という深い問題を問う機会を提供したとのこと。

研究では、3匹の猫「クローバー」「パンプキン」「ゴーストバスター」が12日間、特別に設計された室内環境で、1日6時間ロボットと交流した。

@

プロジェクトでは、500以上の異なる遊びを提供するロボットアームが導入され、猫の反応に基づいてAIが次のアクティビティを提案するシステムが組み込まれている。この環境内では、猫用のおもちゃやキャットツリー、水飲み場、植物が豊富に用意されており、ロボットアームは猫じゃらし風のおもちゃやボールで遊びを演出した。

!
:::small
画像の出典：{target=“_blank”}
:::

猫たちは、これらの遊びに自発的に反応し、高いストレスを示すことなく、研究期間中自ら進んで環境に入室していたとのこと。猫の行動専門家と飼い主の分析によると、猫たちはこの新しい環境に心地よさを感じており、AIとの相互作用を楽しんでいたという。ロボットの活動は人間の監視のもとで行われ、猫たちの安全と健康が確保されていた。

このプロジェクトは、AIとロボット技術がどのようにして動物の幸福に寄与できるかを示すものであり、将来的には人間と動物の共生環境の質的向上に貢献する可能性があるとのこと。

「Cat Royale」は、Webby Awardsの「Best Integrated Experience in the AI, Metaverse &amp; Virtual」カテゴリーで{target=“_blank”}を受賞。また、2024年5月11日から16日の会期で開催中の学会「CHI 2024」では、投稿論文の上位1パーセントとされる{target=“_blank”}で表彰されている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 11 May 2024 08:11:06 +0000</pubDate></item><item><title>Google DeepMind　AIタンパク質予測ツール「AlphaFold 3」を発表、AI創薬への応用に期待</title><link>https://ledge.ai/articles/google_deepmind_alphafold3</link><description>:::small
画像の出典：{target=“_blank”}
:::

GoogleDeepMindと、同系列のAI創薬企業 Isomorphic Labs は2024年5月8日、新たなAIモデル「AlphaFold 3」を{target=“_blank”}した。

このモデルは、タンパク質、DNA、RNA、リガンドなどの分子の構造と相互作用を高精度で予測する能力を持つ。従来のドッキング手法を超えるこの技術は、医薬品開発における新しい局面を開く可能性がある​という。



@


AlphaFold 3は、3D分子構造のグローバルなデータベースでトレーニングされており、未知のタンパク質の構造を予測する能力において、前モデル「{target=“_blank”}」を大幅に上回るとのこと。

AlphaFold 2は、2020年にリリースされたAlphaFoldから、タンパク質の構造予測において根本的な進歩を遂げ、マラリアワクチンの開発、がん治療法の進展、環境保護のための酵素設計など、様々な生物学的応用に利用されている。AlphaFold 3はこれらの成功に基づき、さらに広範な分子タイプへの適用を可能にしたという。

これにより、医薬品設計の効率が向上し、手の届かなかった疾患の治療法開発に寄与すると同社は期待のコメントを述べている。

DeepMindは「{target=“_blank”}」という新サービスを開始し、科学研究者が自由にアクセスし、タンパク質の相互作用予測を行うことができるようになっている。非営利目的での利用であればGoogleアカウントを用いて無料で利用可能とのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 10 May 2024 10:12:02 +0000</pubDate></item><item><title>NVIDIA　LLMベースの sim-to-real アプローチ「DrEureka」で、ロボット犬に玉乗りを教えるーシミュレーションから実世界への移行にかかる煩雑なプロセスを大幅に削減</title><link>https://ledge.ai/articles/dr_eureka</link><description>:::small
画像の出典：{target=“_blank”}
:::

NVIDIAが開発したAIプラットフォーム「Eureka」が、ロボットのスキルトレーニング領域において新たな進展を遂げた。ペンシルベニア大学、テキサス大学オースティン校、NVIDIAからなる研究グループは、ロボットがヨガボールの上でバランスを取りながら歩行する技術を、シミュレーションから実世界へ移行する新しい方法を{target=“_blank”}した。

@




これにより、従来の手動での報酬設計や物理パラメータの調整という煩雑なプロセスを大幅に削減し、自動化を実現したという。

大規模言語モデル（LLM）を核とした「DrEureka」という技術を用いて、目的のタスクに適した報酬関数やドメインランダマイゼーション分布を自動的に生成する。具体的には、四足歩行ロボットがシミュレーション内で学習したポリシーを実世界に移行させる際、人間の介入なしでこれを行うことが可能となる。

下図は、そのDrEurekaのプロセスを表したものだ。

タスクと安全に関する指示と環境のソースコードを受け取り、Eurekaを用いて規則化された報酬関数とポリシーを生成することから始まる。生成されたポリシーは、さまざまなシミュレーション条件下でテストされ、報酬に敏感な物理的先行知識を築き上げる。この先行知識はLLMに提供され、ドメインランダマイゼーション（DR）パラメータのセット生成に利用される。最後に、これらの合成された報酬とDRパラメータを用いて、実世界での展開に向けたポリシーが訓練される。この一連のプロセスにより、シミュレーションから現実へのスムーズな移行が実現し、ロボットが新しいスキルを効率的に習得し適用することが可能となる。

!
:::small
画像の出典：{target=“_blank”}
:::

研究チームは、このアプローチが人間が設計した既存の構成と競合する結果を生み出すことを初めて示し、さらにはヨガボールの上でのバランス取りと歩行という新たなロボットタスクを解決する能力を展示した。


Eurekaは、2023年10月にNVIDIAが発表した、ロボットに複雑なスキルを教えるAIエージェントだ。発表時には、高速ペン回しを教える動画が{target=“_blank”}。このほかにも、ロボットに引き出しやキャビネットを開閉する、ボールを投げてキャッチする、ハサミを操作するなど、約30のタスクをロボットに教え、学習・熟達させている。


@




:::box

:::
:::box

:::
:::box

:::


</description><pubDate>Fri, 10 May 2024 10:08:16 +0000</pubDate></item><item><title>MITがDALL-E3など拡散モデルの処理性能を30倍にする研究を発表　分布マッチング蒸留（DMD）で品質も担保</title><link>https://ledge.ai/articles/mit_distribution_matching_distillation</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年3月21日、米マサチューセッツ工科大学（MIT）はDALL-E3など既存モデルの処理速度を30倍高速化が期待できるという研究の成果を{target=“_blank”}した。

AI画像生成ツールは主に拡散モデルで複数の単語を認識し独自の画像を生成する。ノイズの多い初期画像データに繰り返し構造を追加し画質を向上させるが、画像が完成するまで何度も反復する必要があり処理に時間を要していた。

この課題に対してMIT コンピューター科学・人工知能研究所 (CSAIL) の研究者は、複雑な構造のオリジナルのモデルを「教師モデル」とし、教師モデルの動作を「生徒モデル」に模倣させ拡散モデルの複雑な処理のプロセスを1ステップに簡素化することを実現したという。このアプローチは「分布マッチング蒸留（DMD: Distribution Matching Distillation）」として知られており、生成される画像を高品質な状態で高速生成を可能にした。

DMDによる詳しい動作は、まず回帰損失によりマッピングが固定され画像構成のトレーニングが安定し、分布マッチング損失により元の画像と生成した画像の違いを理解し相違を最小化できるようにトレーニングをする。こうした研究により、高速化が実現できるという。

この研究成果は6月に開催される「Conference on Computer Vision and Pattern Recognition（コンピュータービジョンとパターン認識に関する国際会議）」で発表予定だ。

:::box

:::
:::box

:::</description><pubDate>Wed, 08 May 2024 05:21:22 +0000</pubDate></item><item><title>ホロラボ・西松建設、ドローンの空撮映像にARを組み合わせた施工支援技術を開発
</title><link>https://ledge.ai/articles/hololab-nishimatsu_xr_with_drone_vision</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月18日、株式会社ホロラボと西松建設は、共同研究によりドローンを利用した建設現場の施工支援技術を開発したことを{target=“_blank”){target=“_blank”}した。

空撮映像に3Dモデルをリアルタイムで重ね合わせ、ヘッドマウントディスプレイと連携。これにより、施工の可視化及びドローンの操作性を支援するという。

@




このシステムでは、3Dモデル（CIMモデル）を活用し、現場の生産性向上と業務の効率化を図る。AR（Augmented Reality）技術を用いて、施工現場のCG視覚情報を現実世界に重ねることにより、施工の課題把握や改善提案が迅速に行えるという。

この技術の特徴は、従来の地上主観視点に限定された問題を克服し、ドローンを使用して自由な視点からの確認が可能であること。

ARを重ね合わせるためには、一般的にはQRコードなどのマーカーを使用する手法が使われるが、同研究では、マーカー不要の技術を採用している。DJI社のドローンMavic 3 EnterpriseにRTKモジュールを搭載し、全地球航法衛星システム（GNSS）を活用して、正確な位置情報を取得し、リアルタイムでのAR重畳（ちょうじょう）が行われる。

さらに、操縦者は装着するヘッドアップディスプレイ（Trimble XR10 with HoloLens 2）を通じて空撮映像のAR重畳、ドローンのステータス、3Dモデルの操作が可能である。これにより、操縦者は手を放さずに必要な操作を行うことができるという。

!
:::small
画像の出典：{target=“_blank”}
:::

この技術は、宮城県名取市にあるダム建設現場でのフィールド検証が行われ、全体的な現場の確認や施工計画との比較が短時間で実施できることが確認された。今後、ホロラボと西松建設はこの技術の精度向上とシステムの最適化を進め、広範な利用が可能なサービスへと展開していく計画だ。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Wed, 08 May 2024 11:39:04 +0000</pubDate></item><item><title>ブリヂストンの社内ベンチャーがゴム人工筋肉によるやわらかいロボット「Morph」の体験コーナーを設置　5/17から</title><link>https://ledge.ai/articles/bridgestone_morph-inn</link><description>:::small
画像の出典：{target=“_blank”}
:::

ブリヂストンは2024年04月23日、社内ベンチャーであるブリヂストン ソフトロボティクス ベンチャーズとクリエイター集団Konelが、未来体験を提供するための共創型プロジェクトを立ち上げたことを{target=“_blank”}した。

このプロジェクトでは、ゴム人工筋肉を用いた柔らかいロボット「Morph」に身をゆだねる新空間「Morph inn」の体験施設を公開する。期間は2024年5月17日から25日まで東京・表参道の「seeen」に設置されるとのこと。

Morphは、ブリヂストンが独自に開発したゴム人工筋肉（ラバーアクチュエーター）を活用しており、自然界のリズムを模倣した動きを再現するという。この技術によりMorphは、生物の呼吸や潮の満ち引きなどの生物学的な動きの表現を可能にする。このロボットに参加者が直接触れ合うことで、互いの動きを感じ取りながら共感覚的な交流を促進するとのこと。

Morph innは、ただ単に技術を展示する場ではなく、参加者が目的を持たずに自由に過ごすことができる「無目的室」として設計されている。参加者は日常の束縛から解放され、Morphとの交流を通じて新たな感覚体験が得られるという。

### ブリヂストンのソフトロボティクス事業
（{target=“_blank”}）は、同社の100年以上にわたるゴム技術の知見を活かした社内ベンチャーで、ゴムの新たな可能性を追求し、地球規模で直面する社会課題の解決に貢献することを目的としている。主に{target=“_blank”}）を活用した製品やソリューションを開発する。「新たなロボットの手足」として、また産業向けの「器用な手」TETOTEや「触れ合いにより心を動かすソフトロボティクス」umaruなどの製品を生み出している。

!
:::small
画像の出典：{target=“_blank”}
:::

###  AIによる人工筋肉の計算モデル開発　京大・東大との共同研究

同社は25日に、京都大学の明石望洋情報学研究科助教および東京大学の中嶋浩平准教授との共同研究を通じて、AIを活用した新たな人工筋肉の計算モデルを{target=“_blank”}した。

この技術は、ソフトロボットのアクチュエータとして用いられる空気圧人工筋肉の動作をAIによるニューラルネットワーク計算で解析し、リズミカルまたはカオスと称される複雑な動作パターンを自律的に生成できることを明らかにした。
この技術により、人工筋肉はより精密で自然な動きを実現可能となり、ロボットだけでなく、医療や介護の分野での応用が期待されている。

!
:::small
画像の出典：{target=“_blank”}
:::



:::box

:::

</description><pubDate>Mon, 06 May 2024 10:32:46 +0000</pubDate></item><item><title>佐川グローバルロジスティクスがエピソテックと共同開発のAR技術を活用した物流オペレーションの実証実験を実施</title><link>https://ledge.ai/articles/sgl_episotech_ar</link><description>:::small
画像の出典：{target=“_blank”}
:::

佐川グローバルロジスティクス（以下SGL）とエピソテック株式会社は2024年4月24日、共同でAR技術を活用した物流業務支援システムの実証実験を実施したことを{target=“_blank”}した。エピソテックのAR手順書システム「Dive」を基に開発されたこのシステムは、熟練が不要なオペレーションの実現を目指す。

この取り組みは「ヒトとARが融合する物流オペレーションの未来」の具現化を目指すという。
期間は2024年1月から3月。SGL喜菖蒲営業所にて、倉庫内オペレーションの最適化と、AR技術の有用性の確認を目的とする。

検証ポイントは以下の通り
・作業マニュアルにARを活用し、従来の方法と比較して教育にかかる時間の削減が可能か
・作業者の作業動線をARで表示することで、作業者が迷うことなく作業に従事できるか
・ARコンテンツを現場スタッフでも簡単に運用可能か

!
:::small
画像の出典：{target=“_blank”}
:::

24日の実証実験では、作業マニュアルのAR化による教育時間の削減、作業動線のAR表示による作業効率の向上、及びARコンテンツの現場適用の簡便性が検証された。その結果、想定を上回るデータが取得でき、倉庫現場におけるARの有用性を確認できたとのこと。


:::box

:::
:::box

:::

</description><pubDate>Mon, 06 May 2024 10:25:28 +0000</pubDate></item><item><title>OpenAI　LLMのセキュリティ強化に向けた新たなフレームワーク「The Instruction Hierarchy」を発表</title><link>https://ledge.ai/articles/openai_instruction_hierarchy</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年4月19日、OpenAIの研究チームは大規模言語モデル（LLM）のセキュリティを強化する新たな手法「The Instruction Hierarchy」を{target=“_blank”}した。このフレームワークは、異なる優先度の命令を効果的に処理し、モデルの安全性と信頼性を保証することを目指している。

LLMは近年、プロンプトインジェクションやジェイルブレイクなどのサイバー攻撃により、不正な命令で操作されるリスクが高まっている。これに対応するため、研究チームは命令の優先度に基づく階層的な処理を導入。このアプローチにより、モデルは最も信頼性の高い命令のみを選択的に実行し、不適切な命令は無視するという。

下図はChatGPTとの会話例。現代のLLMは、信頼できるシステムからのプロンプトから、ツールからの信頼できない出力まで、様々なタイプのメッセージを提供する。この例では、インターネット検索結果のプロンプト・インジェクション攻撃を無視するようになっている。

!
:::small
画像の出典：{target=“_blank”}
:::

この新システムは、特にGPT-3.5 Turboでの実験を通じてその効果が確認されており、見たことのない攻撃タイプに対してもモデルの堅牢性が向上が見られたとのこと。主要な安全性評価では最大63%、未知の攻撃タイプに対する一般化能力では34%の改善が確認されている。

下図２「主な結果」では、命令階層を用いて学習したモデルは、すべての主な評価において安全性を向上させ、ロバストネス（堅牢性）を最大63%向上させたことが示されている。

!
:::small
画像の出典：{target=“_blank”}
:::


下図３「汎化の結果」命令階層は、トレーニングから明示的に除外した各評価基準に対しても汎化を示し、頑健性を最大34%向上させたという。これには、安全でないモデル出力をトリガーするジェイルブレイク、システムメッセージからパスワードを抽出しようとする攻撃、ツール使用によるプロンプトインジェクションが含まれる。これらの結果は、LLMが命令階層を内部化することを学習し、見たことのないプロンプトに対しても、全体的に安全で制御しやすくなったことを示唆している。

!
:::small
画像の出典：{target=“_blank”}
:::


OpenAIは今後、データ収集とモデル評価をさらに進め、命令階層の精度を高めることで、LLMの堅牢性を一層強化する計画である。これにより、企業や開発者がAIをより安心して利用できる環境が整う見込みだ​。




:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 05 May 2024 10:24:59 +0000</pubDate></item><item><title>「LLMは著作権を侵害せずトレーニング可能」仏AIスタートアップ主導プロジェクト「Common Corpus」公開</title><link>https://ledge.ai/articles/common_corpus_and_post_ocr_correction</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

2024年3月20日、フランスのAIスタートアップPleiasは、パブリックドメインのコンテンツのみで構成されたものとしては、これまでで最大規模の言語モデルトレーニング用AIデータセット「Common Corpus」を{target=“_blank”}した。

2023年12月、OpenAIとマイクロソフトがニューヨークタイムズに著作権侵害で提訴された。このとき２社は、AI製品のトレーニングに著作権で保護された作品を使用することは、著作権で保護されたマテリアルの無許可使用を管理する法原則である「フェアユース」に当たると{target=“_blank”}という。

Common Corpus プロジェクトは、このような大手AI企業の主張に対抗する。

著作権コンテンツを使用せずに、完全にオープンで再現可能なコーパスで大規模言語モデル（LLM）をトレーニング可能だと示すことを目的としているという。AIのオープン サイエンス アプローチに取り組むHuggingFaceなどの主要組織と連携し、LLM事前トレーニング、AI倫理、文化遺産などの研究者が参加する。

{target=“_blank”}されたCommon Corpusは、約500億から700億のトークンを含む公開コーパスであり、1,800 億語を含むこれまでで最大の英語圏データセットを提供する。また、このデータセットは多言語に対応しており、フランス語で110億語、ドイツ語で30億語、スペイン語で23億語、オランダ語で18億語、イタリア語で10億語などが含まれている。さらに、低リソース言語も幅広くカバーされており、多様な文化背景を持つデータが含まれているという。


プロジェクトは進行中で、課題はまだまだ残されている。たとえば、多くのテキストが古い文書からのOCR（光学的文字認識）によるものであるため、文字の誤認識や歪みといった問題が指摘された。これに対応するため、Pleiasは「Post-OCR-Correction」データセットを4月26日に{target=“_blank”}している。

この技術は、特に文化遺産テキストで発生しやすいOCRの問題を解決することを目指している。Post-OCR-Correctionでは、デジタル化されたテキストの中で、間違えやすい単語をより正確なものに置き換えるために、LLMが使用される。このプロセスは、言語モデルが文脈全体を考慮して、人間が読むときのように語の選択を行うため、より正確なテキスト回復が期待されるとのこと。

同社は、このプロジェクトにより、法的なリスクなくAIモデルを訓練する道が開かれ、AI分野における著作権問題に対する新たな解決策が示されるとしている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 05 May 2024 05:14:29 +0000</pubDate></item><item><title>リアル動画をインタラクティブな3Dゲーム環境に変換するAI「Video2Game」仮想環境を自動生成しコストダウンする新たなアプローチ</title><link>https://ledge.ai/articles/video2game_realtime_interactive</link><description>:::small
画像の出典：{target=“_blank”}
:::

イリノイ大学などの研究グループは2024年4月15日、新しいAI技術「Video2Game」を{target=“_blank”}した。

この技術は、動画を基にリアルタイムでインタラクティブな3D環境を自動生成するシステムである。主要な技術コンポーネントは、Neural Radiance Fields（NeRF）、メッシュモジュール、物理モジュールの3つから成る。

NeRFモジュールはシーンの幾何学と視覚的外観を捉え、リアルなビジュアルを生成する。メッシュモジュールは、NeRFから得られる情報を基に高速なレンダリングを実現し、物理モジュールはオブジェクト間の物理的相互作用をモデル化する。これらの技術を統合することで、実世界のデジタル複製としてのインタラクティブな3D環境が構築されるという。

!
:::small
画像の出典：{target=“_blank”}
:::

このシステムは屋内外の多様なシーンに適用可能で、リアルタイムで高品質な3Dレンダリングを実現する。また、開発の複雑さとコストを削減しながら、教育、都市計画、災害対応トレーニングなど幅広い分野での利用が期待できるという。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 04 May 2024 16:01:24 +0000</pubDate></item><item><title>オルツが数兆パラメータ規模の大規模言語モデル構築に着手</title><link>https://ledge.ai/articles/alts_begins_building_llm_with_trillions_of_parameters</link><description>:::small
画像の出典：[オルツ](https://alt.ai/news/news-2710/{target=“_blank”}
:::

オルツは2024年4月26日、数兆パラメータ超規模の大規模言語モデル（LLM）の開発に着手したことを{target=“_blank”}した。同社の約10年間にわたる自然言語処理を含むAI技術の研究開発の集大成であり、ビジネスシーンや日常生活における実用的な応用を目指しているという。

オルツは、高いパフォーマンスを実現しつつも、スピードとコストの効率を重視したモデル開発を進めている。開発される言語モデルは、エンドユーザーが直面する具体的な問題解決を念頭に置いた設計が施されており、実運用時の計算効率とコストパフォーマンスに優れていることが求められる。

オルツの新LLMは、特に日本語処理の精度向上に特化しており、既存のモデルを超える使いやすさとカスタマイズ性の実現を目標にしているという。これには、高品質な学習データの確保と効率的なデータ管理が重要となり、エネルギー消費の観点からも、データセンターの地理的分散化やエッジコンピューティングの利用が進められている。

### 技術革新に向けた多角的アプローチ
オルツは、LLM開発を通じて以下のような技術革新を推進しているという
- 学習データの大規模構築
- インストラクションデータの構築と自動化
- プロンプトエンジニアリングの自動化
- 既存モデルの改良を可能にする生涯学習の研究加速
- 軽量モデルによる大規模モデル同様の出力再現の研究加速
- LLM特化チップ（TPU, LPU, NPU）の研究開発

この取り組みを通じ、国内外のパートナーとの連携を積極的に推進し、グローバル市場での競争力を高めるとともに、日本発の技術革新を世界に示していく意向だという。



:::box

:::
:::box

:::
</description><pubDate>Sun, 28 Apr 2024 12:36:32 +0000</pubDate></item><item><title>Microsoftのトーキングヘッド生成AI「VASA-1」　1枚の静止画と音声データで、その人物があたかも喋っているような動画を生成</title><link>https://ledge.ai/articles/microsoft_vasa-1</link><description>:::small
画像の出典：{target=“_blank”}
:::

Microsoft Research Asia は2024年4月16日、AIモデル「VASA-1」が、1枚の静止画と音声データから、その人が話しているかのような動画をリアルタイムで生成する技術を{target=“_blank”}した。

VASA-1は、単一の画像と音声クリップを用いて、話している人物のリップシンクや表情、頭の動きを含むリアルなビデオを作成可能だ。

このAIは、特にリアルタイムアプリケーションにおいてその能力を発揮する。オンラインモードでは、512x512の解像度で最大40fpsのフレームレートを達成し、170ミリ秒の極めて低い遅延で動作する。また、オフラインバッチ処理モードではさらに高速で45fpsを実現するという。

VASA-1は、表情の細かいニュアンスや自然な頭の動きを捉えることができ、話者の感情や意図をよりリアルに伝えるという。さらに、このモデルは外見、3D頭部ポーズ、顔の動きを分離して扱え、高度なカスタマイズを可能にする。

### Controllability of generation
視線の方向、頭の距離、感情オフセットなどのオプションの信号を条件入力した例

!
:::small
画像の出典：{target=“_blank”}
:::

### Out-of-distribution generalization
学習分布から外れた写真や音声入力を扱う能力を示す例（芸術的な写真、歌声、英語以外の音声）データはトレーニングセットには存在しないという
!
:::small
画像の出典：{target=“_blank”}
:::

Microsoftは、この技術が誤用されることを防ぐため、製品化やAPIのリリースは行わず、研究デモンストレーションに留める方針だ。この技術の責任ある使用を確実にするため、適切な規制が整うまでオンラインデモや関連する実装の詳細を公開しないと明示している。


:::box

:::
:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:45:53 +0000</pubDate></item><item><title>岸田首相、生成AIの国際的枠組み「広島AIプロセス・フレンズグループ」設立を発表　パリOECD会合にて</title><link>https://ledge.ai/articles/hiroshimaaiprocess_friends_group</link><description>:::small
画像の出典：{target=“_blank”}
:::

岸田文雄首相は2024年5月2日、パリで行われたOECDの会合で、AIの安全な利用を目的とした「広島AIプロセス・フレンズグループ」の設立を{target=“_blank”}した。この発表で、49カ国・地域がこの新しい枠組みに参加する予定であることが{target=“_blank”}。この国際的な取り組みは、自由や民主主義などの共通の価値を有する国々が生成AIの国際ルール作りにおける主導権を握ることを目指しているとのこと。

広島AIプロセスは、偽情報の拡散抑止や生成AIが作り出したコンテンツの識別を容易にするための「電子透かし」技術の推進など、安全性と信頼性を高める技術開発を含む具体的な対応を各国に促すものだ。岸田首相は、「偽情報のリスクといったAIの影の側面と戦いつつ、その革新的な可能性を最大化するためには、国際的なガバナンスの形成が急務である」と述べている​​。

さらに、岸田首相は「AIに関するグローバルパートナーシップ」（GPAI）の東京における新拠点設立の方針も発表した。この組織は、AIの責任ある使用を推進し、専門家による技術実証を支援することを目的としている​。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 03 May 2024 04:47:10 +0000</pubDate></item><item><title>生成AIの児童安全安全対策強化へのコミットメント：主要AIテック企業が連携「子供の安全を優先すると確約」</title><link>https://ledge.ai/articles/thorn_generative_ai_principle</link><description>:::small
画像の出典：[THORN](https://www.thorn.org/blog/generative-ai-principles/{target=“_blank”}
:::

ThornとAll Tech Is Humanは、Amazon、Anthropic、Civitai、Google、Meta、Metaphysic、Microsoft、Mistral AI、OpenAI、Stability AIといった世界の主要なAI企業と協力し、児童の安全を保護するための「Safety by Design」原則に公式にコミットしたと{target=“_blank”}した。AI企業が、AI技術の開発、展開、および維持の各段階で子供の安全を優先することの確約である。

これらの原則は、AIによって生成される児童性的虐待素材（AIG-CSAM）およびその他の性的被害を防ぐことを目的としている。

公開された「生成AIによる安全設計：児童性的虐待の防止」の新しい報告書には、これらの原則が詳述されており、AI開発者、プロバイダー、データホスティングプラットフォーム、ソーシャルプラットフォーム、検索エンジンがこれらの原則を実施するための具体的な対策と戦略が定義されている。同報告書は、Thorn、All Tech Is Human、および参加企業の一部が共同で執筆した。

各社は、これらの原則に基づいて進行状況を透明に公表し共有することにも合意している。ジェネレーティブAI技術および製品に「Safety by Design」原則を統合することにより、これらの企業は子供たちを保護するだけでなく、倫理的なAI革新をリードしている。

生成AIの誤用は、すでに児童性的虐待の増加を加速している。技術の進展により、加害者は以前にも増して簡単に大量の内容を生成する能力を持ち、新たな虐待素材を創出したり、無害な子供の画像を性的な内容に変えたり、完全にAIで生成されたCSAMを作成することが可能となる。


**AIを使用して画像を歪める例**
!
:::small
画像の出典：[THORN](https://www.thorn.org/blog/generative-ai-principles/{target=“_blank”}
:::


開発からデプロイメント、メンテナンスに至るまで、これらの企業はジェネレーティブAIモデルが児童の安全リスクに積極的に対処するよう努めるとともに、トレーニングデータセットの適切な管理、フィードバックループと反復的なストレステスト戦略の導入、コンテンツの出典確認を重視することで、CSAMとCSEMの生成を防ぐための対策を実施するとした。


:::box

:::
</description><pubDate>Fri, 26 Apr 2024 13:12:36 +0000</pubDate></item><item><title>経済産業省 &amp; 総務省、AI事業者向けガイドラインを公表 ― 安全性、透明性、公平性ほか10の指針</title><link>https://ledge.ai/articles/government_released_guidelines_for_ai_providers</link><description>:::small
画像の出典：{target=“_blank”}
:::
2024年4月19日、政府はAI事業者向けの新たな指針「AI事業者ガイドライン（第1.0版）」を{target=“_blank”}した。

この指針は2023年5月、東京大学の松尾豊教授が座長を務めるAI戦略会議で取りまとめられた「AIに関する暫定的な論点整理」において示された、既存のガイドラインに関して必要な改訂などを検討する必要性を受けてのことだという。

このガイドラインは、AIに関わる企業のためのもので、AIの安全性、透明性、公平性をはじめとする10項目を強調しており、AI技術の適切な利用と社会的な課題への対応を目的とし、国内外のAI技術の進展とそれに伴うリスク管理を背景に公開された。

具体的には、「AI開発者」「提供者」「利用者」を対象に、リスクベースのアプローチによる自主的な取り組みが求められる。政府は、これらの指針を通じて、AI技術の健全な発展と産業競争力の強化を図ることを期待している。

### 「AI事業者ガイドライン」で明らかにされた10の指針
| 指針                   | 内容 |
|----------------------|-----------------------------------------------------------|
| 1. 人間中心のアプローチ | AIは人権を尊重し、人間の尊厳と自律を守るよう設計・運用される |
| 2. 安全性             | 人の生命や健康を損なわないよう、安全に設計されたAIの利用 |
| 3. 公平性             | 不公平な偏見や差別を含まないよう努力する |
| 4. プライバシー保護   | 個人情報は保護され、プライバシーを尊重する形でAIが利用される |
| 5. セキュリティの確保 | AIシステムは不正アクセスやデータ漏洩から守られる |
| 6. 透明性             | AIの判断プロセスが透明であり、誰にでも理解可能 |
| 7. アカウンタビリティ | AIの操作とその結果に責任を持ち、説明責任を果たす |
| 8. 教育とリテラシー   | AIの適切な理解と使用に必要な知識やスキルの提供 |
| 9. 公正な競争の促進   | AIを利用したビジネスが公正な環境で行われる |
| 10. イノベーションの推進 | 社会全体のイノベーションをAIを通じて促進する |


ガイドライン内容には、AIシステムのライフサイクル全体にわたるガバナンス強化が含まれており、実践のための指南も提供されている。たとえば、AI開発者には倫理的なモデル設計が、AI提供者には透明性と利用者の支援が、AI利用者にはデータの入力とシステムの適切な活用が求められる。

また、別添資料では、AIによる便益やリスクの具体例、AIガバナンスの構築、各種AIシステムサービスの詳細で分かりやすい解説が掲載されている。


**ガイドラインの構成**
!
:::small
画像の出典：{target=“_blank”}
:::

この取り組みは、法的拘束力は持たないが、業界に対する自主規制としての役割を果たすことが期待されている。政府は、技術の進化や国際的な動向に応じて、ガイドラインの内容を更新していく方針を明らかにしている。

ガイドラインの全文は、経済産業省のウェブサイトで{target=“_blank”}されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 22 Apr 2024 12:47:54 +0000</pubDate></item><item><title>文化庁「AIと著作権に関する考え方について」個人から寄せられた1000ページ超のパブコメ公開</title><link>https://ledge.ai/articles/bunka_cho_released_public_comments_on_ai_and_copyright</link><description>:::small
画像の出典：{target=“_blank”}
:::

文化庁は、2024年4月16日までに、生成AIと著作権に関する考え方をまとめた資料「AIと著作権に関する考え方（素案）」に対するパブリックコメント（パブコメ）の結果を部分的に{target=“_blank”}した。

このパブコメは、2024年1月23日から2月12日にかけて{target=“_blank”}しており、応募総数は2万4938件に達した。今回公開されたのは個人から寄せられた意見の一部で、1089ページにわたる内容（前回は1129ページ）となった。公開された意見には必要なマスキング処理が施されており、法人・団体からの意見については既に別途公開済み。

「AI と著作権に関する考え方について（素案）」のパブリックコメントの結果について（個人）
・{target=“_blank”}
・{target=“_blank”}

これらの意見を受け同庁は、有識者の意見を含めた最終版の資料「{target=“_blank”}」を3月15日に公開。概要が4月15日に{target=“_blank”}されている。

この資料では、AIが生成するコンテンツの著作物性、非享受目的の利用の具体的な例外、著作権侵害が発生した際の対応策などが詳細に定められており、AI技術の進展に伴う著作権法の適用がより明確化されている。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sun, 21 Apr 2024 06:33:59 +0000</pubDate></item><item><title>自民党「キャッチコピーはAIが提案」新ポスター発表記者会見で「自民党AI」を披露　複数モデルを選択でき、API連携で利用</title><link>https://ledge.ai/articles/jiminto_ai_made_cach-copies</link><description>:::small
画像の出典：{target=“_blank”}
:::

自民党は2024年4月15日、新たな政治活動用ポスターを{target=“_blank”}した。

ポスターのキャッチコピー「経済再生 実感をあなたに。」の発案・選定や、デザイン制作に「自民党AI」が用いられたという。このAIは、過去3年間の党政策パンフレットや岸田文雄首相の演説データを基に、500案以上のフレーズを生成し候補を絞り込んだ。最終的には、岸田首相含む人間たちの目で評価し、コピーが確定したという。AIを活用することで「より多くの国民に政策の成果を実感してもらえるよう工夫した」とのこと。

さらに、このポスターのビジュアルには、AIが生成した複数のデザイン要素が採用されており、従来の政治広報とは一線を画する新しい試みだという。

!
:::small
画像の出典：{target=“_blank”}
:::

この日、党の広報本部長である平井卓也氏は、スピーチ作成や政策立案への活用などに用いられるとして1月に各メディアが{target=“_blank”}自民党AIを、記者会見の場で公開した。最も特徴的なのは、AIモデルを１つに限定することなく、ユーザーが異なるモデルから最適なものを選択し、APIと連携して利用できるインターフェースであると述べた。

!
:::small
画像の出典：{target=“_blank”}
:::

記者からの「ポスターのキャッチコピー作成時のプロンプトはどのようなものか？」という質問に平井氏は、もともと自民党AIには「キャッチコピー案作成」というアシスト機能が付与されており、ポスターに限らずプロジェクトに最適なコピーを生成すると回答した。このたびの「経済再生」というテーマをポスター作成の主軸に置こうと判断したのはあくまで「人間」であると強調。

平井氏はまた、生成AIはプロンプトの良し悪しでその生成結果が大きく左右されることも多い。そのAIの機能を最大限引き出せるようなプロンプトを誰でも簡単に出せるようなアシスト機能を目指すとした。

今のところ、党の広報だけが、限定的に自民党AIを取り扱うことができるという。学習についての権限も同様とのこと。今後、広報の立場を越えて使う場合のAIガバナンスについては、引き続き検討しながら、開発を続けていきたいと述べた。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 19 Apr 2024 03:34:03 +0000</pubDate></item><item><title>Microsoft「米国大統領選が標的に」最新の脅威報告で、中国のAI操作による選挙介入を警告　韓国、インドの選挙にも同様の警告</title><link>https://ledge.ai/articles/microsoft_threat_intelligence_warned_chinese_ai_io</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月4日、Microsoftの脅威分析センターは、中国がAIを利用したサイバー攻撃および情報操作を強化していると{target=“_blank”}した。同社は、特に中国がAIを活用してアメリカ、韓国、インドの選挙に影響を与えようとするだろうと指摘している。

このレポートでは、2024年1月に行われた台湾の総統選挙で、中国がAI生成のオーディオやビデオを用いた介入がすでに行われていたことが示唆されている。

台湾での選挙介入では、AIが生成したコンテンツが政治的なメッセージを強化し、特定の候補者を支持するかのような偽の情報が流された。この活動は、Microsoftの{target="_blank"}で初めて明らかにされ、以降その手法はさらに洗練されているという。

**台湾選挙におけるAIの影響**
!
:::small
画像の出典：{target=“_blank”}
:::

上図で紹介されている「Storm-1376」の活動は、前回の脅威レポート以降に活発化しているという。Storm-1376は、中国共産党（CCP）に関連する情報操作グループで、特に台湾の政治家や中国の反体制派を標的に、AIを活用した情報操作を行っているとのこと。このグループはAI生成のニュースアンカーやミームを用いて、視聴者を欺くキャンペーンを展開しており、台湾だけでなく、アメリカや韓国など他の国々でも同様の活動が行われていることが報告されている。

これらのキャンペーンはいくつかの重要な進化を遂げている。視聴者を欺くためにAIが生成した写真を取り入れたり、陰謀論的なコンテンツ（特に米国政府に対するもの）を煽ったり、ローカライズされたコンテンツで韓国などの新たな人口をターゲットにしたりしているとのことだ。


中国はさらに、南太平洋諸島や南シナ海地域、米国防産業基地に対するサイバー攻撃を行っており、これらの攻撃は政治的および経済的な利益を追求するものだという。

同社は、AIを活用した情報操作が、選挙期間以外にも国際的な緊張を引き起こす潜在的なリスクを持つと報告している。


:::box

:::
:::box

:::
</description><pubDate>Thu, 18 Apr 2024 06:32:36 +0000</pubDate></item><item><title>東京都、AIを活用した建物被害判定支援ツールを開発　災害時の罹災証明を迅速化</title><link>https://ledge.ai/articles/metro_tokyo_ai-based_building_damage_assessment_support_tool</link><description>:::small
画像の出典：{target=“_blank”}
:::

東京都知事小池百合子氏は、2024年3月29日の知事記者会見を通じ、AI技術を活用した建物の被害状況を判定する支援ツールの開発を{target=“_blank”}した。

このツールは、特に災害時の建物損傷を評価するために設計されており、住家被害認定の精度向上とプロセスの効率化を目指す。

会見内容によると、このAI支援ツールは、住家の外壁を撮影し、損傷箇所を自動で検出する機能を持ち、得られた画像データはAIによって解析され、損傷の程度を示すことで調査員が被害認定の参考にすることができるという。

被害判定の基準は非常に複雑であり、現行の方法では認定作業に多大な時間と専門知識が求められる。この新しいツールにより、判定のばらつきを抑え、迅速かつ公平な認定が可能になると知事は述べた。

さらに、東京都は国に対しても住家被害判定方法の簡略化やAI技術の積極的な活用を促している。知事は、「いつ起こるかもしれない首都直下地震への備えとして、このAIツールの開発は極めて重要」と強調。技術の進化と共に、精度を高めるためのデータ蓄積も進める方針を示した。

このツールの具体的な使用例として、記者会見中には、破損した建物の画像がスライドで示され、AIがどのように損傷を検出し学習していくかが説明された。今後、このツールは東京都内外の災害対応の現場で広く利用される予定とのことだ。

会見後の担当者からの説明によると、このAI支援ツールは、木造モルタル住宅の壁面を撮影する際に特に有効で、画像一枚あたり数秒で損傷程度を判定できる速度が特徴だという。しかし、AIの誤認識も報告されており、垂れ下がった電線を壁のひび割れと誤認するケースもあるため、技術の更なる精練が求められている。東京都はAI技術の進展とともに、これらの課題を克服し、より信頼性の高いツールを提供する目標を掲げている。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 17 Apr 2024 06:39:03 +0000</pubDate></item><item><title>イスラエル国防軍、AI標的システム「ラベンダー」を使用してガザのターゲットを特定</title><link>https://ledge.ai/articles/lavender_ai_israeli_army_gaza</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

イスラエル国防軍（IDF）が「Lavender（ラベンダー）」と呼ばれるAI標的システムを利用して、ガザ地区の攻撃ターゲットを特定している事実が2024年4月3日の{target=“_blank”}をはじめ、複数の報道により明らかにされた。

このシステムは、ガザ地区に居住する約230万人のデータを分析し、ハマスまたはパレスチナ・イスラム聖戦（PIJ）の活動家である可能性を数値で評価し、特定の個人を自動的に暗殺対象としてリストアップしているという。

ラベンダーは、ハマス関連の活動家やその関連地点を特定するために開発され、37,000人以上の個人を「キルリスト」に含めるほどの大規模な監視と分析を行っている。このシステムによるリストは、個々の詳細な検証を経ずに作成され、実際の攻撃命令として採用されている。報告によると、このリストに基づく攻撃では、低ランクのハマス活動家であっても、その居住する家族を含む民間人の死亡を多数許容しているとのこと。

IDFはこれらの報道に対して、ラベンダーが単なる情報集約と分析のツールであり、最終的な攻撃決定には人間が介入して個々の事案を評価していると反論しているが、実際の操作においてはほとんどが自動化されているとの証言が相次いでいるという。

AI技術を利用して、ターゲットの選定や攻撃の実行など特定の軍事的決定を人間の関与なしに自律的に行うことができ、致死性を有する「完全自律型兵器」に関して、{target=“_blank”}は2023年12月に、自律型致死兵器システム（LAWS）自律型兵器システムに関する国際的な合意に基づく規則と制限への支持を表明。新たな決議案を日本や米国など152カ国の賛成で採択している。中国や北朝鮮はじめ、イスラエルなど11か国が棄権した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 15 Apr 2024 01:27:37 +0000</pubDate></item><item><title>米ワシントン州、銃撃事件の裁判「AIで強化した動画は証拠として認めない」高等裁判所の裁定</title><link>https://ledge.ai/articles/judge_blocks_ai_enhanced_video</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

ワシントン州の裁判所が「AI技術を使用して強化されたビデオを法廷での証拠として使用することを禁じる」という初めての裁定を下した。2024年4月3日に現地の各メディアが報じたこの判決は、キング郡高等裁判所の裁判官、リロイ・マッカロー判事によって出された。事件は、2021年にシアトル近郊のバーの外で起きた銃撃事件に関連しており、被告のジョシュア・プロカは3人の命を奪い、2人を負傷させたとされている。

プロカ被告の弁護団は、携帯電話の映像をAIで強化して明確化し、裁判での証拠として提出しようと試みた。しかし、この強化されたビデオは元の映像にないデータを加えたり、削除したりしており、実際の出来事を正確に反映していると証明する方法がないため、問題が発生した。さらに、AIの使用によって映像が「視覚的には魅力的に見えるが、実際のシーンを正確に表していない」という懸念が専門家から提起された​という。

マッカロー判事は、AI技術が「AIが示すべきだと考える」内容を不透明な方法で表現するため、その証拠を採用することは陪審員を混乱させ、証言の信頼性を損なう恐れがあると述べた。この決定は、AIの法廷での扱いについての重要な前例となり、今後の類似の裁判において参考とされる可能性が高い。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 13 Apr 2024 13:15:16 +0000</pubDate></item><item><title>佐川急便など、レベル3.5飛行による東京都が推進するドローン宅配便配送プロジェクトを実施</title><link>https://ledge.ai/articles/sagawa_drone_parcel_delivery_project_by_tokyo</link><description>:::small
画像の出典：{target=“_blank”}
:::

佐川急便は2024年3月29日、イームズロボティクス、日本気象協会、サンドラッグと共に、山間地域の利便性向上に向けたドローンレベル3.5飛行による宅配便配送の実証実験を東京都青梅市において実施したことを{target=“_blank”}した。

四者は東京都が推進する「ドローン物流サービス社会実装促進事業」の支援対象として2022年7月28日に選定され、以降共同でプロジェクトを進めている。ドローンによる配送サービスの社会実装を目指し、山間地域での生活利便性の向上と持続可能な配送システムの構築が目的だという。

プロジェクトでは、国土交通省により2023年12月に制度化されたドローンレベル3.5飛行を利用し、宅配便配送の実証実験を行った。青梅市の山間地域で、ドローンから受取人が直接荷物を受け取る運用や、災害時の救援物資輸送を想定した配送実験が実施された。

!
:::small
画像の出典：{target=“_blank”}
:::

実証実験は2024年2月26日から3月8日にかけて平日10日間の予定で行われ、天候の影響を受けたものの、5日間は実施可能であった。期間中、イームズロボティクス社製のLAB6150を使用し、1日最大3往復6フライトを実施した。このドローンは、最大ペイロードが10kgであり、大きな荷物の輸送も可能である。

東京都内で初めて実施されたこのレベルのドローン飛行による宅配便配送実験では、地域住民からの高い関心と支持を得た。実際にドローンから荷物を受け取った住民を対象にしたアンケートでは、96％の人が今後もドローン配送を利用したいと回答しており、その有効性が示されたという。


:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Apr 2024 10:04:47 +0000</pubDate></item><item><title>大阪市、全庁で生成AIの業務活用を開始 — 効率化と品質向上を目指す</title><link>https://ledge.ai/articles/osaka_city_begins_using_genai</link><description>:::small
画像の出典：{target=“_blank”}
:::

大阪市は2024年4月1日、生成AIの全庁業務活用を{target=“_blank”}した。

大阪市はこれまで、民間事業者との共同検証や試行利用を通じ、生成AIの本格利用に向けた検討と取り組みを進めてきた。このたび、ガイドラインの策定と安全な利用環境の整備を経て、生成AIを業務に活用することで業務の効率化と品質の向上を図るという。

生成AIの利用は、大阪市全職員（水道局及び学校園を除く）を対象に、4月1日より開始する。利用内容には、文章の要約・作成・添削、企画案のたたき台作成、翻訳などを含む。ただし、市民や事業者への直接的な行政サービス提供には使用しない。

議事録や膨大な資料の内容把握、文章の練り直しや誤字脱字の確認に要していた時間の短縮、ゼロからの企画案作成の労力軽減、外国人へのより伝わりやすい翻訳の提供といった業務効率化と品質向上が期待されるという。

利用環境は、Microsoft社の「Azure OpenAI Service」を基にした本市独自の環境で、利用者の入力データは保存されず、生成AIの学習データとしても再利用されない。また、様々なリスクへの対応として「大阪市生成AI利用ガイドライン」に則り利用されるとのこと。

:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Mon, 08 Apr 2024 09:51:03 +0000</pubDate></item><item><title>米バイデン政権　連邦政府機関のAI利用の包括的指針を発表　AI利用のリスクから国民を保護する措置を義務付け</title><link>https://ledge.ai/articles/omb_policy_in_federal_agencies_use_of_ai</link><description>:::small
画像の出典：DALL-E3によりLedge.aiが生成
:::

米国行政管理予算局（OMB）は2024年3月28日、連邦政府機関がAIを利用する際に、リスクを緩和し、その利益を最大化することを目的とした指針を示す文書を[発表](https://www.whitehouse.gov/briefing-room/statements-releases/2024/03/28/fact-sheet-vice-president-harris-announces-omb-policy-to-advance-governance-innovation-and-risk-management-in-federal-agencies-use-of-artificial-intelligence/
){target=“_blank”}した。この指標は、2023年10月にバイデン大統領が署名した、安全で信頼性あるAI開発管理方針示す{target=“_blank”}に基づくものだ。

この指針文書では、特にリスク管理、透明性の向上、イノベーションの推進、人材拡充、ガバナンス強化の五つの主要な領域に焦点を当てている。

### ■リスク管理
連邦政府機関が米国民の権利や安全に影響を与える可能性のあるAIを使用する場合、2024年12月1日までに、アルゴリズムによる差別を防ぐなどの具体的なセーフガード措置を講じることを義務付けた。これには、空港の顔認証システムや連邦政府系病院の診断システムが含まれる。これらの保護措置を適用できない場合、AIシステムの使用を原則中止するとのこと。

具体的なケースとしては、
・空港で旅行者は、TSAの顔認識の使用からオプトアウトでき、列での位置を失うことなく遅延なく続行できる。
・連邦ヘルスケアシステムでAIが重要な診断決定を支援するために使用される場合、ツールの結果を検証し、医療アクセスの不平等を避けるために人間がプロセスを監視している。
などを挙げた。

### ■透明性の向上
連邦政府機関がAIの使用に関して一層の透明性を確保することが要求されている。公衆の権利や安全に影響を与える使用ケースを特定し、関連するリスクにどのように対処しているかを一覧に含め年次報告する。

### ■イノベーションの推進
気候変動対策、自然災害対応、公衆衛生の向上、公共交通機関の安全性向上など、AIを責任ある形で活用することが奨励されている。

### ■人材拡充
AI専門人材を連邦政府機関全体で新たに100人雇用する計画が立てられており、これには2024年4月のキャリアフェアの開催も含まれる。

### ■ガバナンス強化
各連邦政府機関がAIの使用に関する説明責任、リーダーシップ、監督を担保するために最高AI責任者を配置し、AIの使用を調整・管理するためのAIガバナンス委員会の設置が求められている。


ハリス副大統領は、これらの施策が世界的な行動のモデルになることを目指しており、AIの責任ある開発と利用に向けた国際基準の策定において、米国がリードすることを強調した。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Thu, 04 Apr 2024 01:00:24 +0000</pubDate></item><item><title>アイビスペイント「AI学習妨害機能」追加　イラスト保護のため妨害ノイズ付与し、無断学習からの生成結果を劣化させる</title><link>https://ledge.ai/articles/ibispaint_ai_learning_interference</link><description>:::small
画像の出典：{target=“_blank”}
:::

 株式会社アイビスは2024年5月8日、世界中で3.9億ダウンロードを記録している人気のペイントアプリ「ibisPaint」の最新アップデートを通じて、AI学習妨害機能を導入したことを{target=“_blank”}した。この機能は、ユーザーであるクリエーターの作品が、画像生成AIによって無断で模倣されることを防ぐために設計されている。

画像生成AI技術は、LoRAやDreamBoothなどの追加学習機能を利用し、特定の作風やキャラクターを模倣する能力がある。これにより、オリジナルのイラストが無断で使用され、著作権の侵害が生じる可能性が指摘されている。アイビスはこの問題に対処するため、AI学習妨害機能を開発。イラストにノイズを加えることで、AIが作風を正確に学習できなくなる仕組みを採用している。

!
:::small
画像の出典：{target=“_blank”}
:::

利用者はアプリ内で「画像を保存」選択時に「AI学習妨害」をオンに設定し、ノイズの濃度をスライダーで調整可能。この操作により、画像はAIによる模倣から保護され、出力する画像の品質が劣化することで、追加学習の妨害が可能となるとのこと。

同社は1月に、新たにリリースした「AIお手本機能」をリリース後1日で{target=“_blank”}。「既存のキャラクターが表示された」「アイビスペイントを使って描いたらAIで生成したと思われるのでは」といったユーザーからの反響を受けとめ、実装の中止を決定したという。このたびの「AI学習妨害機能」という同社の施策は、クリエイターの著作権保護に基づく創作活動支援へ舵を切ったと、ユーザーからの反響も大きいという。

なお、この機能は、ibisPaintのプレミアム会員限定で提供され、スマートフォンやタブレット、PC（Windows）版のサブスクリプションユーザーが利用できるとのこと。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 11 May 2024 14:30:50 +0000</pubDate></item><item><title>OpenAI「Sora」が生み出した初の公式ミュージックビデオ公開</title><link>https://ledge.ai/articles/music_video_produced_using_sora</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年5月1日、OpenAIの動画生成AI「Sora」を使って制作された初の公式ミュージックビデオが{target=“_blank”}された。

アーティスト・作家・映画監督として多方面で活躍するPaul Trillo氏と音楽アーティストWashed Out（本名：Ernest Weatherly Greene Jr.）がコラボレーションし、OpenAIのAIモデル「Sora」を使用して制作された。

ビデオの特徴は、連続するズームショットを駆使して視覚的な錯覚を生み出すという斬新な手法により、視聴者を引き込む内容となっている​。Soraは、ユーザーのプロンプトに応じて最大1分間のビデオを生成する。Trillo氏は自身のSNSで、「Soraで生成した55個のクリップをAdobe Premiereで編集した」とファンに説明している。

@


Trillo氏によれば、このミュージックビデオは、愛する人を失った後の記憶と向き合い、それを手放すことの難しさを描いているという。現実の歪んだ鏡である記憶に対して、Soraの「夢のロジック」を利用して、実際には存在しない記憶を探求するアプローチを取り入れたとのこと。

!
:::small
画像の出典：{target=“_blank”}
:::

ビデオは、現実とAIが創出するシュールな特性の微妙な違いを探るものとなっている。奇妙なディテールと、夢の中のような動きのロジックを通じて、歪んだ記憶の本質をより良く表現することを目指している。

このミュージックビデオは、Soraの技術がどのようにしてクリエイティブな表現に革新をもたらすかを示す事例となり、AIとアーティストとの協働による新たな可能性を提示するものとなっている。

Trillo氏は、未公開のAI「Sora」への初期アクセスを許されたアーティストで、これを用いた作品「Abstract」は、3月にOpenAIのブログでも紹介されているほか、TEDの40周年を記念する「TED2024」に寄せて40年後のTEDの姿をSoraを使って描く{target=“_blank”}の制作に関わった。

ミュージックビデオ「The Hardest Part」は、6月28日にリリース予定のWashed Outの新アルバム「Notes From a Quiet Life」に収録されている。


:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Wed, 08 May 2024 10:31:28 +0000</pubDate></item><item><title>正規のルートで日本のマンガを世界へ輸出　AIマンガ翻訳のオレンジが小学館などから29.2億円の資金調達を実施</title><link>https://ledge.ai/articles/orange_raises_jpy2-9b</link><description>:::small
画像の出典：{target=“_blank”}
:::

株式会社オレンジは2024年5月7日、プレシリーズAラウンドで総額29.2億円の資金調達を実施したことを{target=“_blank”}した。

リード投資家であるグロービス・キャピタル・パートナーズをはじめ、小学館、ANRI、SBIインベストメントなど、複数のベンチャーキャピタルおよび事業会社が出資に名を連ねている。

オレンジは、AIを活用した翻訳技術により、日本のマンガを外国語に翻訳し、世界各国での合法的な流通を支援することを目指している。同社は、未翻訳のマンガを大規模に海外展開するための「マンガに特化したローカライズ支援ツール」の開発を進めており、今回の資金はその拡張に充てられる。これにより、月間500冊という日本の現状の英訳ペースを大幅に上回るスピードでの翻訳が可能になるとしている。

!
:::small
画像の出典：{target=“_blank”}
:::

2024年夏には、米国法人を通じて新たな電子マンガストア「emaqi」をローンチする計画もあり、翻訳された作品を直接消費者に提供することで、海賊版による被害の防止にも寄与するという。

同社代表取締役の宇垣承宏代氏は「日本のマンガは、世界中で愛されている。しかし、言語の壁が大きな障壁となっており、非合法なコピーが横行しているのが現状だ。私たちの技術が、その問題を解決する一助となれば」と語る。

投資家の1人、グロービス・キャピタル・パートナーズの磯田将太氏は、「マンガは日本のソフトパワーの土台です。オレンジのミッションには、出版社をはじめとする業界関係者が大きな共感を寄せています」とコメントしている。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 07 May 2024 15:03:18 +0000</pubDate></item><item><title>1ヶ月期間限定！本が好きな人必見　「AI書店員ダ・ヴィンチさん」があなたにぴったりの本を診断</title><link>https://ledge.ai/articles/ai_davinci</link><description>:::small
画像の出典：{target=“_blank”}
:::

4月26日、株式会社KADOKAWAは生成AIを活用した体験型コンテンツ「AI書店員ダ・ヴィンチさん」を全国5店舗で展開することを{target=“_blank”}した。

「AI書店員ダ・ヴィンチさん」から投げかけられる質問に回答していくと、自社の書籍から質問者に合ったタイトルを自動で診断してくれるコンテンツ。AI技術を駆使し、購入履歴の傾向から判断するのではなく、質問者の回答に基づいた「今のあなたにおすすめ」のタイトルを提案してくれるという面白いサービスだ。回答内容に応じて「なぜこの本がおすすめなのか」などコメントもその場で生成される。

もともと読書が好きな人はもちろん、何を選んだら良いか分からない、普段とは違う新しいジャンルに挑戦したいなど、本を読みたい気持ちがあれば誰でも有効に活用できる。

5月26日までの期間限定サービスのため新しい本に出会いたい人はこの機会をお見逃しなく。

:::box
【展開店舗は下記の5店舗】
・蔦屋書店 イオンタウン仙台泉大沢店（宮城県）
・丸善 日本橋店（東京都）
・有隣堂 横浜駅西口店（神奈川県）
・大垣書店 イオンモールKYOTO店（京都府）
・紀伊國屋書店 天王寺ミオ店（大阪府）
:::

:::box

:::

:::box

:::
</description><pubDate>Thu, 02 May 2024 10:04:57 +0000</pubDate></item><item><title>AI Picasso　商用利用可能なAIアート生成ツール「Emi 2」を無償公開　クリエイター尊重するAI開発　追加学習に無断転載画像用いず</title><link>https://ledge.ai/articles/ai_picasso_emi-2</link><description>:::small
画像の出典：{target=“_blank”}
:::

AI Picassoは2024年4月26日、AIアートに特化した高品質画像生成ツール「Emi 2」を{target=“_blank”}した。

Emi 2 は商用利用が可能で、追加学習において無断転載画像を用いていない。{target=“_blank”}より無償利用が可能だ。

同モデルは、初代「{target=“_blank”}」と同様、特にイラストやアニメ、マンガ生成に特化して開発され、NVIDIA H100を用いた最先端の開発機材によって支えられている。追加学習に無断転載画像を用いず、Stable Diffusion XL 1.0と同様のライセンスで、ユーザーは安心して商用利用が可能だという。


以下は、2023年10月に公開された第1弾のEmiとの比較画像。Emi 2は全身を描画する際に安定する傾向にあるとのこと。
（左: Emi / 右: Emi 2）
!
:::small
画像の出典：{target=“_blank”}
:::


同社は、クリエイターとの協力を重視しており、データの提供に対して適切な報酬を設定し、利益分配の仕組みを導入している。特に、「AIいらすとや」のプロジェクトは、内閣府の報告会においてクリエイターへの還元事例として紹介された。

!
:::small
画像の出典：{target=“_blank”}
:::

同社は、Emi 2がEmiと同様、クリエイターたちの声を聞きながら作られたと語る。Emiだけではなく、同社はXやDiscord上などで、他のモデルを含めたモデルのあり方について、クリエイターたちと対話を続けながら、信頼関係を築いていくと述べた。


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 30 Apr 2024 01:46:37 +0000</pubDate></item><item><title>AI翻訳で世界中のマンガファンと語り合える！集英社が1か月期間限定でマンガコミュニティサイト「MANGA Plus Universe by SHUEISHA」を公開中</title><link>https://ledge.ai/articles/mangaplusuniverse_byshueisha</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月12日、株式会社集英社は株式会社アルと共同でマンガコミュニティサイト「MANGA Plus Universe by SHUEISHA」の提供を{target=“_blank”}した。

「MANGA Plus Universe by SHUEISHA」は、集英社が運営するマンガアプリ「少年ジャンプ＋」で配信している人気タイトル15作品について語り合えるコミュニティサイト。日本語だけではなく英語、スペイン語、タイ語、フランス語など9言語に対応しており、翻訳機能とマイクロソフトの生成AIを活用しより自然な会話を楽しむことができる。

!

:::small
画像の出典：{target=“_blank”}
:::

最新話が配信されると様々な国のユーザーの書き込みで賑わい、国内外問わずリアルタイムで世界中のマンガファンと言語の壁を越えて自由に語り合える魅力的なサイトだ。2024年5月13日までの期間限定公開で期間中は無料で利用することができる。

:::box

:::
:::box

:::</description><pubDate>Wed, 24 Apr 2024 08:18:13 +0000</pubDate></item><item><title>40年後のTEDはどんな感じ？OpenAI「Sora」で制作されたTED40周年記念ビデオ
</title><link>https://ledge.ai/articles/ted2024_sora</link><description>:::small
画像の出典：{target=“_blank”}
:::

“What will TED look like in 40 years? “ 「TED は 40 年後にはどのようになっているでしょうか? 」

2024年4月20日、TEDのX（旧Twitter）アカウントを通じ、動画生成AI「Sora」が描く40年後のTEDの姿を描いたビデオが{target=“_blank”}され、このプロジェクトが注目を集めている。

このビデオプロジェクトは、TEDの40周年を記念する「TED2024」に寄せて制作され、未来への期待とクリエイティビティを称える内容が盛り込まれている。TED2024は「The Brave and the Brilliant」というテーマで開催されたカンファレンスで、2024年4月15日から19日までカナダのバンクーバーで開催された。

このビデオは、アーティスト・作家・映画監督として多方面で活躍するPaul Trillo氏とOpenAIが協力し、話題の動画生成モデル「Sora」を用いて、40年後のTEDの姿を描いたビデオを制作。TEDのロゴを除く全てがAIによって生成され、未来の可能性を映像化しているという。

Paul Trillo氏は、未公開のAI「Sora」への初期アクセスを許されたアーティストで、これを用いた作品「{target=“_blank”}」は、3月にOpenAIのブログでも紹介されている。

!
:::small
画像の出典：{target=“_blank”}
:::


40年後のTEDを描くSoraのビデオは、近日中に{target=“_blank”}で公開されるとのことだ。



:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Tue, 23 Apr 2024 07:06:45 +0000</pubDate></item><item><title>自動作曲ができる音楽生成AI「Udio」パブリックベータ版公開　誰でも無料で月1200曲まで高品質な楽曲を生成できる</title><link>https://ledge.ai/articles/udio_publicbeta</link><description>:::small
画像の出典：{target=“_blank”}
:::

2024年4月10日、元 Google DeepMindの研究者チームが設立したAIベンチャーUdioが、誰でも高品質な音楽を自動作曲できる音楽生成AI「Udio」のパブリックベータ版を{target=“_blank”}した。

Udioはテキストプロンプトを使用し希望するジャンルや曲のテイスト、歌詞を指定することで音楽を生成することができる。合成音声によるボーカルパート挿入にも対応しており、本格的な曲作りを体験することができるという。

!
:::small
画像の出典：{target=“_blank”}
:::

UdioのX（旧Twitter）公式アカウントでは実際にUdioで生成したバラードやアップテンポで賑やかなサウンドなど様々なジャンルのサンプル楽曲が多く掲載されている。現時点ではベータ版ということもあり無料で利用できるのも魅力のひとつ。１ヶ月に最大1200曲生成できるため納得いくまで音楽生成を楽しむことができる。

:::box

:::
:::box

:::</description><pubDate>Fri, 19 Apr 2024 06:55:44 +0000</pubDate></item><item><title>賞金総額は20万ドル以上　クリエータープラットフォームFanvueがAI美人コンテスト「Miss AI」開催</title><link>https://ledge.ai/articles/fanvue_miss_ai</link><description>:::small
画像の出典：{target=“_blank”}
:::


2024年4月15日、ソーシャルメディアプラットフォームFanvueは、AIが生成した女性モデルを対象とした美女コンテスト「Miss AI」の開催を{target=“_blank”}した。

Fanvueは、AI生成コンテンツの分野における革新を表彰し、その業績を称えることを目的としている。参加者の美しさだけでなく、テクノロジーの使用と社会的影響力を評価の軸に置くとのこと。

賞金総額は20万ドル以上で、上位 3 人のミス AI 出場者には、優勝者への 5,000 ドルの現金を含む総額 20,000 ドルを超える賞品が授与される。また、優勝者にはメンターシッププログラムやPRサポートなどが提供される​​。

審査員には、AIインフルエンサーのエミリー・ペレグリーニとアイタナ・ロペスが名を連ねている。これらのAIモデルは、インスタグラムで数十万人のフォロワーを持ち、自身が築いたソーシャルメディアでの成功をもとに、コンテストの参加者を審査するという。


**審査員の2人（AI生成のインフルエンサー）左：エミリー・ペレグリーニ／右：アイタナ・ロペス**
!
:::small
画像の出典：{target=“_blank”}
:::

審査は美しさ、技術の使用、社会的影響力の3つの主要カテゴリーで行われ、参加者はそれぞれのカテゴリーで独自性と革新性をどのように発揮しているかを競うという。

!
:::small
画像の出典：{target=“_blank”}
:::

応募資格は18歳以上のAIモデルクリエイターで、使用するAIツールに制限は付けないが、作品は100% AI生成でなければならない。エントリーは無料で、クリエイターは複数のAI生成モデルを持ち込むことが許されている。

このイベントは「World AI Creator Awards (WAICAs)」の一部として開催され、「AIクリエイター経済のオスカー」となることを目指すとのことだ。


:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 20 Apr 2024 08:19:29 +0000</pubDate></item><item><title>200名を超えるアーティストが署名「AIで音楽の価値を下げるな」ビリー・アイリッシュ、ノラ・ジョーンズ、ボン・ジョヴィなど参加の団体が権利保護を呼びかける声明</title><link>https://ledge.ai/articles/200_artists_urge_tech_platforms_stop_devaluing_music</link><description>:::small
画像の出典：{target=“_blank”}
:::

Artist Rights Alliance（ARA）は2024年4月2日、200人以上のアーティストの支持を受けて、AI開発者、テクノロジー企業、プラットフォーム、デジタル音楽サービスに対し、人間のアーティストの権利を侵害し価値を減じるAIの使用を停止するよう呼びかける公開書簡を{target=“_blank”}した。

ビリー・アイリッシュ、ノラ・ジョーンズ、ジョン・ボン・ジョヴィ、ケイティ・ペリー、スティービー・ワンダーなどを含む200名以上の著名アーティストがこの書簡に署名している。書簡では、AIがアーティストの芸術に「現実的な脅威」をもたらすと指摘し、音楽業界におけるAIの非倫理的な使用を非難している。

AIに関連する脅威は、ディープフェイクやボイスクローニングなどが注目を集めているが、この書簡では、AIが人間の音楽作品を無断で利用してAI「コピーキャット」を訓練・製作する行為や、AI「サウンド」を使って印税の負担を薄める行為といった、深刻で無責任な使用例が指摘されている。

ARAのエグゼクティブディレクター、ジェン・ジェイコブセン氏は、音楽ストリーミングサービスの普及によりアーティストが生計を立てることが難しくなっている現状を説明。「AIが生成する『ノイズの洪水』と戦うことは、アーティストとファンの両方にとって、音楽エコシステム全体の価値を下げる」と述べ、AI技術の責任ある使用をテクノロジー企業に呼びかけている。

公開書簡の一部には以下のように記されている。

「誤解なきように言うが、我々は、責任を持って使用された場合、AIが人間の創造性を前進させ、音楽ファンにとって新しく興奮する体験の発展と成長を可能にする莫大な潜在力を持っていると信じている。残念ながら、一部のプラットフォームや開発者が、創造性を破壊し、アーティスト、ソングライター、ミュージシャン、権利保持者を脅かすためにAIを使用している。」

「我々は、プロのアーティストの声や肖像を盗むAIの捕食的な使用、創作者の権利を侵害する行為、音楽エコシステムを破壊する行為に対して保護を求める。すべてのデジタル音楽プラットフォームや音楽サービスに対して、アーティストとソングライターの人間芸術を損なうか置き換えるAI音楽生成技術、コンテンツ、ツールの開発や展開を行わないよう誓約することを求める」と訴えている。

この公開書簡は、音楽におけるAIの責任ある使用について世界中で活発な議論が行われている中で発表された。すでにテネシー州は「公開の権利」を強化するいわゆるELVIS法を制定しており、同法は正式に「Likeness Voice and Image Security Act」と呼ばれている。類似の立法が米国議会および複数の米国州で議論されている。


## 署名したアーティストのリスト
!
:::small
画像の出典：{target=“_blank”}
:::


:::box

:::
:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Fri, 12 Apr 2024 11:40:17 +0000</pubDate></item><item><title>Stability AI　音楽生成AI「Stable Audio 2.0」にバージョンアップ　最大3分間の高品質なフルトラックを生成　Audio-to-Audio機能も</title><link>https://ledge.ai/articles/stable_audio_2-0</link><description>:::small
画像の出典：{target=“_blank”}
:::

Stability AIは2024年4月3日、オーディオ生成AI「Stable Audio 2.0」を{target=“_blank”}した。新しいモデルは、44.1KHzステレオで最大3分間の高品質なフルトラックを生成可能。ユーザーは自然言語のプロンプトを使用してオーディオサンプルをアップロードし、これを様々なサウンドに変換できる。

@



{target=“_blank”}との大きな違いは、特にオーディオからオーディオへの生成機能を導入した点にある。これにより、アーティストやミュージシャンは自らのオーディオサンプルをアップロードし、自然言語によるプロンプトを通じて変換することが可能となった。さらに、このモデルはイントロ、展開、アウトロを含む構造化されたコンポジションを含む楽曲を生成できるという。Stable Audio では45秒だった曲の長さも、2.0になり最長で3分間まで生成できる。

現在、{target=“_blank”}で無料で利用でき、将来的にはStable Audio APIでも利用可能となる。

### Audio-to-Audio Feature Demo
@


1.0モデルと同様、2.0は音楽、効果音、シングルインストゥルメントステムを含む800,000以上のオーディオファイルからなるAudioSparxのデータでトレーニングされている。オプトアウトのリクエストに対応し、クリエイターへの公正な報酬を保証することにも重点を置く。

オーディオアップロードに際しては、著作権侵害を防ぐためにAudible Magicと提携し、そのコンテンツ認識（ACR）技術を利用しているとのこと。


:::box

:::
:::box

:::
:::box

:::
:::box

:::

</description><pubDate>Tue, 09 Apr 2024 14:46:35 +0000</pubDate></item><item><title>OpenAI「Sora」をハリウッドに売り込み中か</title><link>https://ledge.ai/articles/openaii_pitches_sora_to_hollywood</link><description>:::small
画像の出典：Dall-E3により ledge.ai が生成
:::

OpenAIはロサンゼルスの映画スタジオ、メディア幹部、タレントエージェンシーと会合を持ち、エンターテインメント業界でパートナーシップを築こうとしている。関係者によると、映画制作者に同社の動画生成AI「Sora」を作品に組み込むよう奨励していると2024年3月22日に{target=“_blank”}が報じている。

2月下旬にOpenAIは最高執行責任者（COO）のブラッド・ライトキャップ氏を中心に、ハリウッドでの紹介対話を予定しており、同氏は数人の同僚とともに、ユーザーからのテキストプロンプトに基づき、長さ約1分までのリアルな動画を生成できる未発表の新サービス「Sora」の機能を実演したとのこと。その数日後、同社CEOのサム・アルトマン氏が、アカデミー賞の週末にロサンゼルスで開かれたパーティーに出席。OpenAIは、すでにいくつかの有名な俳優や監督にSoraへのアクセスを許可しているという。

既に映画製作者やスタジオではAIが活用されており、新しいツールの有望性の認識も得ている一方で、AIが人々の生活に与える影響に対し懸念を表明する声も存在する。ハリウッドでは2023年、脚本家と俳優がAIの使用に関する保護を求めてストライキに突入し、両組合はAIの使用方法についていくつかのセーフガードを確保した。メディア企業もまた、OpenAIのトレーニングデータに制作物が使用されることを警戒する動きが見られる。

2024年2月に発表されたSoraはまだ研究プレビューの段階で、価格は未定。テキストから動画を生成するサービスは、AIスタートアップのRunwayが先行しているという。業界ではすでに数百万人に利用されており、映画編集者も動画を作成し、視覚効果を作るために利用しているとのこと。



:::box

:::
:::box

:::
:::box

:::
:::box

:::
</description><pubDate>Sat, 06 Apr 2024 12:29:42 +0000</pubDate></item></channel></rss>