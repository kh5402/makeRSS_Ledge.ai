from bs4 import BeautifulSoup
from feedgenerator import Rss201rev2Feed
from datetime import datetime
import asyncio
import json
import re
from pyppeteer import launch

# è¤‡æ•°ã®URLã‚’ãƒªã‚¹ãƒˆã§ç”¨æ„
urls = [
    'https://ledge.ai/categories/business'#,
    #'https://ledge.ai/categories/learning', 
    #'https://ledge.ai/categories/engineering',
    #'https://ledge.ai/categories/academic',
    #'https://ledge.ai/categories/public',
    #'https://ledge.ai/categories/entertainment'
]

async def main():

    print("RSSãƒ•ã‚£ãƒ¼ãƒ‰ç”Ÿæˆã‚’é–‹å§‹ğŸš€")

    # RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®åˆæœŸåŒ–ã¯ãƒ«ãƒ¼ãƒ—ã®å¤–ã§è¡Œã†
    feed = Rss201rev2Feed(
        title="Ledge.ai è¤‡æ•°ã‚«ãƒ†ã‚´ãƒª",
        link="https://ledge.ai",
        description="Ledge.aiã®è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®æœ€æ–°è¨˜äº‹",
        language="ja",
        pretty=True
    )
    
    for getURL in urls:

        base_url = getURL
        page_num = 1  # ãƒšãƒ¼ã‚¸ç•ªå·ã®åˆæœŸå€¤
        
        while some_condition:  # ã“ã®ãƒ«ãƒ¼ãƒ—ã§ãƒšãƒ¼ã‚¸æ•°ã‚’å¢—ã‚„ã—ã¦ã„ã
            getURL = f"{base_url}?page={page_num}"
            print(f"{getURL} ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚ˆğŸŒ")

            # Pyppeteerã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ã
            browser = await launch(
                executablePath='/usr/bin/chromium-browser',
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-accelerated-2d-canvas',
                    '--disable-gpu'
                ],
            )

            print("ãƒ–ãƒ©ã‚¦ã‚¶é–‹ã„ãŸğŸ“‚")

            page = await browser.newPage()
            await page.goto(getURL)
            print("ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ãŸâœˆï¸")

            # ãƒšãƒ¼ã‚¸ã®HTMLã‚’å–å¾—
            html = await page.content()

            # BeautifulSoupã§è§£æ
            soup = BeautifulSoup(html, 'html.parser')

            # window.__NUXT__ã®å†…å®¹ã‚’å–å¾—ã—ã¦JSONãƒ‡ãƒ¼ã‚¿ã‚’Pythonã®è¾æ›¸ã«å¤‰æ›
            nuxt_data = json.loads(await page.evaluate('() => JSON.stringify(window.__NUXT__)'))
            print(f"JSONãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆä¸€éƒ¨ï¼‰ï¼š{str(nuxt_data)[:100]}... ğŸ“¥")  # JSONãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’ãƒ­ã‚°ã«å‡ºåŠ›

            # URLã‹ã‚‰ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™¤ã„ã¦ã‹ã‚‰ã‚¹ãƒ—ãƒªãƒƒãƒˆ
            category_name = getURL.split('/')[-1].split('?')[0]
            print(f"category_name: {category_name}")

            # "data"ã‚­ãƒ¼ã®ä¸­ã«ã‚ã‚‹"articles"ã‚­ãƒ¼ã®"data"ã‚­ãƒ¼ã®å€¤ã‚’å–å¾—
            #articles = nuxt_data["data"][f"/categories/{getURL.split('/')[-2]}"]["articles"]["data"]
            articles = nuxt_data["data"][f"/categories/{category_name}"]["articles"]["data"]

            if not articles:
                print("è­¦å‘Š: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã‚„ã§â—ï¸")  # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã‹ã©ã†ã‹ã‚’ç¢ºèª
            else:
                print(f"å–å¾—ã—ãŸè¨˜äº‹æ•°ï¼š{len(articles)} ğŸ“š")  # å–å¾—ã—ãŸè¨˜äº‹ã®æ•°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›

            # 12å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— â¡ 1ãƒšãƒ¼ã‚¸ã«12å€‹ã®è¨˜äº‹ã‚ã‚‹ã‹ã‚‰ã€‚
            for article in articles[:12]:
                title = article['attributes']['title']
                date_str = article['attributes']['createdAt']
                date_obj = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                date_formatted = date_obj.strftime("%Y/%m/%d %H:%M")
                url = "https://ledge.ai/articles/" + article['attributes']['slug']
                description = re.sub(r'\[.*?\]\(.*?\)', '', article['attributes']['contents'][0]['content'])

                # ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒ•ã‚£ãƒ¼ãƒ‰ã«è¿½åŠ 
                feed.add_item(
                    title=title,
                    link=url,
                    description=description,
                    pubdate=date_obj
                )
            print("RSSãƒ•ã‚£ãƒ¼ãƒ‰ã«ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã—ãŸğŸ“")
            page_num += 1  # ãƒšãƒ¼ã‚¸ç•ªå·ã‚’1ã¤å¢—ã‚„ã™

    # RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—
    with open('feed.xml', 'w') as f:
        feed.write(f, 'utf-8')

    print("è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸğŸ‰")

# éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œ
asyncio.get_event_loop().run_until_complete(main())
